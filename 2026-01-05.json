[
  {
    "id": "http://arxiv.org/abs/2601.02360v1",
    "title": "Heterogeneous Low-Bandwidth Pre-Training of LLMs",
    "summary": "Pre-training large language models (LLMs) increasingly requires distributed compute, yet bandwidth constraints make it difficult to scale beyond well-provisioned datacenters-especially when model parallelism forces frequent, large inter-device communications. We study whether SparseLoCo, a low-communication data parallel method based on infrequent synchronization and sparse pseudo-gradient exchange, can be combined with low-bandwidth pipeline model parallelism via activation and activation-gradient compression. We introduce a heterogeneous distributed training framework where some participants host full replicas on high-bandwidth interconnects, while resource-limited participants are grouped to jointly instantiate a replica using pipeline parallelism with subspace-projected inter-stage communication. To make the recently introduced subspace pipeline compression compatible with SparseLoCo, we study a number of adaptations. Across large-scale language modeling experiments (178M-1B parameters) on standard pretraining corpora, we find that activation compression composes with SparseLoCo at modest cost, while selective (heterogeneous) compression consistently improves the loss-communication tradeoff relative to compressing all replicas-especially at aggressive compression ratios. These results suggest a practical path to incorporating low-bandwidth model parallelism and heterogeneous participants into LLM pre-training.",
    "authors": [
      "Yazan Obeidi",
      "Amir Sarfi",
      "Joel Lidin",
      "Paul Janson",
      "Eugene Belilovsky"
    ],
    "url": "http://arxiv.org/abs/2601.02360v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于改进大规模语言模型预训练中的分布式计算效率，通过异构低带宽通信优化方法，而非应用于特定科学领域的AI技术。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02357v1",
    "title": "DARC: Drum accompaniment generation with fine-grained rhythm control",
    "summary": "In music creation, rapid prototyping is essential for exploring and refining ideas, yet existing generative tools often fall short when users require both structural control and stylistic flexibility. Prior approaches in stem-to-stem generation can condition on other musical stems but offer limited control over rhythm, and timbre-transfer methods allow users to specify specific rhythms, but cannot condition on musical context. We introduce DARC, a generative drum accompaniment model that conditions both on musical context from other stems and explicit rhythm prompts such as beatboxing or tapping tracks. Using parameter-efficient fine-tuning, we augment STAGE, a state-of-the-art drum stem generator, with fine-grained rhythm control while maintaining musical context awareness.",
    "authors": [
      "Trey Brosnan"
    ],
    "url": "http://arxiv.org/abs/2601.02357v1",
    "published": "2026-01-05",
    "primary_category": "cs.SD",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种结合音乐上下文和精细节奏控制的鼓伴奏生成模型，属于人工智能在音乐创作领域的应用，而非科学发现或扰动预测研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02353v1",
    "title": "Meta-Learning Guided Pruning for Few-Shot Plant Pathology on Edge Devices",
    "summary": "Farmers in remote areas need quick and reliable methods for identifying plant diseases, yet they often lack access to laboratories or high-performance computing resources. Deep learning models can detect diseases from leaf images with high accuracy, but these models are typically too large and computationally expensive to run on low-cost edge devices such as Raspberry Pi. Furthermore, collecting thousands of labeled disease images for training is both expensive and time-consuming. This paper addresses both challenges by combining neural network pruning -- removing unnecessary parts of the model -- with few-shot learning, which enables the model to learn from limited examples. This paper proposes Disease-Aware Channel Importance Scoring (DACIS), a method that identifies which parts of the neural network are most important for distinguishing between different plant diseases, integrated into a three-stage Prune-then-Meta-Learn-then-Prune (PMP) pipeline. Experiments on PlantVillage and PlantDoc datasets demonstrate that the proposed approach reduces model size by 78\\% while maintaining 92.3\\% of the original accuracy, with the compressed model running at 7 frames per second on a Raspberry Pi 4, making real-time field diagnosis practical for smallholder farmers.",
    "authors": [
      "Shahnawaz Alam",
      "Mohammed Mudassir Uddin",
      "Mohammed Kaif Pasha"
    ],
    "url": "http://arxiv.org/abs/2601.02353v1",
    "published": "2026-01-05",
    "primary_category": "cs.CV",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文通过开发用于植物病害识别的轻量化深度学习模型，属于AI在农业科学领域的应用研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02349v1",
    "title": "PRIMAD-LID: A Developed Framework for Computational Reproducibility",
    "summary": "Over the past decade alongside increased focus on computational reproducibility significant efforts have been made to define reproducibility. However, these definitions provide a textual description rather than a framework. The community has sought conceptual frameworks that identify all factors that must be controlled and described for credible computational reproducibility. The PRIMAD model was initially introduced to address inconsistencies in terminology surrounding computational reproducibility by outlining six key factors: P (Platforms), R (Research objective), I (Implementations), M (Methods), A (Actors), and D (Data). Subsequently various studies across different fields adopted the model and proposed extensions. However, these contributions remain fragmented and require systematic integration and cross-disciplinary validation. To bridge this gap and recognising that PRIMAD provides a broadly applicable framework for reproducibility in computational science, this work undertakes a focused investigation of the PRIMAD model. It combines the models previous extensions into a unified framework suitable for diverse research contexts. The result is PRIMAD-LID, a discipline-diagnostic reproducibility framework that retains the original six PRIMAD dimensions and enhances each with three overarching modifiers: Lifespan (temporal qualifier), Interpretation (contextual reasoning) and Depth (necessary granularity), thereby establishing a more cohesive and robust foundation for computational reproducibility practices.",
    "authors": [
      "Meznah Aloqalaa",
      "Stian Soiland-Reyes",
      "Carole Goble"
    ],
    "url": "http://arxiv.org/abs/2601.02349v1",
    "published": "2026-01-05",
    "primary_category": "cs.CE",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一个增强的计算可重复性框架PRIMAD-LID，通过整合现有扩展并增加三个修饰维度来统一跨学科的可重复性实践。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02346v1",
    "title": "Falcon-H1R: Pushing the Reasoning Frontiers with a Hybrid Model for Efficient Test-Time Scaling",
    "summary": "This work introduces Falcon-H1R, a 7B-parameter reasoning-optimized model that establishes the feasibility of achieving competitive reasoning performance with small language models (SLMs). Falcon-H1R stands out for its parameter efficiency, consistently matching or outperforming SOTA reasoning models that are $2\\times$ to $7\\times$ larger across a variety of reasoning-intensive benchmarks. These results underscore the importance of careful data curation and targeted training strategies (via both efficient SFT and RL scaling) in delivering significant performance gains without increasing model size. Furthermore, Falcon-H1R advances the 3D limits of reasoning efficiency by combining faster inference (through its hybrid-parallel architecture design), token efficiency, and higher accuracy. This unique blend makes Falcon-H1R-7B a practical backbone for scaling advanced reasoning systems, particularly in scenarios requiring extensive chain-of-thoughts generation and parallel test-time scaling. Leveraging the recently introduced DeepConf approach, Falcon-H1R achieves state-of-the-art test-time scaling efficiency, offering substantial improvements in both accuracy and computational cost. As a result, Falcon-H1R demonstrates that compact models, through targeted model training and architectural choices, can deliver robust and scalable reasoning performance.",
    "authors": [
      "Falcon LLM Team",
      "Iheb Chaabane",
      "Puneesh Khanna",
      "Suhail Mohmad",
      "Slim Frikha",
      "Shi Hu",
      "Abdalgader Abubaker",
      "Reda Alami",
      "Mikhail Lubinets",
      "Mohamed El Amine Seddik",
      "Hakim Hacid"
    ],
    "url": "http://arxiv.org/abs/2601.02346v1",
    "published": "2026-01-05",
    "primary_category": "cs.AI",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于开发高效的小型语言模型推理架构和训练策略，属于通用人工智能方法学改进，而非针对特定科学领域或扰动预测应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02347v1",
    "title": "Solving Matrix Games with Even Fewer Matrix-Vector Products",
    "summary": "We study the problem of computing an $ε$-approximate Nash equilibrium of a two-player, bilinear, zero-sum game with a bounded payoff matrix $A \\in \\mathbb{R}^{m \\times n}$, when the players' strategies are constrained to lie in simple sets. We provide algorithms which solve this problem in $\\tilde{O}(ε^{-2/3})$ matrix-vector multiplies (matvecs) in two well-studied cases: $\\ell_1$-$\\ell_1$ games, where the players' strategies are both in the probability simplex, and $\\ell_2$-$\\ell_1$ games, where the players' strategies are in the unit Euclidean ball and probability simplex respectively. These results improve upon the previous state-of-the-art complexities of $\\tilde{O}(ε^{-8/9})$ for $\\ell_1$-$\\ell_1$ and of $\\tilde{O}(ε^{-7/9})$ for $\\ell_2$-$\\ell_1$ due to [KOS '25]. In particular, our result for $\\ell_2$-$\\ell_1$, which corresponds to hard-margin support vector machines (SVMs), matches the lower bound of [KS '25] up to polylogarithmic factors.",
    "authors": [
      "Ishani Karmarkar",
      "Liam O'Carroll",
      "Aaron Sidford"
    ],
    "url": "http://arxiv.org/abs/2601.02347v1",
    "published": "2026-01-05",
    "primary_category": "math.OC",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于改进矩阵博弈的算法复杂度，属于计算数学和优化理论领域，不涉及使用AI进行科学发现或预测生物/基因扰动响应。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02324v1",
    "title": "Hunting for \"Oddballs\" with Machine Learning: Detecting Anomalous Exoplanets Using a Deep-Learned Low-Dimensional Representation of Transit Spectra with Autoencoders",
    "summary": "This study explores the application of autoencoder-based machine learning techniques for anomaly detection to identify exoplanet atmospheres with unconventional chemical signatures using a low-dimensional data representation. We use the Atmospheric Big Challenge (ABC) database, a publicly available dataset with over 100,000 simulated exoplanet spectra, to construct an anomaly detection scenario by defining CO2-rich atmospheres as anomalies and CO2-poor atmospheres as the normal class. We benchmarked four different anomaly detection strategies: Autoencoder Reconstruction Loss, One-Class Support Vector Machine (1 class-SVM), K-means Clustering, and Local Outlier Factor (LOF). Each method was evaluated in both the original spectral space and the autoencoder's latent space using Receiver Operating Characteristic (ROC) curves and Area Under the Curve (AUC) metrics. To test the performance of the different methods under realistic conditions, we introduced Gaussian noise levels ranging from 10 to 50 ppm. Our results indicate that anomaly detection is consistently more effective when performed within the latent space across all noise levels. Specifically, K-means clustering in the latent space emerged as a stable and high-performing method. We demonstrate that this anomaly detection approach is robust to noise levels up to 30 ppm (consistent with realistic space-based observations) and remains viable even at 50 ppm when leveraging latent space representations. On the other hand, the performance of the anomaly detection methods applied directly in the raw spectral space degrades significantly with increasing the level of noise. This suggests that autoencoder-driven dimensionality reduction offers a robust methodology for flagging chemically anomalous targets in large-scale surveys where exhaustive retrievals are computationally prohibitive.",
    "authors": [
      "Alexander Roman",
      "Emilie Panek",
      "Roy T. Forestano",
      "Eyup B. Unlu",
      "Katia Matcheva",
      "Konstantin T. Matchev"
    ],
    "url": "http://arxiv.org/abs/2601.02324v1",
    "published": "2026-01-05",
    "primary_category": "astro-ph.EP",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该研究利用自编码器机器学习方法在天体物理学领域检测具有异常化学特征的外行星大气，属于AI在科学发现中的应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02322v1",
    "title": "Environment-Adaptive Covariate Selection: Learning When to Use Spurious Correlations for Out-of-Distribution Prediction",
    "summary": "Out-of-distribution (OOD) prediction is often approached by restricting models to causal or invariant covariates, avoiding non-causal spurious associations that may be unstable across environments. Despite its theoretical appeal, this strategy frequently underperforms empirical risk minimization (ERM) in practice. We investigate the source of this gap and show that such failures naturally arise when only a subset of the true causes of the outcome is observed. In these settings, non-causal spurious covariates can serve as informative proxies for unobserved causes and substantially improve prediction, except under distribution shifts that break these proxy relationships. Consequently, the optimal set of predictive covariates is neither universal nor necessarily exhibits invariant relationships with the outcome across all environments, but instead depends on the specific type of shift encountered. Crucially, we observe that different covariate shifts induce distinct, observable signatures in the covariate distribution itself. Moreover, these signatures can be extracted from unlabeled data in the target OOD environment and used to assess when proxy covariates remain reliable and when they fail. Building on this observation, we propose an environment-adaptive covariate selection (EACS) algorithm that maps environment-level covariate summaries to environment-specific covariate sets, while allowing the incorporation of prior causal knowledge as constraints. Across simulations and applied datasets, EACS consistently outperforms static causal, invariant, and ERM-based predictors under diverse distribution shifts.",
    "authors": [
      "Shuozhi Zuo",
      "Yixin Wang"
    ],
    "url": "http://arxiv.org/abs/2601.02322v1",
    "published": "2026-01-05",
    "primary_category": "stat.ME",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种环境自适应协变量选择算法，通过利用目标环境中未标记数据的协变量分布特征来优化预测模型，适用于需要处理分布偏移的科学发现场景。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02316v1",
    "title": "DatBench: Discriminative, Faithful, and Efficient VLM Evaluations",
    "summary": "Empirical evaluation serves as the primary compass guiding research progress in foundation models. Despite a large body of work focused on training frontier vision-language models (VLMs), approaches to their evaluation remain nascent. To guide their maturation, we propose three desiderata that evaluations should satisfy: (1) faithfulness to the modality and application, (2) discriminability between models of varying quality, and (3) efficiency in compute. Through this lens, we identify critical failure modes that violate faithfulness and discriminability, misrepresenting model capabilities: (i) multiple-choice formats reward guessing, poorly reflect downstream use cases, and saturate early as models improve; (ii) blindly solvable questions, which can be answered without images, constitute up to 70% of some evaluations; and (iii) mislabeled or ambiguous samples compromise up to 42% of examples in certain datasets. Regarding efficiency, the computational burden of evaluating frontier models has become prohibitive: by some accounts, nearly 20% of development compute is devoted to evaluation alone. Rather than discarding existing benchmarks, we curate them via transformation and filtering to maximize fidelity and discriminability. We find that converting multiple-choice questions to generative tasks reveals sharp capability drops of up to 35%. In addition, filtering blindly solvable and mislabeled samples improves discriminative power while simultaneously reducing computational cost. We release DatBench-Full, a cleaned evaluation suite of 33 datasets spanning nine VLM capabilities, and DatBench, a discriminative subset that achieves 13x average speedup (up to 50x) while closely matching the discriminative power of the original datasets. Our work outlines a path toward evaluation practices that are both rigorous and sustainable as VLMs continue to scale.",
    "authors": [
      "Siddharth Joshi",
      "Haoli Yin",
      "Rishabh Adiga",
      "Ricardo Monti",
      "Aldo Carranza",
      "Alex Fang",
      "Alvin Deng",
      "Amro Abbas",
      "Brett Larsen",
      "Cody Blakeney",
      "Darren Teh",
      "David Schwab",
      "Fan Pan",
      "Haakon Mongstad",
      "Jack Urbanek",
      "Jason Lee",
      "Jason Telanoff",
      "Josh Wills",
      "Kaleigh Mentzer",
      "Luke Merrick",
      "Parth Doshi",
      "Paul Burstein",
      "Pratyush Maini",
      "Scott Loftin",
      "Spandan Das",
      "Tony Jiang",
      "Vineeth Dorna",
      "Zhengping Wang",
      "Bogdan Gaza",
      "Ari Morcos",
      "Matthew Leavitt"
    ],
    "url": "http://arxiv.org/abs/2601.02316v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于开发评估视觉语言模型的基准测试方法，而非将AI应用于特定科学领域或预测生物扰动响应。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02314v1",
    "title": "Project Ariadne: A Structural Causal Framework for Auditing Faithfulness in LLM Agents",
    "summary": "As Large Language Model (LLM) agents are increasingly tasked with high-stakes autonomous decision-making, the transparency of their reasoning processes has become a critical safety concern. While \\textit{Chain-of-Thought} (CoT) prompting allows agents to generate human-readable reasoning traces, it remains unclear whether these traces are \\textbf{faithful} generative drivers of the model's output or merely \\textbf{post-hoc rationalizations}. We introduce \\textbf{Project Ariadne}, a novel XAI framework that utilizes Structural Causal Models (SCMs) and counterfactual logic to audit the causal integrity of agentic reasoning. Unlike existing interpretability methods that rely on surface-level textual similarity, Project Ariadne performs \\textbf{hard interventions} ($do$-calculus) on intermediate reasoning nodes -- systematically inverting logic, negating premises, and reversing factual claims -- to measure the \\textbf{Causal Sensitivity} ($φ$) of the terminal answer. Our empirical evaluation of state-of-the-art models reveals a persistent \\textit{Faithfulness Gap}. We define and detect a widespread failure mode termed \\textbf{Causal Decoupling}, where agents exhibit a violation density ($ρ$) of up to $0.77$ in factual and scientific domains. In these instances, agents arrive at identical conclusions despite contradictory internal logic, proving that their reasoning traces function as \"Reasoning Theater\" while decision-making is governed by latent parametric priors. Our findings suggest that current agentic architectures are inherently prone to unfaithful explanation, and we propose the Ariadne Score as a new benchmark for aligning stated logic with model action.",
    "authors": [
      "Sourena Khanzadeh"
    ],
    "url": "http://arxiv.org/abs/2601.02314v1",
    "published": "2026-01-05",
    "primary_category": "cs.AI",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于结构因果模型和反事实逻辑的框架，用于审计大型语言模型代理推理过程的忠实性，而非应用于具体科学发现或细胞扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02313v1",
    "title": "Game of Coding: Coding Theory in the Presence of Rational Adversaries, Motivated by Decentralized Machine Learning",
    "summary": "Coding theory plays a crucial role in enabling reliable communication, storage, and computation. Classical approaches assume a worst-case adversarial model and ensure error correction and data recovery only when the number of honest nodes exceeds the number of adversarial ones by some margin. However, in some emerging decentralized applications, particularly in decentralized machine learning (DeML), participating nodes are rewarded for accepted contributions. This incentive structure naturally gives rise to rational adversaries who act strategically rather than behaving in purely malicious ways.   In this paper, we first motivate the need for coding in the presence of rational adversaries, particularly in the context of outsourced computation in decentralized systems. We contrast this need with existing approaches and highlight their limitations. We then introduce the game of coding, a novel game-theoretic framework that extends coding theory to trust-minimized settings where honest nodes are not in the majority. Focusing on repetition coding, we highlight two key features of this framework: (1) the ability to achieve a non-zero probability of data recovery even when adversarial nodes are in the majority, and (2) Sybil resistance, i.e., the equilibrium remains unchanged even as the number of adversarial nodes increases. Finally, we explore scenarios in which the adversary's strategy is unknown and outline several open problems for future research.",
    "authors": [
      "Hanzaleh Akbari Nodehi",
      "Viveck R. Cadambe",
      "Mohammad Ali Maddah-Ali"
    ],
    "url": "http://arxiv.org/abs/2601.02313v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种结合博弈论与编码理论的新框架，旨在解决去中心化机器学习中理性对手的可靠计算问题，而非将AI应用于传统科学发现或预测生物扰动响应。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02311v1",
    "title": "Placement Semantics for Distributed Deep Learning: A Systematic Framework for Analyzing Parallelism Strategies",
    "summary": "Training large language models requires distributing computation across many accelerators, yet practitioners select parallelism strategies (data, tensor, pipeline, ZeRO) through trial and error because no unified systematic framework predicts their behavior. We introduce placement semantics: each strategy is specified by how it places four training states (parameters, optimizer, gradients, activations) across devices using five modes (replicated, sharded, sharded-with-gather, materialized, offloaded). From placement alone, without implementation details, we derive memory consumption and communication volume. Our predictions match published results exactly: ZeRO-3 uses 8x less memory than data parallelism at 1.5x communication cost, as reported in the original paper. We prove two conditions (gradient integrity, state consistency) are necessary and sufficient for distributed training to match single-device results, and provide composition rules for combining strategies safely. The framework unifies ZeRO Stages 1-3, Fully Sharded Data Parallel (FSDP), tensor parallelism, and pipeline parallelism as instances with different placement choices.",
    "authors": [
      "Deep Pankajbhai Mehta"
    ],
    "url": "http://arxiv.org/abs/2601.02311v1",
    "published": "2026-01-05",
    "primary_category": "cs.DC",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于分析分布式深度学习并行策略的系统框架，专注于训练优化而非具体科学领域应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02310v1",
    "title": "Temporal Kolmogorov-Arnold Networks (T-KAN) for High-Frequency Limit Order Book Forecasting: Efficiency, Interpretability, and Alpha Decay",
    "summary": "High-Frequency trading (HFT) environments are characterised by large volumes of limit order book (LOB) data, which is notoriously noisy and non-linear. Alpha decay represents a significant challenge, with traditional models such as DeepLOB losing predictive power as the time horizon (k) increases. In this paper, using data from the FI-2010 dataset, we introduce Temporal Kolmogorov-Arnold Networks (T-KAN) to replace the fixed, linear weights of standard LSTMs with learnable B-spline activation functions. This allows the model to learn the 'shape' of market signals as opposed to just their magnitude. This resulted in a 19.1% relative improvement in the F1-score at the k = 100 horizon. The efficacy of T-KAN networks cannot be understated, producing a 132.48% return compared to the -82.76% DeepLOB drawdown under 1.0 bps transaction costs. In addition to this, the T-KAN model proves quite interpretable, with the 'dead-zones' being clearly visible in the splines. The T-KAN architecture is also uniquely optimized for low-latency FPGA implementation via High level Synthesis (HLS). The code for the experiments in this project can be found at https://github.com/AhmadMak/Temporal-Kolmogorov-Arnold-Networks-T-KAN-for-High-Frequency-Limit-Order-Book-Forecasting.",
    "authors": [
      "Ahmad Makinde"
    ],
    "url": "http://arxiv.org/abs/2601.02310v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于高频金融交易预测的时序神经网络模型，通过可学习的B样条激活函数改进市场信号分析，属于金融AI应用而非基础科学发现或生物扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02307v1",
    "title": "Differential Privacy for Transformer Embeddings of Text with Nonparametric Variational Information Bottleneck",
    "summary": "We propose a privacy-preserving method for sharing text data by sharing noisy versions of their transformer embeddings. It has been shown that hidden representations learned by deep models can encode sensitive information from the input, making it possible for adversaries to recover the input data with considerable accuracy. This problem is exacerbated in transformer embeddings because they consist of multiple vectors, one per token. To mitigate this risk, we propose Nonparametric Variational Differential Privacy (NVDP), which ensures both useful data sharing and strong privacy protection. We take a differential privacy approach, integrating a Nonparametric Variational Information Bottleneck (NVIB) layer into the transformer architecture to inject noise into its multi-vector embeddings and thereby hide information, and measuring privacy protection with Rényi divergence and its corresponding Bayesian Differential Privacy (BDP) guarantee. Training the NVIB layer calibrates the noise level according to utility. We test NVDP on the GLUE benchmark and show that varying the noise level gives us a useful tradeoff between privacy and accuracy. With lower noise levels, our model maintains high accuracy while offering strong privacy guarantees, effectively balancing privacy and utility.",
    "authors": [
      "Dina El Zein",
      "James Henderson"
    ],
    "url": "http://arxiv.org/abs/2601.02307v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于非参数变分信息瓶颈的差分隐私方法，用于保护Transformer文本嵌入的隐私，而非应用于科学发现或细胞扰动预测领域。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02285v1",
    "title": "pdfQA: Diverse, Challenging, and Realistic Question Answering over PDFs",
    "summary": "PDFs are the second-most used document type on the internet (after HTML). Yet, existing QA datasets commonly start from text sources or only address specific domains. In this paper, we present pdfQA, a multi-domain 2K human-annotated (real-pdfQA) and 2K synthetic dataset (syn-pdfQA) differentiating QA pairs in ten complexity dimensions (e.g., file type, source modality, source position, answer type). We apply and evaluate quality and difficulty filters on both datasets, obtaining valid and challenging QA pairs. We answer the questions with open-source LLMs, revealing existing challenges that correlate with our complexity dimensions. pdfQA presents a basis for end-to-end QA pipeline evaluation, testing diverse skill sets and local optimizations (e.g., in information retrieval or parsing).",
    "authors": [
      "Tobias Schimanski",
      "Imene Kolli",
      "Jingwei Ni",
      "Yu Fan",
      "Ario Saeid Vaghefi",
      "Elliott Ash",
      "Markus Leippold"
    ],
    "url": "http://arxiv.org/abs/2601.02285v1",
    "published": "2026-01-05",
    "primary_category": "cs.CL",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文主要贡献是创建了一个用于评估PDF文档问答系统性能的多领域数据集，而非直接应用于特定科学发现或扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02273v1",
    "title": "TopoLoRA-SAM: Topology-Aware Parameter-Efficient Adaptation of Foundation Segmenters for Thin-Structure and Cross-Domain Binary Semantic Segmentation",
    "summary": "Foundation segmentation models such as the Segment Anything Model (SAM) exhibit strong zero-shot generalization through large-scale pretraining, but adapting them to domain-specific semantic segmentation remains challenging, particularly for thin structures (e.g., retinal vessels) and noisy modalities (e.g., SAR imagery). Full fine-tuning is computationally expensive and risks catastrophic forgetting. We propose \\textbf{TopoLoRA-SAM}, a topology-aware and parameter-efficient adaptation framework for binary semantic segmentation. TopoLoRA-SAM injects Low-Rank Adaptation (LoRA) into the frozen ViT encoder, augmented with a lightweight spatial convolutional adapter and optional topology-aware supervision via differentiable clDice. We evaluate our approach on five benchmarks spanning retinal vessel segmentation (DRIVE, STARE, CHASE\\_DB1), polyp segmentation (Kvasir-SEG), and SAR sea/land segmentation (SL-SSDD), comparing against U-Net, DeepLabV3+, SegFormer, and Mask2Former. TopoLoRA-SAM achieves the best retina-average Dice and the best overall average Dice across datasets, while training only \\textbf{5.2\\%} of model parameters ($\\sim$4.9M). On the challenging CHASE\\_DB1 dataset, our method substantially improves segmentation accuracy and robustness, demonstrating that topology-aware parameter-efficient adaptation can match or exceed fully fine-tuned specialist models. Code is available at : https://github.com/salimkhazem/Seglab.git",
    "authors": [
      "Salim Khazem"
    ],
    "url": "http://arxiv.org/abs/2601.02273v1",
    "published": "2026-01-05",
    "primary_category": "cs.CV",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种拓扑感知的参数高效适应框架，用于医学图像（视网膜血管、息肉）和遥感图像（SAR海陆分割）的二元语义分割，属于AI在生物医学和地球科学领域的应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02265v1",
    "title": "Predicting Early and Complete Drug Release from Long-Acting Injectables Using Explainable Machine Learning",
    "summary": "Polymer-based long-acting injectables (LAIs) have transformed the treatment of chronic diseases by enabling controlled drug delivery, thus reducing dosing frequency and extending therapeutic duration. Achieving controlled drug release from LAIs requires extensive optimization of the complex underlying physicochemical properties. Machine learning (ML) can accelerate LAI development by modeling the complex relationships between LAI properties and drug release. However, recent ML studies have provided limited information on key properties that modulate drug release, due to the lack of custom modeling and analysis tailored to LAI data. This paper presents a novel data transformation and explainable ML approach to synthesize actionable information from 321 LAI formulations by predicting early drug release at 24, 48, and 72 hours, classification of release profile types, and prediction of complete release profiles. These three experiments investigate the contribution and control of LAI material characteristics in early and complete drug release profiles. A strong correlation (>0.65) is observed between the true and predicted drug release in 72 hours, while a 0.87 F1-score is obtained in classifying release profile types. A time-independent ML framework predicts delayed biphasic and triphasic curves with better performance than current time-dependent approaches. Shapley additive explanations reveal the relative influence of material characteristics during early and for complete release which fill several gaps in previous in-vitro and ML-based studies. The novel approach and findings can provide a quantitative strategy and recommendations for scientists to optimize the drug-release dynamics of LAI. The source code for the model implementation is publicly available.",
    "authors": [
      "Karla N. Robles",
      "Manar D. Samad"
    ],
    "url": "http://arxiv.org/abs/2601.02265v1",
    "published": "2026-01-05",
    "primary_category": "q-bio.BM",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文使用可解释机器学习方法预测长效注射剂的药物释放动力学，属于AI在药物化学领域的科学发现应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02264v1",
    "title": "POSEIDON: Physics-Optimized Seismic Energy Inference and Detection Operating Network",
    "summary": "Earthquake prediction and seismic hazard assessment remain fundamental challenges in geophysics, with existing machine learning approaches often operating as black boxes that ignore established physical laws. We introduce POSEIDON (Physics-Optimized Seismic Energy Inference and Detection Operating Network), a physics-informed energy-based model for unified multi-task seismic event prediction, alongside the Poseidon dataset -- the largest open-source global earthquake catalog comprising 2.8 million events spanning 30 years. POSEIDON embeds fundamental seismological principles, including the Gutenberg-Richter magnitude-frequency relationship and Omori-Utsu aftershock decay law, as learnable constraints within an energy-based modeling framework. The architecture simultaneously addresses three interconnected prediction tasks: aftershock sequence identification, tsunami generation potential, and foreshock detection. Extensive experiments demonstrate that POSEIDON achieves state-of-the-art performance across all tasks, outperforming gradient boosting, random forest, and CNN baselines with the highest average F1 score among all compared methods. Crucially, the learned physics parameters converge to scientifically interpretable values -- Gutenberg-Richter b-value of 0.752 and Omori-Utsu parameters p=0.835, c=0.1948 days -- falling within established seismological ranges while enhancing rather than compromising predictive accuracy. The Poseidon dataset is publicly available at https://huggingface.co/datasets/BorisKriuk/Poseidon, providing pre-computed energy features, spatial grid indices, and standardized quality metrics to advance physics-informed seismic research.",
    "authors": [
      "Boris Kriuk",
      "Fedor Kriuk"
    ],
    "url": "http://arxiv.org/abs/2601.02264v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文通过将地震学物理定律嵌入能量模型框架，开发了物理优化的多任务地震事件预测网络，属于AI4Science在物理学领域的应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02257v1",
    "title": "Improved Accuracy for Private Continual Cardinality Estimation in Fully Dynamic Streams via Matrix Factorization",
    "summary": "We study differentially-private statistics in the fully dynamic continual observation model, where many updates can arrive at each time step and updates to a stream can involve both insertions and deletions of an item. Earlier work (e.g., Jain et al., NeurIPS 2023 for counting distinct elements; Raskhodnikova & Steiner, PODS 2025 for triangle counting with edge updates) reduced the respective cardinality estimation problem to continual counting on the difference stream associated with the true function values on the input stream. In such reductions, a change in the original stream can cause many changes in the difference stream, this poses a challenge for applying private continual counting algorithms to obtain optimal error bounds. We improve the accuracy of several such reductions by studying the associated $\\ell_p$-sensitivity vectors of the resulting difference streams and isolating their properties.   We demonstrate that our framework gives improved bounds for counting distinct elements, estimating degree histograms, and estimating triangle counts (under a slightly relaxed privacy model), thus offering a general approach to private continual cardinality estimation in streaming settings. Our improved accuracy stems from tight analysis of known factorization mechanisms for the counting matrix in this setting; the key technical challenge is arguing that one can use state-of-the-art factorizations for sensitivity vector sets with the properties we isolate. Empirically and analytically, we demonstrate that our improved error bounds offer a substantial improvement in accuracy for cardinality estimation problems over a large range of parameters.",
    "authors": [
      "Joel Daniel Andersson",
      "Palak Jain",
      "Satchit Sivakumar"
    ],
    "url": "http://arxiv.org/abs/2601.02257v1",
    "published": "2026-01-05",
    "primary_category": "cs.CR",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文通过改进差分隐私下的矩阵分解机制，提高了动态流中基数估计的准确性，属于理论计算机科学中的隐私保护算法研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02256v1",
    "title": "VAR RL Done Right: Tackling Asynchronous Policy Conflicts in Visual Autoregressive Generation",
    "summary": "Visual generation is dominated by three paradigms: AutoRegressive (AR), diffusion, and Visual AutoRegressive (VAR) models. Unlike AR and diffusion, VARs operate on heterogeneous input structures across their generation steps, which creates severe asynchronous policy conflicts. This issue becomes particularly acute in reinforcement learning (RL) scenarios, leading to unstable training and suboptimal alignment. To resolve this, we propose a novel framework to enhance Group Relative Policy Optimization (GRPO) by explicitly managing these conflicts. Our method integrates three synergistic components: 1) a stabilizing intermediate reward to guide early-stage generation; 2) a dynamic time-step reweighting scheme for precise credit assignment; and 3) a novel mask propagation algorithm, derived from principles of Reward Feedback Learning (ReFL), designed to isolate optimization effects both spatially and temporally. Our approach demonstrates significant improvements in sample quality and objective alignment over the vanilla GRPO baseline, enabling robust and effective optimization for VAR models.",
    "authors": [
      "Shikun Sun",
      "Liao Qu",
      "Huichao Zhang",
      "Yiheng Liu",
      "Yangyang Song",
      "Xian Li",
      "Xu Wang",
      "Yi Jiang",
      "Daniel K. Du",
      "Xinglong Wu",
      "Jia Jia"
    ],
    "url": "http://arxiv.org/abs/2601.02256v1",
    "published": "2026-01-05",
    "primary_category": "cs.CV",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于改进视觉自回归生成模型的强化学习训练方法，解决异步策略冲突问题，属于计算机视觉和机器学习领域的技术优化研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02253v1",
    "title": "Neuro-Channel Networks: A Multiplication-Free Architecture by Biological Signal Transmission",
    "summary": "The rapid proliferation of Deep Learning is increasingly constrained by its heavy reliance on high-performance hardware, particularly Graphics Processing Units (GPUs). These specialized accelerators are not only prohibitively expensive and energy-intensive but also suffer from significant supply scarcity, limiting the ubiquity of Artificial Intelligence (AI) deployment on edge devices. The core of this inefficiency stems from the standard artificial perceptron's dependence on intensive matrix multiplications. However, biological nervous systems achieve unparalleled efficiency without such arithmetic intensity; synaptic signal transmission is regulated by physical ion channel limits and chemical neurotransmitter levels rather than a process that can be analogous to arithmetic multiplication. Inspired by this biological mechanism, we propose Neuro-Channel Networks (NCN), a novel multiplication-free architecture designed to decouple AI from expensive hardware dependencies. In our model, weights are replaced with Channel Widths that physically limit the signal magnitude, while a secondary parameter acts as a Neurotransmitter to regulate Signal Transmission based on sign logic. The forward pass relies exclusively on addition, subtraction, and bitwise operations (minimum, sign), eliminating floating-point multiplication entirely. In this proof-of-concept study, we demonstrate that NCNs can solve non-linearly separable problems like XOR and the Majority function with 100% accuracy using standard backpropagation, proving their capability to form complex decision boundaries without multiplicative weights. This architecture offers a highly efficient alternative for next-generation neuromorphic hardware, paving the way for running complex models on commodity CPUs or ultra-low-power chips without relying on costly GPU clusters.",
    "authors": [
      "Emrah Mete",
      "Emin Erkan Korkmaz"
    ],
    "url": "http://arxiv.org/abs/2601.02253v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种受生物神经系统启发的无乘法神经网络架构，旨在降低AI硬件依赖，而非将AI应用于科学发现或扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02246v1",
    "title": "A Comparative Study of Custom CNNs, Pre-trained Models, and Transfer Learning Across Multiple Visual Datasets",
    "summary": "Convolutional Neural Networks (CNNs) are a standard approach for visual recognition due to their capacity to learn hierarchical representations from raw pixels. In practice, practitioners often choose among (i) training a compact custom CNN from scratch, (ii) using a large pre-trained CNN as a fixed feature extractor, and (iii) performing transfer learning via partial or full fine-tuning of a pre-trained backbone. This report presents a controlled comparison of these three paradigms across five real-world image classification datasets spanning road-surface defect recognition, agricultural variety identification, fruit/leaf disease recognition, pedestrian walkway encroachment recognition, and unauthorized vehicle recognition. Models are evaluated using accuracy and macro F1-score, complemented by efficiency metrics including training time per epoch and parameter counts. The results show that transfer learning consistently yields the strongest predictive performance, while the custom CNN provides an attractive efficiency--accuracy trade-off, especially when compute and memory budgets are constrained.",
    "authors": [
      "Annoor Sharara Akhand"
    ],
    "url": "http://arxiv.org/abs/2601.02246v1",
    "published": "2026-01-05",
    "primary_category": "cs.CV",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文比较了不同CNN训练范式在多个视觉数据集上的性能，属于计算机视觉方法学研究，而非特定科学领域发现或扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02242v1",
    "title": "VIBE: Visual Instruction Based Editor",
    "summary": "Instruction-based image editing is among the fastest developing areas in generative AI. Over the past year, the field has reached a new level, with dozens of open-source models released alongside highly capable commercial systems. However, only a limited number of open-source approaches currently achieve real-world quality. In addition, diffusion backbones, the dominant choice for these pipelines, are often large and computationally expensive for many deployments and research settings, with widely used variants typically containing 6B to 20B parameters. This paper presents a compact, high-throughput instruction-based image editing pipeline that uses a modern 2B-parameter Qwen3-VL model to guide the editing process and the 1.6B-parameter diffusion model Sana1.5 for image generation. Our design decisions across architecture, data processing, training configuration, and evaluation target low-cost inference and strict source consistency while maintaining high quality across the major edit categories feasible at this scale. Evaluated on the ImgEdit and GEdit benchmarks, the proposed method matches or exceeds the performance of substantially heavier baselines, including models with several times as many parameters and higher inference cost, and is particularly strong on edits that require preserving the input image, such as an attribute adjustment, object removal, background edits, and targeted replacement. The model fits within 24 GB of GPU memory and generates edited images at up to 2K resolution in approximately 4 seconds on an NVIDIA H100 in BF16, without additional inference optimizations or distillation.",
    "authors": [
      "Grigorii Alekseenko",
      "Aleksandr Gordeev",
      "Irina Tolstykh",
      "Bulat Suleimanov",
      "Vladimir Dokholyan",
      "Georgii Fedorov",
      "Sergey Yakubson",
      "Aleksandra Tsybina",
      "Mikhail Chernyshov",
      "Maksim Kuprashevich"
    ],
    "url": "http://arxiv.org/abs/2601.02242v1",
    "published": "2026-01-05",
    "primary_category": "cs.CV",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于开发高效的视觉指令图像编辑系统，属于计算机视觉和生成式AI领域，不涉及科学发现或生物分子扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02241v1",
    "title": "From Mice to Trains: Amortized Bayesian Inference on Graph Data",
    "summary": "Graphs arise across diverse domains, from biology and chemistry to social and information networks, as well as in transportation and logistics. Inference on graph-structured data requires methods that are permutation-invariant, scalable across varying sizes and sparsities, and capable of capturing complex long-range dependencies, making posterior estimation on graph parameters particularly challenging. Amortized Bayesian Inference (ABI) is a simulation-based framework that employs generative neural networks to enable fast, likelihood-free posterior inference. We adapt ABI to graph data to address these challenges to perform inference on node-, edge-, and graph-level parameters. Our approach couples permutation-invariant graph encoders with flexible neural posterior estimators in a two-module pipeline: a summary network maps attributed graphs to fixed-length representations, and an inference network approximates the posterior over parameters. In this setting, several neural architectures can serve as the summary network. In this work we evaluate multiple architectures and assess their performance on controlled synthetic settings and two real-world domains - biology and logistics - in terms of recovery and calibration.",
    "authors": [
      "Svenja Jedhoff",
      "Elizaveta Semenova",
      "Aura Raulo",
      "Anne Meyer",
      "Paul-Christian Bürkner"
    ],
    "url": "http://arxiv.org/abs/2601.02241v1",
    "published": "2026-01-05",
    "primary_category": "stat.ML",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于图数据的摊销贝叶斯推断方法，并在生物学和物流等真实世界领域进行了评估，属于AI4Science范畴。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02233v1",
    "title": "PauliEngine: High-Performant Symbolic Arithmetic for Quantum Operations",
    "summary": "Quantum computation is inherently hybrid, and fast classical manipulation of qubit operators is necessary to ensure scalability in quantum software. We introduce PauliEngine, a high-performance C++ framework that provides efficient primitives for Pauli string multiplication, commutators, symbolic phase tracking, and structural transformations. Built on a binary symplectic representation and optimized bit-wise operations, PauliEngine supports both numerical and symbolic coefficients and is accessible through a Python interface. Runtime benchmarks demonstrate substantial speedups over state-of-the-art implementations. PauliEngine provides a scalable backend for operator-based quantum software tools and simulations.",
    "authors": [
      "Leon Müller",
      "Adelina Bärligea",
      "Alexander Knapp",
      "Jakob S. Kottmann"
    ],
    "url": "http://arxiv.org/abs/2601.02233v1",
    "published": "2026-01-05",
    "primary_category": "quant-ph",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文介绍了用于量子计算中泡利字符串高效运算的C++框架，属于量子软件工具开发，而非AI驱动的科学发现或细胞扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02232v1",
    "title": "ELLA: Efficient Lifelong Learning for Adapters in Large Language Models",
    "summary": "Large Language Models (LLMs) suffer severe catastrophic forgetting when adapted sequentially to new tasks in a continual learning (CL) setting. Existing approaches are fundamentally limited: replay-based methods are impractical and privacy-violating, while strict orthogonality-based methods collapse under scale: each new task is projected onto an orthogonal complement, progressively reducing the residual degrees of freedom and eliminating forward transfer by forbidding overlap in shared representations. In this work, we introduce ELLA, a training framework built on the principle of selective subspace de-correlation. Rather than forbidding all overlap, ELLA explicitly characterizes the structure of past updates and penalizes alignments along their high-energy, task-specific directions, while preserving freedom in the low-energy residual subspaces to enable transfer. Formally, this is realized via a lightweight regularizer on a single aggregated update matrix. We prove this mechanism corresponds to an anisotropic shrinkage operator that bounds interference, yielding a penalty that is both memory- and compute-constant regardless of task sequence length. ELLA requires no data replay, no architectural expansion, and negligible storage. Empirically, it achieves state-of-the-art CL performance on three popular benchmarks, with relative accuracy gains of up to $9.6\\%$ and a $35\\times$ smaller memory footprint. Further, ELLA scales robustly across architectures and actively enhances the model's zero-shot generalization performance on unseen tasks, establishing a principled and scalable solution for constructive lifelong LLM adaptation.",
    "authors": [
      "Shristi Das Biswas",
      "Yue Zhang",
      "Anwesan Pal",
      "Radhika Bhargava",
      "Kaushik Roy"
    ],
    "url": "http://arxiv.org/abs/2601.02232v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种名为ELLA的高效持续学习框架，通过选择性子空间去相关机制解决大语言模型在连续任务学习中的灾难性遗忘问题，属于机器学习方法学改进。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02229v1",
    "title": "Extended real number arithmetics via Dedekind cuts",
    "summary": "It is shown how Dedekind cuts can be used to introduce the extended real numbers along with sound arithmetic laws via one simple rule for the addition of sets. The crucial idea is that the use of the lower and the upper part of the cuts, respectively, leads to two different additions which are known in the literature as inf-addition and sup-addition. Moreover, the two resulting structures are conlinear spaces which at the same time are complete lattices with respect to the natural order. This admits the definition of pseudo-differences on the extended reals which also provide formulas for expressions like $(+\\infty) - (+\\infty)$, $(-\\infty) - (-\\infty)$. There are two major motivations: one is that proper and improper extended real-valued functions can be treated in a unified manner, the other that set-valued functions can often be represented by families of scalar functions which may include improper ones.",
    "authors": [
      "Andreas H Hamel"
    ],
    "url": "http://arxiv.org/abs/2601.02229v1",
    "published": "2026-01-05",
    "primary_category": "math.OC",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文通过Dedekind切割构建扩展实数算术系统，属于纯数学基础理论研究，与AI驱动的科学发现或细胞扰动预测无直接关联。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02215v1",
    "title": "LLM-Empowered Functional Safety and Security by Design in Automotive Systems",
    "summary": "This paper presents LLM-empowered workflow to support Software Defined Vehicle (SDV) software development, covering the aspects of security-aware system topology design, as well as event-driven decision-making code analysis. For code analysis we adopt event chains model which provides formal foundations to systematic validation of functional safety, taking into account the semantic validity of messages exchanged between key components, including both CAN and Vehicle Signal Specification (VSS). Analysis of security aspects for topology relies on synergy with Model-Driven Engineering (MDE) approach and Object Constraint Language (OCL) rules. Both locally deployable and proprietary solution are taken into account for evaluation within Advanced Driver-Assistance Systems (ADAS)-related scenarios.",
    "authors": [
      "Nenad Petrovic",
      "Vahid Zolfaghari",
      "Fengjunjie Pan",
      "Alois Knoll"
    ],
    "url": "http://arxiv.org/abs/2601.02215v1",
    "published": "2026-01-05",
    "primary_category": "cs.SE",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于利用大语言模型优化汽车系统的功能安全与安全设计流程，属于工程应用领域而非基础科学研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02213v1",
    "title": "Quantized SO(3)-Equivariant Graph Neural Networks for Efficient Molecular Property Prediction",
    "summary": "Deploying 3D graph neural networks (GNNs) that are equivariant to 3D rotations (the group SO(3)) on edge devices is challenging due to their high computational cost. This paper addresses the problem by compressing and accelerating an SO(3)-equivariant GNN using low-bit quantization techniques. Specifically, we introduce three innovations for quantized equivariant transformers: (1) a magnitude-direction decoupled quantization scheme that separately quantizes the norm and orientation of equivariant (vector) features, (2) a branch-separated quantization-aware training strategy that treats invariant and equivariant feature channels differently in an attention-based $SO(3)$-GNN, and (3) a robustness-enhancing attention normalization mechanism that stabilizes low-precision attention computations. Experiments on the QM9 and rMD17 molecular benchmarks demonstrate that our 8-bit models achieve accuracy on energy and force predictions comparable to full-precision baselines with markedly improved efficiency. We also conduct ablation studies to quantify the contribution of each component to maintain accuracy and equivariance under quantization, using the Local error of equivariance (LEE) metric. The proposed techniques enable the deployment of symmetry-aware GNNs in practical chemistry applications with 2.37--2.73x faster inference and 4x smaller model size, without sacrificing accuracy or physical symmetry.",
    "authors": [
      "Haoyu Zhou",
      "Ping Xue",
      "Tianfan Fu",
      "Hao Zhang"
    ],
    "url": "http://arxiv.org/abs/2601.02213v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文通过量化SO(3)-等变图神经网络，实现了高效分子性质预测，属于AI在化学领域的科学应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02207v1",
    "title": "Risk-Averse Markov Decision Processes: Applications to Electricity Grid and Reservoir Management",
    "summary": "This paper develops risk-averse models to support system operators in planning and operating the electricity grid under uncertainty from renewable power generation. We incorporate financial risk hedging using conditional value at risk (CVaR) within a Markov Decision Process (MDP) framework and propose efficient, exact solution methods for these models. In addition, we introduce a power reliability-oriented risk measure and present new, computationally efficient models for risk-averse grid planning and operations.",
    "authors": [
      "Arash Khojaste",
      "Jonathan Pearce",
      "Daniela Pucci de Farias",
      "Geoffrey Pritchard",
      "Golbon Zakeri"
    ],
    "url": "http://arxiv.org/abs/2601.02207v1",
    "published": "2026-01-05",
    "primary_category": "math.OC",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于条件风险价值（CVaR）的风险规避马尔可夫决策过程模型，用于电力系统在可再生能源不确定性下的规划与运营优化。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02206v1",
    "title": "Seeing the Unseen: Zooming in the Dark with Event Cameras",
    "summary": "This paper addresses low-light video super-resolution (LVSR), aiming to restore high-resolution videos from low-light, low-resolution (LR) inputs. Existing LVSR methods often struggle to recover fine details due to limited contrast and insufficient high-frequency information. To overcome these challenges, we present RetinexEVSR, the first event-driven LVSR framework that leverages high-contrast event signals and Retinex-inspired priors to enhance video quality under low-light scenarios. Unlike previous approaches that directly fuse degraded signals, RetinexEVSR introduces a novel bidirectional cross-modal fusion strategy to extract and integrate meaningful cues from noisy event data and degraded RGB frames. Specifically, an illumination-guided event enhancement module is designed to progressively refine event features using illumination maps derived from the Retinex model, thereby suppressing low-light artifacts while preserving high-contrast details. Furthermore, we propose an event-guided reflectance enhancement module that utilizes the enhanced event features to dynamically recover reflectance details via a multi-scale fusion mechanism. Experimental results show that our RetinexEVSR achieves state-of-the-art performance on three datasets. Notably, on the SDSD benchmark, our method can get up to 2.95 dB gain while reducing runtime by 65% compared to prior event-based methods. Code: https://github.com/DachunKai/RetinexEVSR.",
    "authors": [
      "Dachun Kai",
      "Zeyu Xiao",
      "Huyue Zhu",
      "Jiaxiao Wang",
      "Yueyi Zhang",
      "Xiaoyan Sun"
    ],
    "url": "http://arxiv.org/abs/2601.02206v1",
    "published": "2026-01-05",
    "primary_category": "cs.CV",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于事件相机和Retinex先验的低光视频超分辨率框架，属于计算机视觉领域的方法创新，而非AI4Science或扰动预测研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02204v1",
    "title": "NextFlow: Unified Sequential Modeling Activates Multimodal Understanding and Generation",
    "summary": "We present NextFlow, a unified decoder-only autoregressive transformer trained on 6 trillion interleaved text-image discrete tokens. By leveraging a unified vision representation within a unified autoregressive architecture, NextFlow natively activates multimodal understanding and generation capabilities, unlocking abilities of image editing, interleaved content and video generation. Motivated by the distinct nature of modalities - where text is strictly sequential and images are inherently hierarchical - we retain next-token prediction for text but adopt next-scale prediction for visual generation. This departs from traditional raster-scan methods, enabling the generation of 1024x1024 images in just 5 seconds - orders of magnitude faster than comparable AR models. We address the instabilities of multi-scale generation through a robust training recipe. Furthermore, we introduce a prefix-tuning strategy for reinforcement learning. Experiments demonstrate that NextFlow achieves state-of-the-art performance among unified models and rivals specialized diffusion baselines in visual quality.",
    "authors": [
      "Huichao Zhang",
      "Liao Qu",
      "Yiheng Liu",
      "Hang Chen",
      "Yangyang Song",
      "Yongsheng Dong",
      "Shikun Sun",
      "Xian Li",
      "Xu Wang",
      "Yi Jiang",
      "Hu Ye",
      "Bo Chen",
      "Yiming Gao",
      "Peng Liu",
      "Akide Liu",
      "Zhipeng Yang",
      "Qili Deng",
      "Linjie Xing",
      "Jiyang Liu",
      "Zhao Wang",
      "Yang Zhou",
      "Mingcong Liu",
      "Yi Zhang",
      "Qian He",
      "Xiwei Hu",
      "Zhongqi Qi",
      "Jie Shao",
      "Zhiye Fu",
      "Shuai Wang",
      "Fangmin Chen",
      "Xuezhi Chai",
      "Zhihua Wu",
      "Yitong Wang",
      "Zehuan Yuan",
      "Daniel K. Du",
      "Xinglong Wu"
    ],
    "url": "http://arxiv.org/abs/2601.02204v1",
    "published": "2026-01-05",
    "primary_category": "cs.CV",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种统一的多模态序列建模框架NextFlow，专注于提升图像和视频生成的速度与质量，而非针对特定科学领域或细胞扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02202v1",
    "title": "Density-based topology optimization for turbulent fluid flow using the standard k-epsilon RANS model with wall-functions imposed through an implicit wall penalty formulation",
    "summary": "Turbulent flows have high requirements for very fine meshes near the boundary to ensure accuracy. In the context of topology optimization (TO), such fine meshes become unrealistic and common approaches are hampered by low accuracy and overestimation of boundary layer thickness. Wall-functions are a natural way to ease the computational requirements, but they are not naturally imposed in density-based TO due to the diffuse design parametrization. We propose an implicit wall-function formulation for the Reynolds-Averaged Navier-Stokes (RANS), standard k-epsilon model that extracts wall-normal information directly from the gradient of the design variable and enables a penalty-based formulation for imposing wall-functions to the RANS equations, without the need for body-fitted meshes. The method provides a reliable route to high Reynolds number turbulent topology optimization, delivering boundary layer accuracy comparable to explicit-wall body-fitted analyses, while retaining the flexibility of density-based TO. Furthermore, because wall effects are modeled using wall-functions, accurate solutions are obtained on substantially coarser meshes, leading to significant reductions in computational cost. The approach is validated on three canonical benchmarks over Reynolds numbers up to Re = 2e5: a pipe-bend; a U-bend; and a Tesla-valve. Across all cases, the proposed method accurately recovers near-wall velocity profiles, closely matching verification simulations on body-fitted meshes with explicit wall-functions. In contrast, a conventional turbulent TO formulation, without the proposed wall-function treatment, mispredicts boundary-layer development and yields sub-optimal results.",
    "authors": [
      "Amirhossein Bayat",
      "Hao Li",
      "Joe Alexandersen"
    ],
    "url": "http://arxiv.org/abs/2601.02202v1",
    "published": "2026-01-05",
    "primary_category": "physics.flu-dyn",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于密度拓扑优化的隐式壁面函数方法，用于湍流流体力学模拟，属于计算流体力学与优化设计领域，不涉及人工智能或细胞/分子扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02201v1",
    "title": "CORE: Code-based Inverse Self-Training Framework with Graph Expansion for Virtual Agents",
    "summary": "The development of Multimodal Virtual Agents has made significant progress through the integration of Multimodal Large Language Models. However, mainstream training paradigms face key challenges: Behavior Cloning is simple and effective through imitation but suffers from low behavioral diversity, while Reinforcement Learning is capable of discovering novel strategies through exploration but heavily relies on manually designed reward functions. To address the conflict between these two methods, we present CORE, a Code-based Inverse Self-Training Framework with Graph Expansion that bridges imitation and exploration, offering a novel training framework that promotes behavioral diversity while eliminating the reliance on manually reward design. Specifically, we introduce Semantic Code Abstraction to automatically infers reward functions from expert demonstrations without manual design. The inferred reward function, referred to as the Label Function, is executable code that verifies one key step within a task. Building on this, we propose Strategy Graph Expansion to enhance in-domain behavioral diversity, which constructs a multi-path graph called Strategy Graph that captures diverse valid solutions beyond expert demonstrations. Furthermore, we introduce Trajectory-Guided Extrapolation, which enriches out-of-domain behavioral diversity by utilizing both successful and failed trajectories to expand the task space. Experiments on Web and Android platforms demonstrate that CORE significantly improves both overall performance and generalization, highlighting its potential as a robust and generalizable training paradigm for building powerful virtual agents.",
    "authors": [
      "Keyu Wang",
      "Bingchen Miao",
      "Wendong Bu",
      "Yu Wu",
      "Juncheng Li",
      "Shengyu Zhang",
      "Wenqiao Zhang",
      "Siliang Tang",
      "Jun Xiao",
      "Yueting Zhuang"
    ],
    "url": "http://arxiv.org/abs/2601.02201v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于代码的逆自训练框架，通过图扩展增强虚拟代理的行为多样性，属于强化学习与模仿学习交叉的通用AI训练方法研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02200v1",
    "title": "Code for Machines, Not Just Humans: Quantifying AI-Friendliness with Code Health Metrics",
    "summary": "We are entering a hybrid era in which human developers and AI coding agents work in the same codebases. While industry practice has long optimized code for human comprehension, it is increasingly important to ensure that LLMs with different capabilities can edit code reliably. In this study, we investigate the concept of ``AI-friendly code'' via LLM-based refactoring on a dataset of 5,000 Python files from competitive programming. We find a meaningful association between CodeHealth, a quality metric calibrated for human comprehension, and semantic preservation after AI refactoring. Our findings confirm that human-friendly code is also more compatible with AI tooling. These results suggest that organizations can use CodeHealth to guide where AI interventions are lower risk and where additional human oversight is warranted. Investing in maintainability not only helps humans; it also prepares for large-scale AI adoption.",
    "authors": [
      "Markus Borg",
      "Nadim Hagatulah",
      "Adam Tornhill",
      "Emma Söderberg"
    ],
    "url": "http://arxiv.org/abs/2601.02200v1",
    "published": "2026-01-05",
    "primary_category": "cs.SE",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文研究AI友好型代码与代码健康度的关联，属于软件工程与AI协作领域，不涉及自然科学发现或生物医学扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02198v1",
    "title": "Mind the Gap: Continuous Magnification Sampling for Pathology Foundation Models",
    "summary": "In histopathology, pathologists examine both tissue architecture at low magnification and fine-grained morphology at high magnification. Yet, the performance of pathology foundation models across magnifications and the effect of magnification sampling during training remain poorly understood. We model magnification sampling as a multi-source domain adaptation problem and develop a simple theoretical framework that reveals systematic trade-offs between sampling strategies. We show that the widely used discrete uniform sampling of magnifications (0.25, 0.5, 1.0, 2.0 mpp) leads to degradation at intermediate magnifications. We introduce continuous magnification sampling, which removes gaps in magnification coverage while preserving performance at standard scales. Further, we derive sampling distributions that optimize representation quality across magnification scales. To evaluate these strategies, we introduce two new benchmarks (TCGA-MS, BRACS-MS) with appropriate metrics. Our experiments show that continuous sampling substantially improves over discrete sampling at intermediate magnifications, with gains of up to 4 percentage points in balanced classification accuracy, and that optimized distributions can further improve performance. Finally, we evaluate current histopathology foundation models, finding that magnification is a primary driver of performance variation across models. Our work paves the way towards future pathology foundation models that perform reliably across magnifications.",
    "authors": [
      "Alexander Möllers",
      "Julius Hense",
      "Florian Schulz",
      "Timo Milbich",
      "Maximilian Alber",
      "Lukas Ruff"
    ],
    "url": "http://arxiv.org/abs/2601.02198v1",
    "published": "2026-01-05",
    "primary_category": "cs.CV",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文通过开发连续放大采样方法优化病理学基础模型，属于AI在生物医学科学发现中的应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02196v1",
    "title": "ACDZero: Graph-Embedding-Based Tree Search for Mastering Automated Cyber Defense",
    "summary": "Automated cyber defense (ACD) seeks to protect computer networks with minimal or no human intervention, reacting to intrusions by taking corrective actions such as isolating hosts, resetting services, deploying decoys, or updating access controls. However, existing approaches for ACD, such as deep reinforcement learning (RL), often face difficult exploration in complex networks with large decision/state spaces and thus require an expensive amount of samples. Inspired by the need to learn sample-efficient defense policies, we frame ACD in CAGE Challenge 4 (CAGE-4 / CC4) as a context-based partially observable Markov decision problem and propose a planning-centric defense policy based on Monte Carlo Tree Search (MCTS). It explicitly models the exploration-exploitation tradeoff in ACD and uses statistical sampling to guide exploration and decision making. We make novel use of graph neural networks (GNNs) to embed observations from the network as attributed graphs, to enable permutation-invariant reasoning over hosts and their relationships. To make our solution practical in complex search spaces, we guide MCTS with learned graph embeddings and priors over graph-edit actions, combining model-free generalization and policy distillation with look-ahead planning. We evaluate the resulting agent on CC4 scenarios involving diverse network structures and adversary behaviors, and show that our search-guided, graph-embedding-based planning improves defense reward and robustness relative to state-of-the-art RL baselines.",
    "authors": [
      "Yu Li",
      "Sizhe Tang",
      "Rongqian Chen",
      "Fei Xu Yu",
      "Guangyu Jiang",
      "Mahdi Imani",
      "Nathaniel D. Bastian",
      "Tian Lan"
    ],
    "url": "http://arxiv.org/abs/2601.02196v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于图嵌入和蒙特卡洛树搜索的自动化网络防御方法，属于网络安全领域的AI应用，而非科学发现或细胞/分子扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02193v1",
    "title": "Learning with Monotone Adversarial Corruptions",
    "summary": "We study the extent to which standard machine learning algorithms rely on exchangeability and independence of data by introducing a monotone adversarial corruption model. In this model, an adversary, upon looking at a \"clean\" i.i.d. dataset, inserts additional \"corrupted\" points of their choice into the dataset. These added points are constrained to be monotone corruptions, in that they get labeled according to the ground-truth target function. Perhaps surprisingly, we demonstrate that in this setting, all known optimal learning algorithms for binary classification can be made to achieve suboptimal expected error on a new independent test point drawn from the same distribution as the clean dataset. On the other hand, we show that uniform convergence-based algorithms do not degrade in their guarantees. Our results showcase how optimal learning algorithms break down in the face of seemingly helpful monotone corruptions, exposing their overreliance on exchangeability.",
    "authors": [
      "Kasper Green Larsen",
      "Chirag Pabbaraju",
      "Abhishek Shetty"
    ],
    "url": "http://arxiv.org/abs/2601.02193v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文研究机器学习算法在单调对抗性数据污染下的鲁棒性，属于机器学习理论分析范畴，而非具体科学领域的AI应用或生物分子扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02189v1",
    "title": "QuIC: A Quantum-Inspired Interaction Classifier for Revitalizing Shallow CNNs in Fine-Grained Recognition",
    "summary": "Deploying deep learning models for Fine-Grained Visual Classification (FGVC) on resource-constrained edge devices remains a significant challenge. While deep architectures achieve high accuracy on benchmarks like CUB-200-2011, their computational cost is often prohibitive. Conversely, shallow networks (e.g., AlexNet, VGG) offer efficiency but fail to distinguish visually similar sub-categories. This is because standard Global Average Pooling (GAP) heads capture only first-order statistics, missing the subtle high-order feature interactions required for FGVC. While Bilinear CNNs address this, they suffer from high feature dimensionality and instability during training. To bridge this gap, we propose the Quantum-inspired Interaction Classifier (QuIC). Drawing inspiration from quantum mechanics, QuIC models feature channels as interacting quantum states and captures second-order feature covariance via a learnable observable operator. Designed as a lightweight, plug-and-play module, QuIC supports stable, single-stage end-to-end training without exploding feature dimensions. Experimental results demonstrate that QuIC significantly revitalizes shallow backbones: it boosts the Top-1 accuracy of VGG16 by nearly 20% and outperforms state-of-the-art attention mechanisms (SE-Block) on ResNet18. Qualitative analysis, including t-SNE visualization, further confirms that QuIC resolves ambiguous cases by explicitly attending to fine-grained discriminative features and enforcing compact intra-class clustering.",
    "authors": [
      "Cheng Ying Wu",
      "Yen Jui Chang"
    ],
    "url": "http://arxiv.org/abs/2601.02189v1",
    "published": "2026-01-05",
    "primary_category": "cs.CV",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出一种受量子力学启发的轻量级视觉分类模块，旨在提升浅层卷积神经网络在细粒度图像识别任务中的性能。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02172v1",
    "title": "A stable and accurate X-FFT solver for linear elastic homogenization problems in 3D",
    "summary": "Although FFT-based methods are renowned for their numerical efficiency and stability, traditional discretizations fail to capture material interfaces that are not aligned with the grid, resulting in suboptimal accuracy. To address this issue, the work at hand introduces a novel FFT-based solver that achieves interface-conforming accuracy for three-dimensional mechanical problems. More precisely, we integrate the extended finite element (X-FEM) discretization into the FFT-based framework, leveraging its ability to resolve discontinuities via additional shape functions. We employ the modified abs(olute) enrichment and develop a preconditioner based on the concept of strongly stable GFEM, which mitigates the conditioning issues observed in traditional X-FEM implementations. Our computational studies demonstrate that the developed X-FFT solver achieves interface-conforming accuracy, numerical efficiency, and stability when solving three-dimensional linear elastic homogenization problems with smooth material interfaces.",
    "authors": [
      "Flavia Gehrig",
      "Matti Schneider"
    ],
    "url": "http://arxiv.org/abs/2601.02172v1",
    "published": "2026-01-05",
    "primary_category": "cs.CE",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种结合扩展有限元法和FFT求解器的三维线性弹性均匀化计算方法，旨在提高材料界面模拟的精度和稳定性，属于计算力学领域而非AI4Science或扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02170v1",
    "title": "Streaming Hallucination Detection in Long Chain-of-Thought Reasoning",
    "summary": "Long chain-of-thought (CoT) reasoning improves the performance of large language models, yet hallucinations in such settings often emerge subtly and propagate across reasoning steps. We suggest that hallucination in long CoT reasoning is better understood as an evolving latent state rather than a one-off erroneous event. Accordingly, we treat step-level hallucination judgments as local observations and introduce a cumulative prefix-level hallucination signal that tracks the global evolution of the reasoning state over the entire trajectory. Overall, our approach enables streaming hallucination detection in long CoT reasoning, providing real-time, interpretable evidence.",
    "authors": [
      "Haolang Lu",
      "Minghui Pan",
      "Ripeng Li",
      "Guoshun Nan",
      "Jialin Zhuang",
      "Zijie Zhao",
      "Zhongxiang Sun",
      "Kun Wang",
      "Yang Liu"
    ],
    "url": "http://arxiv.org/abs/2601.02170v1",
    "published": "2026-01-05",
    "primary_category": "cs.AI",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种在长链思维推理中进行流式幻觉检测的方法，通过追踪累积前缀级信号来实时监控推理状态的演变。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02163v1",
    "title": "EverMemOS: A Self-Organizing Memory Operating System for Structured Long-Horizon Reasoning",
    "summary": "Large Language Models (LLMs) are increasingly deployed as long-term interactive agents, yet their limited context windows make it difficult to sustain coherent behavior over extended interactions. Existing memory systems often store isolated records and retrieve fragments, limiting their ability to consolidate evolving user states and resolve conflicts. We introduce EverMemOS, a self-organizing memory operating system that implements an engram-inspired lifecycle for computational memory. Episodic Trace Formation converts dialogue streams into MemCells that capture episodic traces, atomic facts, and time-bounded Foresight signals. Semantic Consolidation organizes MemCells into thematic MemScenes, distilling stable semantic structures and updating user profiles. Reconstructive Recollection performs MemScene-guided agentic retrieval to compose the necessary and sufficient context for downstream reasoning. Experiments on LoCoMo and LongMemEval show that EverMemOS achieves state-of-the-art performance on memory-augmented reasoning tasks. We further report a profile study on PersonaMem v2 and qualitative case studies illustrating chat-oriented capabilities such as user profiling and Foresight. Code is available at https://github.com/EverMind-AI/EverMemOS.",
    "authors": [
      "Chuanrui Hu",
      "Xingze Gao",
      "Zuyi Zhou",
      "Dannong Xu",
      "Yi Bai",
      "Xintong Li",
      "Hui Zhang",
      "Tong Li",
      "Chong Zhang",
      "Lidong Bing",
      "Yafeng Deng"
    ],
    "url": "http://arxiv.org/abs/2601.02163v1",
    "published": "2026-01-05",
    "primary_category": "cs.AI",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于增强大型语言模型长期推理能力的自组织记忆操作系统，属于人工智能系统架构研究，而非特定科学领域的AI应用或扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02158v1",
    "title": "FormationEval, an open multiple-choice benchmark for petroleum geoscience",
    "summary": "This paper presents FormationEval, an open multiple-choice question benchmark for evaluating language models on petroleum geoscience and subsurface disciplines. The dataset contains 505 questions across seven domains including petrophysics, petroleum geology and reservoir engineering, derived from three authoritative sources using a reasoning model with detailed instructions and a concept-based approach that avoids verbatim copying of copyrighted text. Each question includes source metadata to support traceability and audit. The evaluation covers 72 models from major providers including OpenAI, Anthropic, Google, Meta and open-weight alternatives. The top performers achieve over 97\\% accuracy, with Gemini 3 Pro Preview reaching 99.8\\%, while tier and domain gaps persist. Among open-weight models, GLM-4.7 leads at 98.6\\%, with several DeepSeek, Llama, Qwen and Mistral models also exceeding 93\\%. The performance gap between open-weight and closed models is narrower than expected, with several lower-cost open-weight models exceeding 90\\% accuracy. Petrophysics emerges as the most challenging domain across all models, while smaller models show wider performance variance. Residual length bias in the dataset (correct answers tend to be longer) is documented along with bias mitigation strategies applied during construction. The benchmark, evaluation code and results are publicly available.",
    "authors": [
      "Almaz Ermilov"
    ],
    "url": "http://arxiv.org/abs/2601.02158v1",
    "published": "2026-01-05",
    "primary_category": "cs.CL",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文通过构建石油地质科学的多选题基准数据集，评估语言模型在专业科学领域的应用能力，属于AI4Science范畴。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02157v1",
    "title": "Multi-fidelity graph-based neural networks architectures to learn Navier-Stokes solutions on non-parametrized 2D domains",
    "summary": "We propose a graph-based, multi-fidelity learning framework for the prediction of stationary Navier--Stokes solutions in non-parametrized two-dimensional geometries. The method is designed to guide the learning process through successive approximations, starting from reduced-order and full Stokes models, and progressively approaching the Navier--Stokes solution. To effectively capture both local and long-range dependencies in the velocity and pressure fields, we combine graph neural networks with Transformer and Mamba architectures. While Transformers achieve the highest accuracy, we show that Mamba can be successfully adapted to graph-structured data through an unsupervised node-ordering strategy. The Mamba approach significantly reduces computational cost while maintaining performance. Physical knowledge is embedded directly into the architecture through an encoding -- processing -- physics informed decoding pipeline. Derivatives are computed through algebraic operators constructed via the Weighted Least Squares method. The flexibility of these operators allows us not only to make the output obey the governing equations, but also to constrain selected hidden features to satisfy mass conservation. We introduce additional physical biases through an enriched graph convolution with the same differential operators describing the PDEs. Overall, we successfully guide the learning process by physical knowledge and fluid dynamics insights, leading to more regular and accurate predictions",
    "authors": [
      "Francesco Songia",
      "Raoul Sallé de Chou",
      "Hugues Talbot",
      "Irene Vignon-Clementel"
    ],
    "url": "http://arxiv.org/abs/2601.02157v1",
    "published": "2026-01-05",
    "primary_category": "physics.flu-dyn",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于图神经网络的多保真度学习框架，通过结合物理知识引导来预测非参数化二维几何中的Navier-Stokes方程解，属于AI在流体力学领域的科学应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02151v1",
    "title": "Entropy-Adaptive Fine-Tuning: Resolving Confident Conflicts to Mitigate Forgetting",
    "summary": "Supervised Fine-Tuning (SFT) is the standard paradigm for domain adaptation, yet it frequently incurs the cost of catastrophic forgetting. In sharp contrast, on-policy Reinforcement Learning (RL) effectively preserves general capabilities. We investigate this discrepancy and identify a fundamental distributional gap: while RL aligns with the model's internal belief, SFT forces the model to fit external supervision. This mismatch often manifests as \"Confident Conflicts\" tokens characterized by low probability but low entropy. In these instances, the model is highly confident in its own prediction but is forced to learn a divergent ground truth, triggering destructive gradient updates. To address this, we propose Entropy-Adaptive Fine-Tuning (EAFT). Unlike methods relying solely on prediction probability, EAFT utilizes token-level entropy as a gating mechanism to distinguish between epistemic uncertainty and knowledge conflict. This allows the model to learn from uncertain samples while suppressing gradients on conflicting data. Extensive experiments on Qwen and GLM series (ranging from 4B to 32B parameters) across mathematical, medical, and agentic domains confirm our hypothesis. EAFT consistently matches the downstream performance of standard SFT while significantly mitigating the degradation of general capabilities.",
    "authors": [
      "Muxi Diao",
      "Lele Yang",
      "Wuxuan Gong",
      "Yutong Zhang",
      "Zhonghao Yan",
      "Yufei Han",
      "Kongming Liang",
      "Weiran Xu",
      "Zhanyu Ma"
    ],
    "url": "http://arxiv.org/abs/2601.02151v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于熵的自适应微调方法来解决语言模型微调中的灾难性遗忘问题，属于机器学习方法改进研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02149v1",
    "title": "AI-enhanced tuning of quantum dot Hamiltonians toward Majorana modes",
    "summary": "We propose a neural network-based model capable of learning the broad landscape of working regimes in quantum dot simulators, and using this knowledge to autotune these devices - based on transport measurements - toward obtaining Majorana modes in the structure. The model is trained in an unsupervised manner on synthetic data in the form of conductance maps, using a physics-informed loss that incorporates key properties of Majorana zero modes. We show that, with appropriate training, a deep vision-transformer network can efficiently memorize relation between Hamiltonian parameters and structures on conductance maps and use it to propose parameters update for a quantum dot chain that drive the system toward topological phase. Starting from a broad range of initial detunings in parameter space, a single update step is sufficient to generate nontrivial zero modes. Moreover, by enabling an iterative tuning procedure - where the system acquires updated conductance maps at each step - we demonstrate that the method can address a much larger region of the parameter space.",
    "authors": [
      "Mateusz Krawczyk",
      "Jarosław Pawłowski"
    ],
    "url": "http://arxiv.org/abs/2601.02149v1",
    "published": "2026-01-05",
    "primary_category": "cond-mat.mes-hall",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于神经网络的量子点系统自动调谐方法，利用AI技术指导实验参数调整以实现拓扑相变和Majorana零模的获得，属于AI在物理学研究中的应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02147v1",
    "title": "BiPrompt: Bilateral Prompt Optimization for Visual and Textual Debiasing in Vision-Language Models",
    "summary": "Vision language foundation models such as CLIP exhibit impressive zero-shot generalization yet remain vulnerable to spurious correlations across visual and textual modalities. Existing debiasing approaches often address a single modality either visual or textual leading to partial robustness and unstable adaptation under distribution shifts. We propose a bilateral prompt optimization framework (BiPrompt) that simultaneously mitigates non-causal feature reliance in both modalities during test-time adaptation. On the visual side, it employs structured attention-guided erasure to suppress background activations and enforce orthogonal prediction consistency between causal and spurious regions. On the textual side, it introduces balanced prompt normalization, a learnable re-centering mechanism that aligns class embeddings toward an isotropic semantic space. Together, these modules jointly minimize conditional mutual information between spurious cues and predictions, steering the model toward causal, domain invariant reasoning without retraining or domain supervision. Extensive evaluations on real-world and synthetic bias benchmarks demonstrate consistent improvements in both average and worst-group accuracies over prior test-time debiasing methods, establishing a lightweight yet effective path toward trustworthy and causally grounded vision-language adaptation.",
    "authors": [
      "Sunny Gupta",
      "Shounak Das",
      "Amit Sethi"
    ],
    "url": "http://arxiv.org/abs/2601.02147v1",
    "published": "2026-01-05",
    "primary_category": "cs.CV",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种针对视觉语言模型的双边提示优化框架，通过同时减少视觉和文本模态中的非因果特征依赖来提升模型的去偏能力，属于计算机视觉与自然语言处理交叉领域的方法学研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02145v1",
    "title": "Feature-based Inversion of 2.5D Controlled Source Electromagnetic Data using Generative Priors",
    "summary": "In this study, we investigate feature-based 2.5D controlled source marine electromagnetic (mCSEM) data inversion using generative priors. Two-and-half dimensional modeling using finite difference method (FDM) is adopted to compute the response of horizontal electric dipole (HED) excitation. Rather than using a neural network to approximate the entire inverse mapping in a black-box manner, we adopt a plug-andplay strategy in which a variational autoencoder (VAE) is used solely to learn prior information on conductivity distributions. During the inversion process, the conductivity model is iteratively updated using the Gauss Newton method, while the model space is constrained by projections onto the learned VAE decoder. This framework preserves explicit control over data misfit and enables flexible adaptation to different survey configurations. Numerical and field experiments demonstrate that the proposed approach effectively incorporates prior information, improves reconstruction accuracy, and exhibits good generalization performance.",
    "authors": [
      "Hongyu Zhou",
      "Haoran Sun",
      "Rui Guo",
      "Maokun Li",
      "Fan Yang",
      "Shenheng Xu"
    ],
    "url": "http://arxiv.org/abs/2601.02145v1",
    "published": "2026-01-05",
    "primary_category": "physics.geo-ph",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文将变分自编码器作为先验约束应用于地球物理反演问题，属于AI在物理科学领域的研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02144v1",
    "title": "Routing by Analogy: kNN-Augmented Expert Assignment for Mixture-of-Experts",
    "summary": "Mixture-of-Experts (MoE) architectures scale large language models efficiently by employing a parametric \"router\" to dispatch tokens to a sparse subset of experts. Typically, this router is trained once and then frozen, rendering routing decisions brittle under distribution shifts. We address this limitation by introducing kNN-MoE, a retrieval-augmented routing framework that reuses optimal expert assignments from a memory of similar past cases. This memory is constructed offline by directly optimizing token-wise routing logits to maximize the likelihood on a reference set. Crucially, we use the aggregate similarity of retrieved neighbors as a confidence-driven mixing coefficient, thus allowing the method to fall back to the frozen router when no relevant cases are found. Experiments show kNN-MoE outperforms zero-shot baselines and rivals computationally expensive supervised fine-tuning.",
    "authors": [
      "Boxuan Lyu",
      "Soichiro Murakami",
      "Hidetaka Kamigaito",
      "Peinan Zhang"
    ],
    "url": "http://arxiv.org/abs/2601.02144v1",
    "published": "2026-01-05",
    "primary_category": "cs.CL",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于检索增强的路由框架kNN-MoE，用于改进混合专家模型在分布偏移下的路由决策，属于机器学习架构优化领域，而非特定科学发现或扰动预测应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02138v1",
    "title": "Edge-aware GAT-based protein binding site prediction",
    "summary": "Accurate identification of protein binding sites is crucial for understanding biomolecular interaction mechanisms and for the rational design of drug targets. Traditional predictive methods often struggle to balance prediction accuracy with computational efficiency when capturing complex spatial conformations. To address this challenge, we propose an Edge-aware Graph Attention Network (Edge-aware GAT) model for the fine-grained prediction of binding sites across various biomolecules, including proteins, DNA/RNA, ions, ligands, and lipids. Our method constructs atom-level graphs and integrates multidimensional structural features, including geometric descriptors, DSSP-derived secondary structure, and relative solvent accessibility (RSA), to generate spatially aware embedding vectors. By incorporating interatomic distances and directional vectors as edge features within the attention mechanism, the model significantly enhances its representation capacity. On benchmark datasets, our model achieves an ROC-AUC of 0.93 for protein-protein binding site prediction, outperforming several state-of-the-art methods. The use of directional tensor propagation and residue-level attention pooling further improves both binding site localization and the capture of local structural details. Visualizations using PyMOL confirm the model's practical utility and interpretability. To facilitate community access and application, we have deployed a publicly accessible web server at http://119.45.201.89:5000/. In summary, our approach offers a novel and efficient solution that balances prediction accuracy, generalization, and interpretability for identifying functional sites in proteins.",
    "authors": [
      "Weisen Yang",
      "Hanqing Zhang",
      "Wangren Qiu",
      "Xuan Xiao",
      "Weizhong Lin"
    ],
    "url": "http://arxiv.org/abs/2601.02138v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于图注意力网络的深度学习模型，用于预测蛋白质结合位点，属于AI在生物分子结构预测领域的应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02134v1",
    "title": "Complexity of quadratic penalty methods with adaptive accuracy under a PL condition for the constraints",
    "summary": "We study the quadratic penalty method (QPM) for smooth nonconvex optimization problems with equality constraints. Assuming the constraint violation satisfies the PL condition near the feasible set, we derive sharper worst-case complexity bounds for obtaining approximate first-order KKT points. When the objective and constraints are twice continuously differentiable, we show that QPM equipped with a suitable first-order inner solver requires at most $O(\\varepsilon_{0}^{-1}\\varepsilon_{1}^{-2})$ first-order oracle calls to find an $(\\varepsilon_{0},\\varepsilon_{1})$-approximate KKT point -- that is, a point that is $\\varepsilon_{0}$-approximately feasible and $\\varepsilon_{1}$-approximately stationary. Furthermore, when the objective and constraints are three times continuously differentiable, we show that QPM with a suitable second-order inner solver requires at most $O\\left(\\varepsilon_{0}^{-1/2}\\varepsilon_{1}^{-3/2}\\right)$ second-order oracle calls to find an $(\\varepsilon_{0},\\varepsilon_{1})$-approximate KKT point. We also introduce an adaptive, feasibility-aware stopping criterion for the subproblems, which relaxes the stationarity tolerance when far from feasibility. This rule preserves all theoretical guarantees while substantially reducing computational effort in practice.",
    "authors": [
      "Florentin Goyens",
      "Geovani N. Grapiglia"
    ],
    "url": "http://arxiv.org/abs/2601.02134v1",
    "published": "2026-01-05",
    "primary_category": "math.OC",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文研究非凸优化中二次惩罚方法的计算复杂度理论，属于数值优化领域的基础理论研究，与AI4Science或扰动预测无直接关联。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02126v1",
    "title": "Remote Sensing Change Detection via Weak Temporal Supervision",
    "summary": "Semantic change detection in remote sensing aims to identify land cover changes between bi-temporal image pairs. Progress in this area has been limited by the scarcity of annotated datasets, as pixel-level annotation is costly and time-consuming. To address this, recent methods leverage synthetic data or generate artificial change pairs, but out-of-domain generalization remains limited. In this work, we introduce a weak temporal supervision strategy that leverages additional temporal observations of existing single-temporal datasets, without requiring any new annotations. Specifically, we extend single-date remote sensing datasets with new observations acquired at different times and train a change detection model by assuming that real bi-temporal pairs mostly contain no change, while pairing images from different locations to generate change examples. To handle the inherent noise in these weak labels, we employ an object-aware change map generation and an iterative refinement process. We validate our approach on extended versions of the FLAIR and IAILD aerial datasets, achieving strong zero-shot and low-data regime performance across different benchmarks. Lastly, we showcase results over large areas in France, highlighting the scalability potential of our method.",
    "authors": [
      "Xavier Bou",
      "Elliot Vincent",
      "Gabriele Facciolo",
      "Rafael Grompone von Gioi",
      "Jean-Michel Morel",
      "Thibaud Ehret"
    ],
    "url": "http://arxiv.org/abs/2601.02126v1",
    "published": "2026-01-05",
    "primary_category": "cs.CV",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种利用弱时间监督的遥感变化检测方法，通过扩展单时相数据集并假设真实双时相对大多无变化来训练模型，属于AI在地球科学领域的应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02125v1",
    "title": "SingingBot: An Avatar-Driven System for Robotic Face Singing Performance",
    "summary": "Equipping robotic faces with singing capabilities is crucial for empathetic Human-Robot Interaction. However, existing robotic face driving research primarily focuses on conversations or mimicking static expressions, struggling to meet the high demands for continuous emotional expression and coherence in singing. To address this, we propose a novel avatar-driven framework for appealing robotic singing. We first leverage portrait video generation models embedded with extensive human priors to synthesize vivid singing avatars, providing reliable expression and emotion guidance. Subsequently, these facial features are transferred to the robot via semantic-oriented mapping functions that span a wide expression space. Furthermore, to quantitatively evaluate the emotional richness of robotic singing, we propose the Emotion Dynamic Range metric to measure the emotional breadth within the Valence-Arousal space, revealing that a broad emotional spectrum is crucial for appealing performances. Comprehensive experiments prove that our method achieves rich emotional expressions while maintaining lip-audio synchronization, significantly outperforming existing approaches.",
    "authors": [
      "Zhuoxiong Xu",
      "Xuanchen Li",
      "Yuhao Cheng",
      "Fei Xu",
      "Yichao Yan",
      "Xiaokang Yang"
    ],
    "url": "http://arxiv.org/abs/2601.02125v1",
    "published": "2026-01-05",
    "primary_category": "cs.RO",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于虚拟形象驱动的机器人面部歌唱表演系统，通过视频生成模型和语义映射实现情感丰富的机器人歌唱，属于人机交互与机器人技术领域。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02123v1",
    "title": "DeCode: Decoupling Content and Delivery for Medical QA",
    "summary": "Large language models (LLMs) exhibit strong medical knowledge and can generate factually accurate responses. However, existing models often fail to account for individual patient contexts, producing answers that are clinically correct yet poorly aligned with patients' needs. In this work, we introduce DeCode, a training-free, model-agnostic framework that adapts existing LLMs to produce contextualized answers in clinical settings. We evaluate DeCode on OpenAI HealthBench, a comprehensive and challenging benchmark designed to assess clinical relevance and validity of LLM responses. DeCode improves the previous state of the art from $28.4\\%$ to $49.8\\%$, corresponding to a $75\\%$ relative improvement. Experimental results suggest the effectiveness of DeCode in improving clinical question answering of LLMs.",
    "authors": [
      "Po-Jen Ko",
      "Chen-Han Tsai",
      "Yu-Shao Peng"
    ],
    "url": "http://arxiv.org/abs/2601.02123v1",
    "published": "2026-01-05",
    "primary_category": "cs.CL",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出DeCode框架，通过解耦内容和传递方式，使大型语言模型在医疗问答中能生成更符合患者个体化需求的临床响应。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02121v1",
    "title": "Inferring Network Evolutionary History via Structure-State Coupled Learning",
    "summary": "Inferring a network's evolutionary history from a single final snapshot with limited temporal annotations is fundamental yet challenging. Existing approaches predominantly rely on topology alone, which often provides insufficient and noisy cues. This paper leverages network steady-state dynamics -- converged node states under a given dynamical process -- as an additional and widely accessible observation for network evolution history inference. We propose CS$^2$, which explicitly models structure-state coupling to capture how topology modulates steady states and how the two signals jointly improve edge discrimination for formation-order recovery. Experiments on six real temporal networks, evaluated under multiple dynamical processes, show that CS$^2$ consistently outperforms strong baselines, improving pairwise edge precedence accuracy by 4.0% on average and global ordering consistency (Spearman-$ρ$) by 7.7% on average. CS$^2$ also more faithfully recovers macroscopic evolution trajectories such as clustering formation, degree heterogeneity, and hub growth. Moreover, a steady-state-only variant remains competitive when reliable topology is limited, highlighting steady states as an independent signal for evolution inference.",
    "authors": [
      "En Xu",
      "Shihe Zhou",
      "Huandong Wang",
      "Jingtao Ding",
      "Yong Li"
    ],
    "url": "http://arxiv.org/abs/2601.02121v1",
    "published": "2026-01-05",
    "primary_category": "cs.SI",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种结合网络拓扑与稳态动力学的AI方法，用于推断网络演化历史，属于AI在复杂系统科学发现中的应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02112v1",
    "title": "Car Drag Coefficient Prediction from 3D Point Clouds Using a Slice-Based Surrogate Model",
    "summary": "The automotive industry's pursuit of enhanced fuel economy and performance necessitates efficient aerodynamic design. However, traditional evaluation methods such as computational fluid dynamics (CFD) and wind tunnel testing are resource intensive, hindering rapid iteration in the early design stages. Machine learning-based surrogate models offer a promising alternative, yet many existing approaches suffer from high computational complexity, limited interpretability, or insufficient accuracy for detailed geometric inputs. This paper introduces a novel lightweight surrogate model for the prediction of the aerodynamic drag coefficient (Cd) based on a sequential slice-wise processing of the geometry of the 3D vehicle. Inspired by medical imaging, 3D point clouds of vehicles are decomposed into an ordered sequence of 2D cross-sectional slices along the stream-wise axis. Each slice is encoded by a lightweight PointNet2D module, and the sequence of slice embeddings is processed by a bidirectional LSTM to capture longitudinal geometric evolution. The model, trained and evaluated on the DrivAerNet++ dataset, achieves a high coefficient of determination (R^2 > 0.9528) and a low mean absolute error (MAE approx 6.046 x 10^{-3}) in Cd prediction. With an inference time of approximately 0.025 seconds per sample on a consumer-grade GPU, our approach provides fast, accurate, and interpretable aerodynamic feedback, facilitating more agile and informed automotive design exploration.",
    "authors": [
      "Utkarsh Singh",
      "Absaar Ali",
      "Adarsh Roy"
    ],
    "url": "http://arxiv.org/abs/2601.02112v1",
    "published": "2026-01-05",
    "primary_category": "cs.CV",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文将AI技术应用于汽车空气动力学设计，属于AI在物理科学领域的交叉研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02106v1",
    "title": "Prototype-Based Learning for Healthcare: A Demonstration of Interpretable AI",
    "summary": "Despite recent advances in machine learning and explainable AI, a gap remains in personalized preventive healthcare: predictions, interventions, and recommendations should be both understandable and verifiable for all stakeholders in the healthcare sector. We present a demonstration of how prototype-based learning can address these needs. Our proposed framework, ProtoPal, features both front- and back-end modes; it achieves superior quantitative performance while also providing an intuitive presentation of interventions and their simulated outcomes.",
    "authors": [
      "Ashish Rana",
      "Ammar Shaker",
      "Sascha Saralajew",
      "Takashi Suzuki",
      "Kosuke Yasuda",
      "Shintaro Kato",
      "Toshikazu Wada",
      "Toshiyuki Fujikawa",
      "Toru Kikutsuji"
    ],
    "url": "http://arxiv.org/abs/2601.02106v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于原型学习的可解释AI框架，专注于个性化预防医疗中的预测和干预展示，而非基础科学发现或分子层面的扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02105v1",
    "title": "LION-DG: Layer-Informed Initialization with Deep Gradient Protocols for Accelerated Neural Network Training",
    "summary": "Weight initialization remains decisive for neural network optimization, yet existing methods are largely layer-agnostic. We study initialization for deeply-supervised architectures with auxiliary classifiers, where untrained auxiliary heads can destabilize early training through gradient interference.   We propose LION-DG, a layer-informed initialization that zero-initializes auxiliary classifier heads while applying standard He-initialization to the backbone. We prove that this implements Gradient Awakening: auxiliary gradients are exactly zero at initialization, then phase in naturally as weights grow -- providing an implicit warmup without hyperparameters.   Experiments on CIFAR-10 and CIFAR-100 with DenseNet-DS and ResNet-DS architectures demonstrate: (1) DenseNet-DS: +8.3% faster convergence on CIFAR-10 with comparable accuracy, (2) Hybrid approach: Combining LSUV with LION-DG achieves best accuracy (81.92% on CIFAR-10), (3) ResNet-DS: Positive speedup on CIFAR-100 (+11.3%) with side-tap auxiliary design.   We identify architecture-specific trade-offs and provide clear guidelines for practitioners. LION-DG is simple, requires zero hyperparameters, and adds no computational overhead.",
    "authors": [
      "Hyunjun Kim"
    ],
    "url": "http://arxiv.org/abs/2601.02105v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种针对深度监督神经网络的层感知初始化方法，通过零初始化辅助分类器头来加速训练并稳定梯度，属于机器学习优化技术研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02094v1",
    "title": "Horizon Activation Mapping for Neural Networks in Time Series Forecasting",
    "summary": "Neural networks for time series forecasting have relied on error metrics and architecture-specific interpretability approaches for model selection that don't apply across models of different families. To interpret forecasting models agnostic to the types of layers across state-of-the-art model families, we introduce Horizon Activation Mapping (HAM), a visual interpretability technique inspired by grad-CAM that uses gradient norm averages to study the horizon's subseries where grad-CAM studies attention maps over image data. We introduce causal and anti-causal modes to calculate gradient update norm averages across subseries at every timestep and lines of proportionality signifying uniform distributions of the norm averages. Optimization landscape studies with respect to changes in batch sizes, early stopping, train-val-test splits, univariate forecasting and dropouts are studied with respect to performances and subseries in HAM. Interestingly, batch size based differences in activities seem to indicate potential for existence of an exponential approximation across them per epoch relative to each other. Multivariate forecasting models including MLP-based CycleNet, N-Linear, N-HITS, self attention-based FEDformer, Pyraformer, SSM-based SpaceTime and diffusion-based Multi-Resolution DDPM over different horizon sizes trained over the ETTm2 dataset are used for HAM plots in this study. NHITS' neural approximation theorem and SpaceTime's exponential autoregressive activities have been attributed to trends in HAM plots over their training, validation and test sets. In general, HAM can be used for granular model selection, validation set choices and comparisons across different neural network model families.",
    "authors": [
      "Hans Krupakar",
      "V A Kandappan"
    ],
    "url": "http://arxiv.org/abs/2601.02094v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于时间序列预测神经网络模型的可视化解释方法，专注于模型选择和跨模型比较，而非特定科学领域的发现或细胞扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02093v1",
    "title": "Optimal Spectral Inequality for the Higher-Dimensional Landau Operator",
    "summary": "We prove optimal spectral inequalities for Landau operators in full space and in arbitrary dimension. Spectral inequalities are lower bounds on the L 2 -mass of functions in spectral subspaces of finite energy when integrated over a sampling set S $\\subset$ R d . Landau operators are Schr{ö}dinger operators associated with a constant magnetic field of the form (-$\\nabla$ + A(x)) 2 where A is a -in case of non-vanishing magnetic field -unbounded vector potential. Our strategy relies on so-called magnetic Bernstein estimates and analyticity, adapting an approach used by Kovrijkine in the context of the Logvinenko-Sereda theorem. We generalize results previously only known in dimension d = 2. The main difficulty in dimension d $\\ge$ 3 are the magnetic Bernstein inequalities which, in comparison to the twodimensional case, lead to additional complications and require more delicate estimates. Our results have immediate consequences for control theory, spectral theory and mathematical physics which we comment on.",
    "authors": [
      "Sedef Özcan",
      "Matthias Täufer"
    ],
    "url": "http://arxiv.org/abs/2601.02093v1",
    "published": "2026-01-05",
    "primary_category": "math.AP",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文通过推广Kovrijkine方法，证明了高维Landau算子的最优谱不等式，属于数学物理中的谱理论和控制理论研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02085v1",
    "title": "Vision-Based Early Fault Diagnosis and Self-Recovery for Strawberry Harvesting Robots",
    "summary": "Strawberry harvesting robots faced persistent challenges such as low integration of visual perception, fruit-gripper misalignment, empty grasping, and strawberry slippage from the gripper due to insufficient gripping force, all of which compromised harvesting stability and efficiency in orchard environments. To overcome these issues, this paper proposed a visual fault diagnosis and self-recovery framework that integrated multi-task perception with corrective control strategies. At the core of this framework was SRR-Net, an end-to-end multi-task perception model that simultaneously performed strawberry detection, segmentation, and ripeness estimation, thereby unifying visual perception with fault diagnosis. Based on this integrated perception, a relative error compensation method based on the simultaneous target-gripper detection was designed to address positional misalignment, correcting deviations when error exceeded the tolerance threshold. To mitigate empty grasping and fruit-slippage faults, an early abort strategy was implemented. A micro-optical camera embedded in the end-effector provided real-time visual feedback, enabling grasp detection during the deflating stage and strawberry slip prediction during snap-off through MobileNet V3-Small classifier and a time-series LSTM classifier. Experiments demonstrated that SRR-Net maintained high perception accuracy. For detection, it achieved a precision of 0.895 and recall of 0.813 on strawberries, and 0.972/0.958 on hands. In segmentation, it yielded a precision of 0.887 and recall of 0.747 for strawberries, and 0.974/0.947 for hands. For ripeness estimation, SRR-Net attained a mean absolute error of 0.035, while simultaneously supporting multi-task perception and sustaining a competitive inference speed of 163.35 FPS.",
    "authors": [
      "Meili Sun",
      "Chunjiang Zhao",
      "Lichao Yang",
      "Hao Liu",
      "Shimin Hu",
      "Ya Xiong"
    ],
    "url": "http://arxiv.org/abs/2601.02085v1",
    "published": "2026-01-05",
    "primary_category": "cs.RO",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于视觉感知的草莓采摘机器人故障诊断与自恢复框架，属于农业机器人应用研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02084v1",
    "title": "A Perturbed DCA for Computing d-Stationary Points of Nonsmooth DC Programs",
    "summary": "This paper introduces an efficient perturbed difference-of-convex algorithm (pDCA) for computing d-stationary points of an important class of structured nonsmooth difference-of-convex problems. Compared to the principal algorithms introduced in [J.-S. Pang, M. Razaviyayn, and A. Alvarado, Math. Oper. Res. 42(1):95--118 (2017)], which may require solving several subproblems for a one-step update, pDCA only requires solving a single subproblem. Therefore, the computational cost of pDCA for one-step update is comparable to the widely used difference-of-convex algorithm (DCA) introduced in [D. T. Pham and H. A. Le Thi, Acta Math. Vietnam. 22(1):289--355 (1997)] for computing a critical point. Importantly, under practical assumptions, we prove that every accumulation point of the sequence generated by pDCA is a d-stationary point almost surely. Numerical experiment results on several important examples of nonsmooth DC programs demonstrate the efficiency of pDCA for computing d-stationary points.",
    "authors": [
      "Zhangcheng Feng",
      "Yancheng Yuan"
    ],
    "url": "http://arxiv.org/abs/2601.02084v1",
    "published": "2026-01-05",
    "primary_category": "math.OC",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种扰动差分凸算法，用于计算非光滑差分凸问题的d-稳定点，属于优化算法领域，不涉及AI4Science或细胞/基因扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02081v1",
    "title": "A Differentiable Adversarial Framework for Task-Aware Data Subsampling",
    "summary": "The proliferation of large-scale datasets poses a major computational challenge to model training. The traditional data subsampling method works as a static, task independent preprocessing step which usually discards information that is critical to downstream prediction. In this paper, we introduces the antagonistic soft selection subsampling (ASSS) framework as is a novel paradigm that reconstructs data reduction into a differentiable end-to-end learning problem. ASSS uses the adversarial game between selector network and task network, and selector network learning assigns continuous importance weights to samples. This direct optimization implemented by Gumbel-Softmax relaxation allows the selector to identify and retain samples with the maximum amount of information for a specific task target under the guidance of the loss function that balances the fidelity and sparsity of the prediction. Theoretical analysis links this framework with the information bottleneck principle. Comprehensive experiments on four large-scale real world datasets show that ASSS has always been better than heuristic subsampling baselines such as clustering and nearest neighbor thinning in maintaining model performance. It is worth noting that ASSS can not only match, but also sometimes exceed the training performance of the entire dataset, showcasing the effect of intelligent denoising. This work establishes task aware data subsampling as a learnable component, providing a principled solution for effective large-scale data learning.",
    "authors": [
      "Jiacheng Lyu",
      "Bihua Bao"
    ],
    "url": "http://arxiv.org/abs/2601.02081v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种可微分的对抗性框架，用于任务感知的数据子采样，通过优化选择器网络来保留对特定任务最关键的样本信息。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02080v1",
    "title": "The Homogeneity Trap: Spectral Collapse in Doubly-Stochastic Deep Networks",
    "summary": "Doubly-stochastic matrices (DSM) are increasingly utilized in structure-preserving deep architectures -- such as Optimal Transport layers and Sinkhorn-based attention -- to enforce numerical stability and probabilistic interpretability. In this work, we identify a critical spectral degradation phenomenon inherent to these constraints, termed the Homogeneity Trap. We demonstrate that the maximum-entropy bias, typical of Sinkhorn-based projections, drives the mixing operator towards the uniform barycenter, thereby suppressing the subdominant singular value σ_2 and filtering out high-frequency feature components. We derive a spectral bound linking σ_2 to the network's effective depth, showing that high-entropy constraints restrict feature transformation to a shallow effective receptive field. Furthermore, we formally demonstrate that Layer Normalization fails to mitigate this collapse in noise-dominated regimes; specifically, when spectral filtering degrades the Signal-to-Noise Ratio (SNR) below a critical threshold, geometric structure is irreversibly lost to noise-induced orthogonal collapse. Our findings highlight a fundamental trade-off between entropic stability and spectral expressivity in DSM-constrained networks.",
    "authors": [
      "Yizhi Liu"
    ],
    "url": "http://arxiv.org/abs/2601.02080v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文聚焦于深度神经网络架构中双重随机矩阵约束引发的谱退化现象，属于机器学习理论分析而非具体科学领域的AI应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02076v1",
    "title": "Deferred Commitment Decoding for Diffusion Language Models with Confidence-Aware Sliding Windows",
    "summary": "Diffusion language models (DLMs) have recently emerged as a strong alternative to autoregressive models by enabling parallel text generation. To improve inference efficiency and KV-cache compatibility, prior work commonly adopts block-based diffusion, decoding tokens block by block. However, this paradigm suffers from a structural limitation that we term Boundary-Induced Context Truncation (BICT): undecoded tokens near block boundaries are forced to commit without access to nearby future context, even when such context could substantially reduce uncertainty. This limitation degrades decoding confidence and generation quality, especially for tasks requiring precise reasoning, such as mathematical problem solving and code generation. We propose Deferred Commitment Decoding (DCD), a novel, training-free decoding strategy that mitigates this issue. DCD maintains a confidence-aware sliding window over masked tokens, resolving low-uncertainty tokens early while deferring high-uncertainty tokens until sufficient contextual evidence becomes available. This design enables effective bidirectional information flow within the decoding window without sacrificing efficiency. Extensive experiments across multiple diffusion language models, benchmarks, and caching configurations show that DCD improves generation accuracy by 1.39% with comparable time on average compared to fixed block-based diffusion methods, with the most significant improvement reaching 9.0%. These results demonstrate that deferring token commitment based on uncertainty is a simple yet effective principle for improving both the quality and efficiency of diffusion language model decoding.",
    "authors": [
      "Yingte Shu",
      "Yuchuan Tian",
      "Chao Xu",
      "Yunhe Wang",
      "Hanting Chen"
    ],
    "url": "http://arxiv.org/abs/2601.02076v1",
    "published": "2026-01-05",
    "primary_category": "cs.CL",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于扩散语言模型的无训练解码策略，通过置信感知滑动窗口延迟高不确定性标记的生成，以提高文本生成质量和推理效率，而非应用于科学发现或扰动预测领域。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02075v1",
    "title": "MDAgent2: Large Language Model for Code Generation and Knowledge Q&A in Molecular Dynamics",
    "summary": "Molecular dynamics (MD) simulations are essential for understanding atomic-scale behaviors in materials science, yet writing LAMMPS scripts remains highly specialized and time-consuming tasks. Although LLMs show promise in code generation and domain-specific question answering, their performance in MD scenarios is limited by scarce domain data, the high deployment cost of state-of-the-art LLMs, and low code executability. Building upon our prior MDAgent, we present MDAgent2, the first end-to-end framework capable of performing both knowledge Q&A and code generation within the MD domain. We construct a domain-specific data-construction pipeline that yields three high-quality datasets spanning MD knowledge, question answering, and code generation. Based on these datasets, we adopt a three stage post-training strategy--continued pre-training (CPT), supervised fine-tuning (SFT), and reinforcement learning (RL)--to train two domain-adapted models, MD-Instruct and MD-Code. Furthermore, we introduce MD-GRPO, a closed-loop RL method that leverages simulation outcomes as reward signals and recycles low-reward trajectories for continual refinement. We further build MDAgent2-RUNTIME, a deployable multi-agent system that integrates code generation, execution, evaluation, and self-correction. Together with MD-EvalBench proposed in this work, the first benchmark for LAMMPS code generation and question answering, our models and system achieve performance surpassing several strong baselines.This work systematically demonstrates the adaptability and generalization capability of large language models in industrial simulation tasks, laying a methodological foundation for automatic code generation in AI for Science and industrial-scale simulations. URL: https://github.com/FredericVAN/PKU_MDAgent2",
    "authors": [
      "Zhuofan Shi",
      "Hubao A",
      "Yufei Shao",
      "Mengyan Dai",
      "Yadong Yu",
      "Pan Xiang",
      "Dongliang Huang",
      "Hongxu An",
      "Chunxiao Xin",
      "Haiyang Shen",
      "Zhenyu Wang",
      "Yunshan Na",
      "Gang Huang",
      "Xiang Jing"
    ],
    "url": "http://arxiv.org/abs/2601.02075v1",
    "published": "2026-01-05",
    "primary_category": "cs.CE",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文开发了MDAgent2框架，利用大语言模型为分子动力学模拟自动生成可执行代码，属于AI4Science领域在材料科学中的应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02071v1",
    "title": "FormuLLA: A Large Language Model Approach to Generating Novel 3D Printable Formulations",
    "summary": "Pharmaceutical three-dimensional (3D) printing is an advanced fabrication technology with the potential to enable truly personalised dosage forms. Recent studies have integrated artificial intelligence (AI) to accelerate formulation and process development, drastically transforming current approaches to pharmaceutical 3D printing. To date, most AI-driven efforts remain narrowly focused, while failing to account for the broader formulation challenges inherent to the technology. Recent advances in AI have introduced artificial general intelligence concepts, wherein systems extend beyond conventional predictive modelling toward more generalised, human-like reasoning. In this work, we investigate the application of large language models (LLMs), fine-tuned on a fused deposition modelling (FDM) dataset comprising over 1400 formulations, to recommend suitable excipients based on active pharmaceutical ingredient (API) dose, and predict filament mechanical properties. Four LLM architectures were fine-tuned, with systematic evaluation of both fine-tuning and generative parameter configurations. Our results demonstrate that Llama2 was best suited for recommending excipients for FDM formulations. Additionally, model selection and parameterisation significantly influence performance, with smaller LLMs exhibiting instances of catastrophic forgetting. Furthermore, we demonstrate: (i) even with relatively small dataset of over 1400 formulations, it can lead to model catastrophic forgetting; (ii) standard LLM metrics only evaluate linguistic performance but not formulation processability; and (iii) LLMs trained on biomedically-related data do not always produce the best results. Addressing these challenges is essential to advancing LLMs beyond linguistic proficiency and toward reliable systems for pharmaceutical formulation development.",
    "authors": [
      "Adeshola Okubena",
      "Yusuf Ali Mohammed",
      "Moe Elbadawi"
    ],
    "url": "http://arxiv.org/abs/2601.02071v1",
    "published": "2026-01-05",
    "primary_category": "cs.AI",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该研究将大型语言模型应用于药物制剂开发，属于人工智能在化学与制药科学领域的应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02065v1",
    "title": "Cost-Efficient Cross-Lingual Retrieval-Augmented Generation for Low-Resource Languages: A Case Study in Bengali Agricultural Advisory",
    "summary": "Access to reliable agricultural advisory remains limited in many developing regions due to a persistent language barrier: authoritative agricultural manuals are predominantly written in English, while farmers primarily communicate in low-resource local languages such as Bengali. Although recent advances in Large Language Models (LLMs) enable natural language interaction, direct generation in low-resource languages often exhibits poor fluency and factual inconsistency, while cloud-based solutions remain cost-prohibitive. This paper presents a cost-efficient, cross-lingual Retrieval-Augmented Generation (RAG) framework for Bengali agricultural advisory that emphasizes factual grounding and practical deployability. The proposed system adopts a translation-centric architecture in which Bengali user queries are translated into English, enriched through domain-specific keyword injection to align colloquial farmer terminology with scientific nomenclature, and answered via dense vector retrieval over a curated corpus of English agricultural manuals (FAO, IRRI). The generated English response is subsequently translated back into Bengali to ensure accessibility. The system is implemented entirely using open-source models and operates on consumer-grade hardware without reliance on paid APIs. Experimental evaluation demonstrates reliable source-grounded responses, robust rejection of out-of-domain queries, and an average end-to-end latency below 20 seconds. The results indicate that cross-lingual retrieval combined with controlled translation offers a practical and scalable solution for agricultural knowledge access in low-resource language settings",
    "authors": [
      "Md. Asif Hossain",
      "Nabil Subhan",
      "Mantasha Rahman Mahi",
      "Jannatul Ferdous Nabila"
    ],
    "url": "http://arxiv.org/abs/2601.02065v1",
    "published": "2026-01-05",
    "primary_category": "cs.CL",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种跨语言检索增强生成框架，旨在解决低资源语言环境下农业咨询的获取问题，而非用于科学发现或扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02061v1",
    "title": "Higher-Order Action Regularization in Deep Reinforcement Learning: From Continuous Control to Building Energy Management",
    "summary": "Deep reinforcement learning agents often exhibit erratic, high-frequency control behaviors that hinder real-world deployment due to excessive energy consumption and mechanical wear. We systematically investigate action smoothness regularization through higher-order derivative penalties, progressing from theoretical understanding in continuous control benchmarks to practical validation in building energy management. Our comprehensive evaluation across four continuous control environments demonstrates that third-order derivative penalties (jerk minimization) consistently achieve superior smoothness while maintaining competitive performance. We extend these findings to HVAC control systems where smooth policies reduce equipment switching by 60%, translating to significant operational benefits. Our work establishes higher-order action regularization as an effective bridge between RL optimization and operational constraints in energy-critical applications.",
    "authors": [
      "Faizan Ahmed",
      "Aniket Dixit",
      "James Brusey"
    ],
    "url": "http://arxiv.org/abs/2601.02061v1",
    "published": "2026-01-05",
    "primary_category": "cs.AI",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文通过高阶动作正则化技术优化强化学习控制策略的平滑性，应用于建筑能源管理以降低设备能耗，属于工程应用而非基础科学发现。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02060v1",
    "title": "Perish or Flourish? A Holistic Evaluation of Large Language Models for Code Generation in Functional Programming",
    "summary": "Functional programming provides strong foundations for developing reliable and secure software systems, yet its adoption remains not widespread due to the steep learning curve. Recent advances in Large Language Models (LLMs) for code generation present new opportunities to lower these barriers. However, extensive evaluations of LLMs largely focus on imperative programming languages, and their capabilities in functional programming languages (FP) remain underexplored. To address this gap, we introduce FPEval, a holistic evaluation framework built on FPBench, a new benchmark of 721 programming tasks across three difficulty levels on three mainstream FP languages: Haskell, Ocaml and Scala. FPEval provides compehensive evaluation infrastructures with both test validations with comprehensive test suites and static analysis tools to assess both functional correctness and code style and maintainability. Using this framework, we evaluate state-of-the-art LLMs, including GPT-3.5, GPT-4o, and GPT-5, for code generation in functional programming languages and Java as an imperative baseline. Our results demonstrate that LLM performance in functional programming improves substantially with model advancement; however, error rates remain significantly higher in purely functional languages (Haskell and OCaml) than in hybrid (Scala) or imperative (Java) languages. Moreover, LLMs frequently generate non-idiomatic functional code that follows imperative patterns, raising concerns about code style and long-term maintainability. Finally, we show that LLMs can partially self-repair both correctness and quality issues when provided with static analysis feedback and hand-crafted instructions for common types of issues.",
    "authors": [
      "Nguyet-Anh H. Lang",
      "Eric Lang",
      "Thanh Le-Cong",
      "Bach Le",
      "Quyet-Thang Huynh"
    ],
    "url": "http://arxiv.org/abs/2601.02060v1",
    "published": "2026-01-05",
    "primary_category": "cs.PL",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于评估大语言模型在函数式编程语言中的代码生成能力，属于计算机科学和软件工程领域，而非AI4Science或扰动预测的生物医学研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02050v1",
    "title": "Explore the Ideology of Deep Learning in ENSO Forecasts",
    "summary": "The El Ni{~n}o-Southern Oscillation (ENSO) exerts profound influence on global climate variability, yet its prediction remains a grand challenge. Recent advances in deep learning have significantly improved forecasting skill, but the opacity of these models hampers scientific trust and operational deployment. Here, we introduce a mathematically grounded interpretability framework based on bounded variation function. By rescuing the \"dead\" neurons from the saturation zone of the activation function, we enhance the model's expressive capacity. Our analysis reveals that ENSO predictability emerges dominantly from the tropical Pacific, with contributions from the Indian and Atlantic Oceans, consistent with physical understanding. Controlled experiments affirm the robustness of our method and its alignment with established predictors. Notably, we probe the persistent Spring Predictability Barrier (SPB), finding that despite expanded sensitivity during spring, predictive performance declines-likely due to suboptimal variable selection. These results suggest that incorporating additional ocean-atmosphere variables may help transcend SPB limitations and advance long-range ENSO prediction.",
    "authors": [
      "Yanhai Gan",
      "Yipeng Chen",
      "Ning Li",
      "Xingguo Liu",
      "Junyu Dong",
      "Xianyao Chen"
    ],
    "url": "http://arxiv.org/abs/2601.02050v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文通过深度学习模型的可解释性框架，揭示了ENSO预测的物理机制，属于AI在气候科学领域的应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02046v1",
    "title": "Agentic Retoucher for Text-To-Image Generation",
    "summary": "Text-to-image (T2I) diffusion models such as SDXL and FLUX have achieved impressive photorealism, yet small-scale distortions remain pervasive in limbs, face, text and so on. Existing refinement approaches either perform costly iterative re-generation or rely on vision-language models (VLMs) with weak spatial grounding, leading to semantic drift and unreliable local edits. To close this gap, we propose Agentic Retoucher, a hierarchical decision-driven framework that reformulates post-generation correction as a human-like perception-reasoning-action loop. Specifically, we design (1) a perception agent that learns contextual saliency for fine-grained distortion localization under text-image consistency cues, (2) a reasoning agent that performs human-aligned inferential diagnosis via progressive preference alignment, and (3) an action agent that adaptively plans localized inpainting guided by user preference. This design integrates perceptual evidence, linguistic reasoning, and controllable correction into a unified, self-corrective decision process. To enable fine-grained supervision and quantitative evaluation, we further construct GenBlemish-27K, a dataset of 6K T2I images with 27K annotated artifact regions across 12 categories. Extensive experiments demonstrate that Agentic Retoucher consistently outperforms state-of-the-art methods in perceptual quality, distortion localization and human preference alignment, establishing a new paradigm for self-corrective and perceptually reliable T2I generation.",
    "authors": [
      "Shaocheng Shen",
      "Jianfeng Liang. Chunlei Cai",
      "Cong Geng",
      "Huiyu Duan",
      "Xiaoyun Zhang",
      "Qiang Hu",
      "Guangtao Zhai"
    ],
    "url": "http://arxiv.org/abs/2601.02046v1",
    "published": "2026-01-05",
    "primary_category": "cs.CV",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于分层决策框架的文本到图像生成后处理修正方法，通过感知-推理-行动循环机制提升图像质量，属于计算机视觉与生成式AI领域。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02045v1",
    "title": "The New Compiler Stack: A Survey on the Synergy of LLMs and Compilers",
    "summary": "This survey has provided a systematic overview of the emerging field of LLM-enabled compilation by addressing several key research questions. We first answered how LLMs are being integrated by proposing a comprehensive, multi-dimensional taxonomy that categorizes works based on their Design Philosophy (Selector, Translator, Generator), LLM Methodology, their operational Level of Code Abstraction, and the specific Task Type they address. In answering what advancements these approaches offer, we identified three primary benefits: the democratization of compiler development, the discovery of novel optimization strategies, and the broadening of the compiler's traditional scope. Finally, in addressing the field's challenges and opportunities, we highlighted the critical hurdles of ensuring correctness and achieving scalability, while identifying the development of hybrid systems as the most promising path forward. By providing these answers, this survey serves as a foundational roadmap for researchers and practitioners, charting the course for a new generation of LLM-powered, intelligent, adaptive and synergistic compilation tools.",
    "authors": [
      "Shuoming Zhang",
      "Jiacheng Zhao",
      "Qiuchu Yu",
      "Chunwei Xia",
      "Zheng Wang",
      "Xiaobing Feng",
      "Huimin Cui"
    ],
    "url": "http://arxiv.org/abs/2601.02045v1",
    "published": "2026-01-05",
    "primary_category": "cs.PL",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文综述了大型语言模型在编译器技术中的应用，属于计算机科学领域而非生物学、化学或物理学等自然科学中的科学发现。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02043v1",
    "title": "Simulated Reasoning is Reasoning",
    "summary": "Reasoning has long been understood as a pathway between stages of understanding. Proper reasoning leads to understanding of a given subject. This reasoning was conceptualized as a process of understanding in a particular way, i.e., \"symbolic reasoning\". Foundational Models (FM) demonstrate that this is not a necessary condition for many reasoning tasks: they can \"reason\" by way of imitating the process of \"thinking out loud\", testing the produced pathways, and iterating on these pathways on their own. This leads to some form of reasoning that can solve problems on its own or with few-shot learning, but appears fundamentally different from human reasoning due to its lack of grounding and common sense, leading to brittleness of the reasoning process. These insights promise to substantially alter our assessment of reasoning and its necessary conditions, but also inform the approaches to safety and robust defences against this brittleness of FMs. This paper offers and discusses several philosophical interpretations of this phenomenon, argues that the previously apt metaphor of the \"stochastic parrot\" has lost its relevance and thus should be abandoned, and reflects on different normative elements in the safety- and appropriateness-considerations emerging from these reasoning models and their growing capacity.",
    "authors": [
      "Hendrik Kempt",
      "Alon Lavie"
    ],
    "url": "http://arxiv.org/abs/2601.02043v1",
    "published": "2026-01-05",
    "primary_category": "cs.AI",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文主要探讨基础模型的推理机制及其哲学意义，而非将AI应用于具体科学发现或预测生物扰动响应。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02037v1",
    "title": "Multivariate Time-series Anomaly Detection via Dynamic Model Pool & Ensembling",
    "summary": "Multivariate time-series (MTS) anomaly detection is critical in domains such as service monitor, IoT, and network security. While multi-model methods based on selection or ensembling outperform single-model ones, they still face limitations: (i) selection methods rely on a single chosen model and are sensitive to the strategy; (ii) ensembling methods often combine all models or are restricted to univariate data; and (iii) most methods depend on fixed data dimensionality, limiting scalability. To address these, we propose DMPEAD, a Dynamic Model Pool and Ensembling framework for MTS Anomaly Detection. The framework first (i) constructs a diverse model pool via parameter transfer and diversity metric, then (ii) updates it with a meta-model and similarity-based strategy for adaptive pool expansion, subset selection, and pool merging, finally (iii) ensembles top-ranked models through proxy metric ranking and top-k aggregation in the selected subset, outputting the final anomaly detection result. Extensive experiments on 8 real-world datasets show that our model outperforms all baselines, demonstrating superior adaptability and scalability.",
    "authors": [
      "Wei Hu",
      "Zewei Yu",
      "Jianqiu Xu"
    ],
    "url": "http://arxiv.org/abs/2601.02037v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于多元时间序列异常检测的动态模型池集成框架，属于通用机器学习方法在服务监控、物联网和网络安全等工程领域的应用，而非针对特定科学发现或细胞/分子扰动预测的研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02036v1",
    "title": "GDRO: Group-level Reward Post-training Suitable for Diffusion Models",
    "summary": "Recent advancements adopt online reinforcement learning (RL) from LLMs to text-to-image rectified flow diffusion models for reward alignment. The use of group-level rewards successfully aligns the model with the targeted reward. However, it faces challenges including low efficiency, dependency on stochastic samplers, and reward hacking. The problem is that rectified flow models are fundamentally different from LLMs: 1) For efficiency, online image sampling takes much more time and dominates the time of training. 2) For stochasticity, rectified flow is deterministic once the initial noise is fixed. Aiming at these problems and inspired by the effects of group-level rewards from LLMs, we design Group-level Direct Reward Optimization (GDRO). GDRO is a new post-training paradigm for group-level reward alignment that combines the characteristics of rectified flow models. Through rigorous theoretical analysis, we point out that GDRO supports full offline training that saves the large time cost for image rollout sampling. Also, it is diffusion-sampler-independent, which eliminates the need for the ODE-to-SDE approximation to obtain stochasticity. We also empirically study the reward hacking trap that may mislead the evaluation, and involve this factor in the evaluation using a corrected score that not only considers the original evaluation reward but also the trend of reward hacking. Extensive experiments demonstrate that GDRO effectively and efficiently improves the reward score of the diffusion model through group-wise offline optimization across the OCR and GenEval tasks, while demonstrating strong stability and robustness in mitigating reward hacking.",
    "authors": [
      "Yiyang Wang",
      "Xi Chen",
      "Xiaogang Xu",
      "Yu Liu",
      "Hengshuang Zhao"
    ],
    "url": "http://arxiv.org/abs/2601.02036v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于扩散模型奖励对齐的群体级直接奖励优化方法，专注于提升文本到图像生成模型的性能评估效率与稳定性。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02031v1",
    "title": "Output Embedding Centering for Stable LLM Pretraining",
    "summary": "Pretraining of large language models is not only expensive but also prone to certain training instabilities. A specific instability that often occurs for large learning rates at the end of training is output logit divergence. The most widely used mitigation strategy, z-loss, merely addresses the symptoms rather than the underlying cause of the problem. In this paper, we analyze the instability from the perspective of the output embeddings' geometry and identify its cause. Based on this, we propose output embedding centering (OEC) as a new mitigation strategy, and prove that it suppresses output logit divergence. OEC can be implemented in two different ways, as a deterministic operation called μ-centering, or a regularization method called μ-loss. Our experiments show that both variants outperform z-loss in terms of training stability and learning rate sensitivity. In particular, they ensure that training converges even for large learning rates when z-loss fails. Furthermore, we find that μ-loss is significantly less sensitive to regularization hyperparameter tuning than z-loss.",
    "authors": [
      "Felix Stollenwerk",
      "Anna Lokrantz",
      "Niclas Hertzberg"
    ],
    "url": "http://arxiv.org/abs/2601.02031v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出输出嵌入中心化方法以解决大语言模型预训练中的输出对数发散不稳定问题，属于基础模型训练优化技术。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02023v1",
    "title": "Not All Needles Are Found: How Fact Distribution and Don't Make It Up Prompts Shape Literal Extraction, Logical Inference, and Hallucination Risks in Long-Context LLMs",
    "summary": "Large language models (LLMs) increasingly support very long input contexts. Yet it remains unclear how reliably they extract and infer information at scale. Performance varies with context length and strongly interacts with how information is distributed in real-world corpora. Motivated by these observations, we study how fact placement, corpus-level fact distributions, and Don't Make It Up prompts influence model behavior. We introduce an extended needle-in-a-haystack benchmark across four production-scale models: Gemini-2.5-flash, ChatGPT-5-mini, Claude-4.5-haiku, and Deepseek-v3.2-chat. Unlike prior work, we separately evaluate literal extraction, logical inference, and hallucination risk. Our study considers both positional effects and realistic distributions of evidence across long contexts, as well as prompts that explicitly discourage fabrication. We find that longer contexts alone do not guarantee better performance and can be detrimental when relevant evidence is diluted or widely dispersed. Performance varies substantially across models: some show severe degradation under realistic conditions, while others remain more robust at longer context lengths. Anti-hallucination (AH) instructions can make some models overly conservative, sharply reducing accuracy in literal extraction and logical inference. While we do not directly compare retrieval-augmented generation (RAG) and cache-augmented generation (CAG), our results suggest many failures stem from ineffective context utilization. Models often struggle to identify and prioritize relevant information even when it is present. These findings have direct practical implications, as enterprise workflows increasingly involve pasting large volumes of unfiltered documents into LLM prompts. Effective context length and model-specific robustness to long contexts are therefore critical for reliable LLM deployment in research and business.",
    "authors": [
      "Amirali Ebrahimzadeh",
      "Seyyed M. Salili"
    ],
    "url": "http://arxiv.org/abs/2601.02023v1",
    "published": "2026-01-05",
    "primary_category": "cs.CL",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文研究长上下文大语言模型的信息提取、逻辑推理和幻觉风险，属于自然语言处理领域的基础模型评估研究，而非AI4Science或扰动预测的具体应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02022v1",
    "title": "Prior Diffusiveness and Regret in the Linear-Gaussian Bandit",
    "summary": "We prove that Thompson sampling exhibits $\\tilde{O}(σd \\sqrt{T} + d r \\sqrt{\\mathrm{Tr}(Σ_0)})$ Bayesian regret in the linear-Gaussian bandit with a $\\mathcal{N}(μ_0, Σ_0)$ prior distribution on the coefficients, where $d$ is the dimension, $T$ is the time horizon, $r$ is the maximum $\\ell_2$ norm of the actions, and $σ^2$ is the noise variance. In contrast to existing regret bounds, this shows that to within logarithmic factors, the prior-dependent ``burn-in'' term $d r \\sqrt{\\mathrm{Tr}(Σ_0)}$ decouples additively from the minimax (long run) regret $σd \\sqrt{T}$. Previous regret bounds exhibit a multiplicative dependence on these terms. We establish these results via a new ``elliptical potential'' lemma, and also provide a lower bound indicating that the burn-in term is unavoidable.",
    "authors": [
      "Yifan Zhu",
      "John C. Duchi",
      "Benjamin Van Roy"
    ],
    "url": "http://arxiv.org/abs/2601.02022v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于多臂赌博机算法的理论分析，通过新的椭圆势引理改进了Thompson采样在贝叶斯遗憾上的上界，属于机器学习理论领域。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02016v1",
    "title": "Enhancing Object Detection with Privileged Information: A Model-Agnostic Teacher-Student Approach",
    "summary": "This paper investigates the integration of the Learning Using Privileged Information (LUPI) paradigm in object detection to exploit fine-grained, descriptive information available during training but not at inference. We introduce a general, model-agnostic methodology for injecting privileged information-such as bounding box masks, saliency maps, and depth cues-into deep learning-based object detectors through a teacher-student architecture. Experiments are conducted across five state-of-the-art object detection models and multiple public benchmarks, including UAV-based litter detection datasets and Pascal VOC 2012, to assess the impact on accuracy, generalization, and computational efficiency. Our results demonstrate that LUPI-trained students consistently outperform their baseline counterparts, achieving significant boosts in detection accuracy with no increase in inference complexity or model size. Performance improvements are especially marked for medium and large objects, while ablation studies reveal that intermediate weighting of teacher guidance optimally balances learning from privileged and standard inputs. The findings affirm that the LUPI framework provides an effective and practical strategy for advancing object detection systems in both resource-constrained and real-world settings.",
    "authors": [
      "Matthias Bartolo",
      "Dylan Seychell",
      "Gabriel Hili",
      "Matthew Montebello",
      "Carl James Debono",
      "Saviour Formosa",
      "Konstantinos Makantasis"
    ],
    "url": "http://arxiv.org/abs/2601.02016v1",
    "published": "2026-01-05",
    "primary_category": "cs.CV",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种模型无关的师生架构，利用特权信息提升通用物体检测性能，而非针对特定科学领域或细胞扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02015v1",
    "title": "Surprisal and Metaphor Novelty: Moderate Correlations and Divergent Scaling Effects",
    "summary": "Novel metaphor comprehension involves complex semantic processes and linguistic creativity, making it an interesting task for studying language models (LMs). This study investigates whether surprisal, a probabilistic measure of predictability in LMs, correlates with different metaphor novelty datasets. We analyse surprisal from 16 LM variants on corpus-based and synthetic metaphor novelty datasets. We explore a cloze-style surprisal method that conditions on full-sentence context. Results show that LMs yield significant moderate correlations with scores/labels of metaphor novelty. We further identify divergent scaling patterns: on corpus-based data, correlation strength decreases with model size (inverse scaling effect), whereas on synthetic data it increases (Quality-Power Hypothesis). We conclude that while surprisal can partially account for annotations of metaphor novelty, it remains a limited metric of linguistic creativity.",
    "authors": [
      "Omar Momen",
      "Emilie Sitter",
      "Berenike Herrmann",
      "Sina Zarrieß"
    ],
    "url": "http://arxiv.org/abs/2601.02015v1",
    "published": "2026-01-05",
    "primary_category": "cs.CL",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该研究探讨语言模型中的惊奇度与隐喻新颖性的相关性，属于计算语言学和认知科学领域，而非AI4Science或扰动预测范畴。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02010v1",
    "title": "A neural network for modeling human concept formation, understanding and communication",
    "summary": "A remarkable capability of the human brain is to form more abstract conceptual representations from sensorimotor experiences and flexibly apply them independent of direct sensory inputs. However, the computational mechanism underlying this ability remains poorly understood. Here, we present a dual-module neural network framework, the CATS Net, to bridge this gap. Our model consists of a concept-abstraction module that extracts low-dimensional conceptual representations, and a task-solving module that performs visual judgement tasks under the hierarchical gating control of the formed concepts. The system develops transferable semantic structure based on concept representations that enable cross-network knowledge transfer through conceptual communication. Model-brain fitting analyses reveal that these emergent concept spaces align with both neurocognitive semantic model and brain response structures in the human ventral occipitotemporal cortex, while the gating mechanisms mirror that in the semantic control brain network. This work establishes a unified computational framework that can offer mechanistic insights for understanding human conceptual cognition and engineering artificial systems with human-like conceptual intelligence.",
    "authors": [
      "Liangxuan Guo",
      "Haoyang Chen",
      "Yang Chen",
      "Yanchao Bi",
      "Shan Yu"
    ],
    "url": "http://arxiv.org/abs/2601.02010v1",
    "published": "2026-01-05",
    "primary_category": "q-bio.NC",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文通过构建神经网络模型研究人类概念形成的神经机制，属于使用人工智能方法探索神经科学问题的AI4Science研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02008v1",
    "title": "XAI-MeD: Explainable Knowledge Guided Neuro-Symbolic Framework for Domain Generalization and Rare Class Detection in Medical Imaging",
    "summary": "Explainability domain generalization and rare class reliability are critical challenges in medical AI where deep models often fail under real world distribution shifts and exhibit bias against infrequent clinical conditions This paper introduces XAIMeD an explainable medical AI framework that integrates clinically accurate expert knowledge into deep learning through a unified neuro symbolic architecture XAIMeD is designed to improve robustness under distribution shift enhance rare class sensitivity and deliver transparent clinically aligned interpretations The framework encodes clinical expertise as logical connectives over atomic medical propositions transforming them into machine checkable class specific rules Their diagnostic utility is quantified through weighted feature satisfaction scores enabling a symbolic reasoning branch that complements neural predictions A confidence weighted fusion integrates symbolic and deep outputs while a Hunt inspired adaptive routing mechanism guided by Entropy Imbalance Gain EIG and Rare Class Gini mitigates class imbalance high intra class variability and uncertainty We evaluate XAIMeD across diverse modalities on four challenging tasks i Seizure Onset Zone SOZ localization from rs fMRI ii Diabetic Retinopathy grading across 6 multicenter datasets demonstrate substantial performance improvements including 6 percent gains in cross domain generalization and a 10 percent improved rare class F1 score far outperforming state of the art deep learning baselines Ablation studies confirm that the clinically grounded symbolic components act as effective regularizers ensuring robustness to distribution shifts XAIMeD thus provides a principled clinically faithful and interpretable approach to multimodal medical AI.",
    "authors": [
      "Midhat Urooj",
      "Ayan Banerjee",
      "Sandeep Gupta"
    ],
    "url": "http://arxiv.org/abs/2601.02008v1",
    "published": "2026-01-05",
    "primary_category": "cs.AI",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种融合神经符号架构的医疗AI框架，通过整合临床专家知识来提升医学影像分析的泛化能力和罕见类别检测性能。"
  },
  {
    "id": "http://arxiv.org/abs/2601.02002v1",
    "title": "Exploring Approaches for Detecting Memorization of Recommender System Data in Large Language Models",
    "summary": "Large Language Models (LLMs) are increasingly applied in recommendation scenarios due to their strong natural language understanding and generation capabilities. However, they are trained on vast corpora whose contents are not publicly disclosed, raising concerns about data leakage. Recent work has shown that the MovieLens-1M dataset is memorized by both the LLaMA and OpenAI model families, but the extraction of such memorized data has so far relied exclusively on manual prompt engineering. In this paper, we pose three main questions: Is it possible to enhance manual prompting? Can LLM memorization be detected through methods beyond manual prompting? And can the detection of data leakage be automated? To address these questions, we evaluate three approaches: (i) jailbreak prompt engineering; (ii) unsupervised latent knowledge discovery, probing internal activations via Contrast-Consistent Search (CCS) and Cluster-Norm; and (iii) Automatic Prompt Engineering (APE), which frames prompt discovery as a meta-learning process that iteratively refines candidate instructions. Experiments on MovieLens-1M using LLaMA models show that jailbreak prompting does not improve the retrieval of memorized items and remains inconsistent; CCS reliably distinguishes genuine from fabricated movie titles but fails on numerical user and rating data; and APE retrieves item-level information with moderate success yet struggles to recover numerical interactions. These findings suggest that automatically optimizing prompts is the most promising strategy for extracting memorized samples.",
    "authors": [
      "Antonio Colacicco",
      "Vito Guida",
      "Dario Di Palma",
      "Fedelucio Narducci",
      "Tommaso Di Noia"
    ],
    "url": "http://arxiv.org/abs/2601.02002v1",
    "published": "2026-01-05",
    "primary_category": "cs.IR",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文研究大语言模型在推荐系统中数据记忆化的检测方法，属于机器学习安全领域而非传统科学发现或生物医学扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01997v1",
    "title": "Exploring Diversity, Novelty, and Popularity Bias in ChatGPT's Recommendations",
    "summary": "ChatGPT has emerged as a versatile tool, demonstrating capabilities across diverse domains. Given these successes, the Recommender Systems (RSs) community has begun investigating its applications within recommendation scenarios primarily focusing on accuracy. While the integration of ChatGPT into RSs has garnered significant attention, a comprehensive analysis of its performance across various dimensions remains largely unexplored. Specifically, the capabilities of providing diverse and novel recommendations or exploring potential biases such as popularity bias have not been thoroughly examined. As the use of these models continues to expand, understanding these aspects is crucial for enhancing user satisfaction and achieving long-term personalization.   This study investigates the recommendations provided by ChatGPT-3.5 and ChatGPT-4 by assessing ChatGPT's capabilities in terms of diversity, novelty, and popularity bias. We evaluate these models on three distinct datasets and assess their performance in Top-N recommendation and cold-start scenarios. The findings reveal that ChatGPT-4 matches or surpasses traditional recommenders, demonstrating the ability to balance novelty and diversity in recommendations. Furthermore, in the cold-start scenario, ChatGPT models exhibit superior performance in both accuracy and novelty, suggesting they can be particularly beneficial for new users. This research highlights the strengths and limitations of ChatGPT's recommendations, offering new perspectives on the capacity of these models to provide recommendations beyond accuracy-focused metrics.",
    "authors": [
      "Dario Di Palma",
      "Giovanni Maria Biancofiore",
      "Vito Walter Anelli",
      "Fedelucio Narducci",
      "Tommaso Di Noia"
    ],
    "url": "http://arxiv.org/abs/2601.01997v1",
    "published": "2026-01-05",
    "primary_category": "cs.IR",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于评估ChatGPT在推荐系统中的多样性、新颖性和流行度偏差，不涉及生物学、化学或物理学等领域的科学发现或细胞/基因扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01993v1",
    "title": "MindChat: A Privacy-preserving Large Language Model for Mental Health Support",
    "summary": "Large language models (LLMs) have shown promise for mental health support, yet training such models is constrained by the scarcity and sensitivity of real counseling dialogues. In this article, we present MindChat, a privacy-preserving LLM for mental health support, together with MindCorpus, a synthetic multi-turn counseling dataset constructed via a multi-agent role-playing framework. To synthesize high-quality counseling data, the developed dialogue-construction framework employs a dual closed-loop feedback design to integrate psychological expertise and counseling techniques through role-playing: (i) turn-level critique-and-revision to improve coherence and counseling appropriateness within a session, and (ii) session-level strategy refinement to progressively enrich counselor behaviors across sessions. To mitigate privacy risks under decentralized data ownership, we fine-tune the base model using federated learning with parameter-efficient LoRA adapters and incorporate differentially private optimization to reduce membership and memorization risks. Experiments on synthetic-data quality assessment and counseling capability evaluation show that MindCorpus improves training effectiveness and that MindChat is competitive with existing general and counseling-oriented LLM baselines under both automatic LLM-judge and human evaluation protocols, while exhibiting reduced privacy leakage under membership inference attacks.",
    "authors": [
      "Dong Xue",
      "Jicheng Tu",
      "Ming Wang",
      "Xin Yan",
      "Fangzhou Liu",
      "Jie Hu"
    ],
    "url": "http://arxiv.org/abs/2601.01993v1",
    "published": "2026-01-05",
    "primary_category": "cs.AI",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于心理健康支持的隐私保护大语言模型MindChat，并通过多智能体角色扮演框架构建合成咨询数据集MindCorpus，属于人工智能在心理健康领域的应用研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01989v1",
    "title": "VIT-Ped: Visionary Intention Transformer for Pedestrian Behavior Analysis",
    "summary": "Pedestrian Intention prediction is one of the key technologies in the transition from level 3 to level 4 autonomous driving. To understand pedestrian crossing behaviour, several elements and features should be taken into consideration to make the roads of tomorrow safer for everybody. We introduce a transformer / video vision transformer based algorithm of different sizes which uses different data modalities .We evaluated our algorithms on popular pedestrian behaviour dataset, JAAD, and have reached SOTA performance and passed the SOTA in metrics like Accuracy, AUC and F1-score. The advantages brought by different model design choices are investigated via extensive ablation studies.",
    "authors": [
      "Aly R. Elkammar",
      "Karim M. Gamaleldin",
      "Catherine M. Elias"
    ],
    "url": "http://arxiv.org/abs/2601.01989v1",
    "published": "2026-01-05",
    "primary_category": "cs.CV",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出基于Transformer的视觉算法用于分析行人行为，旨在提升自动驾驶安全性，而非应用于生物学、化学或物理学等科学发现领域。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01982v1",
    "title": "ChaosBench-Logic: A Benchmark for Logical and Symbolic Reasoning on Chaotic Dynamical Systems",
    "summary": "Large language models (LLMs) excel at natural language tasks but remain brittle in domains requiring precise logical and symbolic reasoning. Chaotic dynamical systems provide an especially demanding test because chaos is deterministic yet often misinterpreted as randomness or complexity. We introduce ChaosBench-Logic, a benchmark that evaluates LLM reasoning across 30 diverse dynamical systems using a unified first-order logic (FOL) ontology. Each system is annotated with truth assignments for 11 semantic predicates, and 621 questions are generated across seven reasoning categories, including multi-hop implications, cross-system analogies, counterfactual reasoning, bias probes, and multi-turn dialogues. We define metrics for logical accuracy, implication consistency, dialogue coherence, and contradiction, and we release an open-source evaluation pipeline. Initial experiments show that frontier LLMs such as GPT-4, Claude 3.5 Sonnet, Gemini 2.5 Flash, and the open-source LLaMA-3 70B achieve 91-94% per-item accuracy, yet still score 0% on compositional items and exhibit fragile global coherence. Dialogue-level accuracy ranges from 53.1% (GPT-4 CoT) to 75.5% (LLaMA-3 zero-shot). ChaosBench-Logic provides a rigorous testbed for diagnosing such failures and a foundation for developing neuro-symbolic approaches that improve scientific reasoning in LLMs.",
    "authors": [
      "Noel Thomas"
    ],
    "url": "http://arxiv.org/abs/2601.01982v1",
    "published": "2026-01-05",
    "primary_category": "cs.AI",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文通过构建混沌动力系统的逻辑推理基准，为开发提升大语言模型科学推理能力的神经符号方法奠定了基础。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01979v1",
    "title": "SerpentFlow: Generative Unpaired Domain Alignment via Shared-Structure Decomposition",
    "summary": "Domain alignment refers broadly to learning correspondences between data distributions from distinct domains. In this work, we focus on a setting where domains share underlying structural patterns despite differences in their specific realizations. The task is particularly challenging in the absence of paired observations, which removes direct supervision across domains. We introduce a generative framework, called SerpentFlow (SharEd-structuRe decomPosition for gEnerative domaiN adapTation), for unpaired domain alignment. SerpentFlow decomposes data within a latent space into a shared component common to both domains and a domain-specific one. By isolating the shared structure and replacing the domain-specific component with stochastic noise, we construct synthetic training pairs between shared representations and target-domain samples, thereby enabling the use of conditional generative models that are traditionally restricted to paired settings. We apply this approach to super-resolution tasks, where the shared component naturally corresponds to low-frequency content while high-frequency details capture domain-specific variability. The cutoff frequency separating low- and high-frequency components is determined automatically using a classifier-based criterion, ensuring a data-driven and domain-adaptive decomposition. By generating pseudo-pairs that preserve low-frequency structures while injecting stochastic high-frequency realizations, we learn the conditional distribution of the target domain given the shared representation. We implement SerpentFlow using Flow Matching as the generative pipeline, although the framework is compatible with other conditional generative approaches. Experiments on synthetic images, physical process simulations, and a climate downscaling task demonstrate that the method effectively reconstructs high-frequency structures consistent with underlying low-frequency patterns, supporting shared-structure decomposition as an effective strategy for unpaired domain alignment.",
    "authors": [
      "Julie Keisler",
      "Anastase Alexandre Charantonis",
      "Yannig Goude",
      "Boutheina Oueslati",
      "Claire Monteleoni"
    ],
    "url": "http://arxiv.org/abs/2601.01979v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于共享结构分解的生成式无配对域对齐方法，通过将数据分解为共享结构和域特定成分来构建合成训练对，并应用于气候降尺度等科学任务。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01976v1",
    "title": "CNC-TP: Classifier Nominal Concept Based on Top-Pertinent Attributes",
    "summary": "Knowledge Discovery in Databases (KDD) aims to exploit the vast amounts of data generated daily across various domains of computer applications. Its objective is to extract hidden and meaningful knowledge from datasets through a structured process comprising several key steps: data selection, preprocessing, transformation, data mining, and visualization. Among the core data mining techniques are classification and clustering. Classification involves predicting the class of new instances using a classifier trained on labeled data. Several approaches have been proposed in the literature, including Decision Tree Induction, Bayesian classifiers, Nearest Neighbor search, Neural Networks, Support Vector Machines, and Formal Concept Analysis (FCA). The last one is recognized as an effective approach for interpretable and explainable learning. It is grounded in the mathematical structure of the concept lattice, which enables the generation of formal concepts and the discovery of hidden relationships among them. In this paper, we present a state-of-theart review of FCA-based classifiers. We explore various methods for computing closure operators from nominal data and introduce a novel approach for constructing a partial concept lattice that focuses on the most relevant concepts. Experimental results are provided to demonstrate the efficiency of the proposed method.",
    "authors": [
      "Yasmine Souissi",
      "Fabrice Boissier",
      "Nida Meddouri"
    ],
    "url": "http://arxiv.org/abs/2601.01976v1",
    "published": "2026-01-05",
    "primary_category": "cs.AI",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于形式概念分析的分类器改进方法，专注于数据挖掘中的分类技术而非特定科学领域的发现。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01970v1",
    "title": "A Multilayered Approach to Classifying Customer Responsiveness and Credit Risk",
    "summary": "This study evaluates the performance of various classifiers in three distinct models: response, risk, and response-risk, concerning credit card mail campaigns and default prediction. In the response model, the Extra Trees classifier demonstrates the highest recall level (79.1%), emphasizing its effectiveness in identifying potential responders to targeted credit card offers. Conversely, in the risk model, the Random Forest classifier exhibits remarkable specificity of 84.1%, crucial for identifying customers least likely to default. Furthermore, in the multi-class response-risk model, the Random Forest classifier achieves the highest accuracy (83.2%), indicating its efficacy in discerning both potential responders to credit card mail campaign and low-risk credit card users. In this study, we optimized various performance metrics to solve a specific credit risk and mail responsiveness business problem.",
    "authors": [
      "Ayomide Afolabi",
      "Ebere Ogburu",
      "Symon Kimitei"
    ],
    "url": "http://arxiv.org/abs/2601.01970v1",
    "published": "2026-01-05",
    "primary_category": "stat.ML",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于商业信用风险评估和营销响应预测，属于金融应用领域，而非生物学、化学或物理学等基础科学发现。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01966v1",
    "title": "Refinement Provenance Inference: Detecting LLM-Refined Training Prompts from Model Behavior",
    "summary": "Instruction tuning increasingly relies on LLM-based prompt refinement, where prompts in the training corpus are selectively rewritten by an external refiner to improve clarity and instruction alignment. This motivates an instance-level audit problem: for a fine-tuned model and a training prompt-response pair, can we infer whether the model was trained on the original prompt or its LLM-refined version within a mixed corpus? This matters for dataset governance and dispute resolution when training data are contested. However, it is non-trivial in practice: refined and raw instances are interleaved in the training corpus with unknown, source-dependent mixture ratios, making it harder to develop provenance methods that generalize across models and training setups. In this paper, we formalize this audit task as Refinement Provenance Inference (RPI) and show that prompt refinement yields stable, detectable shifts in teacher-forced token distributions, even when semantic differences are not obvious. Building on this phenomenon, we propose RePro, a logit-based provenance framework that fuses teacher-forced likelihood features with logit-ranking signals. During training, RePro learns a transferable representation via shadow fine-tuning, and uses a lightweight linear head to infer provenance on unseen victims without training-data access. Empirically, RePro consistently attains strong performance and transfers well across refiners, suggesting that it exploits refiner-agnostic distribution shifts rather than rewrite-style artifacts.",
    "authors": [
      "Bo Yin",
      "Qi Li",
      "Runpeng Yu",
      "Xinchao Wang"
    ],
    "url": "http://arxiv.org/abs/2601.01966v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种检测大语言模型训练数据中提示词是否经过精炼的方法，属于机器学习模型审计领域。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01963v1",
    "title": "Forget Less by Learning Together through Concept Consolidation",
    "summary": "Custom Diffusion Models (CDMs) have gained significant attention due to their remarkable ability to personalize generative processes. However, existing CDMs suffer from catastrophic forgetting when continuously learning new concepts. Most prior works attempt to mitigate this issue under the sequential learning setting with a fixed order of concept inflow and neglect inter-concept interactions. In this paper, we propose a novel framework - Forget Less by Learning Together (FL2T) - that enables concurrent and order-agnostic concept learning while addressing catastrophic forgetting. Specifically, we introduce a set-invariant inter-concept learning module where proxies guide feature selection across concepts, facilitating improved knowledge retention and transfer. By leveraging inter-concept guidance, our approach preserves old concepts while efficiently incorporating new ones. Extensive experiments, across three datasets, demonstrates that our method significantly improves concept retention and mitigates catastrophic forgetting, highlighting the effectiveness of inter-concept catalytic behavior in incremental concept learning of ten tasks with at least 2% gain on average CLIP Image Alignment scores.",
    "authors": [
      "Arjun Ramesh Kaushik",
      "Naresh Kumar Devulapally",
      "Vishnu Suresh Lokhande",
      "Nalini Ratha",
      "Venu Govindaraju"
    ],
    "url": "http://arxiv.org/abs/2601.01963v1",
    "published": "2026-01-05",
    "primary_category": "cs.CV",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种解决定制扩散模型中灾难性遗忘问题的框架，属于机器学习方法改进，而非应用于特定科学领域或扰动预测研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01944v1",
    "title": "The Invisible Hand of AI Libraries Shaping Open Source Projects and Communities",
    "summary": "In the early 1980s, Open Source Software emerged as a revolutionary concept amidst the dominance of proprietary software. What began as a revolutionary idea has now become the cornerstone of computer science. Amidst OSS projects, AI is increasing its presence and relevance. However, despite the growing popularity of AI, its adoption and impacts on OSS projects remain underexplored.   We aim to assess the adoption of AI libraries in Python and Java OSS projects and examine how they shape development, including the technical ecosystem and community engagement. To this end, we will perform a large-scale analysis on 157.7k potential OSS repositories, employing repository metrics and software metrics to compare projects adopting AI libraries against those that do not. We expect to identify measurable differences in development activity, community engagement, and code complexity between OSS projects that adopt AI libraries and those that do not, offering evidence-based insights into how AI integration reshapes software development practices.",
    "authors": [
      "Matteo Esposito",
      "Andrea Janes",
      "Valentina Lenarduzzi",
      "Davide Taibi"
    ],
    "url": "http://arxiv.org/abs/2601.01944v1",
    "published": "2026-01-05",
    "primary_category": "cs.SE",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文研究AI库在开源项目中的采用及其对软件开发实践的影响，而非将AI应用于特定科学领域的发现。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01943v1",
    "title": "SynRXN: An Open Benchmark and Curated Dataset for Computational Reaction Modeling",
    "summary": "We present SynRXN, a unified benchmarking framework and open-data resource for computer-aided synthesis planning (CASP). SynRXN decomposes end-to-end synthesis planning into five task families, covering reaction rebalancing, atom-to-atom mapping, reaction classification, reaction property prediction, and synthesis route design. Curated, provenance-tracked reaction corpora are assembled from heterogeneous public sources into a harmonized representation and packaged as versioned datasets for each task family, with explicit source metadata, licence tags, and machine-readable manifests that record checksums, and row counts. For every task, SynRXN provides transparent splitting functions that generate leakage-aware train, validation, and test partitions, together with standardized evaluation workflows and metric suites tailored to classification, regression, and structured prediction settings. For sensitive benchmarking, we combine public training and validation data with held-out gold-standard test sets, and contamination-prone tasks such as reaction rebalancing and atom-to-atom mapping are distributed only as evaluation sets and are explicitly not intended for model training. Scripted build recipes enable bitwise-reproducible regeneration of all corpora across machines and over time, and the entire resource is released under permissive open licences to support reuse and extension. By removing dataset heterogeneity and packaging transparent, reusable evaluation scaffolding, SynRXN enables fair longitudinal comparison of CASP methods, supports rigorous ablations and stress tests along the full reaction-informatics pipeline, and lowers the barrier for practitioners who seek robust and comparable performance estimates for real-world synthesis planning workloads.",
    "authors": [
      "Tieu-Long Phan",
      "Nhu-Ngoc Nguyen Song",
      "Peter F. Stadler"
    ],
    "url": "http://arxiv.org/abs/2601.01943v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文通过构建统一的基准测试框架和开放数据集，专门用于计算机辅助合成规划（CASP），属于人工智能在化学领域的科学发现应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01940v1",
    "title": "Policy Optimization with Differentiable MPC: Convergence Analysis under Uncertainty",
    "summary": "Model-based policy optimization is a well-established framework for designing reliable and high-performance controllers across a wide range of control applications. Recently, this approach has been extended to model predictive control policies, where explicit dynamical models are embedded within the control law. However, the performance of the resulting controllers, and the convergence of the associated optimization algorithms, critically depends on the accuracy of the models. In this paper, we demonstrate that combining gradient-based policy optimization with recursive system identification ensures convergence to an optimal controller design and showcase our finding in several control examples.",
    "authors": [
      "Riccardo Zuliani",
      "Efe C. Balta",
      "John Lygeros"
    ],
    "url": "http://arxiv.org/abs/2601.01940v1",
    "published": "2026-01-05",
    "primary_category": "eess.SY",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文聚焦于控制理论中结合梯度优化与系统辨识的模型预测控制策略收敛性分析，属于工程控制领域而非AI4Science或生物扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01939v1",
    "title": "OpenSocInt: A Multi-modal Training Environment for Human-Aware Social Navigation",
    "summary": "In this paper, we introduce OpenSocInt, an open-source software package providing a simulator for multi-modal social interactions and a modular architecture to train social agents. We described the software package and showcased its interest via an experimental protocol based on the task of social navigation. Our framework allows for exploring the use of different perceptual features, their encoding and fusion, as well as the use of different agents. The software is already publicly available under GPL at https://gitlab.inria.fr/robotlearn/OpenSocInt/.",
    "authors": [
      "Victor Sanchez",
      "Chris Reinke",
      "Ahamed Mohamed",
      "Xavier Alameda-Pineda"
    ],
    "url": "http://arxiv.org/abs/2601.01939v1",
    "published": "2026-01-05",
    "primary_category": "cs.AI",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文介绍了一个用于社会导航训练的多模态模拟环境，属于机器人学和人机交互领域，而非AI4Science或细胞扰动预测范畴。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01932v1",
    "title": "Visualizing the Structure of Lenia Parameter Space",
    "summary": "Continuous cellular automata are rocketing in popularity, yet developing a theoretical understanding of their behaviour remains a challenge. In the case of Lenia, a few fundamental open problems include determining what exactly constitutes a soliton, what is the overall structure of the parameter space, and where do the solitons occur in it. In this abstract, we present a new method to automatically classify Lenia systems into four qualitatively different dynamical classes. This allows us to detect moving solitons, and to provide an interactive visualization of Lenia's parameter space structure on our website https://lenia-explorer.vercel.app/. The results shed new light on the above-mentioned questions and lead to several observations: the existence of new soliton families for parameters where they were not believed to exist, or the universality of the phase space structure across various kernels.",
    "authors": [
      "Barbora Hudcová",
      "František Dušek",
      "Marco Tuccio",
      "Clément Hongler"
    ],
    "url": "http://arxiv.org/abs/2601.01932v1",
    "published": "2026-01-05",
    "primary_category": "nlin.CG",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文通过开发自动分类方法可视化Lenia参数空间结构，属于利用计算技术研究复杂系统动力学的AI4Science范畴。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01931v1",
    "title": "DéjàQ: Open-Ended Evolution of Diverse, Learnable and Verifiable Problems",
    "summary": "Recent advances in reasoning models have yielded impressive results in mathematics and coding. However, most approaches rely on static datasets, which have been suggested to encourage memorisation and limit generalisation. We introduce DéjàQ, a framework that departs from this paradigm by jointly evolving a diverse set of synthetic mathematical problems alongside model training. This evolutionary process adapts to the model's ability throughout training, optimising problems for learnability. We propose two LLM-driven mutation strategies in which the model itself mutates the training data, either by altering contextual details or by directly modifying problem structure. We find that the model can generate novel and meaningful problems, and that these LLM-driven mutations improve RL training. We analyse key aspects of DéjàQ, including the validity of generated problems and computational overhead. Our results underscore the potential of dynamically evolving training data to enhance mathematical reasoning and indicate broader applicability, which we will support by open-sourcing our code.",
    "authors": [
      "Willem Röpke",
      "Samuel Coward",
      "Andrei Lupu",
      "Thomas Foster",
      "Tim Rocktäschel",
      "Jakob Foerster"
    ],
    "url": "http://arxiv.org/abs/2601.01931v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种通过进化合成数学问题来增强模型推理能力的训练框架，而非将AI应用于传统科学领域或预测生物扰动响应。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01930v1",
    "title": "MCGI: Manifold-Consistent Graph Indexing for Billion-Scale Disk-Resident Vector Search",
    "summary": "Graph-based Approximate Nearest Neighbor (ANN) search often suffers from performance degradation in high-dimensional spaces due to the ``Euclidean-Geodesic mismatch,'' where greedy routing diverges from the underlying data manifold. To address this, we propose Manifold-Consistent Graph Indexing (MCGI), a geometry-aware and disk-resident indexing method that leverages Local Intrinsic Dimensionality (LID) to dynamically adapt search strategies to the data's intrinsic geometry. Unlike standard algorithms that treat dimensions uniformly, MCGI modulates its beam search budget based on in situ geometric analysis, eliminating dependency on static hyperparameters. Theoretical analysis confirms that MCGI enables improved approximation guarantees by preserving manifold-consistent topological connectivity. Empirically, MCGI achieves 5.8$\\times$ higher throughput at 95\\% recall on high-dimensional GIST1M compared to state-of-the-art DiskANN. On the billion-scale SIFT1B dataset, MCGI further validates its scalability by reducing high-recall query latency by 3$\\times$, while maintaining performance parity on standard lower-dimensional datasets.",
    "authors": [
      "Dongfang Zhao"
    ],
    "url": "http://arxiv.org/abs/2601.01930v1",
    "published": "2026-01-05",
    "primary_category": "cs.IR",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于流形几何感知的图索引方法，用于提升高维向量搜索的性能和可扩展性，属于计算机科学中的算法优化研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01927v1",
    "title": "Theoretical Convergence of SMOTE-Generated Samples",
    "summary": "Imbalanced data affects a wide range of machine learning applications, from healthcare to network security. As SMOTE is one of the most popular approaches to addressing this issue, it is imperative to validate it not only empirically but also theoretically. In this paper, we provide a rigorous theoretical analysis of SMOTE's convergence properties. Concretely, we prove that the synthetic random variable Z converges in probability to the underlying random variable X. We further prove a stronger convergence in mean when X is compact. Finally, we show that lower values of the nearest neighbor rank lead to faster convergence offering actionable guidance to practitioners. The theoretical results are supported by numerical experiments using both real-life and synthetic data. Our work provides a foundational understanding that enhances data augmentation techniques beyond imbalanced data scenarios.",
    "authors": [
      "Firuz Kamalov",
      "Hana Sulieman",
      "Witold Pedrycz"
    ],
    "url": "http://arxiv.org/abs/2601.01927v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文聚焦于SMOTE算法的理论收敛性分析，属于机器学习方法论的数学基础研究，而非特定科学领域的AI应用或扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01922v1",
    "title": "Efficient temporal prediction of compressible flows in irregular domains using Fourier neural operators",
    "summary": "This paper investigates the temporal evolution of high-speed compressible fluids in irregular flow fields using the Fourier Neural Operator (FNO). We reconstruct the irregular flow field point set into sequential format compatible with FNO input requirements, and then embed temporal bundling technique within a recurrent neural network (RNN) for multi-step prediction. We further employ a composite loss function to balance errors across different physical quantities. Experiments are conducted on three different types of irregular flow fields, including orthogonal and non-orthogonal grid configurations. Then we comprehensively analyze the physical component loss curves, flow field visualizations, and physical profiles. Results demonstrate that our approach significantly surpasses traditional numerical methods in computational efficiency while achieving high accuracy, with maximum relative $L_2$ errors of (0.78, 0.57, 0.35)% for ($p$, $T$, $\\mathbf{u}$) respectively. This verifies that the method can efficiently and accurately simulate the temporal evolution of high-speed compressible flows in irregular domains.",
    "authors": [
      "Yifan Nie",
      "Qiaoxin Li"
    ],
    "url": "http://arxiv.org/abs/2601.01922v1",
    "published": "2026-01-05",
    "primary_category": "physics.flu-dyn",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文使用傅里叶神经算子等AI方法高效模拟不规则域中高速可压缩流体的时间演化，属于AI在物理流体力学领域的科学应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01921v1",
    "title": "A Defect is Being Born: How Close Are We? A Time Sensitive Forecasting Approach",
    "summary": "Background. Defect prediction has been a highly active topic among researchers in the Empirical Software Engineering field. Previous literature has successfully achieved the most accurate prediction of an incoming fault and identified the features and anomalies that precede it through just-in-time prediction. As software systems evolve continuously, there is a growing need for time-sensitive methods capable of forecasting defects before they manifest.   Aim. Our study seeks to explore the effectiveness of time-sensitive techniques for defect forecasting. Moreover, we aim to investigate the early indicators that precede the occurrence of a defect.   Method. We will train multiple time-sensitive forecasting techniques to forecast the future bug density of a software project, as well as identify the early symptoms preceding the occurrence of a defect.   Expected results. Our expected results are translated into empirical evidence on the effectiveness of our approach for early estimation of bug proneness.",
    "authors": [
      "Mikel Robredo",
      "Matteo Esposito",
      "Fabio Palomba",
      "Rafael Peñaloza",
      "Valentina Lenarduzzi"
    ],
    "url": "http://arxiv.org/abs/2601.01921v1",
    "published": "2026-01-05",
    "primary_category": "cs.SE",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文研究软件工程中的缺陷预测方法，属于计算机科学领域而非传统自然科学。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01917v1",
    "title": "Distorted Distributional Policy Evaluation for Offline Reinforcement Learning",
    "summary": "While Distributional Reinforcement Learning (DRL) methods have demonstrated strong performance in online settings, its success in offline scenarios remains limited. We hypothesize that a key limitation of existing offline DRL methods lies in their approach to uniformly underestimate return quantiles. This uniform pessimism can lead to overly conservative value estimates, ultimately hindering generalization and performance. To address this, we introduce a novel concept called quantile distortion, which enables non-uniform pessimism by adjusting the degree of conservatism based on the availability of supporting data. Our approach is grounded in theoretical analysis and empirically validated, demonstrating improved performance over uniform pessimism.",
    "authors": [
      "Ryo Iwaki",
      "Takayuki Osogami"
    ],
    "url": "http://arxiv.org/abs/2601.01917v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于离线强化学习的分布扭曲评估方法，通过非均匀悲观主义改进值估计，属于强化学习算法改进范畴。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01916v1",
    "title": "Toward Thermodynamic Reservoir Computing: Exploring SHA-256 ASICs as Potential Physical Substrates",
    "summary": "We propose a theoretical framework--Holographic Reservoir Computing (HRC)--which hypothesizes that the thermodynamic noise and timing dynamics in voltage-stressed Bitcoin mining ASICs (BM1366) could potentially serve as a physical reservoir computing substrate. We present the CHIMERA (Conscious Hybrid Intelligence via Miner-Embedded Resonance Architecture) system architecture, which treats the SHA-256 hashing pipeline not as an entropy source, but as a deterministic diffusion operator whose timing characteristics under controlled voltage and frequency conditions may exhibit computationally useful dynamics. We report preliminary observations of non-Poissonian variability in inter-arrival time statistics during edge-of-stability operation, which we term the \"Silicon Heartbeat\" hypothesis. Theoretical analysis based on Hierarchical Number System (HNS) representations suggests that such architectures could achieve O(log n) energy scaling compared to traditional von Neumann O(2^n) dependencies. However, we emphasize that these are theoretical projections requiring experimental validation. We present the implemented measurement infrastructure, acknowledge current limitations, and outline the experimental program necessary to confirm or refute these hypotheses. This work contributes to the emerging field of thermodynamic computing by proposing a novel approach to repurposing obsolete cryptographic hardware for neuromorphic applications.",
    "authors": [
      "Francisco Angulo de Lafuente",
      "Vladimir Veselov",
      "Richard Goodman"
    ],
    "url": "http://arxiv.org/abs/2601.01916v1",
    "published": "2026-01-05",
    "primary_category": "cs.NE",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出利用比特币挖矿芯片的热力学噪声和时序动力学作为物理储层计算基板，属于将AI方法应用于物理计算系统的新型交叉研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01910v1",
    "title": "MMP-A*: Multimodal Perception Enhanced Incremental Heuristic Search on Path Planning",
    "summary": "Autonomous path planning requires a synergy between global reasoning and geometric precision, especially in complex or cluttered environments. While classical A* is valued for its optimality, it incurs prohibitive computational and memory costs in large-scale scenarios. Recent attempts to mitigate these limitations by using Large Language Models for waypoint guidance remain insufficient, as they rely only on text-based reasoning without spatial grounding. As a result, such models often produce incorrect waypoints in topologically complex environments with dead ends, and lack the perceptual capacity to interpret ambiguous physical boundaries. These inconsistencies lead to costly corrective expansions and undermine the intended computational efficiency.   We introduce MMP-A*, a multimodal framework that integrates the spatial grounding capabilities of vision-language models with a novel adaptive decay mechanism. By anchoring high-level reasoning in physical geometry, the framework produces coherent waypoint guidance that addresses the limitations of text-only planners. The adaptive decay mechanism dynamically regulates the influence of uncertain waypoints within the heuristic, ensuring geometric validity while substantially reducing memory overhead. To evaluate robustness, we test the framework in challenging environments characterized by severe clutter and topological complexity. Experimental results show that MMP-A* achieves near-optimal trajectories with significantly reduced operational costs, demonstrating its potential as a perception-grounded and computationally efficient paradigm for autonomous navigation.",
    "authors": [
      "Minh Hieu Ha",
      "Khanh Ly Ta",
      "Hung Phan",
      "Tung Doan",
      "Tung Dao",
      "Dao Tran",
      "Huynh Thi Thanh Binh"
    ],
    "url": "http://arxiv.org/abs/2601.01910v1",
    "published": "2026-01-05",
    "primary_category": "cs.AI",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种结合视觉语言模型与自适应衰减机制的多模态路径规划框架，旨在提升自主导航的感知能力和计算效率。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01908v1",
    "title": "Nodule-DETR: A Novel DETR Architecture with Frequency-Channel Attention for Ultrasound Thyroid Nodule Detection",
    "summary": "Thyroid cancer is the most common endocrine malignancy, and its incidence is rising globally. While ultrasound is the preferred imaging modality for detecting thyroid nodules, its diagnostic accuracy is often limited by challenges such as low image contrast and blurred nodule boundaries. To address these issues, we propose Nodule-DETR, a novel detection transformer (DETR) architecture designed for robust thyroid nodule detection in ultrasound images. Nodule-DETR introduces three key innovations: a Multi-Spectral Frequency-domain Channel Attention (MSFCA) module that leverages frequency analysis to enhance features of low-contrast nodules; a Hierarchical Feature Fusion (HFF) module for efficient multi-scale integration; and Multi-Scale Deformable Attention (MSDA) to flexibly capture small and irregularly shaped nodules. We conducted extensive experiments on a clinical dataset of real-world thyroid ultrasound images. The results demonstrate that Nodule-DETR achieves state-of-the-art performance, outperforming the baseline model by a significant margin of 0.149 in mAP@0.5:0.95. The superior accuracy of Nodule-DETR highlights its significant potential for clinical application as an effective tool in computer-aided thyroid diagnosis. The code of work is available at https://github.com/wjj1wjj/Nodule-DETR.",
    "authors": [
      "Jingjing Wang",
      "Qianglin Liu",
      "Zhuo Xiao",
      "Xinning Yao",
      "Bo Liu",
      "Lu Li",
      "Lijuan Niu",
      "Fugen Zhou"
    ],
    "url": "http://arxiv.org/abs/2601.01908v1",
    "published": "2026-01-05",
    "primary_category": "cs.CV",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于DETR架构的深度学习模型，用于医学超声图像中的甲状腺结节检测，属于AI在生物医学影像分析领域的应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01904v1",
    "title": "Evaluating Feature Dependent Noise in Preference-based Reinforcement Learning",
    "summary": "Learning from Preferences in Reinforcement Learning (PbRL) has gained attention recently, as it serves as a natural fit for complicated tasks where the reward function is not easily available. However, preferences often come with uncertainty and noise if they are not from perfect teachers. Much prior literature aimed to detect noise, but with limited types of noise and most being uniformly distributed with no connection to observations. In this work, we formalize the notion of targeted feature-dependent noise and propose several variants like trajectory feature noise, trajectory similarity noise, uncertainty-aware noise, and Language Model noise.   We evaluate feature-dependent noise, where noise is correlated with certain features in complex continuous control tasks from DMControl and Meta-world. Our experiments show that in some feature-dependent noise settings, the state-of-the-art noise-robust PbRL method's learning performance is significantly deteriorated, while PbRL method with no explicit denoising can surprisingly outperform noise-robust PbRL in majority settings.   We also find language model's noise exhibits similar characteristics to feature-dependent noise, thereby simulating realistic humans and call for further study in learning with feature-dependent noise robustly.",
    "authors": [
      "Yuxuan Li",
      "Harshith Reddy Kethireddy",
      "Srijita Das"
    ],
    "url": "http://arxiv.org/abs/2601.01904v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于强化学习中的偏好噪声问题，提出特征依赖性噪声概念并在机器人控制任务中评估，不涉及科学发现或生物医学扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01903v1",
    "title": "TT-FSI: Scalable Faithful Shapley Interactions via Tensor-Train",
    "summary": "The Faithful Shapley Interaction (FSI) index uniquely satisfies the faithfulness axiom among Shapley interaction indices, but computing FSI requires $O(d^\\ell \\cdot 2^d)$ time and existing implementations use $O(4^d)$ memory. We present TT-FSI, which exploits FSI's algebraic structure via Matrix Product Operators (MPO). Our main theoretical contribution is proving that the linear operator $v \\mapsto \\text{FSI}(v)$ admits an MPO representation with TT-rank $O(\\ell d)$, enabling an efficient sweep algorithm with $O(\\ell^2 d^3 \\cdot 2^d)$ time and $O(\\ell d^2)$ core storage an exponential improvement over existing methods. Experiments on six datasets ($d=8$ to $d=20$) demonstrate up to 280$\\times$ speedup over baseline, 85$\\times$ over SHAP-IQ, and 290$\\times$ memory reduction. TT-FSI scales to $d=20$ (1M coalitions) where all competing methods fail.",
    "authors": [
      "Ungsik Kim",
      "Suwon Lee"
    ],
    "url": "http://arxiv.org/abs/2601.01903v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于张量网络的算法来高效计算Shapley交互指数，属于机器学习可解释性方法的技术改进。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01901v1",
    "title": "FedBiCross: A Bi-Level Optimization Framework to Tackle Non-IID Challenges in Data-Free One-Shot Federated Learning on Medical Data",
    "summary": "Data-free knowledge distillation-based one-shot federated learning (OSFL) trains a model in a single communication round without sharing raw data, making OSFL attractive for privacy-sensitive medical applications. However, existing methods aggregate predictions from all clients to form a global teacher. Under non-IID data, conflicting predictions cancel out during averaging, yielding near-uniform soft labels that provide weak supervision for distillation. We propose FedBiCross, a personalized OSFL framework with three stages: (1) clustering clients by model output similarity to form coherent sub-ensembles, (2) bi-level cross-cluster optimization that learns adaptive weights to selectively leverage beneficial cross-cluster knowledge while suppressing negative transfer, and (3) personalized distillation for client-specific adaptation. Experiments on four medical image datasets demonstrate that FedBiCross consistently outperforms state-of-the-art baselines across different non-IID degrees.",
    "authors": [
      "Yuexuan Xia",
      "Yinghao Zhang",
      "Yalin Liu",
      "Hong-Ning Dai",
      "Yong Xia"
    ],
    "url": "http://arxiv.org/abs/2601.01901v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种针对医学图像数据的联邦学习框架，通过双层优化解决非独立同分布数据下的知识蒸馏问题，属于AI在医学科学领域的应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01898v1",
    "title": "Multi-strategy Improved Northern Goshawk Optimization for WSN Coverage Enhancement",
    "summary": "To enhance the coverage rate of Wireless Sensor Networks (WSNs), this paper proposes an advanced optimization strategy based on a multi-strategy integrated Northern Goshawk Optimization (NGO) algorithm. Specifically, multivariate chaotic mapping is first employed to improve the randomness and uniformity of the initial population. To further bolster population diversity and prevent the algorithm from stagnating in local optima, a bidirectional population evolutionary dynamics strategy is incorporated following the pursuit-and-evasion phase, thereby facilitating the attainment of the global optimal solution. Extensive simulations were conducted to evaluate the performance of the proposed multi-strategy NGO in WSN coverage. Experimental results demonstrate that the proposed algorithm significantly outperforms existing benchmarks in terms of both coverage enhancement and node connectivity.",
    "authors": [
      "Yiran Tian",
      "Yuanjia Liu"
    ],
    "url": "http://arxiv.org/abs/2601.01898v1",
    "published": "2026-01-05",
    "primary_category": "cs.NE",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出一种改进的北方苍鹰优化算法用于增强无线传感器网络覆盖，属于工程优化领域而非基础科学发现。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01896v1",
    "title": "Tackling the Inherent Difficulty of Noise Filtering in RAG",
    "summary": "Retrieval-Augmented Generation (RAG) has become a widely adopted approach to enhance Large Language Models (LLMs) by incorporating external knowledge and reducing hallucinations. However, noisy or irrelevant documents are often introduced during RAG, potentially degrading performance and even causing hallucinated outputs. While various methods have been proposed to filter out such noise, we argue that identifying irrelevant information from retrieved content is inherently difficult and limited number of transformer layers can hardly solve this. Consequently, retrievers fail to filter out irrelevant documents entirely. Therefore, LLMs must be robust against such noise, but we demonstrate that standard fine-tuning approaches are often ineffective in enabling the model to selectively utilize relevant information while ignoring irrelevant content due to the structural constraints of attention patterns. To address this, we propose a novel fine-tuning method designed to enhance the model's ability to distinguish between relevant and irrelevant information within retrieved documents. Extensive experiments across multiple benchmarks show that our approach significantly improves the robustness and performance of LLMs.",
    "authors": [
      "Jingyu Liu",
      "Jiaen Lin",
      "Yong Liu"
    ],
    "url": "http://arxiv.org/abs/2601.01896v1",
    "published": "2026-01-05",
    "primary_category": "cs.CL",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于改进RAG系统中大语言模型的噪声过滤能力，属于自然语言处理领域的方法论研究，不涉及特定科学领域的发现或细胞/分子层面的扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01892v1",
    "title": "Forget Less by Learning from Parents Through Hierarchical Relationships",
    "summary": "Custom Diffusion Models (CDMs) offer impressive capabilities for personalization in generative modeling, yet they remain vulnerable to catastrophic forgetting when learning new concepts sequentially. Existing approaches primarily focus on minimizing interference between concepts, often neglecting the potential for positive inter-concept interactions. In this work, we present Forget Less by Learning from Parents (FLLP), a novel framework that introduces a parent-child inter-concept learning mechanism in hyperbolic space to mitigate forgetting. By embedding concept representations within a Lorentzian manifold, naturally suited to modeling tree-like hierarchies, we define parent-child relationships in which previously learned concepts serve as guidance for adapting to new ones. Our method not only preserves prior knowledge but also supports continual integration of new concepts. We validate FLLP on three public datasets and one synthetic benchmark, showing consistent improvements in both robustness and generalization.",
    "authors": [
      "Arjun Ramesh Kaushik",
      "Naresh Kumar Devulapally",
      "Vishnu Suresh Lokhande",
      "Nalini K. Ratha",
      "Venu Govindaraju"
    ],
    "url": "http://arxiv.org/abs/2601.01892v1",
    "published": "2026-01-05",
    "primary_category": "cs.CV",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种在双曲空间中通过父子关系学习机制来缓解扩散模型灾难性遗忘的新框架，属于机器学习方法改进而非特定科学领域的AI应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01888v1",
    "title": "SafeLoad: Efficient Admission Control Framework for Identifying Memory-Overloading Queries in Cloud Data Warehouses",
    "summary": "Memory overload is a common form of resource exhaustion in cloud data warehouses. When database queries fail due to memory overload, it not only wastes critical resources such as CPU time but also disrupts the execution of core business processes, as memory-overloading (MO) queries are typically part of complex workflows. If such queries are identified in advance and scheduled to memory-rich serverless clusters, it can prevent resource wastage and query execution failure. Therefore, cloud data warehouses desire an admission control framework with high prediction precision, interpretability, efficiency, and adaptability to effectively identify MO queries. However, existing admission control frameworks primarily focus on scenarios like SLA satisfaction and resource isolation, with limited precision in identifying MO queries. Moreover, there is a lack of publicly available MO-labeled datasets with workloads for training and benchmarking. To tackle these challenges, we propose SafeLoad, the first query admission control framework specifically designed to identify MO queries. Alongside, we release SafeBench, an open-source, industrial-scale benchmark for this task, which includes 150 million real queries. SafeLoad first filters out memory-safe queries using the interpretable discriminative rule. It then applies a hybrid architecture that integrates both a global model and cluster-level models, supplemented by a misprediction correction module to identify MO queries. Additionally, a self-tuning quota management mechanism dynamically adjusts prediction quotas per cluster to improve precision. Experimental results show that SafeLoad achieves state-of-the-art prediction performance with low online and offline time overhead. Specifically, SafeLoad improves precision by up to 66% over the best baseline and reduces wasted CPU time by up to 8.09x compared to scenarios without SafeLoad.",
    "authors": [
      "Yifan Wu",
      "Yuhan Li",
      "Zhenhua Wang",
      "Zhongle Xie",
      "Dingyu Yang",
      "Ke Chen",
      "Lidan Shou",
      "Bo Tang",
      "Liang Lin",
      "Huan Li",
      "Gang Chen"
    ],
    "url": "http://arxiv.org/abs/2601.01888v1",
    "published": "2026-01-05",
    "primary_category": "cs.DB",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于云数据仓库的查询准入控制框架SafeLoad，通过可解释规则和混合模型架构来识别内存过载查询，属于数据库系统优化领域而非科学发现或生物医学扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01887v1",
    "title": "Safety at One Shot: Patching Fine-Tuned LLMs with A Single Instance",
    "summary": "Fine-tuning safety-aligned large language models (LLMs) can substantially compromise their safety. Previous approaches require many safety samples or calibration sets, which not only incur significant computational overhead during realignment but also lead to noticeable degradation in model utility. Contrary to this belief, we show that safety alignment can be fully recovered with only a single safety example, without sacrificing utility and at minimal cost. Remarkably, this recovery is effective regardless of the number of harmful examples used in fine-tuning or the size of the underlying model, and convergence is achieved within just a few epochs. Furthermore, we uncover the low-rank structure of the safety gradient, which explains why such efficient correction is possible. We validate our findings across five safety-aligned LLMs and multiple datasets, demonstrating the generality of our approach.",
    "authors": [
      "Jiawen Zhang",
      "Lipeng He",
      "Kejia Chen",
      "Jian Lou",
      "Jian Liu",
      "Xiaohu Yang",
      "Ruoxi Jia"
    ],
    "url": "http://arxiv.org/abs/2601.01887v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于大语言模型的安全对齐修复方法，属于人工智能安全领域，而非将AI应用于自然科学发现或生物医学扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01878v1",
    "title": "Theory Trace Card: Theory-Driven Socio-Cognitive Evaluation of LLMs",
    "summary": "Socio-cognitive benchmarks for large language models (LLMs) often fail to predict real-world behavior, even when models achieve high benchmark scores. Prior work has attributed this evaluation-deployment gap to problems of measurement and validity. While these critiques are insightful, we argue that they overlook a more fundamental issue: many socio-cognitive evaluations proceed without an explicit theoretical specification of the target capability, leaving the assumptions linking task performance to competence implicit. Without this theoretical grounding, benchmarks that exercise only narrow subsets of a capability are routinely misinterpreted as evidence of broad competence: a gap that creates a systemic validity illusion by masking the failure to evaluate the capability's other essential dimensions. To address this gap, we make two contributions. First, we diagnose and formalize this theory gap as a foundational failure that undermines measurement and enables systematic overgeneralization of benchmark results. Second, we introduce the Theory Trace Card (TTC), a lightweight documentation artifact designed to accompany socio-cognitive evaluations, which explicitly outlines the theoretical basis of an evaluation, the components of the target capability it exercises, its operationalization, and its limitations. We argue that TTCs enhance the interpretability and reuse of socio-cognitive evaluations by making explicit the full validity chain, which links theory, task operationalization, scoring, and limitations, without modifying benchmarks or requiring agreement on a single theory.",
    "authors": [
      "Farzan Karimi-Malekabadi",
      "Suhaib Abdurahman",
      "Zhivar Sourati",
      "Jackson Trager",
      "Morteza Dehghani"
    ],
    "url": "http://arxiv.org/abs/2601.01878v1",
    "published": "2026-01-05",
    "primary_category": "cs.AI",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种理论驱动的评估框架（Theory Trace Card），用于改进大语言模型的社会认知能力评估，而非应用于具体科学发现或扰动预测领域。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01877v1",
    "title": "Random-Matrix-Induced Simplicity Bias in Over-parameterized Variational Quantum Circuits",
    "summary": "Over-parameterization is commonly used to increase the expressivity of variational quantum circuits (VQCs), yet deeper and more highly parameterized circuits often exhibit poor trainability and limited generalization. In this work, we provide a theoretical explanation for this phenomenon from a function-class perspective. We show that sufficiently expressive, unstructured variational ansatze enter a Haar-like universality class in which both observable expectation values and parameter gradients concentrate exponentially with system size. As a consequence, the hypothesis class induced by such circuits collapses with high probability to a narrow family of near-constant functions, a phenomenon we term simplicity bias, with barren plateaus arising as a consequence rather than the root cause. Using tools from random matrix theory and concentration of measure, we rigorously characterize this universality class and establish uniform hypothesis-class collapse over finite datasets. We further show that this collapse is not unavoidable: tensor-structured VQCs, including tensor-network-based and tensor-hypernetwork parameterizations, lie outside the Haar-like universality class. By restricting the accessible unitary ensemble through bounded tensor rank or bond dimension, these architectures prevent concentration of measure, preserve output variability for local observables, and retain non-degenerate gradient signals even in over-parameterized regimes. Together, our results unify barren plateaus, expressivity limits, and generalization collapse under a single structural mechanism rooted in random-matrix universality, highlighting the central role of architectural inductive bias in variational quantum algorithms.",
    "authors": [
      "Jun Qi",
      "Chao-Han Huck Yang",
      "Pin-Yu Chen",
      "Min-Hsiu Hsieh"
    ],
    "url": "http://arxiv.org/abs/2601.01877v1",
    "published": "2026-01-05",
    "primary_category": "quant-ph",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文从随机矩阵理论角度解释了过参数化变分量子电路中出现的简单性偏置现象，属于量子计算理论分析范畴。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01875v1",
    "title": "Toward Auditable Neuro-Symbolic Reasoning in Pathology: SQL as an Explicit Trace of Evidence",
    "summary": "Automated pathology image analysis is central to clinical diagnosis, but clinicians still ask which slide features drive a model's decision and why. Vision-language models can produce natural language explanations, but these are often correlational and lack verifiable evidence. In this paper, we introduce an SQL-centered agentic framework that enables both feature measurement and reasoning to be auditable. Specifically, after extracting human-interpretable cellular features, Feature Reasoning Agents compose and execute SQL queries over feature tables to aggregate visual evidence into quantitative findings. A Knowledge Comparison Agent then evaluates these findings against established pathological knowledge, mirroring how pathologists justify diagnoses from measurable observations. Extensive experiments evaluated on two pathology visual question answering datasets demonstrate our method improves interpretability and decision traceability while producing executable SQL traces that link cellular measurements to diagnostic conclusions.",
    "authors": [
      "Kewen Cao",
      "Jianxu Chen",
      "Yongbing Zhang",
      "Ye Zhang",
      "Hongxiao Wang"
    ],
    "url": "http://arxiv.org/abs/2601.01875v1",
    "published": "2026-01-05",
    "primary_category": "cs.AI",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于SQL的代理框架，通过可执行的SQL追踪将细胞特征测量与病理诊断结论联系起来，提高了病理图像分析的透明度和可审计性。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01874v1",
    "title": "CogFlow: Bridging Perception and Reasoning through Knowledge Internalization for Visual Mathematical Problem Solving",
    "summary": "Despite significant progress, multimodal large language models continue to struggle with visual mathematical problem solving. Some recent works recognize that visual perception is a bottleneck in visual mathematical reasoning, but their solutions are limited to improving the extraction and interpretation of visual inputs. Notably, they all ignore the key issue of whether the extracted visual cues are faithfully integrated and properly utilized in subsequent reasoning. Motivated by this, we present CogFlow, a novel cognitive-inspired three-stage framework that incorporates a knowledge internalization stage, explicitly simulating the hierarchical flow of human reasoning: perception$\\Rightarrow$internalization$\\Rightarrow$reasoning. Inline with this hierarchical flow, we holistically enhance all its stages. We devise Synergistic Visual Rewards to boost perception capabilities in parametric and semantic spaces, jointly improving visual information extraction from symbols and diagrams. To guarantee faithful integration of extracted visual cues into subsequent reasoning, we introduce a Knowledge Internalization Reward model in the internalization stage, bridging perception and reasoning. Moreover, we design a Visual-Gated Policy Optimization algorithm to further enforce the reasoning is grounded with the visual knowledge, preventing models seeking shortcuts that appear coherent but are visually ungrounded reasoning chains. Moreover, we contribute a new dataset MathCog for model training, which contains samples with over 120K high-quality perception-reasoning aligned annotations. Comprehensive experiments and analysis on commonly used visual mathematical reasoning benchmarks validate the superiority of the proposed CogFlow.",
    "authors": [
      "Shuhang Chen",
      "Yunqiu Xu",
      "Junjie Xie",
      "Aojun Lu",
      "Tao Feng",
      "Zeying Huang",
      "Ning Zhang",
      "Yi Sun",
      "Yi Yang",
      "Hangjie Yuan"
    ],
    "url": "http://arxiv.org/abs/2601.01874v1",
    "published": "2026-01-05",
    "primary_category": "cs.CV",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种认知启发的三阶段框架CogFlow，通过知识内化阶段增强视觉数学问题解决中感知与推理的整合，属于多模态人工智能领域而非特定科学发现或扰动预测研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01860v1",
    "title": "High-Order Epistasis Detection Using Factorization Machine with Quadratic Optimization Annealing and MDR-Based Evaluation",
    "summary": "Detecting high-order epistasis is a fundamental challenge in genetic association studies due to the combinatorial explosion of candidate locus combinations. Although multifactor dimensionality reduction (MDR) is a widely used method for evaluating epistasis, exhaustive MDR-based searches become computationally infeasible as the number of loci or the interaction order increases. In this paper, we define the epistasis detection problem as a black-box optimization problem and solve it with a factorization machine with quadratic optimization annealing (FMQA). We propose an efficient epistasis detection method based on FMQA, in which the classification error rate (CER) computed by MDR is used as a black-box objective function. Experimental evaluations were conducted using simulated case-control datasets with predefined high-order epistasis. The results demonstrate that the proposed method successfully identified ground-truth epistasis across various interaction orders and the numbers of genetic loci within a limited number of iterations. These results indicate that the proposed method is effective and computationally efficient for high-order epistasis detection.",
    "authors": [
      "Shuta Kikuchi",
      "Shu Tanaka"
    ],
    "url": "http://arxiv.org/abs/2601.01860v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于因子分解机和二次优化退火的AI方法，用于高效检测遗传学中的高阶上位性相互作用，属于AI在生物学科学发现中的应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01857v1",
    "title": "Jenius Agent: Towards Experience-Driven Accuracy Optimization in Real-World Scenarios",
    "summary": "As agent systems powered by large language models (LLMs) advance, improving the task performance of an autonomous agent, especially in context understanding, tool usage, and response generation, has become increasingly critical. Although prior studies have advanced the overall design of LLM-based agents, systematic optimization of their internal reasoning and tool-use pipelines remains underexplored. This paper introduces an agent framework grounded in real-world practical experience, with three key innovations: (1) an adaptive prompt generation strategy that aligns with the agent's state and task goals to improve reliability and robustness; (2) a context-aware tool orchestration module that performs tool categorization, semantic retrieval, and adaptive invocation based on user intent and context; and (3) a layered memory mechanism that integrates session memory, task history, and external summaries to improve relevance and efficiency through dynamic summarization and compression. An end-to-end framework named Jenius-Agent has been integrated with three key optimizations, including tools based on the Model Context Protocol (MCP), file input/output (I/O), and execution feedback. The experiments show a 20 percent improvement in task accuracy, along with a reduced token cost, response latency, and invocation failures. The framework is already deployed in Jenius (https://www.jenius.cn), providing a lightweight and scalable solution for robust, protocol-compatible autonomous agents.",
    "authors": [
      "Defei Xia",
      "Bingfeng Pi",
      "Shenbin Zhang",
      "Song Hua",
      "Yunfei Wei",
      "Lei Zuo"
    ],
    "url": "http://arxiv.org/abs/2601.01857v1",
    "published": "2026-01-05",
    "primary_category": "cs.AI",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于实际经验优化的自主智能体框架，专注于提升任务性能、工具使用和响应生成，而非特定科学领域的AI应用或扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01853v1",
    "title": "Asymptotic Convergence and Stability of Adaptive Gradient Methods in Smooth Non-convex Optimization",
    "summary": "Adaptive gradient methods, such as AdaGrad, have become fundamental tools in deep learning. Despite their widespread use, the asymptotic convergence of AdaGrad remains poorly understood in non-convex scenarios. In this work, we present the first rigorous asymptotic convergence analysis of AdaGrad-Norm for smooth non-convex optimization. Using a novel stopping-time partitioning technique, we establish a key stability result: the objective function values remain bounded in expectation, and the iterates are bounded almost surely under a mild coercivity assumption. Building on these stability results, we prove that AdaGrad-Norm achieves both almost sure and mean-square convergence. Furthermore, we extend our analysis to RMSProp and show that, with appropriate hyperparameter choices, it also enjoys stability and asymptotic convergence. The techniques developed herein may be of independent interest for analyzing other adaptive stochastic optimization algorithms.",
    "authors": [
      "Ruinan Jin",
      "Xiaoyu Wang"
    ],
    "url": "http://arxiv.org/abs/2601.01853v1",
    "published": "2026-01-05",
    "primary_category": "math.OC",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于自适应梯度方法在非凸优化中的收敛性理论分析，属于机器学习优化算法的基础理论研究，而非应用于具体科学领域的AI4Science或扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01852v1",
    "title": "MORE: Multi-Objective Adversarial Attacks on Speech Recognition",
    "summary": "The emergence of large-scale automatic speech recognition (ASR) models such as Whisper has greatly expanded their adoption across diverse real-world applications. Ensuring robustness against even minor input perturbations is therefore critical for maintaining reliable performance in real-time environments. While prior work has mainly examined accuracy degradation under adversarial attacks, robustness with respect to efficiency remains largely unexplored. This narrow focus provides only a partial understanding of ASR model vulnerabilities. To address this gap, we conduct a comprehensive study of ASR robustness under multiple attack scenarios. We introduce MORE, a multi-objective repetitive doubling encouragement attack, which jointly degrades recognition accuracy and inference efficiency through a hierarchical staged repulsion-anchoring mechanism. Specifically, we reformulate multi-objective adversarial optimization into a hierarchical framework that sequentially achieves the dual objectives. To further amplify effectiveness, we propose a novel repetitive encouragement doubling objective (REDO) that induces duplicative text generation by maintaining accuracy degradation and periodically doubling the predicted sequence length. Overall, MORE compels ASR models to produce incorrect transcriptions at a substantially higher computational cost, triggered by a single adversarial input. Experiments show that MORE consistently yields significantly longer transcriptions while maintaining high word error rates compared to existing baselines, underscoring its effectiveness in multi-objective adversarial attack.",
    "authors": [
      "Xiaoxue Gao",
      "Zexin Li",
      "Yiming Chen",
      "Nancy F. Chen"
    ],
    "url": "http://arxiv.org/abs/2601.01852v1",
    "published": "2026-01-05",
    "primary_category": "eess.AS",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于开发针对语音识别系统的多目标对抗攻击方法，属于计算机安全与机器学习领域，而非利用AI进行科学发现或预测生物/分子层面的扰动响应。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01844v1",
    "title": "Clinical Knowledge Graph Construction and Evaluation with Multi-LLMs via Retrieval-Augmented Generation",
    "summary": "Large language models (LLMs) offer new opportunities for constructing knowledge graphs (KGs) from unstructured clinical narratives. However, existing approaches often rely on structured inputs and lack robust validation of factual accuracy and semantic consistency, limitations that are especially problematic in oncology. We introduce an end-to-end framework for clinical KG construction and evaluation directly from free text using multi-agent prompting and a schema-constrained Retrieval-Augmented Generation (KG-RAG) strategy. Our pipeline integrates (1) prompt-driven entity, attribute, and relation extraction; (2) entropy-based uncertainty scoring; (3) ontology-aligned RDF/OWL schema generation; and (4) multi-LLM consensus validation for hallucination detection and semantic refinement. Beyond static graph construction, the framework supports continuous refinement and self-supervised evaluation, enabling iterative improvement of graph quality. Applied to two oncology cohorts (PDAC and BRCA), our method produces interpretable, SPARQL-compatible, and clinically grounded knowledge graphs without relying on gold-standard annotations. Experimental results demonstrate consistent gains in precision, relevance, and ontology compliance over baseline methods.",
    "authors": [
      "Udiptaman Das",
      "Krishnasai B. Atmakuri",
      "Duy Ho",
      "Chi Lee",
      "Yugyung Lee"
    ],
    "url": "http://arxiv.org/abs/2601.01844v1",
    "published": "2026-01-05",
    "primary_category": "cs.AI",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种利用多智能体提示和检索增强生成技术从临床文本构建知识图谱的端到端框架，属于AI在生物医学领域的应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01840v1",
    "title": "Tackling Resource-Constrained and Data-Heterogeneity in Federated Learning with Double-Weight Sparse Pack",
    "summary": "Federated learning has drawn widespread interest from researchers, yet the data heterogeneity across edge clients remains a key challenge, often degrading model performance. Existing methods enhance model compatibility with data heterogeneity by splitting models and knowledge distillation. However, they neglect the insufficient communication bandwidth and computing power on the client, failing to strike an effective balance between addressing data heterogeneity and accommodating limited client resources. To tackle this limitation, we propose a personalized federated learning method based on cosine sparsification parameter packing and dual-weighted aggregation (FedCSPACK), which effectively leverages the limited client resources and reduces the impact of data heterogeneity on model performance. In FedCSPACK, the client packages model parameters and selects the most contributing parameter packages for sharing based on cosine similarity, effectively reducing bandwidth requirements. The client then generates a mask matrix anchored to the shared parameter package to improve the alignment and aggregation efficiency of sparse updates on the server. Furthermore, directional and distribution distance weights are embedded in the mask to implement a weighted-guided aggregation mechanism, enhancing the robustness and generalization performance of the global model. Extensive experiments across four datasets using ten state-of-the-art methods demonstrate that FedCSPACK effectively improves communication and computational efficiency while maintaining high model accuracy.",
    "authors": [
      "Qiantao Yang",
      "Liquan Chen",
      "Mingfu Xue",
      "Songze Li"
    ],
    "url": "http://arxiv.org/abs/2601.01840v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出一种联邦学习方法FedCSPACK，通过余弦稀疏参数打包和双权重聚合解决客户端资源受限和数据异质性问题，属于机器学习优化技术而非特定科学领域的AI应用或扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01839v1",
    "title": "The Machine Learning Canvas: Empirical Findings on Why Strategy Matters More Than AI Code Generation",
    "summary": "Despite the growing popularity of AI coding assistants, over 80% of machine learning (ML) projects fail to deliver real business value. This study creates and tests a Machine Learning Canvas, a practical framework that combines business strategy, software engineering, and data science in order to determine the factors that lead to the success of ML projects. We surveyed 150 data scientists and analyzed their responses using statistical modeling. We identified four key success factors: Strategy (clear goals and planning), Process (how work gets done), Ecosystem (tools and infrastructure), and Support (organizational backing and resources). Our results show that these factors are interconnected - each one affects the next. For instance, strong organizational support results in a clearer strategy (β= 0.432, p < 0.001), which improves work processes (β= 0.428, p < 0.001) and builds better infrastructure (β= 0.547, p < 0.001). Together, these elements determine whether a project succeeds. The surprising finding? Although AI assistants make coding faster, they don't guarantee project success. AI assists with the \"how\" of coding but cannot replace the \"why\" and \"what\" of strategic thinking.",
    "authors": [
      "Martin Prause"
    ],
    "url": "http://arxiv.org/abs/2601.01839v1",
    "published": "2026-01-05",
    "primary_category": "cs.SE",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文研究机器学习项目的成功因素，如战略和流程，而非将AI应用于科学发现或扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01836v1",
    "title": "COMPASS: A Framework for Evaluating Organization-Specific Policy Alignment in LLMs",
    "summary": "As large language models are deployed in high-stakes enterprise applications, from healthcare to finance, ensuring adherence to organization-specific policies has become essential. Yet existing safety evaluations focus exclusively on universal harms. We present COMPASS (Company/Organization Policy Alignment Assessment), the first systematic framework for evaluating whether LLMs comply with organizational allowlist and denylist policies. We apply COMPASS to eight diverse industry scenarios, generating and validating 5,920 queries that test both routine compliance and adversarial robustness through strategically designed edge cases. Evaluating seven state-of-the-art models, we uncover a fundamental asymmetry: models reliably handle legitimate requests (>95% accuracy) but catastrophically fail at enforcing prohibitions, refusing only 13-40% of adversarial denylist violations. These results demonstrate that current LLMs lack the robustness required for policy-critical deployments, establishing COMPASS as an essential evaluation framework for organizational AI safety.",
    "authors": [
      "Dasol Choi",
      "DongGeon Lee",
      "Brigitta Jesica Kartono",
      "Helena Berndt",
      "Taeyoun Kwon",
      "Joonwon Jang",
      "Haon Park",
      "Hwanjo Yu",
      "Minsuk Kahng"
    ],
    "url": "http://arxiv.org/abs/2601.01836v1",
    "published": "2026-01-05",
    "primary_category": "cs.AI",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出COMPASS框架，专注于评估大语言模型在企业特定政策遵循方面的表现，而非科学发现或细胞/基因扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01835v1",
    "title": "RSwinV2-MD: An Enhanced Residual SwinV2 Transformer for Monkeypox Detection from Skin Images",
    "summary": "In this paper, a deep learning approach for Mpox diagnosis named Customized Residual SwinTransformerV2 (RSwinV2) has been proposed, trying to enhance the capability of lesion classification by employing the RSwinV2 tool-assisted vision approach. In the RSwinV2 method, a hierarchical structure of the transformer has been customized based on the input dimensionality, embedding structure, and output targeted by the method. In this RSwinV2 approach, the input image has been split into non-overlapping patches and processed using shifted windows and attention in these patches. This process has helped the method link all the windows efficiently by avoiding the locality issues of non-overlapping regions in attention, while being computationally efficient. RSwinV2 has further developed based on SwinTransformer and has included patch and position embeddings to take advantage of the transformer global-linking capability by employing multi-head attention in these embeddings. Furthermore, RSwinV2 has developed and incorporated the Inverse Residual Block (IRB) into this method, which utilizes convolutional skip connections with these inclusive designs to address the vanishing gradient issues during processing. RSwinV2 inclusion of IRB has therefore facilitated this method to link global patterns as well as local patterns; hence, its integrity has helped improve lesion classification capability by minimizing variability of Mpox and increasing differences of Mpox, chickenpox, measles, and cowpox. In testing SwinV2, its accuracy of 96.21 and an F1score of 95.62 have been achieved on the Kaggle public dataset, which has outperformed standard CNN models and SwinTransformers; RSwinV2 vector has thus proved its valiance as a computer-assisted tool for Mpox lesion observation interpretation.",
    "authors": [
      "Rashid Iqbal",
      "Saddam Hussain Khan"
    ],
    "url": "http://arxiv.org/abs/2601.01835v1",
    "published": "2026-01-05",
    "primary_category": "cs.CV",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于改进SwinTransformer的深度学习方法RSwinV2-MD，用于从皮肤图像中检测猴痘，属于利用人工智能技术解决医学诊断问题的AI4Science范畴。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01833v1",
    "title": "FAROS: Robust Federated Learning with Adaptive Scaling against Backdoor Attacks",
    "summary": "Federated Learning (FL) enables multiple clients to collaboratively train a shared model without exposing local data. However, backdoor attacks pose a significant threat to FL. These attacks aim to implant a stealthy trigger into the global model, causing it to mislead on inputs that possess a specific trigger while functioning normally on benign data. Although pre-aggregation detection is a main defense direction, existing state-of-the-art defenses often rely on fixed defense parameters. This reliance makes them vulnerable to single-point-of-failure risks, rendering them less effective against sophisticated attackers. To address these limitations, we propose FAROS, an enhanced FL framework that incorporates Adaptive Differential Scaling (ADS) and Robust Core-set Computing (RCC). The ADS mechanism adjusts the defense's sensitivity dynamically, based on the dispersion of uploaded gradients by clients in each round. This allows it to counter attackers who strategically shift between stealthiness and effectiveness. Furthermore, the RCC effectively mitigates the risk of single-point failure by computing the centroid of a core set comprising clients with the highest confidence. We conducted extensive experiments across various datasets, models, and attack scenarios. The results demonstrate that our method outperforms current defenses in both attack success rate and main task accuracy.",
    "authors": [
      "Chenyu Hu",
      "Qiming Hu",
      "Sinan Chen",
      "Nianyu Li",
      "Mingyue Zhang",
      "Jialong Li"
    ],
    "url": "http://arxiv.org/abs/2601.01833v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种名为FAROS的联邦学习防御框架，通过自适应差分缩放和鲁棒核心集计算来增强对后门攻击的抵抗能力，属于机器学习安全领域的研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01832v1",
    "title": "Yukthi Opus: A Multi-Chain Hybrid Metaheuristic for Large-Scale NP-Hard Optimization",
    "summary": "We present Yukthi Opus (YO), a multi-chain hybrid metaheuristic designed for NP-hard optimization under explicit evaluation budget constraints. YO integrates three complementary mechanisms in a structured two-phase architecture: Markov Chain Monte Carlo (MCMC) for global exploration, greedy local search for exploitation, and simulated annealing with adaptive reheating to enable controlled escape from local minima. A dedicated burn-in phase allocates evaluations to probabilistic exploration, after which a hybrid optimization loop refines promising candidates. YO further incorporates a spatial blacklist mechanism to avoid repeated evaluation of poor regions and a multi-chain execution strategy to improve robustness and reduce sensitivity to initialization.   We evaluate YO on three benchmarks: the Rastrigin function (5D) with ablation studies, the Traveling Salesman Problem with 50 to 200 cities, and the Rosenbrock function (5D) with comparisons against established optimizers including CMA-ES, Bayesian optimization, and accelerated particle swarm optimization. Results show that MCMC exploration and greedy refinement are critical for solution quality, while simulated annealing and multi-chain execution primarily improve stability and variance reduction. Overall, YO achieves competitive performance on large and multimodal problems while maintaining predictable evaluation budgets, making it suitable for expensive black-box optimization settings.",
    "authors": [
      "SB Danush Vikraman",
      "Hannah Abagail",
      "Prasanna Kesavraj",
      "Gajanan V Honnavar"
    ],
    "url": "http://arxiv.org/abs/2601.01832v1",
    "published": "2026-01-05",
    "primary_category": "cs.NE",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于NP难优化问题的混合元启发式算法，属于通用优化方法研究，而非针对特定科学领域的AI应用或扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01831v1",
    "title": "ARIES: A Scalable Multi-Agent Orchestration Framework for Real-Time Epidemiological Surveillance and Outbreak Monitoring",
    "summary": "Global health surveillance is currently facing a challenge of Knowledge Gaps. While general-purpose AI has proliferated, it remains fundamentally unsuited for the high-stakes epidemiological domain due to chronic hallucinations and an inability to navigate specialized data silos. This paper introduces ARIES (Agentic Retrieval Intelligence for Epidemiological Surveillance), a specialized, autonomous multi-agent framework designed to move beyond static, disease-specific dashboards toward a dynamic intelligence ecosystem. Built on a hierarchical command structure, ARIES utilizes GPTs to orchestrate a scalable swarm of sub-agents capable of autonomously querying World Health Organization (WHO), Center for Disease Control and Prevention (CDC), and peer-reviewed research papers. By automating the extraction and logical synthesis of surveillance data, ARIES provides a specialized reasoning that identifies emergent threats and signal divergence in near real-time. This modular architecture proves that a task-specific agentic swarm can outperform generic models, offering a robust, extensible for next-generation outbreak response and global health intelligence.",
    "authors": [
      "Aniket Wattamwar",
      "Sampson Akwafuo"
    ],
    "url": "http://arxiv.org/abs/2601.01831v1",
    "published": "2026-01-05",
    "primary_category": "cs.MA",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一个专门用于流行病学监测的多智能体框架，通过AI技术自动化查询和分析公共卫生数据，属于AI在生物医学科学领域的应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01829v1",
    "title": "RealPDEBench: A Benchmark for Complex Physical Systems with Real-World Data",
    "summary": "Predicting the evolution of complex physical systems remains a central problem in science and engineering. Despite rapid progress in scientific Machine Learning (ML) models, a critical bottleneck is the lack of expensive real-world data, resulting in most current models being trained and validated on simulated data. Beyond limiting the development and evaluation of scientific ML, this gap also hinders research into essential tasks such as sim-to-real transfer. We introduce RealPDEBench, the first benchmark for scientific ML that integrates real-world measurements with paired numerical simulations. RealPDEBench consists of five datasets, three tasks, eight metrics, and ten baselines. We first present five real-world measured datasets with paired simulated datasets across different complex physical systems. We further define three tasks, which allow comparisons between real-world and simulated data, and facilitate the development of methods to bridge the two. Moreover, we design eight evaluation metrics, spanning data-oriented and physics-oriented metrics, and finally benchmark ten representative baselines, including state-of-the-art models, pretrained PDE foundation models, and a traditional method. Experiments reveal significant discrepancies between simulated and real-world data, while showing that pretraining with simulated data consistently improves both accuracy and convergence. In this work, we hope to provide insights from real-world data, advancing scientific ML toward bridging the sim-to-real gap and real-world deployment. Our benchmark, datasets, and instructions are available at https://realpdebench.github.io/.",
    "authors": [
      "Peiyan Hu",
      "Haodong Feng",
      "Hongyuan Liu",
      "Tongtong Yan",
      "Wenhao Deng",
      "Tianrun Gao",
      "Rong Zheng",
      "Haoren Zheng",
      "Chenglei Yu",
      "Chuanrui Wang",
      "Kaiwen Li",
      "Zhi-Ming Ma",
      "Dezhi Zhou",
      "Xingcai Lu",
      "Dixia Fan",
      "Tailin Wu"
    ],
    "url": "http://arxiv.org/abs/2601.01829v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文通过整合真实世界测量数据与数值模拟，为复杂物理系统的科学机器学习建立首个基准测试，旨在弥合模拟与现实的差距。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01828v1",
    "title": "Emergent Introspective Awareness in Large Language Models",
    "summary": "We investigate whether large language models can introspect on their internal states. It is difficult to answer this question through conversation alone, as genuine introspection cannot be distinguished from confabulations. Here, we address this challenge by injecting representations of known concepts into a model's activations, and measuring the influence of these manipulations on the model's self-reported states. We find that models can, in certain scenarios, notice the presence of injected concepts and accurately identify them. Models demonstrate some ability to recall prior internal representations and distinguish them from raw text inputs. Strikingly, we find that some models can use their ability to recall prior intentions in order to distinguish their own outputs from artificial prefills. In all these experiments, Claude Opus 4 and 4.1, the most capable models we tested, generally demonstrate the greatest introspective awareness; however, trends across models are complex and sensitive to post-training strategies. Finally, we explore whether models can explicitly control their internal representations, finding that models can modulate their activations when instructed or incentivized to \"think about\" a concept. Overall, our results indicate that current language models possess some functional introspective awareness of their own internal states. We stress that in today's models, this capacity is highly unreliable and context-dependent; however, it may continue to develop with further improvements to model capabilities.",
    "authors": [
      "Jack Lindsey"
    ],
    "url": "http://arxiv.org/abs/2601.01828v1",
    "published": "2026-01-05",
    "primary_category": "cs.CL",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文研究大型语言模型的自我认知能力，通过注入概念表征来测试模型对内部状态的感知，属于人工智能基础研究而非具体科学领域的应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01827v1",
    "title": "Aspect Extraction from E-Commerce Product and Service Reviews",
    "summary": "Aspect Extraction (AE) is a key task in Aspect-Based Sentiment Analysis (ABSA), yet it remains difficult to apply in low-resource and code-switched contexts like Taglish, a mix of Tagalog and English commonly used in Filipino e-commerce reviews. This paper introduces a comprehensive AE pipeline designed for Taglish, combining rule-based, large language model (LLM)-based, and fine-tuning techniques to address both aspect identification and extraction. A Hierarchical Aspect Framework (HAF) is developed through multi-method topic modeling, along with a dual-mode tagging scheme for explicit and implicit aspects. For aspect identification, four distinct models are evaluated: a Rule-Based system, a Generative LLM (Gemini 2.0 Flash), and two Fine-Tuned Gemma-3 1B models trained on different datasets (Rule-Based vs. LLM-Annotated). Results indicate that the Generative LLM achieved the highest performance across all tasks (Macro F1 0.91), demonstrating superior capability in handling implicit aspects. In contrast, the fine-tuned models exhibited limited performance due to dataset imbalance and architectural capacity constraints. This work contributes a scalable and linguistically adaptive framework for enhancing ABSA in diverse, code-switched environments.",
    "authors": [
      "Valiant Lance D. Dionela",
      "Fatima Kriselle S. Dy",
      "Robin James M. Hombrebueno",
      "Aaron Rae M. Nicolas",
      "Charibeth K. Cheng",
      "Raphael W. Gonda"
    ],
    "url": "http://arxiv.org/abs/2601.01827v1",
    "published": "2026-01-05",
    "primary_category": "cs.CL",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于电子商务评论中的方面提取任务，属于自然语言处理领域，不涉及生物学、化学或物理学等科学发现，也不涉及细胞或基因层面的扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01816v1",
    "title": "Admissibility Alignment",
    "summary": "This paper introduces Admissibility Alignment: a reframing of AI alignment as a property of admissible action and decision selection over distributions of outcomes under uncertainty, evaluated through the behavior of candidate policies. We present MAP-AI (Monte Carlo Alignment for Policy) as a canonical system architecture for operationalizing admissibility alignment, formalizing alignment as a probabilistic, decision-theoretic property rather than a static or binary condition.   MAP-AI, a new control-plane system architecture for aligned decision-making under uncertainty, enforces alignment through Monte Carlo estimation of outcome distributions and admissibility-controlled policy selection rather than static model-level constraints. The framework evaluates decision policies across ensembles of plausible futures, explicitly modeling uncertainty, intervention effects, value ambiguity, and governance constraints. Alignment is assessed through distributional properties including expected utility, variance, tail risk, and probability of misalignment rather than accuracy or ranking performance. This approach distinguishes probabilistic prediction from decision reasoning under uncertainty and provides an executable methodology for evaluating trust and alignment in enterprise and institutional AI systems. The result is a practical foundation for governing AI systems whose impact is determined not by individual forecasts, but by policy behavior across distributions and tail events. Finally, we show how distributional alignment evaluation can be integrated into decision-making itself, yielding an admissibility-controlled action selection mechanism that alters policy behavior under uncertainty without retraining or modifying underlying models.",
    "authors": [
      "Chris Duffey"
    ],
    "url": "http://arxiv.org/abs/2601.01816v1",
    "published": "2026-01-05",
    "primary_category": "cs.AI",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于概率决策理论和蒙特卡洛方法的AI对齐框架，专注于政策行为在不确定性下的分布评估，而非特定科学领域的发现或细胞扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01813v1",
    "title": "Spatio-temporal modeling and forecasting with Fourier neural operators",
    "summary": "Spatio-temporal process models are often used for modeling dynamic physical and biological phenomena that evolve across space and time. These phenomena may exhibit environmental heterogeneity and complex interactions that are difficult to capture using traditional statistical process models such as Gaussian processes. This work proposes the use of Fourier neural operators (FNOs) for constructing statistical dynamical spatio-temporal models for forecasting. An FNO is a flexible mapping of functions that approximates the solution operator of possibly unknown linear or non-linear partial differential equations (PDEs) in a computationally efficient manner. It does so using samples of inputs and their respective outputs, and hence explicit knowledge of the underlying PDE is not required. Through simulations from a nonlinear PDE with known solution, we compare FNO forecasts to those from state-of-the-art statistical spatio-temporal-forecasting methods. Further, using sea surface temperature data over the Atlantic Ocean and precipitation data across Europe, we demonstrate the ability of FNO-based dynamic spatio-temporal (DST) statistical modeling to capture complex real-world spatio-temporal dependencies. Using collections of testing instances, we show that the FNO-DST forecasts are accurate with valid uncertainty quantification.",
    "authors": [
      "Pratik Nag",
      "Andrew Zammit-Mangion",
      "Sumeetpal Singh",
      "Noel Cressie"
    ],
    "url": "http://arxiv.org/abs/2601.01813v1",
    "published": "2026-01-05",
    "primary_category": "stat.ME",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出使用傅里叶神经算子进行时空建模，通过海洋温度和降水数据验证其在环境科学领域的预测能力，属于AI在科学发现中的应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01807v1",
    "title": "Adaptive Hybrid Optimizer based Framework for Lumpy Skin Disease Identification",
    "summary": "Lumpy Skin Disease (LSD) is a contagious viral infection that significantly deteriorates livestock health, thereby posing a serious threat to the global economy and food security. Owing to its rapid spread characteristics, early and precise identification is crucial to prevent outbreaks and ensure timely intervention. In this paper, we propose a hybrid deep learning-based approach called LUMPNet for the early detection of LSD. LUMPNet utilizes image data to detect and classify skin nodules -- the primary indicator of LSD. To this end, LUMPNet uses YOLOv11, EfficientNet-based CNN classifier with compound scaling, and a novel adaptive hybrid optimizer. More precisely, LUMPNet detects and localizes LSD skin nodules and lesions on cattle images. It exploits EfficientNet to classify the localized cattle images into LSD-affected or healthy categories. To stabilize and accelerate the training of YOLOv11 and EfficientNet hybrid model, a novel adaptive hybrid optimizer is proposed and utilized. We evaluate LUMPNet at various stages of LSD using a publicly available dataset. Results indicate that the proposed scheme achieves 99% LSD detection training accuracy, and outperforms existing schemes. The model also achieves validation accuracy of 98%. Moreover, for further evaluation, we conduct a case study using an optimized EfficientNet-B0 model trained with the AdamW optimizer, and compare its performance with LUMPNet. The results show that LUMPNet achieves superior performance.",
    "authors": [
      "Ubaidullah",
      "Muhammad Abid Hussain",
      "Mohsin Raza Jafri",
      "Rozi Khan",
      "Moid Sandhu",
      "Abd Ullah Khan",
      "Hyundong Shin"
    ],
    "url": "http://arxiv.org/abs/2601.01807v1",
    "published": "2026-01-05",
    "primary_category": "cs.CV",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于混合深度学习的自适应优化框架LUMPNet，用于通过图像数据检测和分类牛结节性皮肤病，属于AI在兽医病理学领域的应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01803v1",
    "title": "Moments Matter:Stabilizing Policy Optimization using Return Distributions",
    "summary": "Deep Reinforcement Learning (RL) agents often learn policies that achieve the same episodic return yet behave very differently, due to a combination of environmental (random transitions, initial conditions, reward noise) and algorithmic (minibatch selection, exploration noise) factors. In continuous control tasks, even small parameter shifts can produce unstable gaits, complicating both algorithm comparison and real-world transfer. Previous work has shown that such instability arises when policy updates traverse noisy neighborhoods and that the spread of post-update return distribution $R(θ)$, obtained by repeatedly sampling minibatches, updating $θ$, and measuring final returns, is a useful indicator of this noise. Although explicitly constraining the policy to maintain a narrow $R(θ)$ can improve stability, directly estimating $R(θ)$ is computationally expensive in high-dimensional settings. We propose an alternative that takes advantage of environmental stochasticity to mitigate update-induced variability. Specifically, we model state-action return distribution through a distributional critic and then bias the advantage function of PPO using higher-order moments (skewness and kurtosis) of this distribution. By penalizing extreme tail behaviors, our method discourages policies from entering parameter regimes prone to instability. We hypothesize that in environments where post-update critic values align poorly with post-update returns, standard PPO struggles to produce a narrow $R(θ)$. In such cases, our moment-based correction narrows $R(θ)$, improving stability by up to 75% in Walker2D, while preserving comparable evaluation returns.",
    "authors": [
      "Dennis Jabs",
      "Aditya Mohan",
      "Marius Lindauer"
    ],
    "url": "http://arxiv.org/abs/2601.01803v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种通过分布评论家建模状态-动作回报分布，并利用高阶矩（偏度和峰度）修正PPO优势函数来稳定强化学习策略优化的方法。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01802v1",
    "title": "PsychEval: A Multi-Session and Multi-Therapy Benchmark for High-Realism and Comprehensive AI Psychological Counselor",
    "summary": "To develop a reliable AI for psychological assessment, we introduce \\texttt{PsychEval}, a multi-session, multi-therapy, and highly realistic benchmark designed to address three key challenges: \\textbf{1) Can we train a highly realistic AI counselor?} Realistic counseling is a longitudinal task requiring sustained memory and dynamic goal tracking. We propose a multi-session benchmark (spanning 6-10 sessions across three distinct stages) that demands critical capabilities such as memory continuity, adaptive reasoning, and longitudinal planning. The dataset is annotated with extensive professional skills, comprising over 677 meta-skills and 4577 atomic skills. \\textbf{2) How to train a multi-therapy AI counselor?} While existing models often focus on a single therapy, complex cases frequently require flexible strategies among various therapies. We construct a diverse dataset covering five therapeutic modalities (Psychodynamic, Behaviorism, CBT, Humanistic Existentialist, and Postmodernist) alongside an integrative therapy with a unified three-stage clinical framework across six core psychological topics. \\textbf{3) How to systematically evaluate an AI counselor?} We establish a holistic evaluation framework with 18 therapy-specific and therapy-shared metrics across Client-Level and Counselor-Level dimensions. To support this, we also construct over 2,000 diverse client profiles. Extensive experimental analysis fully validates the superior quality and clinical fidelity of our dataset. Crucially, \\texttt{PsychEval} transcends static benchmarking to serve as a high-fidelity reinforcement learning environment that enables the self-evolutionary training of clinically responsible and adaptive AI counselors.",
    "authors": [
      "Qianjun Pan",
      "Junyi Wang",
      "Jie Zhou",
      "Yutao Yang",
      "Junsong Li",
      "Kaiyin Xu",
      "Yougen Zhou",
      "Yihan Li",
      "Jingyuan Zhao",
      "Qin Chen",
      "Ningning Zhou",
      "Kai Chen",
      "Liang He"
    ],
    "url": "http://arxiv.org/abs/2601.01802v1",
    "published": "2026-01-05",
    "primary_category": "cs.AI",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一个用于评估AI心理咨询师的多会话、多疗法基准测试框架，属于AI在心理健康领域的应用研究，而非传统自然科学领域的科学发现或细胞分子层面的扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01800v1",
    "title": "Sparse Threats, Focused Defense: Criticality-Aware Robust Reinforcement Learning for Safe Autonomous Driving",
    "summary": "Reinforcement learning (RL) has shown considerable potential in autonomous driving (AD), yet its vulnerability to perturbations remains a critical barrier to real-world deployment. As a primary countermeasure, adversarial training improves policy robustness by training the AD agent in the presence of an adversary that deliberately introduces perturbations. Existing approaches typically model the interaction as a zero-sum game with continuous attacks. However, such designs overlook the inherent asymmetry between the agent and the adversary and then fail to reflect the sparsity of safety-critical risks, rendering the achieved robustness inadequate for practical AD scenarios. To address these limitations, we introduce criticality-aware robust RL (CARRL), a novel adversarial training approach for handling sparse, safety-critical risks in autonomous driving. CARRL consists of two interacting components: a risk exposure adversary (REA) and a risk-targeted robust agent (RTRA). We model the interaction between the REA and RTRA as a general-sum game, allowing the REA to focus on exposing safety-critical failures (e.g., collisions) while the RTRA learns to balance safety with driving efficiency. The REA employs a decoupled optimization mechanism to better identify and exploit sparse safety-critical moments under a constrained budget. However, such focused attacks inevitably result in a scarcity of adversarial data. The RTRA copes with this scarcity by jointly leveraging benign and adversarial experiences via a dual replay buffer and enforces policy consistency under perturbations to stabilize behavior. Experimental results demonstrate that our approach reduces the collision rate by at least 22.66\\% across all cases compared to state-of-the-art baseline methods.",
    "authors": [
      "Qi Wei",
      "Junchao Fan",
      "Zhao Yang",
      "Jianhua Wang",
      "Jingkai Mao",
      "Xiaolin Chang"
    ],
    "url": "http://arxiv.org/abs/2601.01800v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种针对自动驾驶中稀疏安全风险的对抗性强化学习方法，通过风险暴露对抗器和风险目标鲁棒代理的博弈设计来提升策略的鲁棒性。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01798v1",
    "title": "VerLM: Explaining Face Verification Using Natural Language",
    "summary": "Face verification systems have seen substantial advancements; however, they often lack transparency in their decision-making processes. In this paper, we introduce an innovative Vision-Language Model (VLM) for Face Verification, which not only accurately determines if two face images depict the same individual but also explicitly explains the rationale behind its decisions. Our model is uniquely trained using two complementary explanation styles: (1) concise explanations that summarize the key factors influencing its decision, and (2) comprehensive explanations detailing the specific differences observed between the images. We adapt and enhance a state-of-the-art modeling approach originally designed for audio-based differentiation to suit visual inputs effectively. This cross-modal transfer significantly improves our model's accuracy and interpretability. The proposed VLM integrates sophisticated feature extraction techniques with advanced reasoning capabilities, enabling clear articulation of its verification process. Our approach demonstrates superior performance, surpassing baseline methods and existing models. These findings highlight the immense potential of vision language models in face verification set up, contributing to more transparent, reliable, and explainable face verification systems.",
    "authors": [
      "Syed Abdul Hannan",
      "Hazim Bukhari",
      "Thomas Cantalapiedra",
      "Eman Ansar",
      "Massa Baali",
      "Rita Singh",
      "Bhiksha Raj"
    ],
    "url": "http://arxiv.org/abs/2601.01798v1",
    "published": "2026-01-05",
    "primary_category": "cs.CV",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于人脸验证的可解释视觉语言模型，通过自然语言解释其决策过程，属于计算机视觉与自然语言处理的交叉领域，而非AI4Science或扰动预测研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01793v1",
    "title": "Distributed Federated Learning by Alternating Periods of Training",
    "summary": "Federated learning is a privacy-focused approach towards machine learning where models are trained on client devices with locally available data and aggregated at a central server. However, the dependence on a single central server is challenging in the case of a large number of clients and even poses the risk of a single point of failure. To address these critical limitations of scalability and fault-tolerance, we present a distributed approach to federated learning comprising multiple servers with inter-server communication capabilities. While providing a fully decentralized approach, the designed framework retains the core federated learning structure where each server is associated with a disjoint set of clients with server-client communication capabilities. We propose a novel DFL (Distributed Federated Learning) algorithm which uses alternating periods of local training on the client data followed by global training among servers. We show that the DFL algorithm, under a suitable choice of parameters, ensures that all the servers converge to a common model value within a small tolerance of the ideal model, thus exhibiting effective integration of local and global training models. Finally, we illustrate our theoretical claims through numerical simulations.",
    "authors": [
      "Shamik Bhattacharyya",
      "Rachel Kalpana Kalaimani"
    ],
    "url": "http://arxiv.org/abs/2601.01793v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种分布式联邦学习算法，通过交替本地训练和服务器间全局训练来解决传统联邦学习的可扩展性和容错性问题，属于机器学习系统优化领域。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01792v1",
    "title": "HyperCLOVA X 8B Omni",
    "summary": "In this report, we present HyperCLOVA X 8B Omni, the first any-to-any omnimodal model in the HyperCLOVA X family that supports text, audio, and vision as both inputs and outputs. By consolidating multimodal understanding and generation into a single model rather than separate modality-specific pipelines, HyperCLOVA X 8B Omni serves as an 8B-scale omni-pathfinding point toward practical any-to-any omni assistants. At a high level, the model unifies modalities through a shared next-token prediction interface over an interleaved multimodal sequence, while vision and audio encoders inject continuous embeddings for fine-grained understanding and grounding. Empirical evaluations demonstrate competitive performance against comparably sized models across diverse input-output combinations spanning text, audio, and vision, in both Korean and English. We anticipate that the open-weight release of HyperCLOVA X 8B Omni will support a wide range of research and deployment scenarios.",
    "authors": [
      "NAVER Cloud HyperCLOVA X Team"
    ],
    "url": "http://arxiv.org/abs/2601.01792v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文介绍了一个支持文本、音频和视觉多模态输入输出的通用人工智能模型，而非专门针对科学发现或细胞扰动预测的研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01786v1",
    "title": "UnPII: Unlearning Personally Identifiable Information with Quantifiable Exposure Risk",
    "summary": "The ever-increasing adoption of Large Language Models in critical sectors like finance, healthcare, and government raises privacy concerns regarding the handling of sensitive Personally Identifiable Information (PII) during training. In response, regulations such as European Union's General Data Protection Regulation (GDPR) mandate the deletion of PII upon requests, underscoring the need for reliable and cost-effective data removal solutions. Machine unlearning has emerged as a promising direction for selectively forgetting data points. However, existing unlearning techniques typically apply a uniform forgetting strategy that neither accounts for the varying privacy risks posed by different PII attributes nor reflects associated business risks. In this work, we propose UnPII, the first PII-centric unlearning approach that prioritizes forgetting based on the risk of individual or combined PII attributes. To this end, we introduce the PII risk index (PRI), a composite metric that incorporates multiple dimensions of risk factors: identifiability, sensitivity, usability, linkability, permanency, exposability, and compliancy. The PRI enables a nuanced evaluation of privacy risks associated with PII exposures and can be tailored to align with organizational privacy policies. To support realistic assessment, we systematically construct a synthetic PII dataset (e.g., 1,700 PII instances) that simulates realistic exposure scenarios. UnPII seamlessly integrates with established unlearning algorithms, such as Gradient Ascent, Negative Preference Optimization, and Direct Preference Optimization, without modifying their underlying principles. Our experimental results demonstrate that UnPII achieves the improvements of accuracy up to 11.8%, utility up to 6.3%, and generalizability up to 12.4%, respectively, while incurring a modest fine-tuning overhead of 27.5% on average during unlearning.",
    "authors": [
      "Intae Jeon",
      "Yujeong Kwon",
      "Hyungjoon Koo"
    ],
    "url": "http://arxiv.org/abs/2601.01786v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于风险评估的PII遗忘方法，专注于提升大型语言模型在隐私合规场景下的数据删除效率和安全性。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01785v1",
    "title": "SRAS: A Lightweight Reinforcement Learning-based Document Selector for Edge-Native RAG Pipelines",
    "summary": "Retrieval-Augmented Generation (RAG) systems often rely on fixed top-k document selection mechanisms that ignore downstream generation quality and impose computational overheads. We propose SRAS (Sparse Reward-Aware Selector), a lightweight document selector trained via reinforcement learning (RL) for edge-native RAG deployment. Unlike prior RL-based retrievers that assume large memory and latency budgets, SRAS learns a compact (~0.76MB) policy using Proximal Policy Optimization (PPO), guided by a hybrid reward signal combining Relaxed F1 and BERTScore. Our method operates under tight token and compute constraints, maintaining <1s latency on CPU. SRAS outperforms supervised and random selectors on a synthetic QA benchmark, and generalizes to real-world data, achieving BERTScore F1 of 0.8546 on SQuAD v2 without domain-specific tuning. This work is the first to demonstrate that RL-based document selection can be made ultra-lightweight, latency-aware, and effective for on-device RAG pipelines.",
    "authors": [
      "Rajiv Chaitanya Muttur"
    ],
    "url": "http://arxiv.org/abs/2601.01785v1",
    "published": "2026-01-05",
    "primary_category": "cs.IR",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于边缘计算环境中检索增强生成系统的轻量级文档选择器，属于自然语言处理与系统优化领域，而非针对特定科学发现或细胞/基因扰动预测的研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01781v1",
    "title": "Subimage Overlap Prediction: Task-Aligned Self-Supervised Pretraining For Semantic Segmentation In Remote Sensing Imagery",
    "summary": "Self-supervised learning (SSL) methods have become a dominant paradigm for creating general purpose models whose capabilities can be transferred to downstream supervised learning tasks. However, most such methods rely on vast amounts of pretraining data. This work introduces Subimage Overlap Prediction, a novel self-supervised pretraining task to aid semantic segmentation in remote sensing imagery that uses significantly lesser pretraining imagery. Given an image, a sub-image is extracted and the model is trained to produce a semantic mask of the location of the extracted sub-image within the original image. We demonstrate that pretraining with this task results in significantly faster convergence, and equal or better performance (measured via mIoU) on downstream segmentation. This gap in convergence and performance widens when labeled training data is reduced. We show this across multiple architecture types, and with multiple downstream datasets. We also show that our method matches or exceeds performance while requiring significantly lesser pretraining data relative to other SSL methods. Code and model weights are provided at \\href{https://github.com/sharmalakshay93/subimage-overlap-prediction}{github.com/sharmalakshay93/subimage-overlap-prediction}.",
    "authors": [
      "Lakshay Sharma",
      "Alex Marin"
    ],
    "url": "http://arxiv.org/abs/2601.01781v1",
    "published": "2026-01-05",
    "primary_category": "cs.CV",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于遥感图像语义分割的自监督预训练方法，通过子图像重叠预测任务减少预训练数据需求并提升下游任务性能。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01780v1",
    "title": "LIA: Supervised Fine-Tuning of Large Language Models for Automatic Issue Assignment",
    "summary": "Issue assignment is a critical process in software maintenance, where new issue reports are validated and assigned to suitable developers. However, manual issue assignment is often inconsistent and error-prone, especially in large open-source projects where thousands of new issues are reported monthly. Existing automated approaches have shown promise, but many rely heavily on large volumes of project-specific training data or relational information that is often sparse and noisy, which limits their effectiveness. To address these challenges, we propose LIA (LLM-based Issue Assignment), which employs supervised fine-tuning to adapt an LLM, DeepSeek-R1-Distill-Llama-8B in this work, for automatic issue assignment. By leveraging the LLM's pretrained semantic understanding of natural language and software-related text, LIA learns to generate ranked developer recommendations directly from issue titles and descriptions. The ranking is based on the model's learned understanding of historical issue-to-developer assignments, using patterns from past tasks to infer which developers are most likely to handle new issues. Through comprehensive evaluation, we show that LIA delivers substantial improvements over both its base pretrained model and state-of-the-art baselines. It achieves up to +187.8% higher Hit@1 compared to the DeepSeek-R1-Distill-Llama-8B pretrained base model, and outperforms four leading issue assignment methods by as much as +211.2% in Hit@1 score. These results highlight the effectiveness of domain-adapted LLMs for software maintenance tasks and establish LIA as a practical, high-performing solution for issue assignment.",
    "authors": [
      "Arsham Khosravani",
      "Alireza Hosseinpour",
      "Arshia Akhavan",
      "Mehdi Keshani",
      "Abbas Heydarnoori"
    ],
    "url": "http://arxiv.org/abs/2601.01780v1",
    "published": "2026-01-05",
    "primary_category": "cs.SE",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于大语言模型监督微调的软件维护任务自动分配方法，属于软件工程领域而非自然科学发现或生物医学扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01779v1",
    "title": "Machine learning modularity",
    "summary": "Based on a transformer based sequence-to-sequence architecture combined with a dynamic batching algorithm, this work introduces a machine learning framework for automatically simplifying complex expressions involving multiple elliptic Gamma functions, including the $q$-$θ$ function and the elliptic Gamma function. The model learns to apply algebraic identities, particularly the SL$(2,\\mathbb{Z})$ and SL$(3,\\mathbb{Z})$ modular transformations, to reduce heavily scrambled expressions to their canonical forms. Experimental results show that the model achieves over 99\\% accuracy on in-distribution tests and maintains robust performance (exceeding 90\\% accuracy) under significant extrapolation, such as with deeper scrambling depths. This demonstrates that the model has internalized the underlying algebraic rules of modular transformations rather than merely memorizing training patterns. Our work presents the first successful application of machine learning to perform symbolic simplification using modular identities, offering a new automated tool for computations with special functions in quantum field theory and the string theory.",
    "authors": [
      "Yi Fan",
      "Vishnu Jejjala",
      "Yang Lei"
    ],
    "url": "http://arxiv.org/abs/2601.01779v1",
    "published": "2026-01-05",
    "primary_category": "hep-th",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出首个基于机器学习利用模变换代数规则自动简化量子场论和弦理论中特殊函数表达式的框架，属于AI在物理学领域的科学发现应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01776v1",
    "title": "Data-driven sparse modeling and decomposition for superspreading-wetting dynamics of a droplet",
    "summary": "Superspreading wetting is traditionally attributed to surfactant-driven mechanisms. However, recent observations of superspreading in surfactant-free nanofluids defy standard theoretical explanations. This study considers a data-driven approach to model droplet dynamics with the thickness of liquid films on the nanometer-micrometer scale in a compact form of a partial differential equation. We examine spatiotemporal film-thickness profiles resolved at the nanometer scale via phase-shifting imaging ellipsometry. For a pure solvent, the present governing equation recovers the classical lubrication physics driven by disjoining pressure and evaporation. In contrast, the nanofluid dynamics necessitates a unique transport term scaling with the gradient of the inverse film thickness. Theoretical analysis suggests this term represents a nanoparticle-induced bias flux, consistent with a hypothesized capillary wicking mechanism within the precursor film. The identification of the current nanofluid-specific term underscores the efficacy of integrating high-precision experimental measurements with data-driven modeling to unravel complex wetting dynamics.",
    "authors": [
      "Kai Fukami",
      "Eita Shoji"
    ],
    "url": "http://arxiv.org/abs/2601.01776v1",
    "published": "2026-01-05",
    "primary_category": "physics.flu-dyn",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文通过数据驱动建模方法，结合高精度实验测量，揭示了纳米流体超铺展润湿动力学中纳米颗粒诱导的偏置通量机制。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01774v1",
    "title": "Can Large Language Models Solve Engineering Equations? A Systematic Comparison of Direct Prediction and Solver-Assisted Approaches",
    "summary": "Transcendental equations requiring iterative numerical solution pervade engineering practice, from fluid mechanics friction factor calculations to orbital position determination. We systematically evaluate whether Large Language Models can solve these equations through direct numerical prediction or whether a hybrid architecture combining LLM symbolic manipulation with classical iterative solvers proves more effective. Testing six state-of-the-art models (GPT-5.1, GPT-5.2, Gemini-3-Flash, Gemini-2.5-Lite, Claude-Sonnet-4.5, Claude-Opus-4.5) on 100 problems spanning seven engineering domains, we compare direct prediction against solver-assisted computation where LLMs formulate governing equations and provide initial conditions while Newton-Raphson iteration performs numerical solution. Direct prediction yields mean relative errors of 0.765 to 1.262 across models, while solver-assisted computation achieves 0.225 to 0.301, representing error reductions of 67.9% to 81.8%. Domain-specific analysis reveals dramatic improvements in Electronics (93.1%) due to exponential equation sensitivity, contrasted with modest gains in Fluid Mechanics (7.2%) where LLMs exhibit effective pattern recognition. These findings establish that contemporary LLMs excel at symbolic manipulation and domain knowledge retrieval but struggle with precision-critical iterative arithmetic, suggesting their optimal deployment as intelligent interfaces to classical numerical solvers rather than standalone computational engines.",
    "authors": [
      "Sai Varun Kodathala",
      "Rakesh Vunnam"
    ],
    "url": "http://arxiv.org/abs/2601.01774v1",
    "published": "2026-01-05",
    "primary_category": "cs.AI",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文系统评估了大型语言模型在工程方程求解中的表现，通过比较直接预测与求解器辅助方法，为AI在科学计算领域的应用提供了实证依据。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01765v1",
    "title": "A New Benchmark for the Appropriate Evaluation of RTL Code Optimization",
    "summary": "The rapid progress of artificial intelligence increasingly relies on efficient integrated circuit (IC) design. Recent studies have explored the use of large language models (LLMs) for generating Register Transfer Level (RTL) code, but existing benchmarks mainly evaluate syntactic correctness rather than optimization quality in terms of power, performance, and area (PPA). This work introduces RTL-OPT, a benchmark for assessing the capability of LLMs in RTL optimization. RTL-OPT contains 36 handcrafted digital designs that cover diverse implementation categories including combinational logic, pipelined datapaths, finite state machines, and memory interfaces. Each task provides a pair of RTL codes, a suboptimal version and a human-optimized reference that reflects industry-proven optimization patterns not captured by conventional synthesis tools. Furthermore, RTL-OPT integrates an automated evaluation framework to verify functional correctness and quantify PPA improvements, enabling standardized and meaningful assessment of generative models for hardware design optimization.",
    "authors": [
      "Yao Lu",
      "Shang Liu",
      "Hangan Zhou",
      "Wenji Fang",
      "Qijun Zhang",
      "Zhiyao Xie"
    ],
    "url": "http://arxiv.org/abs/2601.01765v1",
    "published": "2026-01-05",
    "primary_category": "cs.AI",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出用于评估大语言模型在硬件设计优化中性能的RTL-OPT基准测试，属于集成电路设计领域而非传统自然科学发现。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01757v1",
    "title": "Sparse Convex Biclustering",
    "summary": "Biclustering is an essential unsupervised machine learning technique for simultaneously clustering rows and columns of a data matrix, with widespread applications in genomics, transcriptomics, and other high-dimensional omics data. Despite its importance, existing biclustering methods struggle to meet the demands of modern large-scale datasets. The challenges stem from the accumulation of noise in high-dimensional features, the limitations of non-convex optimization formulations, and the computational complexity of identifying meaningful biclusters. These issues often result in reduced accuracy and stability as the size of the dataset increases. To overcome these challenges, we propose Sparse Convex Biclustering (SpaCoBi), a novel method that penalizes noise during the biclustering process to improve both accuracy and robustness. By adopting a convex optimization framework and introducing a stability-based tuning criterion, SpaCoBi achieves an optimal balance between cluster fidelity and sparsity. Comprehensive numerical studies, including simulations and an application to mouse olfactory bulb data, demonstrate that SpaCoBi significantly outperforms state-of-the-art methods in accuracy. These results highlight SpaCoBi as a robust and efficient solution for biclustering in high-dimensional and large-scale datasets.",
    "authors": [
      "Jiakun Jiang",
      "Dewei Xiang",
      "Chenliang Gu",
      "Wei Liu",
      "Binhuan Wang"
    ],
    "url": "http://arxiv.org/abs/2601.01757v1",
    "published": "2026-01-05",
    "primary_category": "stat.ML",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于高维组学数据分析的稀疏凸双聚类方法，通过改进机器学习算法来增强生物数据挖掘能力。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01756v1",
    "title": "A Wachspress-based transfinite formulation for exactly enforcing Dirichlet boundary conditions on convex polygonal domains in physics-informed neural networks",
    "summary": "In this paper, we present a Wachspress-based transfinite formulation on convex polygonal domains for exact enforcement of Dirichlet boundary conditions in physics-informed neural networks. This approach leverages prior advances in geometric design such as blending functions and transfinite interpolation over convex domains. For prescribed Dirichlet boundary function $\\mathcal{B}$, the transfinite interpolant of $\\mathcal{B}$, $g : \\bar P \\to C^0(\\bar P)$, $\\textit{lifts}$ functions from the boundary of a two-dimensional polygonal domain to its interior. The trial function is expressed as the difference between the neural network's output and the extension of its boundary restriction into the interior of the domain, with $g$ added to it. This ensures kinematic admissibility of the trial function in the deep Ritz method. Wachspress coordinates for an $n$-gon are used in the transfinite formula, which generalizes bilinear Coons transfinite interpolation on rectangles to convex polygons. The neural network trial function has a bounded Laplacian, thereby overcoming a limitation in a previous contribution where approximate distance functions were used to exactly enforce Dirichlet boundary conditions. For a point $\\boldsymbol{x} \\in \\bar{P}$, Wachspress coordinates, $\\boldsymbolλ : \\bar P \\to [0,1]^n$, serve as a geometric feature map for the neural network: $\\boldsymbolλ$ encodes the boundary edges of the polygonal domain. This offers a framework for solving problems on parametrized convex geometries using neural networks. The accuracy of physics-informed neural networks and deep Ritz is assessed on forward, inverse, and parametrized geometric Poisson boundary-value problems.",
    "authors": [
      "N. Sukumar",
      "Ritwick Roy"
    ],
    "url": "http://arxiv.org/abs/2601.01756v1",
    "published": "2026-01-05",
    "primary_category": "math.NA",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于Wachspress坐标的几何设计方法，用于在物理信息神经网络中精确施加狄利克雷边界条件，属于AI在物理建模领域的应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01753v1",
    "title": "MergeRec: Model Merging for Data-Isolated Cross-Domain Sequential Recommendation",
    "summary": "Modern recommender systems trained on domain-specific data often struggle to generalize across multiple domains. Cross-domain sequential recommendation has emerged as a promising research direction to address this challenge; however, existing approaches face fundamental limitations, such as reliance on overlapping users or items across domains, or unrealistic assumptions that ignore privacy constraints. In this work, we propose a new framework, MergeRec, based on model merging under a new and realistic problem setting termed data-isolated cross-domain sequential recommendation, where raw user interaction data cannot be shared across domains. MergeRec consists of three key components: (1) merging initialization, (2) pseudo-user data construction, and (3) collaborative merging optimization. First, we initialize a merged model using training-free merging techniques. Next, we construct pseudo-user data by treating each item as a virtual sequence in each domain, enabling the synthesis of meaningful training samples without relying on real user interactions. Finally, we optimize domain-specific merging weights through a joint objective that combines a recommendation loss, which encourages the merged model to identify relevant items, and a distillation loss, which transfers collaborative filtering signals from the fine-tuned source models. Extensive experiments demonstrate that MergeRec not only preserves the strengths of the original models but also significantly enhances generalizability to unseen domains. Compared to conventional model merging methods, MergeRec consistently achieves superior performance, with average improvements of up to 17.21% in Recall@10, highlighting the potential of model merging as a scalable and effective approach for building universal recommender systems. The source code is available at https://github.com/DIALLab-SKKU/MergeRec.",
    "authors": [
      "Hyunsoo Kim",
      "Jaewan Moon",
      "Seongmin Park",
      "Jongwuk Lee"
    ],
    "url": "http://arxiv.org/abs/2601.01753v1",
    "published": "2026-01-05",
    "primary_category": "cs.IR",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于模型融合的数据隔离跨域序列推荐框架，专注于推荐系统领域的技术创新，而非生物、化学等自然科学领域的科学发现或细胞/分子层面的扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01754v1",
    "title": "Context-Free Recognition with Transformers",
    "summary": "Transformers excel on tasks that process well-formed inputs according to some grammar, such as natural language and code. However, it remains unclear how they can process grammatical syntax. In fact, under standard complexity conjectures, standard transformers cannot recognize context-free languages (CFLs), a canonical formalism to describe syntax, or even regular languages, a subclass of CFLs (Merrill et al., 2022). Merrill & Sabharwal (2024) show that $\\mathcal{O}(\\log n)$ looping layers (w.r.t. input length $n$) allows transformers to recognize regular languages, but the question of context-free recognition remained open. In this work, we show that looped transformers with $\\mathcal{O}(\\log n)$ looping layers and $\\mathcal{O}(n^6)$ padding tokens can recognize all CFLs. However, training and inference with $\\mathcal{O}(n^6)$ padding tokens is potentially impractical. Fortunately, we show that, for natural subclasses such as unambiguous CFLs, the recognition problem on transformers becomes more tractable, requiring $\\mathcal{O}(n^3)$ padding. We empirically validate our results and show that looping helps on a language that provably requires logarithmic depth. Overall, our results shed light on the intricacy of CFL recognition by transformers: While general recognition may require an intractable amount of padding, natural constraints such as unambiguity yield efficient recognition algorithms.",
    "authors": [
      "Selim Jerad",
      "Anej Svete",
      "Sophie Hao",
      "Ryan Cotterell",
      "William Merrill"
    ],
    "url": "http://arxiv.org/abs/2601.01754v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文研究循环Transformer在理论计算能力上的扩展，证明其能识别上下文无关语言，属于计算理论和机器学习基础研究范畴。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01751v1",
    "title": "Query-Document Dense Vectors for LLM Relevance Judgment Bias Analysis",
    "summary": "Large Language Models (LLMs) have been used as relevance assessors for Information Retrieval (IR) evaluation collection creation due to reduced cost and increased scalability as compared to human assessors. While previous research has looked at the reliability of LLMs as compared to human assessors, in this work, we aim to understand if LLMs make systematic mistakes when judging relevance, rather than just understanding how good they are on average. To this aim, we propose a novel representational method for queries and documents that allows us to analyze relevance label distributions and compare LLM and human labels to identify patterns of disagreement and localize systematic areas of disagreement. We introduce a clustering-based framework that embeds query-document (Q-D) pairs into a joint semantic space, treating relevance as a relational property. Experiments on TREC Deep Learning 2019 and 2020 show that systematic disagreement between humans and LLMs is concentrated in specific semantic clusters rather than distributed randomly. Query-level analyses reveal recurring failures, most often in definition-seeking, policy-related, or ambiguous contexts. Queries with large variation in agreement across their clusters emerge as disagreement hotspots, where LLMs tend to under-recall relevant content or over-include irrelevant material. This framework links global diagnostics with localized clustering to uncover hidden weaknesses in LLM judgments, enabling bias-aware and more reliable IR evaluation.",
    "authors": [
      "Samaneh Mohtadi",
      "Gianluca Demartini"
    ],
    "url": "http://arxiv.org/abs/2601.01751v1",
    "published": "2026-01-05",
    "primary_category": "cs.IR",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文研究大型语言模型在信息检索评估中的系统性偏差，属于人工智能评估方法学范畴，而非应用于自然科学发现的AI4Science或分子层面的扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01747v1",
    "title": "Crafting Adversarial Inputs for Large Vision-Language Models Using Black-Box Optimization",
    "summary": "Recent advancements in Large Vision-Language Models (LVLMs) have shown groundbreaking capabilities across diverse multimodal tasks. However, these models remain vulnerable to adversarial jailbreak attacks, where adversaries craft subtle perturbations to bypass safety mechanisms and trigger harmful outputs. Existing white-box attacks methods require full model accessibility, suffer from computing costs and exhibit insufficient adversarial transferability, making them impractical for real-world, black-box settings. To address these limitations, we propose a black-box jailbreak attack on LVLMs via Zeroth-Order optimization using Simultaneous Perturbation Stochastic Approximation (ZO-SPSA). ZO-SPSA provides three key advantages: (i) gradient-free approximation by input-output interactions without requiring model knowledge, (ii) model-agnostic optimization without the surrogate model and (iii) lower resource requirements with reduced GPU memory consumption. We evaluate ZO-SPSA on three LVLMs, including InstructBLIP, LLaVA and MiniGPT-4, achieving the highest jailbreak success rate of 83.0% on InstructBLIP, while maintaining imperceptible perturbations comparable to white-box methods. Moreover, adversarial examples generated from MiniGPT-4 exhibit strong transferability to other LVLMs, with ASR reaching 64.18%. These findings underscore the real-world feasibility of black-box jailbreaks and expose critical weaknesses in the safety mechanisms of current LVLMs",
    "authors": [
      "Jiwei Guan",
      "Haibo Jin",
      "Haohan Wang"
    ],
    "url": "http://arxiv.org/abs/2601.01747v1",
    "published": "2026-01-05",
    "primary_category": "cs.CR",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种针对大型视觉语言模型的黑盒对抗攻击方法，通过零阶优化生成难以察觉的扰动来绕过安全机制，属于人工智能安全领域的研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01745v1",
    "title": "Multi-granularity Interactive Attention Framework for Residual Hierarchical Pronunciation Assessment",
    "summary": "Automatic pronunciation assessment plays a crucial role in computer-assisted pronunciation training systems. Due to the ability to perform multiple pronunciation tasks simultaneously, multi-aspect multi-granularity pronunciation assessment methods are gradually receiving more attention and achieving better performance than single-level modeling tasks. However, existing methods only consider unidirectional dependencies between adjacent granularity levels, lacking bidirectional interaction among phoneme, word, and utterance levels and thus insufficiently capturing the acoustic structural correlations. To address this issue, we propose a novel residual hierarchical interactive method, HIA for short, that enables bidirectional modeling across granularities. As the core of HIA, the Interactive Attention Module leverages an attention mechanism to achieve dynamic bidirectional interaction, effectively capturing linguistic features at each granularity while integrating correlations between different granularity levels. We also propose a residual hierarchical structure to alleviate the feature forgetting problem when modeling acoustic hierarchies. In addition, we use 1-D convolutional layers to enhance the extraction of local contextual cues at each granularity. Extensive experiments on the speechocean762 dataset show that our model is comprehensively ahead of the existing state-of-the-art methods.",
    "authors": [
      "Hong Han",
      "Hao-Chen Pei",
      "Zhao-Zheng Nie",
      "Xin Luo",
      "Xin-Shun Xu"
    ],
    "url": "http://arxiv.org/abs/2601.01745v1",
    "published": "2026-01-05",
    "primary_category": "cs.CL",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于发音评估的多粒度交互注意力框架，属于语音处理和计算机辅助语言学习领域，而非生物学、化学或物理学中的科学发现或细胞/分子层面的扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01743v1",
    "title": "AI Agent Systems: Architectures, Applications, and Evaluation",
    "summary": "AI agents -- systems that combine foundation models with reasoning, planning, memory, and tool use -- are rapidly becoming a practical interface between natural-language intent and real-world computation. This survey synthesizes the emerging landscape of AI agent architectures across: (i) deliberation and reasoning (e.g., chain-of-thought-style decomposition, self-reflection and verification, and constraint-aware decision making), (ii) planning and control (from reactive policies to hierarchical and multi-step planners), and (iii) tool calling and environment interaction (retrieval, code execution, APIs, and multimodal perception). We organize prior work into a unified taxonomy spanning agent components (policy/LLM core, memory, world models, planners, tool routers, and critics), orchestration patterns (single-agent vs.\\ multi-agent; centralized vs.\\ decentralized coordination), and deployment settings (offline analysis vs.\\ online interactive assistance; safety-critical vs.\\ open-ended tasks). We discuss key design trade-offs -- latency vs.\\ accuracy, autonomy vs.\\ controllability, and capability vs.\\ reliability -- and highlight how evaluation is complicated by non-determinism, long-horizon credit assignment, tool and environment variability, and hidden costs such as retries and context growth. Finally, we summarize measurement and benchmarking practices (task suites, human preference and utility metrics, success under constraints, robustness and security) and identify open challenges including verification and guardrails for tool actions, scalable memory and context management, interpretability of agent decisions, and reproducible evaluation under realistic workloads.",
    "authors": [
      "Bin Xu"
    ],
    "url": "http://arxiv.org/abs/2601.01743v1",
    "published": "2026-01-05",
    "primary_category": "cs.AI",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文主要综述AI智能体系统的架构设计、应用场景与评估方法，属于通用人工智能系统研究，未涉及特定科学领域的AI应用或细胞/分子层面的扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01741v1",
    "title": "Latent Space Element Method",
    "summary": "How can we build surrogate solvers that train on small domains but scale to larger ones without intrusive access to PDE operators? Inspired by the Data-Driven Finite Element Method (DD-FEM) framework for modular data-driven solvers, we propose the Latent Space Element Method (LSEM), an element-based latent surrogate assembly approach in which a learned subdomain (\"element\") model can be tiled and coupled to form a larger computational domain. Each element is a LaSDI latent ODE surrogate trained from snapshots on a local patch, and neighboring elements are coupled through learned directional interaction terms in latent space, avoiding Schwarz iterations and interface residual evaluations. A smooth window-based blending reconstructs a global field from overlapping element predictions, yielding a scalable assembled latent dynamical system. Experiments on the 1D Burgers and Korteweg-de Vries equations show that LSEM maintains predictive accuracy while scaling to spatial domains larger than those seen in training. LSEM offers an interpretable and extensible route toward foundation-model surrogate solvers built from reusable local models.",
    "authors": [
      "Seung Whan Chung",
      "Youngsoo Choi",
      "Christopher Miller",
      "H. Keo Springer",
      "Kyle T. Sullivan"
    ],
    "url": "http://arxiv.org/abs/2601.01741v1",
    "published": "2026-01-05",
    "primary_category": "math.DS",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于AI的代理求解器方法，用于解决偏微分方程问题，属于AI在物理科学领域的应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01739v1",
    "title": "K-EXAONE Technical Report",
    "summary": "This technical report presents K-EXAONE, a large-scale multilingual language model developed by LG AI Research. K-EXAONE is built on a Mixture-of-Experts architecture with 236B total parameters, activating 23B parameters during inference. It supports a 256K-token context window and covers six languages: Korean, English, Spanish, German, Japanese, and Vietnamese. We evaluate K-EXAONE on a comprehensive benchmark suite spanning reasoning, agentic, general, Korean, and multilingual abilities. Across these evaluations, K-EXAONE demonstrates performance comparable to open-weight models of similar size. K-EXAONE, designed to advance AI for a better life, is positioned as a powerful proprietary AI foundation model for a wide range of industrial and research applications.",
    "authors": [
      "Eunbi Choi",
      "Kibong Choi",
      "Seokhee Hong",
      "Junwon Hwang",
      "Hyojin Jeon",
      "Hyunjik Jo",
      "Joonkee Kim",
      "Seonghwan Kim",
      "Soyeon Kim",
      "Sunkyoung Kim",
      "Yireun Kim",
      "Yongil Kim",
      "Haeju Lee",
      "Jinsik Lee",
      "Kyungmin Lee",
      "Sangha Park",
      "Heuiyeen Yeen",
      "Hwan Chang",
      "Stanley Jungkyu Choi",
      "Yejin Choi",
      "Jiwon Ham",
      "Kijeong Jeon",
      "Geunyeong Jeong",
      "Gerrard Jeongwon Jo",
      "Yonghwan Jo",
      "Jiyeon Jung",
      "Naeun Kang",
      "Dohoon Kim",
      "Euisoon Kim",
      "Hayeon Kim",
      "Hyosang Kim",
      "Hyunseo Kim",
      "Jieun Kim",
      "Minu Kim",
      "Myoungshin Kim",
      "Unsol Kim",
      "Youchul Kim",
      "YoungJin Kim",
      "Chaeeun Lee",
      "Chaeyoon Lee",
      "Changhun Lee",
      "Dahm Lee",
      "Edward Hwayoung Lee",
      "Honglak Lee",
      "Jinsang Lee",
      "Jiyoung Lee",
      "Sangeun Lee",
      "Seungwon Lim",
      "Solji Lim",
      "Woohyung Lim",
      "Chanwoo Moon",
      "Jaewoo Park",
      "Jinho Park",
      "Yongmin Park",
      "Hyerin Seo",
      "Wooseok Seo",
      "Yongwoo Song",
      "Sejong Yang",
      "Sihoon Yang",
      "Chang En Yea",
      "Sihyuk Yi",
      "Chansik Yoon",
      "Dongkeun Yoon",
      "Sangyeon Yoon",
      "Hyeongu Yun"
    ],
    "url": "http://arxiv.org/abs/2601.01739v1",
    "published": "2026-01-05",
    "primary_category": "cs.CL",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该技术报告介绍了一个通用多语言大语言模型K-EXAONE，未涉及特定科学领域发现或细胞/基因扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01718v1",
    "title": "Yuan3.0 Flash: An Open Multimodal Large Language Model for Enterprise Applications",
    "summary": "We introduce Yuan3.0 Flash, an open-source Mixture-of-Experts (MoE) MultiModal Large Language Model featuring 3.7B activated parameters and 40B total parameters, specifically designed to enhance performance on enterprise-oriented tasks while maintaining competitive capabilities on general-purpose tasks. To address the overthinking phenomenon commonly observed in Large Reasoning Models (LRMs), we propose Reflection-aware Adaptive Policy Optimization (RAPO), a novel RL training algorithm that effectively regulates overthinking behaviors. In enterprise-oriented tasks such as retrieval-augmented generation (RAG), complex table understanding, and summarization, Yuan3.0 Flash consistently achieves superior performance. Moreover, it also demonstrates strong reasoning capabilities in domains such as mathematics, science, etc., attaining accuracy comparable to frontier model while requiring only approximately 1/4 to 1/2 of the average tokens. Yuan3.0 Flash has been fully open-sourced to facilitate further research and real-world deployment: https://github.com/Yuan-lab-LLM/Yuan3.0.",
    "authors": [
      "YuanLab. ai",
      ":",
      "Shawn Wu",
      "Sean Wang",
      "Louie Li",
      "Darcy Chen",
      "Allen Wang",
      "Jiangang Luo",
      "Xudong Zhao",
      "Joseph Shen",
      "Gawain Ma",
      "Jasper Jia",
      "Marcus Mao",
      "Claire Wang",
      "Hunter He",
      "Carol Wang",
      "Zera Zhang",
      "Jason Wang",
      "Chonly Shen",
      "Leo Zhang",
      "Logan Chen",
      "Qasim Meng",
      "James Gong",
      "Danied Zhao",
      "Penn Zheng",
      "Owen Zhu",
      "Tong Yu"
    ],
    "url": "http://arxiv.org/abs/2601.01718v1",
    "published": "2026-01-05",
    "primary_category": "cs.AI",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文主要介绍了一个面向企业应用的多模态大语言模型及其优化算法，并未涉及使用AI进行生物学、化学、物理学等领域的科学发现，也未涉及细胞或基因扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01714v1",
    "title": "Entropy-Aligned Decoding of LMs for Better Writing and Reasoning",
    "summary": "Language models (LMs) are trained on billions of tokens in an attempt to recover the true language distribution. Still, vanilla random sampling from LMs yields low quality generations. Decoding algorithms attempt to restrict the LM distribution to a set of high-probability continuations, but rely on greedy heuristics that introduce myopic distortions, yielding sentences that are homogeneous, repetitive and incoherent. In this paper, we introduce EPIC, a hyperparameter-free decoding approach that incorporates the entropy of future trajectories into LM decoding. EPIC explicitly regulates the amount of uncertainty expressed at every step of generation, aligning the sampling distribution's entropy to the aleatoric (data) uncertainty. Through Entropy-Aware Lazy Gumbel-Max sampling, EPIC manages to be exact, while also being efficient, requiring only a sublinear number of entropy evaluations per step. Unlike current baselines, EPIC yields sampling distributions that are empirically well-aligned with the entropy of the underlying data distribution. Across creative writing and summarization tasks, EPIC consistently improves LM-as-judge preference win-rates over widely used decoding strategies. These preference gains are complemented by automatic metrics, showing that EPIC produces more diverse generations and more faithful summaries. We also evaluate EPIC on mathematical reasoning, where it outperforms all baselines.",
    "authors": [
      "Kareem Ahmed",
      "Sameer Singh"
    ],
    "url": "http://arxiv.org/abs/2601.01714v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于熵对齐的语言模型解码方法，旨在提高文本生成的质量和多样性，而非应用于科学发现或扰动预测领域。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01712v1",
    "title": "RelayGR: Scaling Long-Sequence Generative Recommendation via Cross-Stage Relay-Race Inference",
    "summary": "Real-time recommender systems execute multi-stage cascades (retrieval, pre-processing, fine-grained ranking) under strict tail-latency SLOs, leaving only tens of milliseconds for ranking. Generative recommendation (GR) models can improve quality by consuming long user-behavior sequences, but in production their online sequence length is tightly capped by the ranking-stage P99 budget. We observe that the majority of GR tokens encode user behaviors that are independent of the item candidates, suggesting an opportunity to pre-infer a user-behavior prefix once and reuse it during ranking rather than recomputing it on the critical path. Realizing this idea at industrial scale is non-trivial: the prefix cache must survive across multiple pipeline stages before the final ranking instance is determined, the user population implies cache footprints far beyond a single device, and indiscriminate pre-inference would overload shared resources under high QPS. We present RelayGR, a production system that enables in-HBM relay-race inference for GR. RelayGR selectively pre-infers long-term user prefixes, keeps their KV caches resident in HBM over the request lifecycle, and ensures the subsequent ranking can consume them without remote fetches. RelayGR combines three techniques: 1) a sequence-aware trigger that admits only at-risk requests under a bounded cache footprint and pre-inference load, 2) an affinity-aware router that co-locates cache production and consumption by routing both the auxiliary pre-infer signal and the ranking request to the same instance, and 3) a memory-aware expander that uses server-local DRAM to capture short-term cross-request reuse while avoiding redundant reloads. We implement RelayGR on Huawei Ascend NPUs and evaluate it with real queries. Under a fixed P99 SLO, RelayGR supports up to 1.5$\\times$ longer sequences and improves SLO-compliant throughput by up to 3.6$\\times$.",
    "authors": [
      "Jiarui Wang",
      "Huichao Chai",
      "Yuanhang Zhang",
      "Zongjin Zhou",
      "Wei Guo",
      "Xingkun Yang",
      "Qiang Tang",
      "Bo Pan",
      "Jiawei Zhu",
      "Ke Cheng",
      "Yuting Yan",
      "Shulan Wang",
      "Yingjie Zhu",
      "Zhengfan Yuan",
      "Jiaqi Huang",
      "Yuhan Zhang",
      "Xiaosong Sun",
      "Zhinan Zhang",
      "Hong Zhu",
      "Yongsheng Zhang",
      "Tiantian Dong",
      "Zhong Xiao",
      "Deliang Liu",
      "Chengzhou Lu",
      "Yuan Sun",
      "Zhiyuan Chen",
      "Xinming Han",
      "Zaizhu Liu",
      "Yaoyuan Wang",
      "Ziyang Zhang",
      "Yong Liu",
      "Jinxin Xu",
      "Yajing Sun",
      "Zhoujun Yu",
      "Wenting Zhou",
      "Qidong Zhang",
      "Zhengyong Zhang",
      "Zhonghai Gu",
      "Yibo Jin",
      "Yongxiang Feng",
      "Pengfei Zuo"
    ],
    "url": "http://arxiv.org/abs/2601.01712v1",
    "published": "2026-01-05",
    "primary_category": "cs.DC",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于工业推荐系统的推理优化系统，通过跨阶段缓存和路由技术提升生成式推荐模型的序列处理能力和吞吐量。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01709v1",
    "title": "Reinforcement Learning for Option Hedging: Static Implied-Volatility Fit versus Shortfall-Aware Performance",
    "summary": "We extend the Q-learner in Black-Scholes (QLBS) framework by incorporating risk aversion and trading costs, and propose a novel Replication Learning of Option Pricing (RLOP) approach. Both methods are fully compatible with standard reinforcement learning algorithms and operate under market frictions. Using SPY and XOP option data, we evaluate performance along static and dynamic dimensions. Adaptive-QLBS achieves higher static pricing accuracy in implied volatility space, while RLOP delivers superior dynamic hedging performance by reducing shortfall probability. These results highlight the importance of evaluating option pricing models beyond static fit, emphasizing realized hedging outcomes.",
    "authors": [
      "Ziheng Chen",
      "Minxuan Hu",
      "Jiayu Yi",
      "Wenxi Sun"
    ],
    "url": "http://arxiv.org/abs/2601.01709v1",
    "published": "2026-01-05",
    "primary_category": "q-fin.PR",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于金融领域，利用强化学习改进期权定价和对冲策略，而非生物学、化学或物理学等自然科学领域的科学发现。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01706v1",
    "title": "Semantic Non-Fungibility and Violations of the Law of One Price in Prediction Markets",
    "summary": "Prediction markets are designed to aggregate dispersed information about future events, yet today's ecosystem is fragmented across heterogeneous operator-run platforms and blockchain-based protocols that independently list economically identical events. In the absence of a shared notion of event identity, liquidity fails to pool across venues, arbitrage becomes capital-intensive or unenforceable, and prices systematically violate the Law of One Price. As a result, market prices reflect platform-local beliefs rather than a single, globally aggregated probability, undermining the core information-aggregation function of prediction markets. We address this gap by introducing a semantic alignment framework that makes cross-platform event identity explicit through joint analysis of natural-language descriptions, resolution semantics, and temporal scope. Applying this framework, we construct the first human-validated, cross-platform dataset of aligned prediction markets, covering over 100 000 events across ten major venues from 2018 to 2025. Using this dataset, we show that roughly 6% of all events are concurrently listed across platforms and that semantically equivalent markets exhibit persistent execution-aware price deviations of 2-4% on average, even in highly liquid and information-rich settings. These mispricings give rise to persistent cross-platform arbitrage opportunities driven by structural frictions rather than informational disagreement. Overall, our results demonstrate that semantic non-fungibility is a fundamental barrier to price convergence, and that resolving event identity is a prerequisite for prediction markets to aggregate information at a global scale.",
    "authors": [
      "Jonas Gebele",
      "Florian Matthes"
    ],
    "url": "http://arxiv.org/abs/2601.01706v1",
    "published": "2026-01-05",
    "primary_category": "cs.CE",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文通过语义对齐框架解决预测市场中事件身份识别问题，以促进价格收敛和信息聚合，属于经济学和金融科技领域，而非AI4Science或扰动预测研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01705v1",
    "title": "Explicit World Models for Reliable Human-Robot Collaboration",
    "summary": "This paper addresses the topic of robustness under sensing noise, ambiguous instructions, and human-robot interaction. We take a radically different tack to the issue of reliable embodied AI: instead of focusing on formal verification methods aimed at achieving model predictability and robustness, we emphasise the dynamic, ambiguous and subjective nature of human-robot interactions that requires embodied AI systems to perceive, interpret, and respond to human intentions in a manner that is consistent, comprehensible and aligned with human expectations. We argue that when embodied agents operate in human environments that are inherently social, multimodal, and fluid, reliability is contextually determined and only has meaning in relation to the goals and expectations of humans involved in the interaction. This calls for a fundamentally different approach to achieving reliable embodied AI that is centred on building and updating an accessible \"explicit world model\" representing the common ground between human and AI, that is used to align robot behaviours with human expectations.",
    "authors": [
      "Kenneth Kwok",
      "Basura Fernando",
      "Qianli Xu",
      "Vigneshwaran Subbaraju",
      "Dongkyu Choi",
      "Boon Kiat Quek"
    ],
    "url": "http://arxiv.org/abs/2601.01705v1",
    "published": "2026-01-05",
    "primary_category": "cs.RO",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于人机交互中可靠性的实现方法，通过构建显式世界模型来对齐人类期望与机器人行为，而非涉及科学发现或细胞分子层面的扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01703v1",
    "title": "Beyond Homophily: Community Search on Heterophilic Graphs",
    "summary": "Community search aims to identify a refined set of nodes that are most relevant to a given query, supporting tasks ranging from fraud detection to recommendation. Unlike homophilic graphs, many real-world networks are heterophilic, where edges predominantly connect dissimilar nodes. Therefore, structural signals that once reflected smooth, low-frequency similarity now appear as sharp, high-frequency contrasts. However, both classical algorithms (e.g., k-core, k-truss) and recent ML-based models struggle to achieve effective community search on heterophilic graphs, where edge signs or semantics are generally unknown. Algorithm-based methods often return communities with mixed class labels, while GNNs, built on homophily, smooth away meaningful signals and blur community boundaries. Therefore, we propose Adaptive Community Search (AdaptCS), a unified framework featuring three key designs: (i) an AdaptCS Encoder that disentangles multi-hop and multi-frequency signals, enabling the model to capture both smooth (homophilic) and contrastive (heterophilic) relations; (ii) a memory-efficient low-rank optimization that removes the main computational bottleneck and ensures model scalability; and (iii) an Adaptive Community Score (ACS) that guides online search by balancing embedding similarity and topological relations. Extensive experiments on both heterophilic and homophilic benchmarks demonstrate that AdaptCS outperforms the best-performing baseline by an average of 11% in F1-score, retains robustness across heterophily levels, and achieves up to 2 orders of magnitude speedup.",
    "authors": [
      "Qing Sima",
      "Xiaoyang Wang",
      "Wenjie Zhang"
    ],
    "url": "http://arxiv.org/abs/2601.01703v1",
    "published": "2026-01-05",
    "primary_category": "cs.SI",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于异质图社区搜索的统一框架AdaptCS，通过解耦多跳多频信号、低秩优化和自适应评分机制来改进异质网络中的社区发现性能。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01701v1",
    "title": "Digital Twin-Driven Communication-Efficient Federated Anomaly Detection for Industrial IoT",
    "summary": "Anomaly detection is increasingly becoming crucial for maintaining the safety, reliability, and efficiency of industrial systems. Recently, with the advent of digital twins and data-driven decision-making, several statistical and machine-learning methods have been proposed. However, these methods face several challenges, such as dependence on only real sensor datasets, limited labeled data, high false alarm rates, and privacy concerns. To address these problems, we propose a suite of digital twin-integrated federated learning (DTFL) methods that enhance global model performance while preserving data privacy and communication efficiency. Specifically, we present five novel approaches: Digital Twin-Based Meta-Learning (DTML), Federated Parameter Fusion (FPF), Layer-wise Parameter Exchange (LPE), Cyclic Weight Adaptation (CWA), and Digital Twin Knowledge Distillation (DTKD). Each method introduces a unique mechanism to combine synthetic and real-world knowledge, balancing generalization with communication overhead. We conduct an extensive experiment using a publicly available cyber-physical anomaly detection dataset. For a target accuracy of 80%, CWA reaches the target in 33 rounds, FPF in 41 rounds, LPE in 48 rounds, and DTML in 87 rounds, whereas the standard FedAvg baseline and DTKD do not reach the target within 100 rounds. These results highlight substantial communication-efficiency gains (up to 62% fewer rounds than DTML and 31% fewer than LPE) and demonstrate that integrating DT knowledge into FL accelerates convergence to operationally meaningful accuracy thresholds for IIoT anomaly detection.",
    "authors": [
      "Mohammed Ayalew Belay",
      "Adil Rasheed",
      "Pierluigi Salvo Rossi"
    ],
    "url": "http://arxiv.org/abs/2601.01701v1",
    "published": "2026-01-05",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出数字孪生驱动的联邦学习方法，专注于工业物联网异常检测的通信效率提升，而非科学发现或细胞扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01699v1",
    "title": "Varying-Coefficient Mixture of Experts Model",
    "summary": "Mixture-of-Experts (MoE) is a flexible framework that combines multiple specialized submodels (``experts''), by assigning covariate-dependent weights (``gating functions'') to each expert, and have been commonly used for analyzing heterogeneous data. Existing statistical MoE formulations typically assume constant coefficients, for covariate effects within the expert or gating models, which can be inadequate for longitudinal, spatial, or other dynamic settings where covariate influences and latent subpopulation structure evolve across a known dimension. We propose a Varying-Coefficient Mixture of Experts (VCMoE) model that allows all coefficient effects in both the gating functions and expert models to vary along an indexing variable. We establish identifiability and consistency of the proposed model, and develop an estimation procedure, label-consistent EM algorithm, for both fully functional and hybrid specifications, along with the corresponding asymptotic distributions of the resulting estimators. For inference, simultaneous confidence bands are constructed using both asymptotic theory for the maximum discrepancy between the estimated functional coefficients and their true counterparts, and with bootstrap methods. In addition, a generalized likelihood ratio test is developed to examine whether a coefficient function is genuinely varying across the index variable. Simulation studies demonstrate good finite-sample performance, with acceptable bias and satisfactory coverage rates. We illustrate the proposed VCMoE model using a dataset of single nucleus gene expression in embryonic mice to characterize the temporal dynamics of the associations between the expression levels of genes Satb2 and Bcl11b across two latent cell subpopulations of neurons, yielding results that are consistent with prior findings.",
    "authors": [
      "Qicheng Zhao",
      "Celia M. T. Greenwood",
      "Qihuang Zhang"
    ],
    "url": "http://arxiv.org/abs/2601.01699v1",
    "published": "2026-01-05",
    "primary_category": "stat.ME",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种可变系数混合专家模型，用于分析胚胎小鼠单核基因表达数据，以揭示神经元亚群中基因表达的时间动态关联，属于利用统计学习方法进行生物学发现的AI4Science范畴。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01698v1",
    "title": "Hidden costs for inference with deep network on embedded system devices",
    "summary": "This study evaluates the inference performance of various deep learning models under an embedded system environment. In previous works, Multiply-Accumulate operation is typically used to measure computational load of a deep model. According to this study, however, this metric has a limitation to estimate inference time on embedded devices. This paper poses the question of what aspects are overlooked when expressed in terms of Multiply-Accumulate operations. In experiments, an image classification task is performed on an embedded system device using the CIFAR-100 dataset to compare and analyze the inference times of ten deep models with the theoretically calculated Multiply-Accumulate operations for each model. The results highlight the importance of considering additional computations between tensors when optimizing deep learning models for real-time performing in embedded systems.",
    "authors": [
      "Chankyu Lee",
      "Woohyun Choi",
      "Sangwook Park"
    ],
    "url": "http://arxiv.org/abs/2601.01698v1",
    "published": "2026-01-05",
    "primary_category": "cs.CC",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文研究嵌入式系统中深度学习模型推理性能的评估方法，关注计算负载度量标准的局限性，而非将AI应用于具体科学领域发现或扰动预测。"
  }
]