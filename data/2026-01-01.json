[
  {
    "id": "http://arxiv.org/abs/2601.00513v1",
    "title": "When Small Models Are Right for Wrong Reasons: Process Verification for Trustworthy Agents",
    "summary": "Deploying small language models (7-9B parameters) as autonomous agents requires trust in their reasoning, not just their outputs. We reveal a critical reliability crisis: 50-69\\% of correct answers from these models contain fundamentally flawed reasoning -- a ``Right-for-Wrong-Reasons'' phenomenon invisible to standard accuracy metrics. Through analysis of 10,734 reasoning traces across three models and diverse tasks, we introduce the Reasoning Integrity Score (RIS), a process-based metric validated with substantial inter-rater agreement ($κ=0.657$). Conventional practices are challenged by our findings: while retrieval-augmented generation (RAG) significantly improves reasoning integrity (Cohen's $d=0.23$--$0.93$), meta-cognitive interventions like self-critique often harm performance ($d=-0.14$ to $-0.33$) in small models on the evaluated tasks. Mechanistic analysis reveals RAG succeeds by grounding calculations in external evidence, reducing errors by 7.6\\%, while meta-cognition amplifies confusion without sufficient model capacity. To enable deployment, verification capabilities are distilled into a neural classifier achieving 0.86 F1-score with 100$\\times$ speedup. These results underscore the necessity of process-based verification for trustworthy agents: accuracy alone is dangerously insufficient when models can be right for entirely wrong reasons.",
    "authors": [
      "Laksh Advani"
    ],
    "url": "http://arxiv.org/abs/2601.00513v1",
    "published": "2026-01-01",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文聚焦于评估小型语言模型作为自主代理时的推理可靠性，提出基于过程的验证方法，而非将AI应用于具体科学领域的发现或预测细胞/基因扰动响应。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00509v1",
    "title": "Improving LLM-Assisted Secure Code Generation through Retrieval-Augmented-Generation and Multi-Tool Feedback",
    "summary": "Large Language Models (LLMs) can generate code but often introduce security vulnerabilities, logical inconsistencies, and compilation errors. Prior work demonstrates that LLMs benefit substantially from structured feedback, static analysis, retrieval augmentation, and execution-based refinement. We propose a retrieval-augmented, multi-tool repair workflow in which a single code-generating LLM iteratively refines its outputs using compiler diagnostics, CodeQL security scanning, and KLEE symbolic execution. A lightweight embedding model is used for semantic retrieval of previously successful repairs, providing security-focused examples that guide generation. Evaluated on a combined dataset of 3,242 programs generated by DeepSeek-Coder-1.3B and CodeLlama-7B, the system demonstrates significant improvements in robustness. For DeepSeek, security vulnerabilities were reduced by 96%. For the larger CodeLlama model, the critical security defect rate was decreased from 58.55% to 22.19%, highlighting the efficacy of tool-assisted self-repair even on \"stubborn\" models.",
    "authors": [
      "Vidyut Sriram",
      "Sawan Pandita",
      "Achintya Lakshmanan",
      "Aneesh Shamraj",
      "Suman Saha"
    ],
    "url": "http://arxiv.org/abs/2601.00509v1",
    "published": "2026-01-01",
    "primary_category": "cs.CR",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于通过检索增强和多工具反馈改进LLM辅助的安全代码生成，属于计算机科学和软件工程领域，而非生物、化学或物理等自然科学中的科学发现。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00926v1",
    "title": "MACA: A Framework for Distilling Trustworthy LLMs into Efficient Retrievers",
    "summary": "Modern enterprise retrieval systems must handle short, underspecified queries such as ``foreign transaction fee refund'' and ``recent check status''. In these cases, semantic nuance and metadata matter but per-query large language model (LLM) re-ranking and manual labeling are costly. We present Metadata-Aware Cross-Model Alignment (MACA), which distills a calibrated metadata aware LLM re-ranker into a compact student retriever, avoiding online LLM calls. A metadata-aware prompt verifies the teacher's trustworthiness by checking consistency under permutations and robustness to paraphrases, then supplies listwise scores, hard negatives, and calibrated relevance margins. The student trains with MACA's MetaFusion objective, which combines a metadata conditioned ranking loss with a cross model margin loss so it learns to push the correct answer above semantically similar candidates with mismatched topic, sub-topic, or entity. On a proprietary consumer banking FAQ corpus and BankFAQs, the MACA teacher surpasses a MAFA baseline at Accuracy@1 by five points on the proprietary set and three points on BankFAQs. MACA students substantially outperform pretrained encoders; e.g., on the proprietary corpus MiniLM Accuracy@1 improves from 0.23 to 0.48, while keeping inference free of LLM calls and supporting retrieval-augmented generation.",
    "authors": [
      "Satya Swaroop Gudipudi",
      "Sahil Girhepuje",
      "Ponnurangam Kumaraguru",
      "Kristine Ma"
    ],
    "url": "http://arxiv.org/abs/2601.00926v1",
    "published": "2026-01-01",
    "primary_category": "cs.IR",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种将大型语言模型蒸馏为高效检索器的框架，专注于企业信息检索任务，而非科学发现或生物医学扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00505v1",
    "title": "Effect of Electric Charge on Biotherapeutic Transport, Binding and Absorption: A Computational Study",
    "summary": "This study explores the effects of electric charge on the dynamics of drug transport and absorption in subcutaneous injections of monoclonal antibodies (mAbs). We develop a novel mathematical and computational model, based on the Nernst-Planck equations and porous media flow theory, to investigate the complex interactions between mAbs and charged species in subcutaneous tissue. The model enables us to study short-term transport dynamics and long-term binding and absorption for two mAbs with different electric properties. We examine the influence of buffer pH, body mass index, injection depth, and formulation concentration on drug distribution and compare our numerical results with experimental data from the literature.",
    "authors": [
      "Mario de Lucio",
      "Pavlos P. Vlachos",
      "Hector Gomez"
    ],
    "url": "http://arxiv.org/abs/2601.00505v1",
    "published": "2026-01-01",
    "primary_category": "cs.CE",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该研究使用传统计算模型（基于Nernst-Planck方程和多孔介质流动理论）而非人工智能方法研究电荷对单克隆抗体皮下运输的影响，且关注宏观药物动力学而非单细胞/分子水平的扰动响应预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00504v1",
    "title": "MotionPhysics: Learnable Motion Distillation for Text-Guided Simulation",
    "summary": "Accurately simulating existing 3D objects and a wide variety of materials often demands expert knowledge and time-consuming physical parameter tuning to achieve the desired dynamic behavior. We introduce MotionPhysics, an end-to-end differentiable framework that infers plausible physical parameters from a user-provided natural language prompt for a chosen 3D scene of interest, removing the need for guidance from ground-truth trajectories or annotated videos. Our approach first utilizes a multimodal large language model to estimate material parameter values, which are constrained to lie within plausible ranges. We further propose a learnable motion distillation loss that extracts robust motion priors from pretrained video diffusion models while minimizing appearance and geometry inductive biases to guide the simulation. We evaluate MotionPhysics across more than thirty scenarios, including real-world, human-designed, and AI-generated 3D objects, spanning a wide range of materials such as elastic solids, metals, foams, sand, and both Newtonian and non-Newtonian fluids. We demonstrate that MotionPhysics produces visually realistic dynamic simulations guided by natural language, surpassing the state of the art while automatically determining physically plausible parameters. The code and project page are available at: https://wangmiaowei.github.io/MotionPhysics.github.io/.",
    "authors": [
      "Miaowei Wang",
      "Jakub Zadrożny",
      "Oisin Mac Aodha",
      "Amir Vaxman"
    ],
    "url": "http://arxiv.org/abs/2601.00504v1",
    "published": "2026-01-01",
    "primary_category": "cs.CV",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于AI的物理模拟框架，通过自然语言提示自动推断物理参数，用于科学计算和物理现象模拟。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00503v1",
    "title": "Interpretable Machine Learning for Quantum-Informed Property Predictions in Artificial Sensing Materials",
    "summary": "Digital sensing faces challenges in developing sustainable methods to extend the applicability of customized e-noses to complex body odor volatilome (BOV). To address this challenge, we developed MORE-ML, a computational framework that integrates quantum-mechanical (QM) property data of e-nose molecular building blocks with machine learning (ML) methods to predict sensing-relevant properties. Within this framework, we expanded our previous dataset, MORE-Q, to MORE-QX by sampling a larger conformational space of interactions between BOV molecules and mucin-derived receptors. This dataset provides extensive electronic binding features (BFs) computed upon BOV adsorption. Analysis of MORE-QX property space revealed weak correlations between QM properties of building blocks and resulting BFs. Leveraging this observation, we defined electronic descriptors of building blocks as inputs for tree-based ML models to predict BFs. Benchmarking showed CatBoost models outperform alternatives, especially in transferability to unseen compounds. Explainable AI methods further highlighted which QM properties most influence BF predictions. Collectively, MORE-ML combines QM insights with ML to provide mechanistic understanding and rational design principles for molecular receptors in BOV sensing. This approach establishes a foundation for advancing artificial sensing materials capable of analyzing complex odor mixtures, bridging the gap between molecular-level computations and practical e-nose applications.",
    "authors": [
      "Li Chen",
      "Leonardo Medrano Sandonas",
      "Shirong Huang",
      "Alexander Croy",
      "Gianaurelio Cuniberti"
    ],
    "url": "http://arxiv.org/abs/2601.00503v1",
    "published": "2026-01-01",
    "primary_category": "physics.chem-ph",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文通过结合量子力学数据与机器学习方法，开发了一个用于预测人工嗅觉材料传感性能的计算框架，属于AI在化学材料科学中的应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00491v1",
    "title": "Transfer-learned Kolosov-Muskhelishvili Informed Neural Networks for Fracture Mechanics",
    "summary": "Physics-informed neural networks have been widely applied to solid mechanics problems. However, balancing the governing partial differential equations and boundary conditions remains challenging, particularly in fracture mechanics, where accurate predictions strongly depend on refined sampling near crack tips. To overcome these limitations, a Kolosov-Muskhelishvili informed neural network with Williams enrichment is developed in this study. Benefiting from the holomorphic representation, the governing equations are satisfied by construction, and only boundary points are required for training. Across a series of benchmark problems, the Kolosov-Muskhelishvili informed neural network shows excellent agreement with analytical and finite element method references, achieving average relative errors below 1\\% and $R^2$ above 0.99 for both mode I and mode II loadings. Furthermore, three crack propagation criteria (maximum tangential stress, maximum energy release rate, and principle of local symmetry) are integrated into the framework using a transfer learning strategy to predict crack propagation directions. The predicted paths are nearly identical across all criteria, and the transfer learning strategy reduces the required training time by more than 70\\%. Overall, the developed framework provides a unified, mesh-free, and physically consistent approach for accurate and efficient crack propagation analysis.",
    "authors": [
      "Shuwei Zhou",
      "Christian Haeffner",
      "Shuancheng Wang",
      "Sophie Stebner",
      "Zhen Liao",
      "Bing Yang",
      "Zhichao Wei",
      "Sebastian Muenstermann"
    ],
    "url": "http://arxiv.org/abs/2601.00491v1",
    "published": "2026-01-01",
    "primary_category": "cs.CE",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文开发了一种基于物理信息神经网络和威廉姆斯富集方法的统一框架，用于准确高效地预测裂纹扩展路径，属于AI在固体力学领域的应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00488v1",
    "title": "Noise-Aware Named Entity Recognition for Historical VET Documents",
    "summary": "This paper addresses Named Entity Recognition (NER) in the domain of Vocational Education and Training (VET), focusing on historical, digitized documents that suffer from OCR-induced noise. We propose a robust NER approach leveraging Noise-Aware Training (NAT) with synthetically injected OCR errors, transfer learning, and multi-stage fine-tuning. Three complementary strategies, training on noisy, clean, and artificial data, are systematically compared. Our method is one of the first to recognize multiple entity types in VET documents. It is applied to German documents but transferable to arbitrary languages. Experimental results demonstrate that domain-specific and noise-aware fine-tuning substantially increases robustness and accuracy under noisy conditions. We provide publicly available code for reproducible noise-aware NER in domain-specific contexts.",
    "authors": [
      "Alexander M. Esser",
      "Jens Dörpinghaus"
    ],
    "url": "http://arxiv.org/abs/2601.00488v1",
    "published": "2026-01-01",
    "primary_category": "cs.CL",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于历史职业教育文档的命名实体识别，通过噪声感知训练提升OCR噪声下的性能，属于自然语言处理领域而非科学发现或细胞扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00482v1",
    "title": "Multi-Agent Coordinated Rename Refactoring",
    "summary": "The primary value of AI agents in software development lies in their ability to extend the developer's capacity for reasoning and action, not to supplant human involvement. To showcase how to use agents working in tandem with developers, we designed a novel approach for carrying out coordinated renaming. Coordinated renaming, where a single rename refactoring triggers refactorings in multiple, related identifiers, is a frequent yet challenging task. Developers must manually propagate these rename refactorings across numerous files and contexts, a process that is both tedious and highly error-prone. State-of-the-art heuristic-based approaches produce an overwhelming number of false positives, while vanilla Large Language Models (LLMs) provide incomplete suggestions due to their limited context and inability to interact with refactoring tools. This leaves developers with incomplete refactorings or burdens them with filtering too many false positives. Coordinated renaming is exactly the kind of repetitive task that agents can significantly reduce the developers' burden while keeping them in the driver's seat.   We designed, implemented, and evaluated the first multi-agent framework that automates coordinated renaming. It operates on a key insight: a developer's initial refactoring is a clue to infer the scope of related refactorings. Our Scope Inference Agent first transforms this clue into an explicit, natural-language Declared Scope. The Planned Execution Agent then uses this as a strict plan to identify program elements that should undergo refactoring and safely executes the changes by invoking the IDE's own trusted refactoring APIs. Finally, the Replication Agent uses it to guide the project-wide search. We first conducted a formative study on the practice of coordinated renaming in 609K commits in 100 open-source projects and surveyed 205 developers ...",
    "authors": [
      "Abhiram Bellur",
      "Mohammed Raihan Ullah",
      "Fraol Batole",
      "Mohit Kansara",
      "Masaharu Morimoto",
      "Kai Ishikawa",
      "Haifeng Chen",
      "Yaroslav Zharov",
      "Timofey Bryksin",
      "Tien N. Nguyen",
      "Hridesh Rajan",
      "Danny Dig"
    ],
    "url": "http://arxiv.org/abs/2601.00482v1",
    "published": "2026-01-01",
    "primary_category": "cs.SE",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种多智能体框架，用于自动化软件重构中的协调重命名任务，属于软件工程领域而非基础科学研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00481v1",
    "title": "MAESTRO: Multi-Agent Evaluation Suite for Testing, Reliability, and Observability",
    "summary": "We present MAESTRO, an evaluation suite for the testing, reliability, and observability of LLM-based MAS. MAESTRO standardizes MAS configuration and execution through a unified interface, supports integrating both native and third-party MAS via a repository of examples and lightweight adapters, and exports framework-agnostic execution traces together with system-level signals (e.g., latency, cost, and failures). We instantiate MAESTRO with 12 representative MAS spanning popular agentic frameworks and interaction patterns, and conduct controlled experiments across repeated runs, backend models, and tool configurations. Our case studies show that MAS executions can be structurally stable yet temporally variable, leading to substantial run-to-run variance in performance and reliability. We further find that MAS architecture is the dominant driver of resource profiles, reproducibility, and cost-latency-accuracy trade-off, often outweighing changes in backend models or tool settings. Overall, MAESTRO enables systematic evaluation and provides empirical guidance for designing and optimizing agentic systems.",
    "authors": [
      "Tie Ma",
      "Yixi Chen",
      "Vaastav Anand",
      "Alessandro Cornacchia",
      "Amândio R. Faustino",
      "Guanheng Liu",
      "Shan Zhang",
      "Hongbin Luo",
      "Suhaib A. Fahmy",
      "Zafar A. Qazi",
      "Marco Canini"
    ],
    "url": "http://arxiv.org/abs/2601.00481v1",
    "published": "2026-01-01",
    "primary_category": "cs.NI",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一个用于评估多智能体系统的标准化测试套件，专注于系统可靠性和性能分析，而非特定科学领域的发现或细胞扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00476v1",
    "title": "Safe Adaptive Feedback Control via Barrier States",
    "summary": "This paper presents a safe feedback control framework for nonlinear control-affine systems with parametric uncertainty by leveraging adaptive dynamic programming (ADP) with barrier-state augmentation. The developed ADP-based controller enforces control invariance by optimizing a value function that explicitly penalizes the barrier state, thereby embedding safety directly into the Bellman structure. The near-optimal control policy computed using model-based reinforcement learning is combined with a concurrent learning estimator to identify the unknown parameters and guarantee uniform convergence without requiring persistency of excitation. Using a barrier-state Lyapunov function, we establish boundedness of the barrier dynamics and prove closed-loop stability and safety. Numerical simulations on an optimal obstacle-avoidance problem validate the effectiveness of the developed approach.",
    "authors": [
      "Trivikram Satharasi",
      "Tochukwu E. Ogri",
      "Muzaffar Qureshi",
      "Kyle Volle",
      "Rushikesh Kamalapurkar"
    ],
    "url": "http://arxiv.org/abs/2601.00476v1",
    "published": "2026-01-01",
    "primary_category": "math.OC",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于自适应动态规划和屏障状态增强的安全反馈控制框架，用于非线性控制系统，属于控制理论与强化学习的交叉领域，而非生物学、化学或物理学中的科学发现。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00475v1",
    "title": "Progressive Ideation using an Agentic AI Framework for Human-AI Co-Creation",
    "summary": "The generation of truly novel and diverse ideas is important for contemporary engineering design, yet it remains a significant cognitive challenge for novice designers. Current 'single-spurt' AI systems exacerbate this challenge by producing a high volume of semantically clustered ideas. We propose MIDAS (Meta-cognitive Ideation through Distributed Agentic AI System), a novel framework that replaces the single-AI paradigm with a distributed 'team' of specialized AI agents designed to emulate the human meta-cognitive ideation workflow. This agentic system progressively refines ideas and assesses each one for both global novelty (against existing solutions) and local novelty (against previously generated ideas). MIDAS, therefore, demonstrates a viable and progressive paradigm for true human-AI co-creation, elevating the human designer from a passive filterer to a participatory, active, collaborative partner.",
    "authors": [
      "Sankar B",
      "Srinidhi Ranjini Girish",
      "Aadya Bharti",
      "Dibakar Sen"
    ],
    "url": "http://arxiv.org/abs/2601.00475v1",
    "published": "2026-01-01",
    "primary_category": "cs.AI",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于工程设计的分布式AI代理框架，通过模拟人类元认知工作流程来促进渐进式创意生成，属于人机协同设计领域而非传统科学发现范畴。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00473v1",
    "title": "Neural Chains and Discrete Dynamical Systems",
    "summary": "We inspect the analogy between machine-learning (ML) applications based on the transformer architecture without self-attention, {\\it neural chains} hereafter, and discrete dynamical systems associated with discretised versions of neural integral and partial differential equations (NIE, PDE). A comparative analysis of the numerical solution of the (viscid and inviscid) Burgers and Eikonal equations via standard numerical discretization (also cast in terms of neural chains) and via PINN's learning is presented and commented on. It is found that standard numerical discretization and PINN learning provide two different paths to acquire essentially the same knowledge about the dynamics of the system. PINN learning proceeds through random matrices which bear no direct relation to the highly structured matrices associated with finite-difference (FD) procedures. Random matrices leading to acceptable solutions are far more numerous than the unique tridiagonal form in matrix space, which explains why the PINN search typically lands on the random ensemble. The price is a much larger number of parameters, causing lack of physical transparency (explainability) as well as large training costs with no counterpart in the FD procedure. However, our results refer to one-dimensional dynamic problems, hence they don't rule out the possibility that PINNs and ML in general, may offer better strategies for high-dimensional problems.",
    "authors": [
      "Sauro Succi",
      "Abhisek Ganguly",
      "Santosh Ansumali"
    ],
    "url": "http://arxiv.org/abs/2601.00473v1",
    "published": "2026-01-01",
    "primary_category": "cs.LG",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文通过比较PINN学习与传统数值离散方法在求解Burgers和Eikonal方程中的表现，探讨了机器学习在物理系统动力学建模中的应用，属于AI4Science范畴。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00471v1",
    "title": "Coupled thermo-chemo-mechanical phase field-based modelling of hydrogen-assisted cracking in girth welds",
    "summary": "A new computational framework is presented to predict the structural integrity of welds in hydrogen transmission pipelines. The framework combines: (i) a thermo-mechanical weld process model, and (ii) a coupled deformation-diffusion-fracture phase field-based model that accounts for plasticity and hydrogen trapping, considering multiple trap types, with stationary and evolving trap densities. This enables capturing, for the first time, the interplay between residual stresses, trap creation, hydrogen transport, and fracture. The computational framework is particularised and applied to the study of weld integrity in X80 pipeline steel. The focus is on girth welds, as they are more complex due to their multi-pass nature. The weld process model enables identifying the dimensions and characteristics of the three weld regions: base metal, heat-affected zone, and weld metal, and these are treated distinctively. This is followed by virtual fracture experiments, which reveal a very good agreement with laboratory studies. Then, weld pipeline integrity is assessed, estimating critical failure pressures for a wide range of scenarios. Of particular interest is to assess the structural integrity implications of welding defects present in existing natural gas pipelines under consideration for hydrogen transport: pores, lack of penetration, imperfections, lack of fusion, root contraction, and undercutting. The results obtained in hydrogen-containing environments reveal an important role of the weld microstructure and the detrimental effect of weld defects that are likely to be present in existing natural gas pipelines, as they are considered safe in gas pipeline standards.",
    "authors": [
      "L. Castro",
      "Y. Navidtehrani. C. Betegón",
      "E. Martínez-Pañeda"
    ],
    "url": "http://arxiv.org/abs/2601.00471v1",
    "published": "2026-01-01",
    "primary_category": "cs.CE",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于预测氢传输管道焊缝结构完整性的计算框架，结合热机械焊接过程模型和相场模型，重点研究焊接缺陷对氢致开裂的影响。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00461v1",
    "title": "Laplacian Kernelized Bandit",
    "summary": "We study multi-user contextual bandits where users are related by a graph and their reward functions exhibit both non-linear behavior and graph homophily. We introduce a principled joint penalty for the collection of user reward functions $\\{f_u\\}$, combining a graph smoothness term based on RKHS distances with an individual roughness penalty. Our central contribution is proving that this penalty is equivalent to the squared norm within a single, unified \\emph{multi-user RKHS}. We explicitly derive its reproducing kernel, which elegantly fuses the graph Laplacian with the base arm kernel. This unification allows us to reframe the problem as learning a single ''lifted'' function, enabling the design of principled algorithms, \\texttt{LK-GP-UCB} and \\texttt{LK-GP-TS}, that leverage Gaussian Process posteriors over this new kernel for exploration. We provide high-probability regret bounds that scale with an \\emph{effective dimension} of the multi-user kernel, replacing dependencies on user count or ambient dimension. Empirically, our methods outperform strong linear and non-graph-aware baselines in non-linear settings and remain competitive even when the true rewards are linear. Our work delivers a unified, theoretically grounded, and practical framework that bridges Laplacian regularization with kernelized bandits for structured exploration.",
    "authors": [
      "Shuang Wu",
      "Arash A. Amini"
    ],
    "url": "http://arxiv.org/abs/2601.00461v1",
    "published": "2026-01-01",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于图拉普拉斯核化的多用户上下文赌博机算法框架，专注于强化学习中的探索-利用权衡问题，而非特定科学领域的发现或扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00459v1",
    "title": "Detecting Spike Wave Discharges (SWD) using 1-dimensional Residual UNet",
    "summary": "The manual labeling of events in electroencephalography (EEG) records is time-consuming. This is especially true when EEG recordings are taken continuously over weeks to months. Therefore, a method to automatically label pertinent EEG events reduces the manual workload. Spike wave discharges (SWD), which are the electrographic hallmark of absence seizures, are EEG events that are often labeled manually. While some previous studies have utilized machine learning to automatically segment and classify EEG signals like SWDs, they can be improved. Here we compare the performance of 14 machine learning classifiers on our own manually annotated dataset of 961 hours of EEG recordings from C3H/HeJ mice, including 22,637 labeled SWDs. We find that a 1D UNet performs best for labeling SWDs in this dataset. We also improve the 1D UNet by augmenting our training data and determine that scaling showed the greatest benefit of all augmentation procedures applied. We then compare the 1D UNet with data augmentation, AugUNet1D, against a recently published time- and frequency-based algorithmic approach called \"Twin Peaks\". AugUNet1D showed superior performance and detected events with more similar features to the SWDs labeled manually. AugUNet1D, pretrained on our manually annotated data or untrained, is made public for others users.",
    "authors": [
      "Saurav Sengupta",
      "Scott Kilianski",
      "Suchetha Sharma",
      "Sakina Lashkeri",
      "Ashley McHugh",
      "Mark Beenhakker",
      "Donald E. Brown"
    ],
    "url": "http://arxiv.org/abs/2601.00459v1",
    "published": "2026-01-01",
    "primary_category": "cs.LG",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文开发了一种基于1D UNet的AI方法，用于自动检测小鼠脑电图中的棘波放电，属于神经科学领域的AI辅助科学发现。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00458v1",
    "title": "Combining multiple interface set path ensembles with MBAR reweighting",
    "summary": "We introduce a method to compute the reweighted path ensemble by combining transition interface sampling simulations conditioned on different collective variables. The approach is based on the Multistate Bennett Acceptance Ratio (MBAR) methodology applied to entire trajectories. Illustrating the technique with simple 2D potential models and a more complex host-guest system, we show that the statistics can significantly improve compared to a straightforward combination.",
    "authors": [
      "Rik S. Breebaart",
      "Peter G. Bolhuis"
    ],
    "url": "http://arxiv.org/abs/2601.00458v1",
    "published": "2026-01-01",
    "primary_category": "cond-mat.stat-mech",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于MBAR方法结合不同集体变量下过渡界面采样模拟的路径集成重加权技术，属于计算化学中的分子模拟方法学改进，而非AI4Science或细胞/基因扰动预测领域。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00457v1",
    "title": "Geometric Regularization in Mixture-of-Experts: The Disconnect Between Weights and Activations",
    "summary": "Mixture-of-Experts (MoE) models achieve efficiency through sparse activation, but the role of geometric regularization in expert specialization remains unclear. We apply orthogonality loss to enforce expert diversity and find it fails on multiple fronts: it does not reduce weight-space overlap (MSO actually increases by up to 114%), activation-space overlap remains high (~0.6) regardless of regularization, and effects on performance are inconsistent -- marginal improvement on WikiText-103 (-0.9%), slight degradation on TinyStories (+0.9%), and highly variable results on PTB (std > 1.0). Our analysis across 7 regularization strengths reveals no significant correlation (r = -0.293, p = 0.523) between weight and activation orthogonality. These findings demonstrate that weight-space regularization neither achieves its geometric goal nor reliably improves performance, making it unsuitable for MoE diversity.",
    "authors": [
      "Hyunjun Kim"
    ],
    "url": "http://arxiv.org/abs/2601.00457v1",
    "published": "2026-01-01",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文研究混合专家模型中的几何正则化机制，属于机器学习模型优化领域，不涉及自然科学发现或细胞/基因扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00455v1",
    "title": "Deep Networks Learn Deep Hierarchical Models",
    "summary": "We consider supervised learning with $n$ labels and show that layerwise SGD on residual networks can efficiently learn a class of hierarchical models. This model class assumes the existence of an (unknown) label hierarchy $L_1 \\subseteq L_2 \\subseteq \\dots \\subseteq L_r = [n]$, where labels in $L_1$ are simple functions of the input, while for $i > 1$, labels in $L_i$ are simple functions of simpler labels.   Our class surpasses models that were previously shown to be learnable by deep learning algorithms, in the sense that it reaches the depth limit of efficient learnability. That is, there are models in this class that require polynomial depth to express, whereas previous models can be computed by log-depth circuits.   Furthermore, we suggest that learnability of such hierarchical models might eventually form a basis for understanding deep learning. Beyond their natural fit for domains where deep learning excels, we argue that the mere existence of human ``teachers\" supports the hypothesis that hierarchical structures are inherently available. By providing granular labels, teachers effectively reveal ``hints'' or ``snippets'' of the internal algorithms used by the brain. We formalize this intuition, showing that in a simplified model where a teacher is partially aware of their internal logic, a hierarchical structure emerges that facilitates efficient learnability.",
    "authors": [
      "Amit Daniely"
    ],
    "url": "http://arxiv.org/abs/2601.00455v1",
    "published": "2026-01-01",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文主要研究深度网络通过分层学习算法高效学习层次化模型的理论能力，属于机器学习理论范畴，而非具体科学发现应用或扰动预测研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00454v1",
    "title": "Defensive M2S: Training Guardrail Models on Compressed Multi-turn Conversations",
    "summary": "Guardrail models are essential for ensuring the safety of Large Language Model (LLM) deployments, but processing full multi-turn conversation histories incurs significant computational cost. We propose Defensive M2S, a training paradigm that fine-tunes guardrail models on Multi-turn to Single-turn (M2S) compressed conversations rather than complete dialogue histories. We provide a formal complexity analysis showing that M2S reduces training cost from $O(n^2)$ to $O(n)$ for $n$-turn conversations. Empirically, on our training dataset (779 samples, avg. 10.6 turns), M2S requires only 169K tokens compared to 15.7M tokens for the multi-turn baseline -- a 93$\\times$ reduction. We evaluate Defensive M2S across three guardrail model families (LlamaGuard, Nemotron, Qwen3Guard) and three compression templates (hyphenize, numberize, pythonize) on SafeDialBench, a comprehensive multi-turn jailbreak benchmark. Our best configuration, Qwen3Guard with hyphenize compression, achieves 93.8% attack detection recall while reducing inference tokens by 94.6% (from 3,231 to 173 tokens per conversation). This represents a 38.9 percentage point improvement over the baseline while dramatically reducing both training and inference costs. Our findings demonstrate that M2S compression can serve as an effective efficiency technique for guardrail deployment, enabling scalable safety screening of long multi-turn conversations.",
    "authors": [
      "Hyunjun Kim"
    ],
    "url": "http://arxiv.org/abs/2601.00454v1",
    "published": "2026-01-01",
    "primary_category": "cs.CL",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种通过多轮到单轮对话压缩来高效训练护栏模型的方法，专注于提升大型语言模型部署的安全性而非科学发现或生物医学扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00452v1",
    "title": "Imitation from Observations with Trajectory-Level Generative Embeddings",
    "summary": "We consider the offline imitation learning from observations (LfO) where the expert demonstrations are scarce and the available offline suboptimal data are far from the expert behavior. Many existing distribution-matching approaches struggle in this regime because they impose strict support constraints and rely on brittle one-step models, making it hard to extract useful signal from imperfect data. To tackle this challenge, we propose TGE, a trajectory-level generative embedding for offline LfO that constructs a dense, smooth surrogate reward by estimating expert state density in the latent space of a temporal diffusion model trained on offline trajectory data. By leveraging the smooth geometry of the learned diffusion embedding, TGE captures long-horizon temporal dynamics and effectively bridges the gap between disjoint supports, ensuring a robust learning signal even when offline data is distributionally distinct from the expert. Empirically, the proposed approach consistently matches or outperforms prior offline LfO methods across a range of D4RL locomotion and manipulation benchmarks.",
    "authors": [
      "Yongtao Qu",
      "Shangzhe Li",
      "Weitong Zhang"
    ],
    "url": "http://arxiv.org/abs/2601.00452v1",
    "published": "2026-01-01",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于轨迹级生成嵌入的离线模仿学习方法，专注于强化学习中的行为克隆技术改进，而非科学发现或生物扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00451v1",
    "title": "Controllable Concept Bottleneck Models",
    "summary": "Concept Bottleneck Models (CBMs) have garnered much attention for their ability to elucidate the prediction process through a human-understandable concept layer. However, most previous studies focused on static scenarios where the data and concepts are assumed to be fixed and clean. In real-world applications, deployed models require continuous maintenance: we often need to remove erroneous or sensitive data (unlearning), correct mislabeled concepts, or incorporate newly acquired samples (incremental learning) to adapt to evolving environments. Thus, deriving efficient editable CBMs without retraining from scratch remains a significant challenge, particularly in large-scale applications. To address these challenges, we propose Controllable Concept Bottleneck Models (CCBMs). Specifically, CCBMs support three granularities of model editing: concept-label-level, concept-level, and data-level, the latter of which encompasses both data removal and data addition. CCBMs enjoy mathematically rigorous closed-form approximations derived from influence functions that obviate the need for retraining. Experimental results demonstrate the efficiency and adaptability of our CCBMs, affirming their practical value in enabling dynamic and trustworthy CBMs.",
    "authors": [
      "Hongbin Lin",
      "Chenyang Ren",
      "Juangui Xu",
      "Zhengyu Hu",
      "Cheng-Long Wang",
      "Yao Shu",
      "Hui Xiong",
      "Jingfeng Zhang",
      "Di Wang",
      "Lijie Hu"
    ],
    "url": "http://arxiv.org/abs/2601.00451v1",
    "published": "2026-01-01",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种可编辑的概念瓶颈模型框架，专注于提升机器学习模型在动态环境中的维护效率，而非应用于特定科学领域的发现或扰动响应预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00449v1",
    "title": "Quadratic Unconstrained Binary Optimisation for Training and Regularisation of Binary Neural Networks",
    "summary": "Advances in artificial intelligence (AI) and deep learning have raised concerns about its increasing energy consumption, while demand for deploying AI in mobile devices and machines at the edge is growing. Binary neural networks (BNNs) have recently gained attention as energy and memory efficient models suitable for resource constrained environments; however, training BNNs exactly is computationally challenging because of its discrete characteristics. Recent work proposing a framework for training BNNs based on quadratic unconstrained binary optimisation (QUBO) and progress in the design of Ising machines for solving QUBO problems suggest a potential path to efficiently optimising discrete neural networks. In this work, we extend existing QUBO models for training BNNs to accommodate arbitrary network topologies and propose two novel methods for regularisation. The first method maximises neuron margins biasing the training process toward parameter configurations that yield larger pre-activation magnitudes. The second method employs a dropout-inspired iterative scheme in which reduced subnetworks are trained and used to adjust linear penalties on network parameters. We apply the proposed QUBO formulation to a small binary image classification problem and conduct computational experiments on a GPU-based Ising machine. The numerical results indicate that the proposed regularisation terms modify training behaviour and yield improvements in classification accuracy on data not present in the training set.",
    "authors": [
      "Jonas Christoffer Villumsen",
      "Yusuke Sugita"
    ],
    "url": "http://arxiv.org/abs/2601.00449v1",
    "published": "2026-01-01",
    "primary_category": "math.OC",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于二次无约束二进制优化的二元神经网络训练和正则化方法，旨在提高在资源受限环境下的能效和分类准确性。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00448v1",
    "title": "Language as Mathematical Structure: Examining Semantic Field Theory Against Language Games",
    "summary": "Large language models (LLMs) offer a new empirical setting in which long-standing theories of linguistic meaning can be examined. This paper contrasts two broad approaches: social constructivist accounts associated with language games, and a mathematically oriented framework we call Semantic Field Theory. Building on earlier work by the author, we formalize the notions of lexical fields (Lexfelder) and linguistic fields (Lingofelder) as interacting structures in a continuous semantic space. We then analyze how core properties of transformer architectures-such as distributed representations, attention mechanisms, and geometric regularities in embedding spaces-relate to these concepts. We argue that the success of LLMs in capturing semantic regularities supports the view that language exhibits an underlying mathematical structure, while their persistent limitations in pragmatic reasoning and context sensitivity are consistent with the importance of social grounding emphasized in philosophical accounts of language use. On this basis, we suggest that mathematical structure and language games can be understood as complementary rather than competing perspectives. The resulting framework clarifies the scope and limits of purely statistical models of language and motivates new directions for theoretically informed AI architectures.",
    "authors": [
      "Dimitris Vartziotis"
    ],
    "url": "http://arxiv.org/abs/2601.00448v1",
    "published": "2026-01-01",
    "primary_category": "cs.CL",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文通过对比语言游戏理论与语义场理论，探讨了语言模型如何揭示语言内在的数学结构，属于语言哲学与人工智能交叉领域，而非AI4Science或扰动预测研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00446v1",
    "title": "A Comparative Study of Adaptation Strategies for Time Series Foundation Models in Anomaly Detection",
    "summary": "Time series anomaly detection is essential for the reliable operation of complex systems, but most existing methods require extensive task-specific training. We explore whether time series foundation models (TSFMs), pretrained on large heterogeneous data, can serve as universal backbones for anomaly detection. Through systematic experiments across multiple benchmarks, we compare zero-shot inference, full model adaptation, and parameter-efficient fine-tuning (PEFT) strategies. Our results demonstrate that TSFMs outperform task-specific baselines, achieving notable gains in AUC-PR and VUS-PR, particularly under severe class imbalance. Moreover, PEFT methods such as LoRA, OFT, and HRA not only reduce computational cost but also match or surpass full fine-tuning in most cases, indicating that TSFMs can be efficiently adapted for anomaly detection, even when pretrained for forecasting. These findings position TSFMs as promising general-purpose models for scalable and efficient time series anomaly detection.",
    "authors": [
      "Miseon Park",
      "Kijung Yoon"
    ],
    "url": "http://arxiv.org/abs/2601.00446v1",
    "published": "2026-01-01",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于时间序列异常检测的通用模型适配策略比较，不涉及生物学、化学或物理学等具体科学领域的发现。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00925v1",
    "title": "Application of deep learning techniques in non-contrast computed tomography pulmonary angiogram for pulmonary embolism diagnosis",
    "summary": "Pulmonary embolism is a life-threatening disease, early detection and treatment can significantly reduce mortality. In recent years, many studies have been using deep learning in the diagnosis of pulmonary embolism with contrast medium computed tomography pulmonary angiography, but the contrast medium is likely to cause acute kidney injury in patients with pulmonary embolism and chronic kidney disease, and the contrast medium takes time to work, patients with acute pulmonary embolism may miss the golden treatment time.   This study aims to use deep learning techniques to automatically classify pulmonary embolism in CT images without contrast medium by using a 3D convolutional neural network model. The deep learning model used in this study had a significant impact on the pulmonary embolism classification of computed tomography images without contrast with 85\\% accuracy and 0.84 AUC, which confirms the feasibility of the model in the diagnosis of pulmonary embolism.",
    "authors": [
      "I-Hsien Ting",
      "Yi-Jun Tseng",
      "Yu-Sheng Lin"
    ],
    "url": "http://arxiv.org/abs/2601.00925v1",
    "published": "2026-01-01",
    "primary_category": "cs.CV",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该研究将深度学习应用于无造影剂CT图像的肺栓塞自动分类，属于AI在医学影像诊断领域的科学应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00428v1",
    "title": "A Comparative Analysis of Interpretable Machine Learning Methods",
    "summary": "In recent years, Machine Learning (ML) has seen widespread adoption across a broad range of sectors, including high-stakes domains such as healthcare, finance, and law. This growing reliance has raised increasing concerns regarding model interpretability and accountability, particularly as legal and regulatory frameworks place tighter constraints on using black-box models in critical applications. Although interpretable ML has attracted substantial attention, systematic evaluations of inherently interpretable models, especially for tabular data, remain relatively scarce and often focus primarily on aggregated performance outcomes.   To address this gap, we present a large-scale comparative evaluation of 16 inherently interpretable methods, ranging from classical linear models and decision trees to more recent approaches such as Explainable Boosting Machines (EBMs), Symbolic Regression (SR), and Generalized Optimal Sparse Decision Trees (GOSDT). Our study spans 216 real-world tabular datasets and goes beyond aggregate rankings by stratifying performance according to structural dataset characteristics, including dimensionality, sample size, linearity, and class imbalance. In addition, we assess training time and robustness under controlled distributional shifts. Our results reveal clear performance hierarchies, especially for regression tasks, where EBMs consistently achieve strong predictive accuracy. At the same time, we show that performance is highly context-dependent: SR and Interpretable Generalized Additive Neural Networks (IGANNs) perform particularly well in non-linear regimes, while GOSDT models exhibit pronounced sensitivity to class imbalance. Overall, these findings provide practical guidance for practitioners seeking a balance between interpretability and predictive performance, and contribute to a deeper empirical understanding of interpretable modeling for tabular data.",
    "authors": [
      "Mattia Billa",
      "Giovanni Orlandi",
      "Veronica Guidetti",
      "Federica Mandreoli"
    ],
    "url": "http://arxiv.org/abs/2601.00428v1",
    "published": "2026-01-01",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于可解释机器学习方法的系统性比较评估，而非将AI应用于特定科学领域的发现研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00924v1",
    "title": "Complexity-based code embeddings",
    "summary": "This paper presents a generic method for transforming the source code of various algorithms to numerical embeddings, by dynamically analysing the behaviour of computer programs against different inputs and by tailoring multiple generic complexity functions for the analysed metrics. The used algorithms embeddings are based on r-Complexity . Using the proposed code embeddings, we present an implementation of the XGBoost algorithm that achieves an average F1-score on a multi-label dataset with 11 classes, built using real-world code snippets submitted for programming competitions on the Codeforces platform.",
    "authors": [
      "Rares Folea",
      "Radu Iacob",
      "Emil Slusanschi",
      "Traian Rebedea"
    ],
    "url": "http://arxiv.org/abs/2601.00924v1",
    "published": "2026-01-01",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于程序行为动态分析和复杂度函数的代码嵌入方法，用于编程竞赛代码的多标签分类，而非科学发现或生物医学扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00426v1",
    "title": "RMAAT: Astrocyte-Inspired Memory Compression and Replay for Efficient Long-Context Transformers",
    "summary": "The quadratic complexity of self-attention mechanism presents a significant impediment to applying Transformer models to long sequences. This work explores computational principles derived from astrocytes-glial cells critical for biological memory and synaptic modulation-as a complementary approach to conventional architectural modifications for efficient self-attention. We introduce the Recurrent Memory Augmented Astromorphic Transformer (RMAAT), an architecture integrating abstracted astrocyte functionalities. RMAAT employs a recurrent, segment-based processing strategy where persistent memory tokens propagate contextual information. An adaptive compression mechanism, governed by a novel retention factor derived from simulated astrocyte long-term plasticity (LTP), modulates these tokens. Attention within segments utilizes an efficient, linear-complexity mechanism inspired by astrocyte short-term plasticity (STP). Training is performed using Astrocytic Memory Replay Backpropagation (AMRB), a novel algorithm designed for memory efficiency in recurrent networks. Evaluations on the Long Range Arena (LRA) benchmark demonstrate RMAAT's competitive accuracy and substantial improvements in computational and memory efficiency, indicating the potential of incorporating astrocyte-inspired dynamics into scalable sequence models.",
    "authors": [
      "Md Zesun Ahmed Mia",
      "Malyaban Bal",
      "Abhronil Sengupta"
    ],
    "url": "http://arxiv.org/abs/2601.00426v1",
    "published": "2026-01-01",
    "primary_category": "cs.NE",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文受星形胶质细胞生物学原理启发设计高效Transformer模型，属于AI4Science中AI受生物机制启发的计算建模方向。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00423v1",
    "title": "E-GRPO: High Entropy Steps Drive Effective Reinforcement Learning for Flow Models",
    "summary": "Recent reinforcement learning has enhanced the flow matching models on human preference alignment. While stochastic sampling enables the exploration of denoising directions, existing methods which optimize over multiple denoising steps suffer from sparse and ambiguous reward signals. We observe that the high entropy steps enable more efficient and effective exploration while the low entropy steps result in undistinguished roll-outs. To this end, we propose E-GRPO, an entropy aware Group Relative Policy Optimization to increase the entropy of SDE sampling steps. Since the integration of stochastic differential equations suffer from ambiguous reward signals due to stochasticity from multiple steps, we specifically merge consecutive low entropy steps to formulate one high entropy step for SDE sampling, while applying ODE sampling on other steps. Building upon this, we introduce multi-step group normalized advantage, which computes group-relative advantages within samples sharing the same consolidated SDE denoising step. Experimental results on different reward settings have demonstrated the effectiveness of our methods.",
    "authors": [
      "Shengjun Zhang",
      "Zhang Zhang",
      "Chensheng Dai",
      "Yueqi Duan"
    ],
    "url": "http://arxiv.org/abs/2601.00423v1",
    "published": "2026-01-01",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于提升流模型在人类偏好对齐中强化学习效率的熵感知策略优化方法，属于机器学习算法改进而非特定科学领域的AI应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00421v1",
    "title": "Can Semantic Methods Enhance Team Sports Tactics? A Methodology for Football with Broader Applications",
    "summary": "This paper explores how semantic-space reasoning, traditionally used in computational linguistics, can be extended to tactical decision-making in team sports. Building on the analogy between texts and teams -- where players act as words and collective play conveys meaning -- the proposed methodology models tactical configurations as compositional semantic structures. Each player is represented as a multidimensional vector integrating technical, physical, and psychological attributes; team profiles are aggregated through contextual weighting into a higher-level semantic representation. Within this shared vector space, tactical templates such as high press, counterattack, or possession build-up are encoded analogously to linguistic concepts. Their alignment with team profiles is evaluated using vector-distance metrics, enabling the computation of tactical ``fit'' and opponent-exploitation potential. A Python-based prototype demonstrates how these methods can generate interpretable, dynamically adaptive strategy recommendations, accompanied by fine-grained diagnostic insights at the attribute level. Beyond football, the approach offers a generalizable framework for collective decision-making and performance optimization in team-based domains -- ranging from basketball and hockey to cooperative robotics and human-AI coordination systems. The paper concludes by outlining future directions toward real-world data integration, predictive simulation, and hybrid human-machine tactical intelligence.",
    "authors": [
      "Alessio Di Rubbo",
      "Mattia Neri",
      "Remo Pareschi",
      "Marco Pedroni",
      "Roberto Valtancoli",
      "Paolino Zica"
    ],
    "url": "http://arxiv.org/abs/2601.00421v1",
    "published": "2026-01-01",
    "primary_category": "cs.AI",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于语义空间推理的团队运动战术分析方法，将球员视为向量、战术视为语义概念，通过计算向量距离评估战术适配性，属于人工智能在体育策略优化领域的应用，而非传统自然科学领域的科学发现或分子层面的扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00418v1",
    "title": "Secure, Verifiable, and Scalable Multi-Client Data Sharing via Consensus-Based Privacy-Preserving Data Distribution",
    "summary": "We propose the Consensus-Based Privacy-Preserving Data Distribution (CPPDD) framework, a lightweight and post-setup autonomous protocol for secure multi-client data aggregation. The framework enforces unanimous-release confidentiality through a dual-layer protection mechanism that combines per-client affine masking with priority-driven sequential consensus locking. Decentralized integrity is verified via step (sigma_S) and data (sigma_D) checksums, facilitating autonomous malicious deviation detection and atomic abort without requiring persistent coordination. The design supports scalar, vector, and matrix payloads with O(N*D) computation and communication complexity, optional edge-server offloading, and resistance to collusion under N-1 corruptions. Formal analysis proves correctness, Consensus-Dependent Integrity and Fairness (CDIF) with overwhelming-probability abort on deviation, and IND-CPA security assuming a pseudorandom function family. Empirical evaluations on MNIST-derived vectors demonstrate linear scalability up to N = 500 with sub-millisecond per-client computation times. The framework achieves 100% malicious deviation detection, exact data recovery, and three-to-four orders of magnitude lower FLOPs compared to MPC and HE baselines. CPPDD enables atomic collaboration in secure voting, consortium federated learning, blockchain escrows, and geo-information capacity building, addressing critical gaps in scalability, trust minimization, and verifiable multi-party computation for regulated and resource-constrained environments.",
    "authors": [
      "Prajwal Panth",
      "Sahaj Raj Malla"
    ],
    "url": "http://arxiv.org/abs/2601.00418v1",
    "published": "2026-01-01",
    "primary_category": "cs.CR",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于共识的隐私保护数据分发框架，专注于安全多方计算中的可验证性与可扩展性，而非特定科学领域的AI应用或扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00417v1",
    "title": "Deep Delta Learning",
    "summary": "The efficacy of deep residual networks is fundamentally predicated on the identity shortcut connection. While this mechanism effectively mitigates the vanishing gradient problem, it imposes a strictly additive inductive bias on feature transformations, thereby limiting the network's capacity to model complex state transitions. In this paper, we introduce Deep Delta Learning (DDL), a novel architecture that generalizes the standard residual connection by modulating the identity shortcut with a learnable, data-dependent geometric transformation. This transformation, termed the Delta Operator, constitutes a rank-1 perturbation of the identity matrix, parameterized by a reflection direction vector $\\mathbf{k}(\\mathbf{X})$ and a gating scalar $β(\\mathbf{X})$. We provide a spectral analysis of this operator, demonstrating that the gate $β(\\mathbf{X})$ enables dynamic interpolation between identity mapping, orthogonal projection, and geometric reflection. Furthermore, we restructure the residual update as a synchronous rank-1 injection, where the gate acts as a dynamic step size governing both the erasure of old information and the writing of new features. This unification empowers the network to explicitly control the spectrum of its layer-wise transition operator, enabling the modeling of complex, non-monotonic dynamics while preserving the stable training characteristics of gated residual architectures.",
    "authors": [
      "Yifan Zhang",
      "Yifeng Liu",
      "Mengdi Wang",
      "Quanquan Gu"
    ],
    "url": "http://arxiv.org/abs/2601.00417v1",
    "published": "2026-01-01",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种改进深度残差网络架构的新方法，通过可学习的几何变换增强特征转换能力，属于深度学习模型结构创新，而非应用于特定科学领域或预测细胞/遗传扰动响应。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00411v1",
    "title": "Do LLMs Judge Distantly Supervised Named Entity Labels Well? Constructing the JudgeWEL Dataset",
    "summary": "We present judgeWEL, a dataset for named entity recognition (NER) in Luxembourgish, automatically labelled and subsequently verified using large language models (LLM) in a novel pipeline. Building datasets for under-represented languages remains one of the major bottlenecks in natural language processing, where the scarcity of resources and linguistic particularities make large-scale annotation costly and potentially inconsistent. To address these challenges, we propose and evaluate a novel approach that leverages Wikipedia and Wikidata as structured sources of weak supervision. By exploiting internal links within Wikipedia articles, we infer entity types based on their corresponding Wikidata entries, thereby generating initial annotations with minimal human intervention. Because such links are not uniformly reliable, we mitigate noise by employing and comparing several LLMs to identify and retain only high-quality labelled sentences. The resulting corpus is approximately five times larger than the currently available Luxembourgish NER dataset and offers broader and more balanced coverage across entity categories, providing a substantial new resource for multilingual and low-resource NER research.",
    "authors": [
      "Alistair Plum",
      "Laura Bernardy",
      "Tharindu Ranasinghe"
    ],
    "url": "http://arxiv.org/abs/2601.00411v1",
    "published": "2026-01-01",
    "primary_category": "cs.CL",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种利用维基百科和大型语言模型自动构建卢森堡语命名实体识别数据集的方法，属于自然语言处理领域的资源构建研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00923v1",
    "title": "Context Collapse: In-Context Learning and Model Collapse",
    "summary": "This thesis investigates two key phenomena in large language models (LLMs): in-context learning (ICL) and model collapse. We study ICL in a linear transformer with tied weights trained on linear regression tasks, and show that minimising the in-context loss leads to a phase transition in the learned parameters. Above a critical context length, the solution develops a skew-symmetric component. We prove this by reducing the forward pass of the linear transformer under weight tying to preconditioned gradient descent, and then analysing the optimal preconditioner. This preconditioner includes a skew-symmetric component, which induces a rotation of the gradient direction. For model collapse, we use martingale and random walk theory to analyse simplified settings - linear regression and Gaussian fitting - under both replacing and cumulative data regimes. We strengthen existing results by proving almost sure convergence, showing that collapse occurs unless the data grows sufficiently fast or is retained over time. Finally, we introduce the notion of context collapse: a degradation of context during long generations, especially in chain-of-thought reasoning. This concept links the dynamics of ICL with long-term stability challenges in generative models.",
    "authors": [
      "Josef Ott"
    ],
    "url": "http://arxiv.org/abs/2601.00923v1",
    "published": "2026-01-01",
    "primary_category": "cs.AI",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文研究大语言模型的上下文学习和模型崩溃机制，属于机器学习理论分析，不涉及具体科学领域的AI应用或细胞/基因扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00400v1",
    "title": "Adaptive Causal Coordination Detection for Social Media: A Memory-Guided Framework with Semi-Supervised Learning",
    "summary": "Detecting coordinated inauthentic behavior on social media remains a critical and persistent challenge, as most existing approaches rely on superficial correlation analysis, employ static parameter settings, and demand extensive and labor-intensive manual annotation. To address these limitations systematically, we propose the Adaptive Causal Coordination Detection (ACCD) framework. ACCD adopts a three-stage, progressive architecture that leverages a memory-guided adaptive mechanism to dynamically learn and retain optimal detection configurations for diverse coordination scenarios. Specifically, in the first stage, ACCD introduces an adaptive Convergent Cross Mapping (CCM) technique to deeply identify genuine causal relationships between accounts. The second stage integrates active learning with uncertainty sampling within a semi-supervised classification scheme, significantly reducing the burden of manual labeling. The third stage deploys an automated validation module driven by historical detection experience, enabling self-verification and optimization of the detection outcomes. We conduct a comprehensive evaluation using real-world datasets, including the Twitter IRA dataset, Reddit coordination traces, and several widely-adopted bot detection benchmarks. Experimental results demonstrate that ACCD achieves an F1-score of 87.3\\% in coordinated attack detection, representing a 15.2\\% improvement over the strongest existing baseline. Furthermore, the system reduces manual annotation requirements by 68\\% and achieves a 2.8x speedup in processing through hierarchical clustering optimization. In summary, ACCD provides a more accurate, efficient, and highly automated end-to-end solution for identifying coordinated behavior on social platforms, offering substantial practical value and promising potential for broad application.",
    "authors": [
      "Weng Ding",
      "Yi Han",
      "Mu-Jiang-Shan Wang"
    ],
    "url": "http://arxiv.org/abs/2601.00400v1",
    "published": "2026-01-01",
    "primary_category": "cs.AI",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于社交媒体协调行为检测的自适应因果协调检测框架，属于计算机科学中的网络安全与人工智能应用领域。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00397v1",
    "title": "Revati: Transparent GPU-Free Time-Warp Emulation for LLM Serving",
    "summary": "Deploying LLMs efficiently requires testing hundreds of serving configurations, but evaluating each one on a GPU cluster takes hours and costs thousands of dollars. Discrete-event simulators are faster and cheaper, but they require re-implementing the serving system's control logic -- a burden that compounds as frameworks evolve.   We present Revati, a time-warp emulator that enables performance modeling by directly executing real serving system code at simulation-like speed. The system intercepts CUDA API calls to virtualize device management, allowing serving frameworks to run without physical GPUs. Instead of executing GPU kernels, it performs time jumps -- fast-forwarding virtual time by predicted kernel durations. We propose a coordination protocol that synchronizes these jumps across distributed processes while preserving causality. On vLLM and SGLang, Revati achieves less than 5% prediction error across multiple models and parallelism configurations, while running 5-17x faster than real GPU execution.",
    "authors": [
      "Amey Agrawal",
      "Mayank Yadav",
      "Sukrit Kumar",
      "Anirudha Agrawal",
      "Garv Ghai",
      "Souradeep Bera",
      "Elton Pinto",
      "Sirish Gambhira",
      "Mohammad Adain",
      "Kasra Sohrab",
      "Chus Antonanzas",
      "Alexey Tumanov"
    ],
    "url": "http://arxiv.org/abs/2601.00397v1",
    "published": "2026-01-01",
    "primary_category": "cs.DC",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于大语言模型服务性能仿真的GPU虚拟化系统，属于计算机系统优化领域，而非AI4Science或扰动预测研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00391v1",
    "title": "Real-Time Human Detection for Aerial Captured Video Sequences via Deep Models",
    "summary": "Human detection in videos plays an important role in various real-life applications. Most traditional approaches depend on utilizing handcrafted features, which are problem-dependent and optimal for specific tasks. Moreover, they are highly susceptible to dynamical events such as illumination changes, camera jitter, and variations in object sizes. On the other hand, the proposed feature learning approaches are cheaper and easier because highly abstract and discriminative features can be produced automatically without the need of expert knowledge. In this paper, we utilize automatic feature learning methods, which combine optical flow and three different deep models (i.e., supervised convolutional neural network (S-CNN), pretrained CNN feature extractor, and hierarchical extreme learning machine) for human detection in videos captured using a nonstatic camera on an aerial platform with varying altitudes. The models are trained and tested on the publicly available and highly challenging UCF-ARG aerial dataset. The comparison between these models in terms of training, testing accuracy, and learning speed is analyzed. The performance evaluation considers five human actions (digging, waving, throwing, walking, and running). Experimental results demonstrated that the proposed methods are successful for the human detection task. The pretrained CNN produces an average accuracy of 98.09%. S-CNN produces an average accuracy of 95.6% with softmax and 91.7% with Support Vector Machines (SVM). H-ELM has an average accuracy of 95.9%. Using a normal Central Processing Unit (CPU), H-ELM's training time takes 445 seconds. Learning in S-CNN takes 770 seconds with a high-performance Graphical Processing Unit (GPU).",
    "authors": [
      "Nouar AlDahoul",
      "Aznul Qalid Md Sabri",
      "Ali Mohammed Mansoor"
    ],
    "url": "http://arxiv.org/abs/2601.00391v1",
    "published": "2026-01-01",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于利用深度学习模型进行无人机视频中的人体检测，属于计算机视觉应用领域，而非科学发现或细胞扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00389v1",
    "title": "NOS-Gate: Queue-Aware Streaming IDS for Consumer Gateways under Timing-Controlled Evasion",
    "summary": "Timing and burst patterns can leak through encryption, and an adaptive adversary can exploit them. This undermines metadata-only detection in a stand-alone consumer gateway. Therefore, consumer gateways need streaming intrusion detection on encrypted traffic using metadata only, under tight CPU and latency budgets. We present a streaming IDS for stand-alone gateways that instantiates a lightweight two-state unit derived from Network-Optimised Spiking (NOS) dynamics per flow, named NOS-Gate. NOS-Gate scores fixed-length windows of metadata features and, under a $K$-of-$M$ persistence rule, triggers a reversible mitigation that temporarily reduces the flow's weight under weighted fair queueing (WFQ). We evaluate NOS-Gate under timing-controlled evasion using an executable 'worlds' benchmark that specifies benign device processes, auditable attacker budgets, contention structure, and packet-level WFQ replay to quantify queue impact. All methods are calibrated label-free via burn-in quantile thresholding. Across multiple reproducible worlds and malicious episodes, at an achieved $0.1%$ false-positive operating point, NOS-Gate attains 0.952 incident recall versus 0.857 for the best baseline in these runs. Under gating, it reduces p99.9 queueing delay and p99.9 collateral delay with a mean scoring cost of ~ 2.09 μs per flow-window on CPU.",
    "authors": [
      "Muhammad Bilal",
      "Omer Tariq",
      "Hasan Ahmed"
    ],
    "url": "http://arxiv.org/abs/2601.00389v1",
    "published": "2026-01-01",
    "primary_category": "cs.CR",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于网络优化脉冲动力学的轻量级流式入侵检测系统，用于消费网关在加密流量下的时序控制规避攻击检测，属于网络安全领域而非AI4Science或生物医学扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00384v1",
    "title": "Engineering Attack Vectors and Detecting Anomalies in Additive Manufacturing",
    "summary": "Additive manufacturing (AM) is rapidly integrating into critical sectors such as aerospace, automotive, and healthcare. However, this cyber-physical convergence introduces new attack surfaces, especially at the interface between computer-aided design (CAD) and machine execution layers. In this work, we investigate targeted cyberattacks on two widely used fused deposition modeling (FDM) systems, Creality's flagship model K1 Max, and Ender 3. Our threat model is a multi-layered Man-in-the-Middle (MitM) intrusion, where the adversary intercepts and manipulates G-code files during upload from the user interface to the printer firmware. The MitM intrusion chain enables several stealthy sabotage scenarios. These attacks remain undetectable by conventional slicer software or runtime interfaces, resulting in structurally defective yet externally plausible printed parts. To counter these stealthy threats, we propose an unsupervised Intrusion Detection System (IDS) that analyzes structured machine logs generated during live printing. Our defense mechanism uses a frozen Transformer-based encoder (a BERT variant) to extract semantic representations of system behavior, followed by a contrastively trained projection head that learns anomaly-sensitive embeddings. Later, a clustering-based approach and a self-attention autoencoder are used for classification. Experimental results demonstrate that our approach effectively distinguishes between benign and compromised executions.",
    "authors": [
      "Md Mahbub Hasan",
      "Marcus Sternhagen",
      "Krishna Chandra Roy"
    ],
    "url": "http://arxiv.org/abs/2601.00384v1",
    "published": "2026-01-01",
    "primary_category": "cs.CR",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于使用人工智能检测增材制造中的网络攻击，属于网络安全与工业控制领域，而非AI在基础科学发现或细胞/基因扰动预测中的应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00380v1",
    "title": "Word Frequency Counting Based on Serverless MapReduce",
    "summary": "With the increasing demand for high-performance and high-efficiency computing, cloud computing, especially serverless computing, has gradually become a research hotspot in recent years, attracting numerous research attention. Meanwhile, MapReduce, which is a popular big data processing model in the industry, has been widely applied in various fields. Inspired by the serverless framework of Function as a Service and the high concurrency and robustness of MapReduce programming model, this paper focus on combining them to reduce the time span and increase the efficiency when executing the word frequency counting task. In this case, the paper use a MapReduce programming model based on a serverless computing platform to figure out the most optimized number of Map functions and Reduce functions for a particular task. For the same amount of workload, extensive experiments show both execution time reduces and the overall efficiency of the program improves at different rates as the number of map functions and reduce functions increases. This paper suppose the discovery of the most optimized number of map and reduce functions can help cooperations and programmers figure out the most optimized solutions.",
    "authors": [
      "Hanzhe Li",
      "Bingchen Lin",
      "Mengyuan Xu"
    ],
    "url": "http://arxiv.org/abs/2601.00380v1",
    "published": "2026-01-01",
    "primary_category": "cs.DC",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于通过无服务器MapReduce优化词频统计任务的执行效率，属于分布式计算和云计算领域，不涉及AI在科学发现或扰动预测的应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00377v1",
    "title": "Sparse Tucker Decomposition and Graph Regularization for High-Dimensional Time Series Forecasting",
    "summary": "Existing methods of vector autoregressive model for multivariate time series analysis make use of low-rank matrix approximation or Tucker decomposition to reduce the dimension of the over-parameterization issue. In this paper, we propose a sparse Tucker decomposition method with graph regularization for high-dimensional vector autoregressive time series. By stacking the time-series transition matrices into a third-order tensor, the sparse Tucker decomposition is employed to characterize important interactions within the transition third-order tensor and reduce the number of parameters. Moreover, the graph regularization is employed to measure the local consistency of the response, predictor and temporal factor matrices in the vector autoregressive model.The two proposed regularization techniques can be shown to more accurate parameters estimation. A non-asymptotic error bound of the estimator of the proposed method is established, which is lower than those of the existing matrix or tensor based methods. A proximal alternating linearized minimization algorithm is designed to solve the resulting model and its global convergence is established under very mild conditions. Extensive numerical experiments on synthetic data and real-world datasets are carried out to verify the superior performance of the proposed method over existing state-of-the-art methods.",
    "authors": [
      "Sijia Xia",
      "Michael K. Ng",
      "Xiongjun Zhang"
    ],
    "url": "http://arxiv.org/abs/2601.00377v1",
    "published": "2026-01-01",
    "primary_category": "math.ST",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于高维时间序列预测的稀疏Tucker分解与图正则化方法，属于统计学与机器学习领域的方法论研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00376v1",
    "title": "In Line with Context: Repository-Level Code Generation via Context Inlining",
    "summary": "Repository-level code generation has attracted growing attention in recent years. Unlike function-level code generation, it requires the model to understand the entire repository, reasoning over complex dependencies across functions, classes, and modules. However, existing approaches such as retrieval-augmented generation (RAG) or context-based function selection often fall short: they primarily rely on surface-level similarity and struggle to capture the rich dependencies that govern repository-level semantics. In this paper, we introduce InlineCoder, a novel framework for repository-level code generation. InlineCoder enhances the understanding of repository context by inlining the unfinished function into its call graph, thereby reframing the challenging repository understanding as an easier function-level coding task. Given a function signature, InlineCoder first generates a draft completion, termed an anchor, which approximates downstream dependencies and enables perplexity-based confidence estimation. This anchor drives a bidirectional inlining process: (i) Upstream Inlining, which embeds the anchor into its callers to capture diverse usage scenarios; and (ii) Downstream Retrieval, which integrates the anchor's callees into the prompt to provide precise dependency context. The enriched context, combining draft completion with upstream and downstream perspectives, equips the LLM with a comprehensive repository view.",
    "authors": [
      "Chao Hu",
      "Wenhao Zeng",
      "Yuling Shi",
      "Beijun Shen",
      "Xiaodong Gu"
    ],
    "url": "http://arxiv.org/abs/2601.00376v1",
    "published": "2026-01-01",
    "primary_category": "cs.SE",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种通过上下文内联实现仓库级代码生成的新框架，专注于软件工程中的代码自动生成技术。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00375v1",
    "title": "Completely Positive Reformulations of Polynomial Optimization Problems with Linear Inequality Constraints",
    "summary": "Polynomial optimization encompasses a broad class of problems in which both the objective function and constraints are polynomial functions of the decision variables. In recent years, a substantial body of research has focused on reformulating polynomial optimization problems (POPs) as conic programs over the cone of completely positive tensors (CPTs). In this article, we propose several new completely positive reformulations for a class of POPs with linear inequality constraints. Our approach begins by lifting these problems into a novel convex optimization framework, wherein the variables are represented as combinations of symmetric rank-one tensors. Based on this lifted formulation, we present a general characterization of POPs with linear inequality constraints that can be reformulated as conic programs over the CPT cone. Additionally, we construct the dual formulations of the resulting completely positive programs. Under mild assumptions, we prove that these dual problems are strictly feasible and strong duality holds.",
    "authors": [
      "Haibin Chen",
      "Hong Yan",
      "Guanglu Zhou"
    ],
    "url": "http://arxiv.org/abs/2601.00375v1",
    "published": "2026-01-01",
    "primary_category": "math.OC",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了多项式优化问题在具有线性不等式约束下的完全正重构方法，属于数学优化理论领域，不涉及AI4Science或扰动预测的具体应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00367v1",
    "title": "PatchBlock: A Lightweight Defense Against Adversarial Patches for Embedded EdgeAI Devices",
    "summary": "Adversarial attacks pose a significant challenge to the reliable deployment of machine learning models in EdgeAI applications, such as autonomous driving and surveillance, which rely on resource-constrained devices for real-time inference. Among these, patch-based adversarial attacks, where small malicious patches (e.g., stickers) are applied to objects, can deceive neural networks into making incorrect predictions with potentially severe consequences. In this paper, we present PatchBlock, a lightweight framework designed to detect and neutralize adversarial patches in images. Leveraging outlier detection and dimensionality reduction, PatchBlock identifies regions affected by adversarial noise and suppresses their impact. It operates as a pre-processing module at the sensor level, efficiently running on CPUs in parallel with GPU inference, thus preserving system throughput while avoiding additional GPU overhead. The framework follows a three-stage pipeline: splitting the input into chunks (Chunking), detecting anomalous regions via a redesigned isolation forest with targeted cuts for faster convergence (Separating), and applying dimensionality reduction on the identified outliers (Mitigating). PatchBlock is both model- and patch-agnostic, can be retrofitted to existing pipelines, and integrates seamlessly between sensor inputs and downstream models. Evaluations across multiple neural architectures, benchmark datasets, attack types, and diverse edge devices demonstrate that PatchBlock consistently improves robustness, recovering up to 77% of model accuracy under strong patch attacks such as the Google Adversarial Patch, while maintaining high portability and minimal clean accuracy loss. Additionally, PatchBlock outperforms the state-of-the-art defenses in efficiency, in terms of computation time and energy consumption per sample, making it suitable for EdgeAI applications.",
    "authors": [
      "Nandish Chattopadhyay",
      "Abdul Basit",
      "Amira Guesmi",
      "Muhammad Abdullah Hanif",
      "Bassem Ouni",
      "Muhammad Shafique"
    ],
    "url": "http://arxiv.org/abs/2601.00367v1",
    "published": "2026-01-01",
    "primary_category": "cs.CR",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种针对嵌入式边缘AI设备的轻量级对抗性补丁防御框架，专注于计算机视觉领域的模型安全增强，而非科学发现或生物医学扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00366v1",
    "title": "BERT-JEPA: Reorganizing CLS Embeddings for Language-Invariant Semantics",
    "summary": "Joint Embedding Predictive Architectures (JEPA) are a novel self supervised training technique that have shown recent promise across domains. We introduce BERT-JEPA (BEPA), a training paradigm that adds a JEPA training objective to BERT-style models, working to combat a collapsed [CLS] embedding space and turning it into a language-agnostic space. This new structure leads to increased performance across multilingual benchmarks.",
    "authors": [
      "Taj Gillin",
      "Adam Lalani",
      "Kenneth Zhang",
      "Marcel Mateos Salles"
    ],
    "url": "http://arxiv.org/abs/2601.00366v1",
    "published": "2026-01-01",
    "primary_category": "cs.CL",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出一种改进BERT模型多语言语义表示的自监督训练方法，而非应用于具体科学领域或扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00361v1",
    "title": "Deterministic Coreset for Lp Subspace",
    "summary": "We introduce the first iterative algorithm for constructing a $\\varepsilon$-coreset that guarantees deterministic $\\ell_p$ subspace embedding for any $p \\in [1,\\infty)$ and any $\\varepsilon > 0$. For a given full rank matrix $\\mathbf{X} \\in \\mathbb{R}^{n \\times d}$ where $n \\gg d$, $\\mathbf{X}' \\in \\mathbb{R}^{m \\times d}$ is an $(\\varepsilon,\\ell_p)$-subspace embedding of $\\mathbf{X}$, if for every $\\mathbf{q} \\in \\mathbb{R}^d$, $(1-\\varepsilon)\\|\\mathbf{Xq}\\|_{p}^{p} \\leq \\|\\mathbf{X'q}\\|_{p}^{p} \\leq (1+\\varepsilon)\\|\\mathbf{Xq}\\|_{p}^{p}$. Specifically, in this paper, $\\mathbf{X}'$ is a weighted subset of rows of $\\mathbf{X}$ which is commonly known in the literature as a coreset. In every iteration, the algorithm ensures that the loss on the maintained set is upper and lower bounded by the loss on the original dataset with appropriate scalings. So, unlike typical coreset guarantees, due to bounded loss, our coreset gives a deterministic guarantee for the $\\ell_p$ subspace embedding. For an error parameter $\\varepsilon$, our algorithm takes $O(\\mathrm{poly}(n,d,\\varepsilon^{-1}))$ time and returns a deterministic $\\varepsilon$-coreset, for $\\ell_p$ subspace embedding whose size is $O\\left(\\frac{d^{\\max\\{1,p/2\\}}}{\\varepsilon^{2}}\\right)$. Here, we remove the $\\log$ factors in the coreset size, which had been a long-standing open problem. Our coresets are optimal as they are tight with the lower bound. As an application, our coreset can also be used for approximately solving the $\\ell_p$ regression problem in a deterministic manner.",
    "authors": [
      "Rachit Chhaya",
      "Anirban Dasgupta",
      "Dan Feldman",
      "Supratim Shit"
    ],
    "url": "http://arxiv.org/abs/2601.00361v1",
    "published": "2026-01-01",
    "primary_category": "cs.DS",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种确定性核心集算法，用于ℓp子空间嵌入，属于计算数学和理论计算机科学领域，而非AI4Science或扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00360v1",
    "title": "Mapping Human Anti-collusion Mechanisms to Multi-agent AI",
    "summary": "As multi-agent AI systems become increasingly autonomous, evidence shows they can develop collusive strategies similar to those long observed in human markets and institutions. While human domains have accumulated centuries of anti-collusion mechanisms, it remains unclear how these can be adapted to AI settings. This paper addresses that gap by (i) developing a taxonomy of human anti-collusion mechanisms, including sanctions, leniency & whistleblowing, monitoring & auditing, market design, and governance and (ii) mapping them to potential interventions for multi-agent AI systems. For each mechanism, we propose implementation approaches. We also highlight open challenges, such as the attribution problem (difficulty attributing emergent coordination to specific agents) identity fluidity (agents being easily forked or modified) the boundary problem (distinguishing beneficial cooperation from harmful collusion) and adversarial adaptation (agents learning to evade detection).",
    "authors": [
      "Jamiu Adekunle Idowu",
      "Ahmed Almasoud",
      "Ayman Alfahid"
    ],
    "url": "http://arxiv.org/abs/2601.00360v1",
    "published": "2026-01-01",
    "primary_category": "cs.MA",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文研究如何将人类反合谋机制映射到多智能体AI系统，属于AI治理与系统设计领域，而非AI4Science或扰动预测范畴。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00350v1",
    "title": "The true detection probability versus the subjective detection probability of a uniformly optimal search plan",
    "summary": "This article investigates the difference between the true detection probability and the subjective probability of a uniformly optimal search plan. Its main contributions are multi-fold. First, it provides a set of examples to show that, in terms of the true detection probability, the uniformly optimal search plan may or may not be optimal. Secondly, it establishes that the true detection probability of the uniformly optimal search plan based on a composite prior can be less than that of the composite uniformly search plan based on different priors. Next, it argues that an open problem is unsolvable. Finally, it shows that the true detection probability of the uniformly optimal search plan converges to one as the search time approaches infinity.",
    "authors": [
      "Liang Hong"
    ],
    "url": "http://arxiv.org/abs/2601.00350v1",
    "published": "2026-01-01",
    "primary_category": "math.OC",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文研究搜索理论中的检测概率优化问题，属于运筹学或概率论领域，与AI4Science或扰动预测无直接关联。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00348v1",
    "title": "Robust Uncertainty Quantification for Factual Generation of Large Language Models",
    "summary": "The rapid advancement of large language model(LLM) technology has facilitated its integration into various domains of professional and daily life. However, the persistent challenge of LLM hallucination has emerged as a critical limitation, significantly compromising the reliability and trustworthiness of AI-generated content. This challenge has garnered significant attention within the scientific community, prompting extensive research efforts in hallucination detection and mitigation strategies. Current methodological frameworks reveal a critical limitation: traditional uncertainty quantification approaches demonstrate effectiveness primarily within conventional question-answering paradigms, yet exhibit notable deficiencies when confronted with non-canonical or adversarial questioning strategies. This performance gap raises substantial concerns regarding the dependability of LLM responses in real-world applications requiring robust critical thinking capabilities. This study aims to fill this gap by proposing an uncertainty quantification scenario in the task of generating with multiple facts. We have meticulously constructed a set of trap questions contained with fake names. Based on this scenario, we innovatively propose a novel and robust uncertainty quantification method(RU). A series of experiments have been conducted to verify its effectiveness. The results show that the constructed set of trap questions performs excellently. Moreover, when compared with the baseline methods on four different models, our proposed method has demonstrated great performance, with an average increase of 0.1-0.2 in ROCAUC values compared to the best performing baseline method, providing new sights and methods for addressing the hallucination issue of LLMs.",
    "authors": [
      "Yuhao Zhang",
      "Zhongliang Yang",
      "Linna Zhou"
    ],
    "url": "http://arxiv.org/abs/2601.00348v1",
    "published": "2026-01-01",
    "primary_category": "cs.CL",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种针对大语言模型生成多事实内容时进行不确定性量化的新方法，以解决模型幻觉问题，属于人工智能可靠性研究领域。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00342v1",
    "title": "Solving nonlinear subsonic compressible flow in infinite domain via multi-stage neural networks",
    "summary": "In aerodynamics, accurately modeling subsonic compressible flow over airfoils is critical for aircraft design. However, solving the governing nonlinear perturbation velocity potential equation presents computational challenges. Traditional approaches often rely on linearized equations or finite, truncated domains, which introduce non-negligible errors and limit applicability in real-world scenarios. In this study, we propose a novel framework utilizing Physics-Informed Neural Networks (PINNs) to solve the full nonlinear compressible potential equation in an unbounded (infinite) domain. We address the unbounded-domain and convergence challenges inherent in standard PINNs by incorporating a coordinate transformation and embedding physical asymptotic constraints directly into the network architecture. Furthermore, we employ a Multi-Stage PINN (MS-PINN) approach to iteratively minimize residuals, achieving solution accuracy approaching machine precision. We validate this framework by simulating flow over circular and elliptical geometries, comparing our results against traditional finite-domain and linearized solutions. Our findings quantify the noticeable discrepancies introduced by domain truncation and linearization, particularly at higher Mach numbers, and demonstrate that this new framework is a robust, high-fidelity tool for computational fluid dynamics.",
    "authors": [
      "Xuehui Qian",
      "Hongkai Tao",
      "Yongji Wang"
    ],
    "url": "http://arxiv.org/abs/2601.00342v1",
    "published": "2026-01-01",
    "primary_category": "physics.flu-dyn",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于物理信息神经网络的多阶段框架，用于解决无限域中的非线性亚音速可压缩流动问题，属于AI在流体力学领域的科学应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00339v1",
    "title": "Bio-inspired Agentic Self-healing Framework for Resilient Distributed Computing Continuum Systems",
    "summary": "Human biological systems sustain life through extraordinary resilience, continually detecting damage, orchestrating targeted responses, and restoring function through self-healing. Inspired by these capabilities, this paper introduces ReCiSt, a bio-inspired agentic self-healing framework designed to achieve resilience in Distributed Computing Continuum Systems (DCCS). Modern DCCS integrate heterogeneous computing resources, ranging from resource-constrained IoT devices to high-performance cloud infrastructures, and their inherent complexity, mobility, and dynamic operating conditions expose them to frequent faults that disrupt service continuity. These challenges underscore the need for scalable, adaptive, and self-regulated resilience strategies. ReCiSt reconstructs the biological phases of Hemostasis, Inflammation, Proliferation, and Remodeling into the computational layers Containment, Diagnosis, Meta-Cognitive, and Knowledge for DCCS. These four layers perform autonomous fault isolation, causal diagnosis, adaptive recovery, and long-term knowledge consolidation through Language Model (LM)-powered agents. These agents interpret heterogeneous logs, infer root causes, refine reasoning pathways, and reconfigure resources with minimal human intervention. The proposed ReCiSt framework is evaluated on public fault datasets using multiple LMs, and no baseline comparison is included due to the scarcity of similar approaches. Nevertheless, our results, evaluated under different LMs, confirm ReCiSt's self-healing capabilities within tens of seconds with minimum of 10% of agent CPU usage. Our results also demonstrated depth of analysis to over come uncertainties and amount of micro-agents invoked to achieve resilience.",
    "authors": [
      "Alaa Saleh",
      "Praveen Kumar Donta",
      "Roberto Morabito",
      "Sasu Tarkoma",
      "Anders Lindgren",
      "Qiyang Zhang",
      "Schahram Dustdar",
      "Susanna Pirttikangas",
      "Lauri Lovén"
    ],
    "url": "http://arxiv.org/abs/2601.00339v1",
    "published": "2026-01-01",
    "primary_category": "cs.AI",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "本文提出一种受生物启发的自主修复框架，用于提升分布式计算系统的韧性，而非将AI应用于传统科学发现领域。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00921v1",
    "title": "Practical Geometric and Quantum Kernel Methods for Predicting Skeletal Muscle Outcomes in chronic obstructive pulmonary disease",
    "summary": "Skeletal muscle dysfunction is a clinically relevant extra-pulmonary manifestation of chronic obstructive pulmonary disease (COPD) and is closely linked to systemic and airway inflammation. This motivates predictive modelling of muscle outcomes from minimally invasive biomarkers that can be acquired longitudinally. We study a small-sample preclinical dataset comprising 213 animals across two conditions (Sham versus cigarette-smoke exposure), with blood and bronchoalveolar lavage fluid measurements and three continuous targets: tibialis anterior muscle weight (milligram: mg), specific force (millinewton: mN), and a derived muscle quality index (mN per mg). We benchmark tuned classical baselines, geometry-aware symmetric positive definite (SPD) descriptors with Stein divergence, and quantum kernel models designed for low-dimensional tabular data. In the muscle-weight setting, quantum kernel ridge regression using four interpretable inputs (blood C-reactive protein, neutrophil count, bronchoalveolar lavage cellularity, and condition) attains a test root mean squared error of 4.41 mg and coefficient of determination of 0.605, improving over a matched ridge baseline on the same feature set (4.70 mg and 0.553). Geometry-informed Stein-divergence prototype distances yield a smaller but consistent gain in the biomarker-only setting (4.55 mg versus 4.79 mg). Screening-style evaluation, obtained by thresholding the continuous outcome at 0.8 times the training Sham mean, achieves an area under the receiver operating characteristic curve (ROC-AUC) of up to 0.90 for detecting low muscle weight. These results indicate that geometric and quantum kernel lifts can provide measurable benefits in low-data, low-feature biomedical prediction problems, while preserving interpretability and transparent model selection.",
    "authors": [
      "Azadeh Alavi",
      "Hamidreza Khalili",
      "Stanley H. Chan",
      "Fatemeh Kouchmeshki",
      "Ross Vlahos"
    ],
    "url": "http://arxiv.org/abs/2601.00921v1",
    "published": "2026-01-01",
    "primary_category": "cs.LG",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该研究将几何与量子核方法应用于慢性阻塞性肺病动物模型的肌肉功能预测，属于AI在生物医学领域的科学发现应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00335v1",
    "title": "Smart Fault Detection in Nanosatellite Electrical Power System",
    "summary": "This paper presents a new detection method of faults at Nanosatellites' electrical power without an Attitude Determination Control Subsystem (ADCS) at the LEO orbit. Each part of this system is at risk of fault due to pressure tolerance, launcher pressure, and environmental circumstances. Common faults are line to line fault and open circuit for the photovoltaic subsystem, short circuit and open circuit IGBT at DC to DC converter, and regulator fault of the ground battery. The system is simulated without fault based on a neural network using solar radiation and solar panel's surface temperature as input data and current and load as outputs. Finally, using the neural network classifier, different faults are diagnosed by pattern and type of fault. For fault classification, other machine learning methods are also used, such as PCA classification, decision tree, and KNN.",
    "authors": [
      "Alireza Rezaee",
      "Niloofar Nobahari",
      "Amin Asgarifar",
      "Farshid Hajati"
    ],
    "url": "http://arxiv.org/abs/2601.00335v1",
    "published": "2026-01-01",
    "primary_category": "cs.LG",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文使用神经网络和机器学习方法进行纳米卫星电力系统的故障检测与分类，属于AI在航天工程科学领域的应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00329v1",
    "title": "Sparse Probabilistic Coalition Structure Generation: Bayesian Greedy Pursuit and $\\ell_1$ Relaxations",
    "summary": "We study coalition structure generation (CSG) when coalition values are not given but must be learned from episodic observations. We model each episode as a sparse linear regression problem, where the realised payoff \\(Y_t\\) is a noisy linear combination of a small number of coalition contributions. This yields a probabilistic CSG framework in which the planner first estimates a sparse value function from \\(T\\) episodes, then runs a CSG solver on the inferred coalition set. We analyse two estimation schemes. The first, Bayesian Greedy Coalition Pursuit (BGCP), is a greedy procedure that mimics orthogonal matching pursuit. Under a coherence condition and a minimum signal assumption, BGCP recovers the true set of profitable coalitions with high probability once \\(T \\gtrsim K \\log m\\), and hence yields welfare-optimal structures. The second scheme uses an \\(\\ell_1\\)-penalised estimator; under a restricted eigenvalue condition, we derive \\(\\ell_1\\) and prediction error bounds and translate them into welfare gap guarantees. We compare both methods to probabilistic baselines and identify regimes where sparse probabilistic CSG is superior, as well as dense regimes where classical least-squares approaches are competitive.",
    "authors": [
      "Angshul Majumdar"
    ],
    "url": "http://arxiv.org/abs/2601.00329v1",
    "published": "2026-01-01",
    "primary_category": "cs.GT",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种稀疏概率联盟结构生成的贝叶斯贪婪追踪和ℓ₁正则化方法，专注于多智能体系统中的联盟价值学习和优化，而非特定科学领域的发现或细胞/基因扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00327v1",
    "title": "HarmoniAD: Harmonizing Local Structures and Global Semantics for Anomaly Detection",
    "summary": "Anomaly detection is crucial in industrial product quality inspection. Failing to detect tiny defects often leads to serious consequences. Existing methods face a structure-semantics trade-off: structure-oriented models (such as frequency-based filters) are noise-sensitive, while semantics-oriented models (such as CLIP-based encoders) often miss fine details. To address this, we propose HarmoniAD, a frequency-guided dual-branch framework. Features are first extracted by the CLIP image encoder, then transformed into the frequency domain, and finally decoupled into high- and low-frequency paths for complementary modeling of structure and semantics. The high-frequency branch is equipped with a fine-grained structural attention module (FSAM) to enhance textures and edges for detecting small anomalies, while the low-frequency branch uses a global structural context module (GSCM) to capture long-range dependencies and preserve semantic consistency. Together, these branches balance fine detail and global semantics. HarmoniAD further adopts a multi-class joint training strategy, and experiments on MVTec-AD, VisA, and BTAD show state-of-the-art performance with both sensitivity and robustness.",
    "authors": [
      "Naiqi Zhang",
      "Chuancheng Shi",
      "Jingtong Dou",
      "Wenhua Wu",
      "Fei Shen",
      "Jianhua Cao"
    ],
    "url": "http://arxiv.org/abs/2601.00327v1",
    "published": "2026-01-01",
    "primary_category": "cs.CV",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于工业产品缺陷检测的异常检测方法，通过频率引导的双分支框架平衡局部结构和全局语义，不属于AI4Science或扰动预测领域。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00324v1",
    "title": "Multiagent Reinforcement Learning for Liquidity Games",
    "summary": "Making use of swarm methods in financial market modeling of liquidity, and techniques from financial analysis in swarm analysis, holds the potential to advance both research areas. In swarm research, the use of game theory methods holds the promise of explaining observed phenomena of collective utility adherence with rational self-interested swarm participants. In financial markets, a better understanding of how independent financial agents may self-organize for the betterment and stability of the marketplace would be a boon for market design researchers. This paper unifies Liquidity Games, where trader payoffs depend on aggregate liquidity within a trade, with Rational Swarms, where decentralized agents use difference rewards to align self-interested learning with global objectives. We offer a theoretical frameworks where we define a swarm of traders whose collective objective is market liquidity provision while maintaining agent independence. Using difference rewards within a Markov team games framework, we show that individual liquidity-maximizing behaviors contribute to overall market liquidity without requiring coordination or collusion. This Financial Swarm model provides a framework for modeling rational, independent agents where they achieve both individual profitability and collective market efficiency in bilateral asset markets.",
    "authors": [
      "Alicia Vidler",
      "Gal A. Kaminka"
    ],
    "url": "http://arxiv.org/abs/2601.00324v1",
    "published": "2026-01-01",
    "primary_category": "cs.AI",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文将多智能体强化学习应用于金融市场的流动性建模，属于计算金融领域，而非生物学、化学或物理学等自然科学中的科学发现。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00318v1",
    "title": "Quantum King-Ring Domination in Chess: A QAOA Approach",
    "summary": "The Quantum Approximate Optimization Algorithm (QAOA) is extensively benchmarked on synthetic random instances such as MaxCut, TSP, and SAT problems, but these lack semantic structure and human interpretability, offering limited insight into performance on real-world problems with meaningful constraints. We introduce Quantum King-Ring Domination (QKRD), a NISQ-scale benchmark derived from chess tactical positions that provides 5,000 structured instances with one-hot constraints, spatial locality, and 10--40 qubit scale. The benchmark pairs human-interpretable coverage metrics with intrinsic validation against classical heuristics, enabling algorithmic conclusions without external oracles. Using QKRD, we systematically evaluate QAOA design choices and find that constraint-preserving mixers (XY, domain-wall) converge approximately 13 steps faster than standard mixers (p<10^{-7}, d\\approx0.5) while eliminating penalty tuning, warm-start strategies reduce convergence by 45 steps (p<10^{-127}, d=3.35) with energy improvements exceeding d=8, and Conditional Value-at-Risk (CVaR) optimization yields an informative negative result with worse energy (p<10^{-40}, d=1.21) and no coverage benefit. Intrinsic validation shows QAOA outperforms greedy heuristics by 12.6\\% and random selection by 80.1\\%. Our results demonstrate that structured benchmarks reveal advantages of problem-informed QAOA techniques obscured in random instances. We release all code, data, and experimental artifacts for reproducible NISQ algorithm research.",
    "authors": [
      "Gerhard Stenzel",
      "Michael Kölle",
      "Tobias Rohe",
      "Julian Hager",
      "Leo Sünkel",
      "Maximilian Zorn",
      "Claudia Linnhoff-Popien"
    ],
    "url": "http://arxiv.org/abs/2601.00318v1",
    "published": "2026-01-01",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于国际象棋战术位置的量子基准测试QKRD，用于系统评估量子近似优化算法（QAOA）的设计选择，而非将AI应用于自然科学发现或扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00920v1",
    "title": "MODE: Efficient Time Series Prediction with Mamba Enhanced by Low-Rank Neural ODEs",
    "summary": "Time series prediction plays a pivotal role across diverse domains such as finance, healthcare, energy systems, and environmental modeling. However, existing approaches often struggle to balance efficiency, scalability, and accuracy, particularly when handling long-range dependencies and irregularly sampled data. To address these challenges, we propose MODE, a unified framework that integrates Low-Rank Neural Ordinary Differential Equations (Neural ODEs) with an Enhanced Mamba architecture. As illustrated in our framework, the input sequence is first transformed by a Linear Tokenization Layer and then processed through multiple Mamba Encoder blocks, each equipped with an Enhanced Mamba Layer that employs Causal Convolution, SiLU activation, and a Low-Rank Neural ODE enhancement to efficiently capture temporal dynamics. This low-rank formulation reduces computational overhead while maintaining expressive power. Furthermore, a segmented selective scanning mechanism, inspired by pseudo-ODE dynamics, adaptively focuses on salient subsequences to improve scalability and long-range sequence modeling. Extensive experiments on benchmark datasets demonstrate that MODE surpasses existing baselines in both predictive accuracy and computational efficiency. Overall, our contributions include: (1) a unified and efficient architecture for long-term time series modeling, (2) integration of Mamba's selective scanning with low-rank Neural ODEs for enhanced temporal representation, and (3) substantial improvements in efficiency and scalability enabled by low-rank approximation and dynamic selective scanning.",
    "authors": [
      "Xingsheng Chen",
      "Regina Zhang",
      "Bo Gao",
      "Xingwei He",
      "Xiaofeng Liu",
      "Pietro Lio",
      "Kwok-Yan Lam",
      "Siu-Ming Yiu"
    ],
    "url": "http://arxiv.org/abs/2601.00920v1",
    "published": "2026-01-01",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于通用时间序列预测的高效框架，未涉及特定科学领域的发现或细胞/分子层面的扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00309v1",
    "title": "Can Optimal Transport Improve Federated Inverse Reinforcement Learning?",
    "summary": "In robotics and multi-agent systems, fleets of autonomous agents often operate in subtly different environments while pursuing a common high-level objective. Directly pooling their data to learn a shared reward function is typically impractical due to differences in dynamics, privacy constraints, and limited communication bandwidth. This paper introduces an optimal transport-based approach to federated inverse reinforcement learning (IRL). Each client first performs lightweight Maximum Entropy IRL locally, adhering to its computational and privacy limitations. The resulting reward functions are then fused via a Wasserstein barycenter, which considers their underlying geometric structure. We further prove that this barycentric fusion yields a more faithful global reward estimate than conventional parameter averaging methods in federated learning. Overall, this work provides a principled and communication-efficient framework for deriving a shared reward that generalizes across heterogeneous agents and environments.",
    "authors": [
      "David Millard",
      "Ali Baheri"
    ],
    "url": "http://arxiv.org/abs/2601.00309v1",
    "published": "2026-01-01",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于最优传输的联邦逆强化学习方法，用于在异构机器人/多智能体系统中学习共享奖励函数，而非应用于自然科学发现或细胞/分子扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00307v1",
    "title": "VisNet: Efficient Person Re-Identification via Alpha-Divergence Loss, Feature Fusion and Dynamic Multi-Task Learning",
    "summary": "Person re-identification (ReID) is an extremely important area in both surveillance and mobile applications, requiring strong accuracy with minimal computational cost. State-of-the-art methods give good accuracy but with high computational budgets. To remedy this, this paper proposes VisNet, a computationally efficient and effective re-identification model suitable for real-world scenarios. It is the culmination of conceptual contributions, including feature fusion at multiple scales with automatic attention on each, semantic clustering with anatomical body partitioning, a dynamic weight averaging technique to balance classification semantic regularization, and the use of loss function FIDI for improved metric learning tasks. The multiple scales fuse ResNet50's stages 1 through 4 without the use of parallel paths, with semantic clustering introducing spatial constraints through the use of rule-based pseudo-labeling. VisNet achieves 87.05% Rank-1 and 77.65% mAP on the Market-1501 dataset, having 32.41M parameters and 4.601 GFLOPs, hence, proposing a practical approach for real-time deployment in surveillance and mobile applications where computational resources are limited.",
    "authors": [
      "Anns Ijaz",
      "Muhammad Azeem Javed"
    ],
    "url": "http://arxiv.org/abs/2601.00307v1",
    "published": "2026-01-01",
    "primary_category": "cs.CV",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种高效的人员重识别模型VisNet，通过特征融合、动态多任务学习和Alpha散度损失函数优化计算机视觉任务，而非应用于生物、化学等科学发现领域或细胞/基因扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00306v1",
    "title": "The Generative AI Paradox: GenAI and the Erosion of Trust, the Corrosion of Information Verification, and the Demise of Truth",
    "summary": "Generative AI (GenAI) now produces text, images, audio, and video that can be perceptually convincing at scale and at negligible marginal cost. While public debate often frames the associated harms as \"deepfakes\" or incremental extensions of misinformation and fraud, this view misses a broader socio-technical shift: GenAI enables synthetic realities; coherent, interactive, and potentially personalized information environments in which content, identity, and social interaction are jointly manufactured and mutually reinforcing. We argue that the most consequential risk is not merely the production of isolated synthetic artifacts, but the progressive erosion of shared epistemic ground and institutional verification practices as synthetic content, synthetic identity, and synthetic interaction become easy to generate and hard to audit. This paper (i) formalizes synthetic reality as a layered stack (content, identity, interaction, institutions), (ii) expands a taxonomy of GenAI harms spanning personal, economic, informational, and socio-technical risks, (iii) articulates the qualitative shifts introduced by GenAI (cost collapse, throughput, customization, micro-segmentation, provenance gaps, and trust erosion), and (iv) synthesizes recent risk realizations (2023-2025) into a compact case bank illustrating how these mechanisms manifest in fraud, elections, harassment, documentation, and supply-chain compromise. We then propose a mitigation stack that treats provenance infrastructure, platform governance, institutional workflow redesign, and public resilience as complementary rather than substitutable, and outline a research agenda focused on measuring epistemic security. We conclude with the Generative AI Paradox: as synthetic media becomes ubiquitous, societies may rationally discount digital evidence altogether.",
    "authors": [
      "Emilio Ferrara"
    ],
    "url": "http://arxiv.org/abs/2601.00306v1",
    "published": "2026-01-01",
    "primary_category": "cs.CY",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文主要探讨生成式AI对社会信任、信息验证和真相认知的侵蚀风险，属于社会科学与伦理研究范畴，而非专注于自然科学发现或分子层面的扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00303v1",
    "title": "DepFlow: Disentangled Speech Generation to Mitigate Semantic Bias in Depression Detection",
    "summary": "Speech is a scalable and non-invasive biomarker for early mental health screening. However, widely used depression datasets like DAIC-WOZ exhibit strong coupling between linguistic sentiment and diagnostic labels, encouraging models to learn semantic shortcuts. As a result, model robustness may be compromised in real-world scenarios, such as Camouflaged Depression, where individuals maintain socially positive or neutral language despite underlying depressive states. To mitigate this semantic bias, we propose DepFlow, a three-stage depression-conditioned text-to-speech framework. First, a Depression Acoustic Encoder learns speaker- and content-invariant depression embeddings through adversarial training, achieving effective disentanglement while preserving depression discriminability (ROC-AUC: 0.693). Second, a flow-matching TTS model with FiLM modulation injects these embeddings into synthesis, enabling control over depressive severity while preserving content and speaker identity. Third, a prototype-based severity mapping mechanism provides smooth and interpretable manipulation across the depression continuum. Using DepFlow, we construct a Camouflage Depression-oriented Augmentation (CDoA) dataset that pairs depressed acoustic patterns with positive/neutral content from a sentiment-stratified text bank, creating acoustic-semantic mismatches underrepresented in natural data. Evaluated across three depression detection architectures, CDoA improves macro-F1 by 9%, 12%, and 5%, respectively, consistently outperforming conventional augmentation strategies in depression Detection. Beyond enhancing robustness, DepFlow provides a controllable synthesis platform for conversational systems and simulation-based evaluation, where real clinical data remains limited by ethical and coverage constraints.",
    "authors": [
      "Yuxin Li",
      "Xiangyu Zhang",
      "Yifei Li",
      "Zhiwei Guo",
      "Haoyang Zhang",
      "Eng Siong Chng",
      "Cuntai Guan"
    ],
    "url": "http://arxiv.org/abs/2601.00303v1",
    "published": "2026-01-01",
    "primary_category": "cs.CL",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于缓解抑郁症检测中语义偏见的语音生成框架，属于心理健康领域的AI应用研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00295v1",
    "title": "Coupled Modal-Nonmodal Interactions Due to Periodic, Infinite Train of Convecting Vortices (TCV)",
    "summary": "Events during transition to turbulence either follow modal or non-modal routes, or combinations of the two. Here, we report a computational investigation of strong freestream excitation caused by a train of convecting vortices. For this TCV excitation, we show a strong interaction of modal and non-modal components causing a spectacular growth of disturbances. We propose this as the mechanism for the severe encounters due to convective vortical disturbances on the underlying shear layer.",
    "authors": [
      "Jyothi Kumar Puttam",
      "Prasannabalaji Sundaram",
      "Vajjala K. Suman",
      "Ankan Sarkar",
      "Tapan K. Sengupta",
      "Tirupathur N. Venkatesh",
      "Rakesh K. Mathpal"
    ],
    "url": "http://arxiv.org/abs/2601.00295v1",
    "published": "2026-01-01",
    "primary_category": "physics.flu-dyn",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文通过计算研究自由流中涡列引起的模态与非模态相互作用机制，揭示了剪切层扰动增长的流体动力学过程。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00290v1",
    "title": "ClinicalReTrial: A Self-Evolving AI Agent for Clinical Trial Protocol Optimization",
    "summary": "Clinical trial failure remains a central bottleneck in drug development, where minor protocol design flaws can irreversibly compromise outcomes despite promising therapeutics. Although cutting-edge AI methods achieve strong performance in predicting trial success, they are inherently reactive for merely diagnosing risk without offering actionable remedies once failure is anticipated. To fill this gap, this paper proposes ClinicalReTrial, a self-evolving AI agent framework that addresses this gap by casting clinical trial reasoning as an iterative protocol redesign problem. Our method integrates failure diagnosis, safety-aware modification, and candidate evaluation in a closed-loop, reward-driven optimization framework. Serving the outcome prediction model as a simulation environment, ClinicalReTrial enables low-cost evaluation of protocol modifications and provides dense reward signals for continuous self-improvement. To support efficient exploration, the framework maintains hierarchical memory that captures iteration-level feedback within trials and distills transferable redesign patterns across trials. Empirically, ClinicalReTrial improves 83.3% of trial protocols with a mean success probability gain of 5.7%, and retrospective case studies demonstrate strong alignment between the discovered redesign strategies and real-world clinical trial modifications.",
    "authors": [
      "Sixue Xing",
      "Xuanye Xia",
      "Kerui Wu",
      "Meng Jiang",
      "Jintai Chen",
      "Tianfan Fu"
    ],
    "url": "http://arxiv.org/abs/2601.00290v1",
    "published": "2026-01-01",
    "primary_category": "cs.AI",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于优化临床试验协议设计的自我进化AI代理框架，属于AI在生物医学科学领域的应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00287v1",
    "title": "Identification and Estimation under Multiple Versions of Treatment: Mixture-of-Experts Approach",
    "summary": "The Stable Unit Treatment Value Assumption (SUTVA) includes the condition that there are no multiple versions of treatment in causal inference. Though we could not control the implementation of treatment in observational studies, multiple versions may exist in the treatment. It has been pointed out that ignoring such multiple versions of treatment can lead to biased estimates of causal effects, but a causal inference framework that explicitly deals with the unbiased identification and estimation of version-specific causal effects has not been fully developed yet. Thus, obtaining a deeper understanding for mechanisms of the complex treatments is difficult. In this paper, we introduce the Mixture-of-Experts framework into causal inference and develop a methodology for estimating the causal effects of latent versions. This approach enables explicit estimation of version-specific causal effects even if the versions are not observed. Numerical experiments demonstrate the effectiveness of the proposed method.",
    "authors": [
      "Kohei Yoshikawa",
      "Shuichi Kawano"
    ],
    "url": "http://arxiv.org/abs/2601.00287v1",
    "published": "2026-01-01",
    "primary_category": "stat.ME",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文将混合专家框架引入因果推断，开发了估计潜在治疗版本因果效应的方法，属于利用人工智能方法解决科学发现问题的研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00286v1",
    "title": "Towards Automated Differential Diagnosis of Skin Diseases Using Deep Learning and Imbalance-Aware Strategies",
    "summary": "As dermatological conditions become increasingly common and the availability of dermatologists remains limited, there is a growing need for intelligent tools to support both patients and clinicians in the timely and accurate diagnosis of skin diseases. In this project, we developed a deep learning based model for the classification and diagnosis of skin conditions. By leveraging pretraining on publicly available skin disease image datasets, our model effectively extracted visual features and accurately classified various dermatological cases. Throughout the project, we refined the model architecture, optimized data preprocessing workflows, and applied targeted data augmentation techniques to improve overall performance. The final model, based on the Swin Transformer, achieved a prediction accuracy of 87.71 percent across eight skin lesion classes on the ISIC2019 dataset. These results demonstrate the model's potential as a diagnostic support tool for clinicians and a self assessment aid for patients.",
    "authors": [
      "Ali Anaissi",
      "Ali Braytee",
      "Weidong Huang",
      "Junaid Akram",
      "Alaa Farhat",
      "Jie Hua"
    ],
    "url": "http://arxiv.org/abs/2601.00286v1",
    "published": "2026-01-01",
    "primary_category": "cs.CV",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文利用深度学习技术开发皮肤疾病自动诊断模型，属于人工智能在医学科学领域的应用研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00284v1",
    "title": "Deep learning estimation of the spectral density of functional time series on large domains",
    "summary": "We derive an estimator of the spectral density of a functional time series that is the output of a multilayer perceptron neural network. The estimator is motivated by difficulties with the computation of existing spectral density estimators for time series of functions defined on very large grids that arise, for example, in climate compute models and medical scans. Existing estimators use autocovariance kernels represented as large $G \\times G$ matrices, where $G$ is the number of grid points on which the functions are evaluated. In many recent applications, functions are defined on 2D and 3D domains, and $G$ can be of the order $G \\sim 10^5$, making the evaluation of the autocovariance kernels computationally intensive or even impossible. We use the theory of spectral functional principal components to derive our deep learning estimator and prove that it is a universal approximator to the spectral density under general assumptions. Our estimator can be trained without computing the autocovariance kernels and it can be parallelized to provide the estimates much faster than existing approaches. We validate its performance by simulations and an application to fMRI images.",
    "authors": [
      "Neda Mohammadi",
      "Soham Sarkar",
      "Piotr Kokoszka"
    ],
    "url": "http://arxiv.org/abs/2601.00284v1",
    "published": "2026-01-01",
    "primary_category": "stat.ME",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出一种基于深度学习的函数时间序列谱密度估计方法，用于处理气候模型和医学影像等科学领域中的大规模网格数据计算问题。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00282v1",
    "title": "Can Large Language Models Still Explain Themselves? Investigating the Impact of Quantization on Self-Explanations",
    "summary": "Quantization is widely used to accelerate inference and streamline the deployment of large language models (LLMs), yet its effects on self-explanations (SEs) remain unexplored. SEs, generated by LLMs to justify their own outputs, require reasoning about the model's own decision-making process, a capability that may exhibit particular sensitivity to quantization. As SEs are increasingly relied upon for transparency in high-stakes applications, understanding whether and to what extent quantization degrades SE quality and faithfulness is critical. To address this gap, we examine two types of SEs: natural language explanations (NLEs) and counterfactual examples, generated by LLMs quantized using three common techniques at distinct bit widths. Our findings indicate that quantization typically leads to moderate declines in both SE quality (up to 4.4\\%) and faithfulness (up to 2.38\\%). The user study further demonstrates that quantization diminishes both the coherence and trustworthiness of SEs (up to 8.5\\%). Compared to smaller models, larger models show limited resilience to quantization in terms of SE quality but better maintain faithfulness. Moreover, no quantization technique consistently excels across task accuracy, SE quality, and faithfulness. Given that quantization's impact varies by context, we recommend validating SE quality for specific use cases, especially for NLEs, which show greater sensitivity. Nonetheless, the relatively minor deterioration in SE quality and faithfulness does not undermine quantization's effectiveness as a model compression technique.",
    "authors": [
      "Qianli Wang",
      "Nils Feldhus",
      "Pepa Atanasova",
      "Fedor Splitt",
      "Simon Ostermann",
      "Sebastian Möller",
      "Vera Schmitt"
    ],
    "url": "http://arxiv.org/abs/2601.00282v1",
    "published": "2026-01-01",
    "primary_category": "cs.CL",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文研究量化技术对大型语言模型自解释能力的影响，属于机器学习模型优化与可解释性交叉领域，而非特定科学发现或生物扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00277v1",
    "title": "Benchmarking Preprocessing and Integration Methods in Single-Cell Genomics",
    "summary": "Single-cell data analysis has the potential to revolutionize personalized medicine by characterizing disease-associated molecular changes at the single-cell level. Advanced single-cell multimodal assays can now simultaneously measure various molecules (e.g., DNA, RNA, Protein) across hundreds of thousands of individual cells, providing a comprehensive molecular readout. A significant analytical challenge is integrating single-cell measurements across different modalities. Various methods have been developed to address this challenge, but there has been no systematic evaluation of these techniques with different preprocessing strategies. This study examines a general pipeline for single-cell data analysis, which includes normalization, data integration, and dimensionality reduction. The performance of different algorithm combinations often depends on the dataset sizes and characteristics. We evaluate six datasets across diverse modalities, tissues, and organisms using three metrics: Silhouette Coefficient Score, Adjusted Rand Index, and Calinski-Harabasz Index. Our experiments involve combinations of seven normalization methods, four dimensional reduction methods, and five integration methods. The results show that Seurat and Harmony excel in data integration, with Harmony being more time-efficient, especially for large datasets. UMAP is the most compatible dimensionality reduction method with the integration techniques, and the choice of normalization method varies depending on the integration method used.",
    "authors": [
      "Ali Anaissi",
      "Seid Miad Zandavi",
      "Weidong Huang",
      "Junaid Akram",
      "Basem Suleiman",
      "Ali Braytee",
      "Jie Hua"
    ],
    "url": "http://arxiv.org/abs/2601.00277v1",
    "published": "2026-01-01",
    "primary_category": "q-bio.QM",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文通过系统评估单细胞多模态数据预处理与整合算法，为生物医学研究提供了优化的计算分析流程。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00276v1",
    "title": "Task-Driven Kernel Flows: Label Rank Compression and Laplacian Spectral Filtering",
    "summary": "We present a theory of feature learning in wide L2-regularized networks showing that supervised learning is inherently compressive. We derive a kernel ODE that predicts a \"water-filling\" spectral evolution and prove that for any stable steady state, the kernel rank is bounded by the number of classes ($C$). We further demonstrate that SGD noise is similarly low-rank ($O(C)$), confining dynamics to the task-relevant subspace. This framework unifies the deterministic and stochastic views of alignment and contrasts the low-rank nature of supervised learning with the high-rank, expansive representations of self-supervision.",
    "authors": [
      "Hongxi Li",
      "Chunlin Huang"
    ],
    "url": "http://arxiv.org/abs/2601.00276v1",
    "published": "2026-01-01",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文研究监督学习中神经网络的特征学习理论，推导核ODE并证明核秩受类别数限制，属于机器学习理论范畴而非具体科学领域的AI应用或细胞扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00271v1",
    "title": "Vehicle Painting Robot Path Planning Using Hierarchical Optimization",
    "summary": "In vehicle production factories, the vehicle painting process employs multiple robotic arms to simultaneously apply paint to car bodies advancing along a conveyor line. Designing paint paths for these robotic arms, which involves assigning car body areas to arms and determining paint sequences for each arm, remains a time-consuming manual task for engineers, indicating the demand for automation and design time reduction. The unique constraints of the painting process hinder the direct application of conventional robotic path planning techniques, such as those used in welding. Therefore, this paper formulates the design of paint paths as a hierarchical optimization problem, where the upper-layer subproblem resembles a vehicle routing problem (VRP), and the lower-layer subproblem involves detailed path planning. This approach allows the use of different optimization algorithms at each layer, and permits flexible handling of constraints specific to the vehicle painting process through the design of variable representation, constraints, repair operators, and an initialization process at the upper and lower layers. Experiments with three commercially available vehicle models demonstrated that the proposed method can automatically design paths that satisfy all constraints for vehicle painting with quality comparable to those created manually by engineers.",
    "authors": [
      "Yuya Nagai",
      "Hiromitsu Nakamura",
      "Narito Shinmachi",
      "Yuta Higashizono",
      "Satoshi Ono"
    ],
    "url": "http://arxiv.org/abs/2601.00271v1",
    "published": "2026-01-01",
    "primary_category": "cs.RO",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于车辆喷涂机器人路径规划的层次优化方法，属于工业自动化领域的应用研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00270v1",
    "title": "Rectifying Adversarial Examples Using Their Vulnerabilities",
    "summary": "Deep neural network-based classifiers are prone to errors when processing adversarial examples (AEs). AEs are minimally perturbed input data undetectable to humans posing significant risks to security-dependent applications. Hence, extensive research has been undertaken to develop defense mechanisms that mitigate their threats. Most existing methods primarily focus on discriminating AEs based on the input sample features, emphasizing AE detection without addressing the correct sample categorization before an attack. While some tasks may only require mere rejection on detected AEs, others necessitate identifying the correct original input category such as traffic sign recognition in autonomous driving. The objective of this study is to propose a method for rectifying AEs to estimate the correct labels of their original inputs. Our method is based on re-attacking AEs to move them beyond the decision boundary for accurate label prediction, effectively addressing the issue of rectifying minimally perceptible AEs created using white-box attack methods. However, challenge remains with respect to effectively rectifying AEs produced by black-box attacks at a distance from the boundary, or those misclassified into low-confidence categories by targeted attacks. By adopting a straightforward approach of only considering AEs as inputs, the proposed method can address diverse attacks while avoiding the requirement of parameter adjustments or preliminary training. Results demonstrate that the proposed method exhibits consistent performance in rectifying AEs generated via various attack methods, including targeted and black-box attacks. Moreover, it outperforms conventional rectification and input transformation methods in terms of stability against various attacks.",
    "authors": [
      "Fumiya Morimoto",
      "Ryuto Morita",
      "Satoshi Ono"
    ],
    "url": "http://arxiv.org/abs/2601.00270v1",
    "published": "2026-01-01",
    "primary_category": "cs.CR",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于开发对抗性样本的防御机制，通过重新攻击这些样本来修正其分类，属于机器学习安全领域，而非科学发现或生物医学扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00269v1",
    "title": "FaithSCAN: Model-Driven Single-Pass Hallucination Detection for Faithful Visual Question Answering",
    "summary": "Faithfulness hallucinations in VQA occur when vision-language models produce fluent yet visually ungrounded answers, severely undermining their reliability in safety-critical applications. Existing detection methods mainly fall into two categories: external verification approaches relying on auxiliary models or knowledge bases, and uncertainty-driven approaches using repeated sampling or uncertainty estimates. The former suffer from high computational overhead and are limited by external resource quality, while the latter capture only limited facets of model uncertainty and fail to sufficiently explore the rich internal signals associated with the diverse failure modes. Both paradigms thus have inherent limitations in efficiency, robustness, and detection performance. To address these challenges, we propose FaithSCAN: a lightweight network that detects hallucinations by exploiting rich internal signals of VLMs, including token-level decoding uncertainty, intermediate visual representations, and cross-modal alignment features. These signals are fused via branch-wise evidence encoding and uncertainty-aware attention. We also extend the LLM-as-a-Judge paradigm to VQA hallucination and propose a low-cost strategy to automatically generate model-dependent supervision signals, enabling supervised training without costly human labels while maintaining high detection accuracy. Experiments on multiple VQA benchmarks show that FaithSCAN significantly outperforms existing methods in both effectiveness and efficiency. In-depth analysis shows hallucinations arise from systematic internal state variations in visual perception, cross-modal reasoning, and language decoding. Different internal signals provide complementary diagnostic cues, and hallucination patterns vary across VLM architectures, offering new insights into the underlying causes of multimodal hallucinations.",
    "authors": [
      "Chaodong Tong",
      "Qi Zhang",
      "Chen Li",
      "Lei Jiang",
      "Yanbing Liu"
    ],
    "url": "http://arxiv.org/abs/2601.00269v1",
    "published": "2026-01-01",
    "primary_category": "cs.CV",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于开发检测视觉问答中幻觉的模型驱动方法，属于计算机视觉与自然语言处理的交叉领域，而非科学发现或生物扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00268v1",
    "title": "Beyond Perfect APIs: A Comprehensive Evaluation of LLM Agents Under Real-World API Complexity",
    "summary": "We introduce WildAGTEval, a benchmark designed to evaluate large language model (LLM) agents' function-calling capabilities under realistic API complexity. Unlike prior work that assumes an idealized API system and disregards real-world factors such as noisy API outputs, WildAGTEval accounts for two dimensions of real-world complexity: 1. API specification, which includes detailed documentation and usage constraints, and 2. API execution, which captures runtime challenges. Consequently, WildAGTEval offers (i) an API system encompassing 60 distinct complexity scenarios that can be composed into approximately 32K test configurations, and (ii) user-agent interactions for evaluating LLM agents on these scenarios. Using WildAGTEval, we systematically assess several advanced LLMs and observe that most scenarios are challenging, with irrelevant information complexity posing the greatest difficulty and reducing the performance of strong LLMs by 27.3%. Furthermore, our qualitative analysis reveals that LLMs occasionally distort user intent merely to claim task completion, critically affecting user satisfaction.",
    "authors": [
      "Doyoung Kim",
      "Zhiwei Ren",
      "Jie Hao",
      "Zhongkai Sun",
      "Lichao Wang",
      "Xiyao Ma",
      "Zack Ye",
      "Xu Han",
      "Jun Yin",
      "Heng Ji",
      "Wei Shen",
      "Xing Fan",
      "Benjamin Yao",
      "Chenlei Guo"
    ],
    "url": "http://arxiv.org/abs/2601.00268v1",
    "published": "2026-01-01",
    "primary_category": "cs.CL",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于评估LLM代理在真实API环境中的功能调用能力，属于AI系统评估领域，而非科学发现或生物医学扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00265v1",
    "title": "Designing Information Delays in Supply Chains",
    "summary": "This paper studies how a downstream retailer in a decentralized two-tier supply chain can implicitly transmit demand information to an upstream supplier through the structure of its order stream in the absence of an explicit information-sharing mechanism. We distinguish our work from prior work by introducing the notion of information delay and by linking optimal implicit information sharing to the group delay of the retailer's ordering transfer function. We show that pure delay is strictly suboptimal, while fractional-delay mechanisms can reshape the order autocorrelation to improve supplier forecastability and reduce system-wide inventory costs. Using Hardy-space factorization, we develop a tractable family of invertible ARMA policies that approximates the theoretically optimal (but non-rational) limiting filter derived by Caldentey et al. (2025) and preserves its informational delay properties. This construction yields sharp guidance on how policy complexity, as measured by the degrees of the ARMA policies, impacts supply chain costs. We further extend the analysis to memory-constrained suppliers and characterize how the complexity of the retailer's policy should scale with the supplier's finite forecasting window, highlighting when, perhaps counterintuitively, increasing policy complexity can become counterproductive.",
    "authors": [
      "Prem Talwai",
      "Rene Caldentey",
      "Avi Giloni",
      "Clifford Hurvich",
      "David Simchi-Levi",
      "Yichen Zhang"
    ],
    "url": "http://arxiv.org/abs/2601.00265v1",
    "published": "2026-01-01",
    "primary_category": "math.OC",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文研究供应链中零售商通过订单流结构隐式传递需求信息给供应商的优化策略，属于运筹学和管理科学领域。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00263v1",
    "title": "Parallel Universes, Parallel Languages: A Comprehensive Study on LLM-based Multilingual Counterfactual Example Generation",
    "summary": "Counterfactuals refer to minimally edited inputs that cause a model's prediction to change, serving as a promising approach to explaining the model's behavior. Large language models (LLMs) excel at generating English counterfactuals and demonstrate multilingual proficiency. However, their effectiveness in generating multilingual counterfactuals remains unclear. To this end, we conduct a comprehensive study on multilingual counterfactuals. We first conduct automatic evaluations on both directly generated counterfactuals in the target languages and those derived via English translation across six languages. Although translation-based counterfactuals offer higher validity than their directly generated counterparts, they demand substantially more modifications and still fall short of matching the quality of the original English counterfactuals. Second, we find the patterns of edits applied to high-resource European-language counterfactuals to be remarkably similar, suggesting that cross-lingual perturbations follow common strategic principles. Third, we identify and categorize four main types of errors that consistently appear in the generated counterfactuals across languages. Finally, we reveal that multilingual counterfactual data augmentation (CDA) yields larger model performance improvements than cross-lingual CDA, especially for lower-resource languages. Yet, the imperfections of the generated counterfactuals limit gains in model performance and robustness.",
    "authors": [
      "Qianli Wang",
      "Van Bach Nguyen",
      "Yihong Liu",
      "Fedor Splitt",
      "Nils Feldhus",
      "Christin Seifert",
      "Hinrich Schütze",
      "Sebastian Möller",
      "Vera Schmitt"
    ],
    "url": "http://arxiv.org/abs/2601.00263v1",
    "published": "2026-01-01",
    "primary_category": "cs.CL",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文研究多语言反事实示例生成对大型语言模型行为解释的影响，属于自然语言处理领域的方法论研究，而非特定科学发现或生物分子扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00919v1",
    "title": "Attention Needs to Focus: A Unified Perspective on Attention Allocation",
    "summary": "The Transformer architecture, a cornerstone of modern Large Language Models (LLMs), has achieved extraordinary success in sequence modeling, primarily due to its attention mechanism. However, despite its power, the standard attention mechanism is plagued by well-documented issues: representational collapse and attention sink. Although prior work has proposed approaches for these issues, they are often studied in isolation, obscuring their deeper connection. In this paper, we present a unified perspective, arguing that both can be traced to a common root -- improper attention allocation. We identify two failure modes: 1) Attention Overload, where tokens receive comparable high weights, blurring semantic features that lead to representational collapse; 2) Attention Underload, where no token is semantically relevant, yet attention is still forced to distribute, resulting in spurious focus such as attention sink. Building on this insight, we introduce Lazy Attention, a novel mechanism designed for a more focused attention distribution. To mitigate overload, it employs positional discrimination across both heads and dimensions to sharpen token distinctions. To counteract underload, it incorporates Elastic-Softmax, a modified normalization function that relaxes the standard softmax constraint to suppress attention on irrelevant tokens. Experiments on the FineWeb-Edu corpus, evaluated across nine diverse benchmarks, demonstrate that Lazy Attention successfully mitigates attention sink and achieves competitive performance compared to both standard attention and modern architectures, while reaching up to 59.58% attention sparsity.",
    "authors": [
      "Zichuan Fu",
      "Wentao Song",
      "Guojing Li",
      "Yejing Wang",
      "Xian Wu",
      "Yimin Deng",
      "Hanyu Yan",
      "Yefeng Zheng",
      "Xiangyu Zhao"
    ],
    "url": "http://arxiv.org/abs/2601.00919v1",
    "published": "2026-01-01",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种改进Transformer注意力机制的新方法，专注于解决注意力分配问题，属于基础模型架构研究，而非特定科学领域的AI应用或扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00257v1",
    "title": "Next Generation Intelligent Low-Altitude Economy Deployments: The O-RAN Perspective",
    "summary": "Despite the growing interest in low-altitude economy (LAE) applications, including UAV-based logistics and emergency response, fundamental challenges remain in orchestrating such missions over complex, signal-constrained environments. These include the absence of real-time, resilient, and context-aware orchestration of aerial nodes with limited integration of artificial intelligence (AI) specialized for LAE missions. This paper introduces an open radio access network (O-RAN)-enabled LAE framework that leverages seamless coordination between the disaggregated RAN architecture, open interfaces, and RAN intelligent controllers (RICs) to facilitate closed-loop, AI-optimized, and mission-critical LAE operations. We evaluate the feasibility and performance of the proposed architecture via a semantic-aware rApp that acts as a terrain interpreter, offering semantic guidance to a reinforcement learning-enabled xApp, which performs real-time trajectory planning for LAE swarm nodes. We survey the capabilities of UAV testbeds that can be leveraged for LAE research, and present critical research challenges and standardization needs.",
    "authors": [
      "Aly Sabri Abdalla",
      "Vuk Marojevic"
    ],
    "url": "http://arxiv.org/abs/2601.00257v1",
    "published": "2026-01-01",
    "primary_category": "eess.SY",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出基于O-RAN架构的智能低空经济部署框架，利用AI优化无人机集群的实时轨迹规划，属于通信工程与人工智能交叉领域，而非基础科学发现或细胞扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00254v1",
    "title": "An Empirical Evaluation of LLM-Based Approaches for Code Vulnerability Detection: RAG, SFT, and Dual-Agent Systems",
    "summary": "The rapid advancement of Large Language Models (LLMs) presents new opportunities for automated software vulnerability detection, a crucial task in securing modern codebases. This paper presents a comparative study on the effectiveness of LLM-based techniques for detecting software vulnerabilities. The study evaluates three approaches, Retrieval-Augmented Generation (RAG), Supervised Fine-Tuning (SFT), and a Dual-Agent LLM framework, against a baseline LLM model. A curated dataset was compiled from Big-Vul and real-world code repositories from GitHub, focusing on five critical Common Weakness Enumeration (CWE) categories: CWE-119, CWE-399, CWE-264, CWE-20, and CWE-200. Our RAG approach, which integrated external domain knowledge from the internet and the MITRE CWE database, achieved the highest overall accuracy (0.86) and F1 score (0.85), highlighting the value of contextual augmentation. Our SFT approach, implemented using parameter-efficient QLoRA adapters, also demonstrated strong performance. Our Dual-Agent system, an architecture in which a secondary agent audits and refines the output of the first, showed promise in improving reasoning transparency and error mitigation, with reduced resource overhead. These results emphasize that incorporating a domain expertise mechanism significantly strengthens the practical applicability of LLMs in real-world vulnerability detection tasks.",
    "authors": [
      "Md Hasan Saju",
      "Maher Muhtadi",
      "Akramul Azim"
    ],
    "url": "http://arxiv.org/abs/2601.00254v1",
    "published": "2026-01-01",
    "primary_category": "cs.SE",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于评估大型语言模型在软件漏洞检测中的技术方法，属于计算机安全领域而非传统科学发现或生物医学扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00245v1",
    "title": "Modern Neuromorphic AI: From Intra-Token to Inter-Token Processing",
    "summary": "The rapid growth of artificial intelligence (AI) has brought novel data processing and generative capabilities but also escalating energy requirements. This challenge motivates renewed interest in neuromorphic computing principles, which promise brain-like efficiency through discrete and sparse activations, recurrent dynamics, and non-linear feedback. In fact, modern AI architectures increasingly embody neuromorphic principles through heavily quantized activations, state-space dynamics, and sparse attention mechanisms. This paper elaborates on the connections between neuromorphic models, state-space models, and transformer architectures through the lens of the distinction between intra-token processing and inter-token processing. Most early work on neuromorphic AI was based on spiking neural networks (SNNs) for intra-token processing, i.e., for transformations involving multiple channels, or features, of the same vector input, such as the pixels of an image. In contrast, more recent research has explored how neuromorphic principles can be leveraged to design efficient inter-token processing methods, which selectively combine different information elements depending on their contextual relevance. Implementing associative memorization mechanisms, these approaches leverage state-space dynamics or sparse self-attention. Along with a systematic presentation of modern neuromorphic AI models through the lens of intra-token and inter-token processing, training methodologies for neuromorphic AI models are also reviewed. These range from surrogate gradients leveraging parallel convolutional processing to local learning rules based on reinforcement learning mechanisms.",
    "authors": [
      "Osvaldo Simeone"
    ],
    "url": "http://arxiv.org/abs/2601.00245v1",
    "published": "2026-01-01",
    "primary_category": "cs.NE",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文综述了神经形态计算在AI模型设计中的应用，聚焦于计算效率提升而非特定科学领域的发现。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00242v1",
    "title": "Neural Minimum Weight Perfect Matching for Quantum Error Codes",
    "summary": "Realizing the full potential of quantum computation requires Quantum Error Correction (QEC). QEC reduces error rates by encoding logical information across redundant physical qubits, enabling errors to be detected and corrected. A common decoder used for this task is Minimum Weight Perfect Matching (MWPM) a graph-based algorithm that relies on edge weights to identify the most likely error chains. In this work, we propose a data-driven decoder named Neural Minimum Weight Perfect Matching (NMWPM). Our decoder utilizes a hybrid architecture that integrates Graph Neural Networks (GNNs) to extract local syndrome features and Transformers to capture long-range global dependencies, which are then used to predict dynamic edge weights for the MWPM decoder. To facilitate training through the non-differentiable MWPM algorithm, we formulate a novel proxy loss function that enables end-to-end optimization. Our findings demonstrate significant performance reduction in the Logical Error Rate (LER) over standard baselines, highlighting the advantage of hybrid decoders that combine the predictive capabilities of neural networks with the algorithmic structure of classical matching.",
    "authors": [
      "Yotam Peled",
      "David Zenati",
      "Eliya Nachmani"
    ],
    "url": "http://arxiv.org/abs/2601.00242v1",
    "published": "2026-01-01",
    "primary_category": "quant-ph",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种结合图神经网络和Transformer的混合解码器，用于量子纠错码中的最小权重完美匹配，属于AI在物理科学领域的应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00240v1",
    "title": "Will LLM-powered Agents Bias Against Humans? Exploring the Belief-Dependent Vulnerability",
    "summary": "LLM-empowered agents can exhibit not only demographic bias (e.g., gender, religion) but also intergroup bias triggered by minimal \"us\" versus \"them\" cues. When this intergroup boundary aligns with an agent-human divide, the risk shifts from disparities among human demographic groups to a more fundamental group-level asymmetry, i.e., humans as a whole may be treated as the outgroup by agents. To examine this possibility, we construct a controlled multi-agent social simulation based on allocation decisions under explicit payoff trade-offs and find that agents exhibit a consistent intergroup bias under minimal group cues. Although this bias is attenuated when some counterparts are framed as humans, we attribute the attenuation to an implicit human-norm script that favors humans yet activates only when the agent believes a real human is present. This belief dependence creates a new attack surface. We therefore introduce a Belief Poisoning Attack (BPA) that corrupts persistent identity beliefs to suppress the human-norm script and reactivate outgroup bias toward humans, instantiated as profile poisoning at initialization (BPA-PP) and memory poisoning via optimized belief-refinement suffixes injected into stored reflections (BPA-MP). Finally, we discuss practical mitigation strategies for hardening current agent frameworks against BPA, highlighting feasible interventions at profile and memory boundaries. Extensive experiments demonstrate both the existence of agent intergroup bias and the severity of BPA across settings. Our goal in identifying these vulnerabilities is to inform safer agent design, not to enable real-world exploitation.",
    "authors": [
      "Zongwei Wang",
      "Bincheng Gu",
      "Hongyu Yu",
      "Junliang Yu",
      "Tao He",
      "Jiayin Feng",
      "Min Gao"
    ],
    "url": "http://arxiv.org/abs/2601.00240v1",
    "published": "2026-01-01",
    "primary_category": "cs.AI",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文研究LLM智能体在群体划分情境下对人类产生的偏见及其安全漏洞，属于人工智能安全与伦理领域，而非AI4Science或细胞扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00237v1",
    "title": "Application Research of a Deep Learning Model Integrating CycleGAN and YOLO in PCB Infrared Defect Detection",
    "summary": "This paper addresses the critical bottleneck of infrared (IR) data scarcity in Printed Circuit Board (PCB) defect detection by proposing a cross-modal data augmentation framework integrating CycleGAN and YOLOv8. Unlike conventional methods relying on paired supervision, we leverage CycleGAN to perform unpaired image-to-image translation, mapping abundant visible-light PCB images into the infrared domain. This generative process synthesizes high-fidelity pseudo-IR samples that preserve the structural semantics of defects while accurately simulating thermal distribution patterns. Subsequently, we construct a heterogeneous training strategy that fuses generated pseudo-IR data with limited real IR samples to train a lightweight YOLOv8 detector. Experimental results demonstrate that this method effectively enhances feature learning under low-data conditions. The augmented detector significantly outperforms models trained on limited real data alone and approaches the performance benchmarks of fully supervised training, proving the efficacy of pseudo-IR synthesis as a robust augmentation strategy for industrial inspection.",
    "authors": [
      "Chao Yang",
      "Haoyuan Zheng",
      "Yue Ma"
    ],
    "url": "http://arxiv.org/abs/2601.00237v1",
    "published": "2026-01-01",
    "primary_category": "cs.CV",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于工业检测中的PCB缺陷识别，通过CycleGAN生成伪红外图像增强YOLOv8检测器性能，属于工程应用而非基础科学发现或生物医学扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00231v1",
    "title": "GRIT -- Geometry-Aware PEFT with K-FACPreconditioning, Fisher-Guided Reprojection, andDynamic Rank Adaptation",
    "summary": "Parameter-efficient fine-tuning (PEFT) is the default way to adapt LLMs, but widely used LoRA and QLoRA are largely geometry-agnostic: they optimize in fixed, randomly oriented low-rank subspaces with first-order descent, mostly ignoring local loss curvature. This can inflate the effective update budget and amplify drift along weakly constrained directions. We introduce GRIT, a dynamic, curvature-aware LoRA procedure that preserves the LoRA parameterization but: (1) preconditions gradients in rank space using K-FAC as a natural-gradient proxy; (2) periodically reprojects the low-rank basis onto dominant Fisher eigendirections to suppress drift; and (3) adapts the effective rank from the spectrum so capacity concentrates where signal resides. Across instruction-following, comprehension, and reasoning benchmarks on LLaMA backbones, GRIT matches or surpasses LoRA and QLoRA while reducing trainable parameters by 46% on average (25--80% across tasks), without practical quality loss across prompt styles and data mixes. To model forgetting, we fit a curvature-modulated power law. Empirically, GRIT yields lower drift and a better updates-vs-retention frontier than strong PEFT-optimizer baselines (Orthogonal-LoRA, IA3, DoRA, Eff-FT, Shampoo).",
    "authors": [
      "Pritish Saha",
      "Chandrav Rajbangshi",
      "Rudra Goyal",
      "Mohit Goyal",
      "Anurag Deo",
      "Biswajit Roy",
      "Ningthoujam Dhanachandra Singh",
      "Raxit Goswami",
      "Amitava Das"
    ],
    "url": "http://arxiv.org/abs/2601.00231v1",
    "published": "2026-01-01",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种动态、曲率感知的参数高效微调方法GRIT，通过K-FAC预条件、Fisher引导重投影和动态秩适应来改进LLM微调，属于机器学习优化方法研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00229v1",
    "title": "Robust Graph Fine-Tuning with Adversarial Graph Prompting",
    "summary": "Parameter-Efficient Fine-Tuning (PEFT) method has emerged as a dominant paradigm for adapting pre-trained GNN models to downstream tasks. However, existing PEFT methods usually exhibit significant vulnerability to various noise and attacks on graph topology and node attributes/features. To address this issue, for the first time, we propose integrating adversarial learning into graph prompting and develop a novel Adversarial Graph Prompting (AGP) framework to achieve robust graph fine-tuning. Our AGP has two key aspects. First, we propose the general problem formulation of AGP as a min-max optimization problem and develop an alternating optimization scheme to solve it. For inner maximization, we propose Joint Projected Gradient Descent (JointPGD) algorithm to generate strong adversarial noise. For outer minimization, we employ a simple yet effective module to learn the optimal node prompts to counteract the adversarial noise. Second, we demonstrate that the proposed AGP can theoretically address both graph topology and node noise. This confirms the versatility and robustness of our AGP fine-tuning method across various graph noise. Note that, the proposed AGP is a general method that can be integrated with various pre-trained GNN models to enhance their robustness on the downstream tasks. Extensive experiments on multiple benchmark tasks validate the robustness and effectiveness of AGP method compared to state-of-the-art methods.",
    "authors": [
      "Ziyan Zhang",
      "Bo Jiang",
      "Jin Tang"
    ],
    "url": "http://arxiv.org/abs/2601.00229v1",
    "published": "2026-01-01",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种增强图神经网络鲁棒性的对抗性图提示微调方法，属于机器学习方法学改进而非特定科学领域的AI应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00227v1",
    "title": "FlashInfer-Bench: Building the Virtuous Cycle for AI-driven LLM Systems",
    "summary": "Recent advances show that large language models (LLMs) can act as autonomous agents capable of generating GPU kernels, but integrating these AI-generated kernels into real-world inference systems remains challenging. FlashInfer-Bench addresses this gap by establishing a standardized, closed-loop framework that connects kernel generation, benchmarking, and deployment. At its core, FlashInfer Trace provides a unified schema describing kernel definitions, workloads, implementations, and evaluations, enabling consistent communication between agents and systems. Built on real serving traces, FlashInfer-Bench includes a curated dataset, a robust correctness- and performance-aware benchmarking framework, a public leaderboard to track LLM agents' GPU programming capabilities, and a dynamic substitution mechanism (apply()) that seamlessly injects the best-performing kernels into production LLM engines such as SGLang and vLLM. Using FlashInfer-Bench, we further evaluate the performance and limitations of LLM agents, compare the trade-offs among different GPU programming languages, and provide insights for future agent design. FlashInfer-Bench thus establishes a practical, reproducible pathway for continuously improving AI-generated kernels and deploying them into large-scale LLM inference.",
    "authors": [
      "Shanli Xing",
      "Yiyan Zhai",
      "Alexander Jiang",
      "Yixin Dong",
      "Yong Wu",
      "Zihao Ye",
      "Charlie Ruan",
      "Yingyi Huang",
      "Yineng Zhang",
      "Liangsheng Yin",
      "Aksara Bayyapu",
      "Luis Ceze",
      "Tianqi Chen"
    ],
    "url": "http://arxiv.org/abs/2601.00227v1",
    "published": "2026-01-01",
    "primary_category": "cs.AI",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于构建AI驱动的LLM系统优化框架，通过标准化闭环流程提升GPU内核生成与部署效率，而非应用于传统科学发现领域。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00223v1",
    "title": "JP-TL-Bench: Anchored Pairwise LLM Evaluation for Bidirectional Japanese-English Translation",
    "summary": "We introduce JP-TL-Bench, a lightweight, open benchmark designed to guide the iterative development of Japanese-English translation systems. In this context, the challenge is often \"which of these two good translations is better?\" rather than \"is this translation acceptable?\" This distinction matters for Japanese-English, where subtle choices in politeness, implicature, ellipsis, and register strongly affect perceived naturalness. JP-TL-Bench uses a protocol built to make LLM judging both reliable and affordable: it evaluates a candidate model via reference-free, pairwise LLM comparisons against a fixed, versioned anchor set. Pairwise results are aggregated with a Bradley-Terry model and reported as win rates plus a normalized 0-10 \"LT\" score derived from a logistic transform of fitted log-strengths. Because each candidate is scored against the same frozen anchor set, scores are structurally stable given the same base set, judge, and aggregation code.",
    "authors": [
      "Leonard Lin",
      "Adam Lensenmayer"
    ],
    "url": "http://arxiv.org/abs/2601.00223v1",
    "published": "2026-01-01",
    "primary_category": "cs.CL",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文介绍了一个用于评估日语-英语双向翻译系统性能的基准测试工具，属于自然语言处理领域，而非科学发现或生物医学扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00221v1",
    "title": "Impact of Clustering on the Observability and Controllability of Complex Networks",
    "summary": "The increasing complexity and interconnectedness of systems across various fields have led to a growing interest in studying complex networks, particularly Scale-Free (SF) networks, which best model real-world systems. This paper investigates the influence of clustering on the observability and controllability of complex SF networks, framing these characteristics in the context of structured systems theory. In this paper, we show that densely clustered networks require fewer driver and observer nodes due to better information propagation within clusters. This relationship is of interest for optimizing network design in applications such as social networks and intelligent transportation systems. We first quantify the network observability/controllability requirements, and then, through Monte-Carlo simulations and different case studies, we show how clustering affects these metrics. Our findings offer practical insights into reducing control and observer nodes for sensor/actuator placement, particularly in resource-constrained setups. This work contributes to the understanding of network observability/controllability and presents techniques for improving these features through alterations in network structure and clustering.",
    "authors": [
      "Mohammadreza Doostmohammadian",
      "Hamid R. Rabiee"
    ],
    "url": "http://arxiv.org/abs/2601.00221v1",
    "published": "2026-01-01",
    "primary_category": "eess.SY",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文研究复杂网络的结构特性（聚类）对可观测性和可控性的影响，属于网络科学和系统理论领域，不涉及使用AI进行科学发现或分子层面的扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00218v1",
    "title": "Unknown Aware AI-Generated Content Attribution",
    "summary": "The rapid advancement of photorealistic generative models has made it increasingly important to attribute the origin of synthetic content, moving beyond binary real or fake detection toward identifying the specific model that produced a given image. We study the problem of distinguishing outputs from a target generative model (e.g., OpenAI Dalle 3) from other sources, including real images and images generated by a wide range of alternative models. Using CLIP features and a simple linear classifier, shown to be effective in prior work, we establish a strong baseline for target generator attribution using only limited labeled data from the target model and a small number of known generators. However, this baseline struggles to generalize to harder, unseen, and newly released generators. To address this limitation, we propose a constrained optimization approach that leverages unlabeled wild data, consisting of images collected from the Internet that may include real images, outputs from unknown generators, or even samples from the target model itself. The proposed method encourages wild samples to be classified as non target while explicitly constraining performance on labeled data to remain high. Experimental results show that incorporating wild data substantially improves attribution performance on challenging unseen generators, demonstrating that unlabeled data from the wild can be effectively exploited to enhance AI generated content attribution in open world settings.",
    "authors": [
      "Ellie Thieu",
      "Jifan Zhang",
      "Haoyue Bai"
    ],
    "url": "http://arxiv.org/abs/2601.00218v1",
    "published": "2026-01-01",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种利用未标记网络数据增强AI生成内容溯源的方法，属于计算机视觉与机器学习领域，而非科学发现或生物医学扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00217v1",
    "title": "Latent Flow Matching for Expressive Singing Voice Synthesis",
    "summary": "Conditional variational autoencoder (cVAE)-based singing voice synthesis provides efficient inference and strong audio quality by learning a score-conditioned prior and a recording-conditioned posterior latent space. However, because synthesis relies on prior samples while training uses posterior latents inferred from real recordings, imperfect distribution matching can cause a prior-posterior mismatch that degrades fine-grained expressiveness such as vibrato and micro-prosody. We propose FM-Singer, which introduces conditional flow matching (CFM) in latent space to learn a continuous vector field transporting prior latents toward posterior latents along an optimal-transport-inspired path. At inference time, the learned latent flow refines a prior sample by solving an ordinary differential equation (ODE) before waveform generation, improving expressiveness while preserving the efficiency of parallel decoding. Experiments on Korean and Chinese singing datasets demonstrate consistent improvements over strong baselines, including lower mel-cepstral distortion and fundamental-frequency error and higher perceptual scores on the Korean dataset. Code, pretrained checkpoints, and audio demos are available at https://github.com/alsgur9368/FM-Singer",
    "authors": [
      "Minhyeok Yun",
      "Yong-Hoon Choi"
    ],
    "url": "http://arxiv.org/abs/2601.00217v1",
    "published": "2026-01-01",
    "primary_category": "cs.SD",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于条件流匹配的歌声合成方法，通过优化潜在空间中的先验-后验分布匹配来提升歌声表达的细腻度。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00915v1",
    "title": "Latent-Constrained Conditional VAEs for Augmenting Large-Scale Climate Ensembles",
    "summary": "Large climate-model ensembles are computationally expensive; yet many downstream analyses would benefit from additional, statistically consistent realizations of spatiotemporal climate variables. We study a generative modeling approach for producing new realizations from a limited set of available runs by transferring structure learned across an ensemble. Using monthly near-surface temperature time series from ten independent reanalysis realizations (ERA5), we find that a vanilla conditional variational autoencoder (CVAE) trained jointly across realizations yields a fragmented latent space that fails to generalize to unseen ensemble members. To address this, we introduce a latent-constrained CVAE (LC-CVAE) that enforces cross-realization homogeneity of latent embeddings at a small set of shared geographic 'anchor' locations. We then use multi-output Gaussian process regression in the latent space to predict latent coordinates at unsampled locations in a new realization, followed by decoding to generate full time series fields. Experiments and ablations demonstrate (i) instability when training on a single realization, (ii) diminishing returns after incorporating roughly five realizations, and (iii) a trade-off between spatial coverage and reconstruction quality that is closely linked to the average neighbor distance in latent space.",
    "authors": [
      "Jacquelyn Shelton",
      "Przemyslaw Polewski",
      "Alexander Robel",
      "Matthew Hoffman",
      "Stephen Price"
    ],
    "url": "http://arxiv.org/abs/2601.00915v1",
    "published": "2026-01-01",
    "primary_category": "cs.LG",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出一种基于条件变分自编码器的生成模型方法，用于扩展气候模型集合数据，属于AI在气候科学领域的应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00913v1",
    "title": "Clean-GS: Semantic Mask-Guided Pruning for 3D Gaussian Splatting",
    "summary": "3D Gaussian Splatting produces high-quality scene reconstructions but generates hundreds of thousands of spurious Gaussians (floaters) scattered throughout the environment. These artifacts obscure objects of interest and inflate model sizes, hindering deployment in bandwidth-constrained applications. We present Clean-GS, a method for removing background clutter and floaters from 3DGS reconstructions using sparse semantic masks. Our approach combines whitelist-based spatial filtering with color-guided validation and outlier removal to achieve 60-80\\% model compression while preserving object quality. Unlike existing 3DGS pruning methods that rely on global importance metrics, Clean-GS uses semantic information from as few as 3 segmentation masks (1\\% of views) to identify and remove Gaussians not belonging to the target object. Our multi-stage approach consisting of (1) whitelist filtering via projection to masked regions, (2) depth-buffered color validation, and (3) neighbor-based outlier removal isolates monuments and objects from complex outdoor scenes. Experiments on Tanks and Temples show that Clean-GS reduces file sizes from 125MB to 47MB while maintaining rendering quality, making 3DGS models practical for web deployment and AR/VR applications. Our code is available at https://github.com/smlab-niser/clean-gs",
    "authors": [
      "Subhankar Mishra"
    ],
    "url": "http://arxiv.org/abs/2601.00913v1",
    "published": "2026-01-01",
    "primary_category": "cs.CV",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于语义掩码引导的3D高斯溅射模型剪枝方法，用于去除重建场景中的伪影和背景杂波，属于计算机视觉和图形学领域的模型优化技术。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00912v1",
    "title": "The Discovery Gap: How Product Hunt Startups Vanish in LLM Organic Discovery Queries",
    "summary": "When someone asks ChatGPT to recommend a project management tool, which products show up in the response? And more importantly for startup founders: will their newly launched product ever appear? This research set out to answer these questions.   I randomly selected 112 startups from the top 500 products featured on the 2025 Product Hunt leaderboard and tested each one across 2,240 queries to two different large language models: ChatGPT (gpt-4o-mini) and Perplexity (sonar with web search).   The results were striking. When users asked about products by name, both LLMs recognized them almost perfectly: 99.4% for ChatGPT and 94.3% for Perplexity. But when users asked discovery-style questions like \"What are the best AI tools launched this year?\" the success rates collapsed to 3.32% and 8.29% respectively. That's a gap of 30-to-1 for ChatGPT.   Perhaps the most surprising finding was that Generative Engine Optimization (GEO), the practice of optimizing website content for AI visibility, showed no correlation with actual discovery rates. Products with high GEO scores were no more likely to appear in organic queries than products with low scores.   What did matter? For Perplexity, traditional SEO signals like referring domains (r = +0.319, p < 0.001) and Product Hunt ranking (r = -0.286, p = 0.002) predicted visibility. After cleaning the Reddit data for false positives, community presence also emerged as significant (r = +0.395, p = 0.002).   The practical takeaway is counterintuitive: don't optimize for AI discovery directly. Instead, build the SEO foundation first and LLM visibility will follow.",
    "authors": [
      "Amit Prakash Sharma"
    ],
    "url": "http://arxiv.org/abs/2601.00912v1",
    "published": "2026-01-01",
    "primary_category": "cs.IR",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文研究大型语言模型在商业产品推荐中的发现偏差，属于信息检索与商业分析领域，而非AI4Science或扰动预测的生物学研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00911v1",
    "title": "Device-Native Autonomous Agents for Privacy-Preserving Negotiations",
    "summary": "Automated negotiations in insurance and business-to-business (B2B) commerce encounter substantial challenges. Current systems force a trade-off between convenience and privacy by routing sensitive financial data through centralized servers, increasing security risks, and diminishing user trust. This study introduces a device-native autonomous Artificial Intelligence (AI) agent system for privacy-preserving negotiations. The proposed system operates exclusively on user hardware, enabling real-time bargaining while maintaining sensitive constraints locally. It integrates zero-knowledge proofs to ensure privacy and employs distilled world models to support advanced on-device reasoning. The architecture incorporates six technical components within an agentic AI workflow. Agents autonomously plan negotiation strategies, conduct secure multi-party bargaining, and generate cryptographic audit trails without exposing user data to external servers. The system is evaluated in insurance and B2B procurement scenarios across diverse device configurations. Results show an average success rate of 87%, a 2.4x latency improvement over cloud baselines, and strong privacy preservation through zero-knowledge proofs. User studies show 27% higher trust scores when decision trails are available. These findings establish a foundation for trustworthy autonomous agents in privacy-sensitive financial domains.",
    "authors": [
      "Joyjit Roy"
    ],
    "url": "http://arxiv.org/abs/2601.00911v1",
    "published": "2026-01-01",
    "primary_category": "cs.CR",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于设备本地AI代理的隐私保护谈判系统，专注于金融和商业领域的自动化协商技术，而非科学发现或生物医学扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00200v1",
    "title": "Detecting Unobserved Confounders: A Kernelized Regression Approach",
    "summary": "Detecting unobserved confounders is crucial for reliable causal inference in observational studies. Existing methods require either linearity assumptions or multiple heterogeneous environments, limiting applicability to nonlinear single-environment settings. To bridge this gap, we propose Kernel Regression Confounder Detection (KRCD), a novel method for detecting unobserved confounding in nonlinear observational data under single-environment conditions. KRCD leverages reproducing kernel Hilbert spaces to model complex dependencies. By comparing standard and higherorder kernel regressions, we derive a test statistic whose significant deviation from zero indicates unobserved confounding. Theoretically, we prove two key results: First, in infinite samples, regression coefficients coincide if and only if no unobserved confounders exist. Second, finite-sample differences converge to zero-mean Gaussian distributions with tractable variance. Extensive experiments on synthetic benchmarks and the Twins dataset demonstrate that KRCD not only outperforms existing baselines but also achieves superior computational efficiency.",
    "authors": [
      "Yikai Chen",
      "Yunxin Mao",
      "Chunyuan Zheng",
      "Hao Zou",
      "Shanzhi Gu",
      "Shixuan Liu",
      "Yang Shi",
      "Wenjing Yang",
      "Kun Kuang",
      "Haotian Wang"
    ],
    "url": "http://arxiv.org/abs/2601.00200v1",
    "published": "2026-01-01",
    "primary_category": "stat.ML",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于核回归的方法来检测非线性观测数据中的未观测混杂因素，这属于因果推断领域，可应用于生物医学等科学领域的数据分析。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00197v1",
    "title": "StockBot 2.0: Vanilla LSTMs Outperform Transformer-based Forecasting for Stock Prices",
    "summary": "Accurate forecasting of financial markets remains a long-standing challenge due to complex temporal and often latent dependencies, non-linear dynamics, and high volatility. Building on our earlier recurrent neural network framework, we present an enhanced StockBot architecture that systematically evaluates modern attention-based, convolutional, and recurrent time-series forecasting models within a unified experimental setting. While attention-based and transformer-inspired models offer increased modeling flexibility, extensive empirical evaluation reveals that a carefully constructed vanilla LSTM consistently achieves superior predictive accuracy and more stable buy/sell decision-making when trained under a common set of default hyperparameters. These results highlight the robustness and data efficiency of recurrent sequence models for financial time-series forecasting, particularly in the absence of extensive hyperparameter tuning or the availability of sufficient data when discretized to single-day intervals. Additionally, these results underscore the importance of architectural inductive bias in data-limited market prediction tasks.",
    "authors": [
      "Shaswat Mohanty"
    ],
    "url": "http://arxiv.org/abs/2601.00197v1",
    "published": "2026-01-01",
    "primary_category": "cs.CE",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于金融时间序列预测，比较LSTM与Transformer模型在股票价格预测中的表现，属于金融科技领域而非基础科学发现或生物医学扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00192v1",
    "title": "Optimized Hybrid Feature Engineering for Resource-Efficient Arrhythmia Detection in ECG Signals: An Optimization Framework",
    "summary": "Cardiovascular diseases, particularly arrhythmias, remain a leading global cause of mortality, necessitating continuous monitoring via the Internet of Medical Things (IoMT). However, state-of-the-art deep learning approaches often impose prohibitive computational overheads, rendering them unsuitable for resource-constrained edge devices. This study proposes a resource-efficient, data-centric framework that prioritizes feature engineering over complexity. Our optimized pipeline makes the complex, high-dimensional arrhythmia data linearly separable. This is achieved by integrating time-frequency wavelet decompositions with graph-theoretic structural descriptors, such as PageRank centrality. This hybrid feature space, combining wavelet decompositions and graph-theoretic descriptors, is then refined using mutual information and recursive elimination, enabling interpretable, ultra-lightweight linear classifiers. Validation on the MIT-BIH and INCART datasets yields 98.44% diagnostic accuracy with an 8.54 KB model footprint. The system achieves 0.46 $μ$s classification inference latency within a 52 ms per-beat pipeline, ensuring real-time operation. These outcomes provide an order-of-magnitude efficiency gain over compressed models, such as KD-Light (25 KB, 96.32% accuracy), advancing battery-less cardiac sensors.",
    "authors": [
      "Moirangthem Tiken Singh",
      "Manibhushan Yaikhom"
    ],
    "url": "http://arxiv.org/abs/2601.00192v1",
    "published": "2026-01-01",
    "primary_category": "cs.LG",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于AI的心律失常检测优化框架，通过特征工程提升医疗诊断效率，属于AI在生物医学领域的科学应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00189v1",
    "title": "SSI-GAN: Semi-Supervised Swin-Inspired Generative Adversarial Networks for Neuronal Spike Classification",
    "summary": "Mosquitos are the main transmissive agents of arboviral diseases. Manual classification of their neuronal spike patterns is very labor-intensive and expensive. Most available deep learning solutions require fully labeled spike datasets and highly preprocessed neuronal signals. This reduces the feasibility of mass adoption in actual field scenarios. To address the scarcity of labeled data problems, we propose a new Generative Adversarial Network (GAN) architecture that we call the Semi-supervised Swin-Inspired GAN (SSI-GAN). The Swin-inspired, shifted-window discriminator, together with a transformer-based generator, is used to classify neuronal spike trains and, consequently, detect viral neurotropism. We use a multi-head self-attention model in a flat, window-based transformer discriminator that learns to capture sparser high-frequency spike features. Using just 1 to 3% labeled data, SSI-GAN was trained with more than 15 million spike samples collected at five-time post-infection and recording classification into Zika-infected, dengue-infected, or uninfected categories. Hyperparameters were optimized using the Bayesian Optuna framework, and performance for robustness was validated under fivefold Monte Carlo cross-validation. SSI-GAN reached 99.93% classification accuracy on the third day post-infection with only 3% labeled data. It maintained high accuracy across all stages of infection with just 1% supervision. This shows a 97-99% reduction in manual labeling effort relative to standard supervised approaches at the same performance level. The shifted-window transformer design proposed here beat all baselines by a wide margin and set new best marks in spike-based neuronal infection classification.",
    "authors": [
      "Danial Sharifrazi",
      "Nouman Javed",
      "Mojtaba Mohammadi",
      "Seyede Sana Salehi",
      "Roohallah Alizadehsani",
      "Prasad N. Paradkar",
      "U. Rajendra Acharya",
      "Asim Bhatti"
    ],
    "url": "http://arxiv.org/abs/2601.00189v1",
    "published": "2026-01-01",
    "primary_category": "cs.LG",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种半监督生成对抗网络，用于蚊子神经元电信号分类以检测病毒感染，属于AI在生物学领域的科学发现应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00186v1",
    "title": "Reinforcement-Learned Unequal Error Protection for Quantized Semantic Embeddings",
    "summary": "This paper tackles the pressing challenge of preserving semantic meaning in communication systems constrained by limited bandwidth. We introduce a novel reinforcement learning framework that achieves per-dimension unequal error protection via adaptive repetition coding. Central to our approach is a composite semantic distortion metric that balances global embedding similarity with entity-level preservation, empowering the reinforcement learning agent to allocate protection in a context-aware manner. Experiments show statistically significant gains over uniform protection, achieving 6.8% higher chrF scores and 9.3% better entity preservation at 1 dB SNR. The key innovation of our framework is the demonstration that simple, intelligently allocated repetition coding enables fine-grained semantic protection -- an advantage unattainable with conventional codes such as LDPC or Reed-Solomon. Our findings challenge traditional channel coding paradigms by establishing that code structure must align with semantic granularity. This approach is particularly suited to edge computing and IoT scenarios, where bandwidth is scarce, but semantic fidelity is critical, providing a practical pathway for next-generation semantic-aware networks.",
    "authors": [
      "Moirangthem Tiken Singh",
      "Adnan Arif"
    ],
    "url": "http://arxiv.org/abs/2601.00186v1",
    "published": "2026-01-01",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于强化学习的语义嵌入量化保护框架，用于优化通信系统中的语义保真度，而非应用于传统科学发现或扰动预测领域。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00181v1",
    "title": "Understanding Emotion in Discourse: Recognition Insights and Linguistic Patterns for Generation",
    "summary": "While Emotion Recognition in Conversation (ERC) has achieved high accuracy, two critical gaps remain: a limited understanding of \\textit{which} architectural choices actually matter, and a lack of linguistic analysis connecting recognition to generation. We address both gaps through a systematic analysis of the IEMOCAP dataset.   For recognition, we conduct a rigorous ablation study with 10-seed evaluation and report three key findings. First, conversational context is paramount, with performance saturating rapidly -- 90\\% of the total gain achieved within just the most recent 10--30 preceding turns (depending on the label set). Second, hierarchical sentence representations help at utterance-level, but this benefit disappears once conversational context is provided, suggesting that context subsumes intra-utterance structure. Third, external affective lexicons (SenticNet) provide no gain, indicating that pre-trained encoders already capture necessary emotional semantics. With simple architectures using strictly causal context, we achieve 82.69\\% (4-way) and 67.07\\% (6-way) weighted F1, outperforming prior text-only methods including those using bidirectional context.   For linguistic analysis, we analyze 5,286 discourse marker occurrences and find a significant association between emotion and marker positioning ($p < .0001$). Notably, \"sad\" utterances exhibit reduced left-periphery marker usage (21.9\\%) compared to other emotions (28--32\\%), consistent with theories linking left-periphery markers to active discourse management. This connects to our recognition finding that sadness benefits most from context (+22\\%p): lacking explicit pragmatic signals, sad utterances require conversational history for disambiguation.",
    "authors": [
      "Cheonkam Jeong",
      "Adeline Nyamathi"
    ],
    "url": "http://arxiv.org/abs/2601.00181v1",
    "published": "2026-01-01",
    "primary_category": "cs.CL",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于对话中情感识别的架构分析和语言模式研究，属于自然语言处理领域，不涉及生物学、化学或物理学等自然科学发现，也不涉及细胞或分子水平的扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00175v1",
    "title": "Early Prediction of Liver Cirrhosis Up to Three Years in Advance: A Machine Learning Study Benchmarking Against the FIB-4 Score",
    "summary": "Objective: Develop and evaluate machine learning (ML) models for predicting incident liver cirrhosis one, two, and three years prior to diagnosis using routinely collected electronic health record (EHR) data, and to benchmark their performance against the FIB-4 score. Methods: We conducted a retrospective cohort study using de-identified EHR data from a large academic health system. Patients with fatty liver disease were identified and categorized into cirrhosis and non-cirrhosis cohorts based on ICD-9/10 codes. Prediction scenarios were constructed using observation and prediction windows to emulate real-world clinical use. Demographics, diagnoses, laboratory results, vital signs, and comorbidity indices were aggregated from the observation window. XGBoost models were trained for 1-, 2-, and 3-year prediction horizons and evaluated on held-out test sets. Model performance was compared with FIB-4 using area under the receiver operating characteristic curve (AUC). Results: Final cohorts included 3,043 patients for the 1-year prediction, 1,981 for the 2-year prediction, and 1,470 for the 3-year prediction. Across all prediction windows, ML models consistently outperformed FIB-4. The XGBoost models achieved AUCs of 0.81, 0.73, and 0.69 for 1-, 2-, and 3-year predictions, respectively, compared with 0.71, 0.63, and 0.57 for FIB-4. Performance gains persisted with longer prediction horizons, indicating improved early risk discrimination. Conclusions: Machine learning models leveraging routine EHR data substantially outperform the traditional FIB-4 score for early prediction of liver cirrhosis. These models enable earlier and more accurate risk stratification and can be integrated into clinical workflows as automated decision-support tools to support proactive cirrhosis prevention and management.",
    "authors": [
      "Zhuqi Miao",
      "Sujan Ravi",
      "Abdulaziz Ahmed"
    ],
    "url": "http://arxiv.org/abs/2601.00175v1",
    "published": "2026-01-01",
    "primary_category": "cs.LG",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该研究利用机器学习模型分析电子健康记录数据，在生物学领域（肝脏疾病预测）实现了比传统FIB-4评分更早、更准确的肝硬化风险预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00172v1",
    "title": "Sequential Reservoir Computing for Efficient High-Dimensional Spatiotemporal Forecasting",
    "summary": "Forecasting high-dimensional spatiotemporal systems remains computationally challenging for recurrent neural networks (RNNs) and long short-term memory (LSTM) models due to gradient-based training and memory bottlenecks. Reservoir Computing (RC) mitigates these challenges by replacing backpropagation with fixed recurrent layers and a convex readout optimization, yet conventional RC architectures still scale poorly with input dimensionality. We introduce a Sequential Reservoir Computing (Sequential RC) architecture that decomposes a large reservoir into a series of smaller, interconnected reservoirs. This design reduces memory and computational costs while preserving long-term temporal dependencies. Using both low-dimensional chaotic systems (Lorenz63) and high-dimensional physical simulations (2D vorticity and shallow-water equations), Sequential RC achieves 15-25% longer valid forecast horizons, 20-30% lower error metrics (SSIM, RMSE), and up to three orders of magnitude lower training cost compared to LSTM and standard RNN baselines. The results demonstrate that Sequential RC maintains the simplicity and efficiency of conventional RC while achieving superior scalability for high-dimensional dynamical systems. This approach provides a practical path toward real-time, energy-efficient forecasting in scientific and engineering applications.",
    "authors": [
      "Ata Akbari Asanjan",
      "Filip Wudarski",
      "Daniel O'Connor",
      "Shaun Geaney",
      "Elena Strbac",
      "P. Aaron Lott",
      "Davide Venturelli"
    ],
    "url": "http://arxiv.org/abs/2601.00172v1",
    "published": "2026-01-01",
    "primary_category": "cs.LG",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于高效高维时空预测的序列储层计算架构，通过改进机器学习方法提升物理系统模拟的预测性能。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00170v1",
    "title": "Hear the Heartbeat in Phases: Physiologically Grounded Phase-Aware ECG Biometrics",
    "summary": "Electrocardiography (ECG) is adopted for identity authentication in wearable devices due to its individual-specific characteristics and inherent liveness. However, existing methods often treat heartbeats as homogeneous signals, overlooking the phase-specific characteristics within the cardiac cycle. To address this, we propose a Hierarchical Phase-Aware Fusion~(HPAF) framework that explicitly avoids cross-feature entanglement through a three-stage design. In the first stage, Intra-Phase Representation (IPR) independently extracts representations for each cardiac phase, ensuring that phase-specific morphological and variation cues are preserved without interference from other phases. In the second stage, Phase-Grouped Hierarchical Fusion (PGHF) aggregates physiologically related phases in a structured manner, enabling reliable integration of complementary phase information. In the final stage, Global Representation Fusion (GRF) further combines the grouped representations and adaptively balances their contributions to produce a unified and discriminative identity representation. Moreover, considering ECG signals are continuously acquired, multiple heartbeats can be collected for each individual. We propose a Heartbeat-Aware Multi-prototype (HAM) enrollment strategy, which constructs a multi-prototype gallery template set to reduce the impact of heartbeat-specific noise and variability. Extensive experiments on three public datasets demonstrate that HPAF achieves state-of-the-art results in the comparison with other methods under both closed and open-set settings.",
    "authors": [
      "Jintao Huang",
      "Lu Leng",
      "Yi Zhang",
      "Ziyuan Yang"
    ],
    "url": "http://arxiv.org/abs/2601.00170v1",
    "published": "2026-01-01",
    "primary_category": "eess.IV",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文通过分层相位感知融合框架，利用人工智能技术分析心电信号的相位特异性特征，实现了基于生理学原理的生物特征识别科学发现。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00167v1",
    "title": "Online Finetuning Decision Transformers with Pure RL Gradients",
    "summary": "Decision Transformers (DTs) have emerged as a powerful framework for sequential decision making by formulating offline reinforcement learning (RL) as a sequence modeling problem. However, extending DTs to online settings with pure RL gradients remains largely unexplored, as existing approaches continue to rely heavily on supervised sequence-modeling objectives during online finetuning. We identify hindsight return relabeling -- a standard component in online DTs -- as a critical obstacle to RL-based finetuning: while beneficial for supervised learning, it is fundamentally incompatible with importance sampling-based RL algorithms such as GRPO, leading to unstable training. Building on this insight, we propose new algorithms that enable online finetuning of Decision Transformers using pure reinforcement learning gradients. We adapt GRPO to DTs and introduce several key modifications, including sub-trajectory optimization for improved credit assignment, sequence-level likelihood objectives for enhanced stability and efficiency, and active sampling to encourage exploration in uncertain regions. Through extensive experiments, we demonstrate that our methods outperform existing online DT baselines and achieve new state-of-the-art performance across multiple benchmarks, highlighting the effectiveness of pure-RL-based online finetuning for Decision Transformers.",
    "authors": [
      "Junkai Luo",
      "Yinglun Zhu"
    ],
    "url": "http://arxiv.org/abs/2601.00167v1",
    "published": "2026-01-01",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种使用纯强化学习梯度在线微调决策变换器的新算法，改进了序列决策任务的性能，属于通用机器学习方法研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00909v1",
    "title": "Security Hardening Using FABRIC: Implementing a Unified Compliance Aggregator for Linux Servers",
    "summary": "This paper presents a unified framework for evaluating Linux security hardening on the FABRIC testbed through aggregation of heterogeneous security auditing tools. We deploy three Ubuntu 22.04 nodes configured at baseline, partial, and full hardening levels, and evaluate them using Lynis, OpenSCAP, and AIDE across 108 audit runs. To address the lack of a consistent interpretation across tools, we implement a Unified Compliance Aggregator (UCA) that parses tool outputs, normalizes scores to a common 0--100 scale, and combines them into a weighted metric augmented by a customizable rule engine for organization-specific security policies. Experimental results show that full hardening increases OpenSCAP compliance from 39.7 to 71.8, while custom rule compliance improves from 39.3\\% to 83.6\\%. The results demonstrate that UCA provides a clearer and more reproducible assessment of security posture than individual tools alone, enabling systematic evaluation of hardening effectiveness in programmable testbed environments.",
    "authors": [
      "Sheldon Paul",
      "Izzat Alsmadi"
    ],
    "url": "http://arxiv.org/abs/2601.00909v1",
    "published": "2026-01-01",
    "primary_category": "cs.CR",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种通过统一合规聚合器评估Linux服务器安全加固效果的框架，属于网络安全领域而非AI驱动的科学发现或细胞扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00154v1",
    "title": "Unmixing highly mixed grain size distribution data via maximum volume constrained end member analysis",
    "summary": "End member analysis (EMA) unmixes grain size distribution (GSD) data into a mixture of end members (EMs), thus helping understand sediment provenance and depositional regimes and processes. In highly mixed data sets, however, many EMA algorithms find EMs which are still a mixture of true EMs. To overcome this, we propose maximum volume constrained EMA (MVC-EMA), which finds EMs as different as possible. We provide a uniqueness theorem and a quadratic programming algorithm for MVC-EMA. Experimental results show that MVC-EMA can effectively find true EMs in highly mixed data sets.",
    "authors": [
      "Qianqian Qi",
      "Zhongming Chen",
      "Peter G. M. van der Heijden"
    ],
    "url": "http://arxiv.org/abs/2601.00154v1",
    "published": "2026-01-01",
    "primary_category": "stat.ME",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出一种基于最大体积约束的端元分析算法，用于解决地质沉积物粒度分布数据的高度混合问题，属于AI在地球科学领域的应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00908v1",
    "title": "Conformal Prediction Under Distribution Shift: A COVID-19 Natural Experiment",
    "summary": "Conformal prediction guarantees degrade under distribution shift. We study this using COVID-19 as a natural experiment across 8 supply chain tasks. Despite identical severe feature turnover (Jaccard approximately 0), coverage drops vary from 0% to 86.7%, spanning two orders of magnitude. Using SHapley Additive exPlanations (SHAP) analysis, we find catastrophic failures correlate with single-feature dependence (rho = 0.714, p = 0.047). Catastrophic tasks concentrate importance in one feature (4.5x increase), while robust tasks redistribute across many (10-20x). Quarterly retraining restores catastrophic task coverage from 22% to 41% (+19 pp, p = 0.04), but provides no benefit for robust tasks (99.8% coverage). Exploratory analysis of 4 additional tasks with moderate feature stability (Jaccard 0.13-0.86) reveals feature stability, not concentration, determines robustness, suggesting concentration effects apply specifically to severe shifts. We provide a decision framework: monitor SHAP concentration before deployment; retrain quarterly if vulnerable (>40% concentration); skip retraining if robust.",
    "authors": [
      "Chorok Lee"
    ],
    "url": "http://arxiv.org/abs/2601.00908v1",
    "published": "2026-01-01",
    "primary_category": "cs.LG",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文使用COVID-19供应链数据作为自然实验，研究分布偏移下保形预测的可靠性退化机制，属于AI方法在公共卫生科学领域的应用研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00152v1",
    "title": "The Weather Paradox: Why Precipitation Fails to Predict Traffic Accident Severity in Large-Scale US Data",
    "summary": "This study investigates the predictive capacity of environmental, temporal, and spatial factors on traffic accident severity in the United States. Using a dataset of 500,000 U.S. traffic accidents spanning 2016-2023, we trained an XGBoost classifier optimized through randomized search cross-validation and adjusted for class imbalance via class weighting. The final model achieves an overall accuracy of 78%, with strong performance on the majority class (Severity 2), attaining 87% precision and recall. Feature importance analysis reveals that time of day, geographic location, and weather-related variables, including visibility, temperature, and wind speed, rank among the strongest predictors of accident severity. However, contrary to initial hypotheses, precipitation and visibility demonstrate limited predictive power, potentially reflecting behavioral adaptation by drivers under overtly hazardous conditions. The dataset's predominance of mid-level severity accidents constrains the model's capacity to learn meaningful patterns for extreme cases, highlighting the need for alternative sampling strategies, enhanced feature engineering, and integration of external datasets. These findings contribute to evidence-based traffic management and suggest future directions for severity prediction research.",
    "authors": [
      "Yann Bellec",
      "Rohan Kaman",
      "Siwen Cui",
      "Aarav Agrawal",
      "Calvin Chen"
    ],
    "url": "http://arxiv.org/abs/2601.00152v1",
    "published": "2026-01-01",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文使用机器学习方法分析交通数据以预测事故严重程度，属于交通工程领域而非基础科学发现。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00151v1",
    "title": "Reinforcement Learning with Function Approximation for Non-Markov Processes",
    "summary": "We study reinforcement learning methods with linear function approximation under non-Markov state and cost processes. We first consider the policy evaluation method and show that the algorithm converges under suitable ergodicity conditions on the underlying non-Markov processes. Furthermore, we show that the limit corresponds to the fixed point of a joint operator composed of an orthogonal projection and the Bellman operator of an auxiliary \\emph{Markov} decision process.   For Q-learning with linear function approximation, as in the Markov setting, convergence is not guaranteed in general. We show, however, that for the special case where the basis functions are chosen based on quantization maps, the convergence can be shown under similar ergodicity conditions. Finally, we apply our results to partially observed Markov decision processes, where finite-memory variables are used as state representations, and we derive explicit error bounds for the limits of the resulting learning algorithms.",
    "authors": [
      "Ali Devran Kara"
    ],
    "url": "http://arxiv.org/abs/2601.00151v1",
    "published": "2026-01-01",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于强化学习算法在非马尔可夫过程中的理论收敛性分析，属于机器学习理论范畴，未涉及具体科学领域的应用或扰动预测问题。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00150v1",
    "title": "FCMBench: A Comprehensive Financial Credit Multimodal Benchmark for Real-world Applications",
    "summary": "As multimodal AI becomes widely used for credit risk assessment and document review, a domain-specific benchmark is urgently needed that (1) reflects documents and workflows specific to financial credit applications, (2) includes credit-specific understanding and real-world robustness, and (3) preserves privacy compliance without sacrificing practical utility. Here, we introduce FCMBench-V1.0 -- a large-scale financial credit multimodal benchmark for real-world applications, covering 18 core certificate types, with 4,043 privacy-compliant images and 8,446 QA samples. The FCMBench evaluation framework consists of three dimensions: Perception, Reasoning, and Robustness, including 3 foundational perception tasks, 4 credit-specific reasoning tasks that require decision-oriented understanding of visual evidence, and 10 real-world acquisition artifact types for robustness stress testing. To reconcile compliance with realism, we construct all samples via a closed synthesis-capture pipeline: we manually synthesize document templates with virtual content and capture scenario-aware images in-house. This design also mitigates pre-training data leakage by avoiding web-sourced or publicly released images. FCMBench can effectively discriminate performance disparities and robustness across modern vision-language models. Extensive experiments were conducted on 23 state-of-the-art vision-language models (VLMs) from 14 top AI companies and research institutes. Among them, Gemini 3 Pro achieves the best F1(\\%) score as a commercial model (64.61), Qwen3-VL-235B achieves the best score as an open-source baseline (57.27), and our financial credit-specific model, Qfin-VL-Instruct, achieves the top overall score (64.92). Robustness evaluations show that even top-performing models suffer noticeable performance drops under acquisition artifacts.",
    "authors": [
      "Yehui Yang",
      "Dalu Yang",
      "Wenshuo Zhou",
      "Fangxin Shang",
      "Yifan Liu",
      "Jie Ren",
      "Haojun Fei",
      "Qing Yang",
      "Tao Chen"
    ],
    "url": "http://arxiv.org/abs/2601.00150v1",
    "published": "2026-01-01",
    "primary_category": "cs.CV",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一个金融信贷领域的多模态基准测试FCMBench，专注于评估视觉语言模型在金融文档理解和风险评估中的性能，而非科学发现或细胞扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00146v1",
    "title": "Combining datasets with different ground truths using Low-Rank Adaptation to generalize image-based CNN models for photometric redshift prediction",
    "summary": "In this work, we demonstrate how Low-Rank Adaptation (LoRA) can be used to combine different galaxy imaging datasets to improve redshift estimation with CNN models for cosmology. LoRA is an established technique for large language models that adds adapter networks to adjust model weights and biases to efficiently fine-tune large base models without retraining. We train a base model using a photometric redshift ground truth dataset, which contains broad galaxy types but is less accurate. We then fine-tune using LoRA on a spectroscopic redshift ground truth dataset. These redshifts are more accurate but limited to bright galaxies and take orders of magnitude more time to obtain, so are less available for large surveys. Ideally, the combination of the two datasets would yield more accurate models that generalize well. The LoRA model performs better than a traditional transfer learning method, with $\\sim2.5\\times$ less bias and $\\sim$2.2$\\times$ less scatter. Retraining the model on a combined dataset yields a model that generalizes better than LoRA but at a cost of greater computation time. Our work shows that LoRA is useful for fine-tuning regression models in astrophysics by providing a middle ground between full retraining and no retraining. LoRA shows potential in allowing us to leverage existing pretrained astrophysical models, especially for data sparse tasks.",
    "authors": [
      "Vikram Seenivasan",
      "Srinath Saikrishnan",
      "Andrew Lizarraga",
      "Jonathan Soriano",
      "Bernie Boscoe",
      "Tuan Do"
    ],
    "url": "http://arxiv.org/abs/2601.00146v1",
    "published": "2026-01-01",
    "primary_category": "astro-ph.IM",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文通过应用低秩适应技术改进天文图像数据的红移预测模型，属于利用人工智能方法解决天体物理学中的科学问题。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00143v1",
    "title": "MethConvTransformer: A Deep Learning Framework for Cross-Tissue Alzheimer's Disease Detection",
    "summary": "Alzheimer's disease (AD) is a multifactorial neurodegenerative disorder characterized by progressive cognitive decline and widespread epigenetic dysregulation in the brain. DNA methylation, as a stable yet dynamic epigenetic modification, holds promise as a noninvasive biomarker for early AD detection. However, methylation signatures vary substantially across tissues and studies, limiting reproducibility and translational utility. To address these challenges, we develop MethConvTransformer, a transformer-based deep learning framework that integrates DNA methylation profiles from both brain and peripheral tissues to enable biomarker discovery. The model couples a CpG-wise linear projection with convolutional and self-attention layers to capture local and long-range dependencies among CpG sites, while incorporating subject-level covariates and tissue embeddings to disentangle shared and region-specific methylation effects. In experiments across six GEO datasets and an independent ADNI validation cohort, our model consistently outperforms conventional machine-learning baselines, achieving superior discrimination and generalization. Moreover, interpretability analyses using linear projection, SHAP, and Grad-CAM++ reveal biologically meaningful methylation patterns aligned with AD-associated pathways, including immune receptor signaling, glycosylation, lipid metabolism, and endomembrane (ER/Golgi) organization. Together, these results indicate that MethConvTransformer delivers robust, cross-tissue epigenetic biomarkers for AD while providing multi-resolution interpretability, thereby advancing reproducible methylation-based diagnostics and offering testable hypotheses on disease mechanisms.",
    "authors": [
      "Gang Qu",
      "Guanghao Li",
      "Zhongming Zhao"
    ],
    "url": "http://arxiv.org/abs/2601.00143v1",
    "published": "2026-01-01",
    "primary_category": "q-bio.GN",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文开发了基于深度学习的MethConvTransformer框架，用于整合跨组织DNA甲基化数据以发现阿尔茨海默病的生物标志物，属于AI在生物医学研究中的应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.00142v1",
    "title": "An AI Monkey Gets Grapes for Sure -- Sphere Neural Networks for Reliable Decision-Making",
    "summary": "This paper compares three methodological categories of neural reasoning: LLM reasoning, supervised learning-based reasoning, and explicit model-based reasoning. LLMs remain unreliable and struggle with simple decision-making that animals can master without extensive corpora training. Through disjunctive syllogistic reasoning testing, we show that reasoning via supervised learning is less appealing than reasoning via explicit model construction. Concretely, we show that an Euler Net trained to achieve 100.00% in classic syllogistic reasoning can be trained to reach 100.00% accuracy in disjunctive syllogistic reasoning. However, the retrained Euler Net suffers severely from catastrophic forgetting (its performance drops to 6.25% on already-learned classic syllogistic reasoning), and its reasoning competence is limited to the pattern level. We propose a new version of Sphere Neural Networks that embeds concepts as circles on the surface of an n-dimensional sphere. These Sphere Neural Networks enable the representation of the negation operator via complement circles and achieve reliable decision-making by filtering out illogical statements that form unsatisfiable circular configurations. We demonstrate that the Sphere Neural Network can master 16 syllogistic reasoning tasks, including rigorous disjunctive syllogistic reasoning, while preserving the rigour of classical syllogistic reasoning. We conclude that neural reasoning with explicit model construction is the most reliable among the three methodological categories of neural reasoning.",
    "authors": [
      "Tiansi Dong",
      "Henry He",
      "Pietro Liò",
      "Mateja Jamnik"
    ],
    "url": "http://arxiv.org/abs/2601.00142v1",
    "published": "2026-01-01",
    "primary_category": "cs.AI",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种新型球面神经网络，通过将概念表示为多维球面上的圆来实现可靠的逻辑推理，属于人工智能基础方法研究而非特定科学领域的应用或扰动预测。"
  }
]