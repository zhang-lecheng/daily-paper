[
  {
    "id": "http://arxiv.org/abs/2601.02360v1",
    "title": "Heterogeneous Low-Bandwidth Pre-Training of LLMs",
    "summary": "Pre-training large language models (LLMs) increasingly requires distributed compute, yet bandwidth constraints make it difficult to scale beyond well-provisioned datacenters-especially when model parallelism forces frequent, large inter-device communications. We study whether SparseLoCo, a low-communication data parallel method based on infrequent synchronization and sparse pseudo-gradient exchange, can be combined with low-bandwidth pipeline model parallelism via activation and activation-gradient compression. We introduce a heterogeneous distributed training framework where some participants host full replicas on high-bandwidth interconnects, while resource-limited participants are grouped to jointly instantiate a replica using pipeline parallelism with subspace-projected inter-stage communication. To make the recently introduced subspace pipeline compression compatible with SparseLoCo, we study a number of adaptations. Across large-scale language modeling experiments (178M-1B parameters) on standard pretraining corpora, we find that activation compression composes with SparseLoCo at modest cost, while selective (heterogeneous) compression consistently improves the loss-communication tradeoff relative to compressing all replicas-especially at aggressive compression ratios. These results suggest a practical path to incorporating low-bandwidth model parallelism and heterogeneous participants into LLM pre-training.",
    "authors": [
      "Yazan Obeidi",
      "Amir Sarfi",
      "Joel Lidin",
      "Paul Janson",
      "Eugene Belilovsky"
    ],
    "url": "http://arxiv.org/abs/2601.02360v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on distributed training methods for large language models (LLMs), specifically addressing bandwidth constraints through techniques like SparseLoCo and pipeline model parallelism with compression. It does not involve applying AI to scientific discovery in fields like biology, chemistry, or physics, nor does it address predicting system responses to perturbations."
  },
  {
    "id": "http://arxiv.org/abs/2601.02357v1",
    "title": "DARC: Drum accompaniment generation with fine-grained rhythm control",
    "summary": "In music creation, rapid prototyping is essential for exploring and refining ideas, yet existing generative tools often fall short when users require both structural control and stylistic flexibility. Prior approaches in stem-to-stem generation can condition on other musical stems but offer limited control over rhythm, and timbre-transfer methods allow users to specify specific rhythms, but cannot condition on musical context. We introduce DARC, a generative drum accompaniment model that conditions both on musical context from other stems and explicit rhythm prompts such as beatboxing or tapping tracks. Using parameter-efficient fine-tuning, we augment STAGE, a state-of-the-art drum stem generator, with fine-grained rhythm control while maintaining musical context awareness.",
    "authors": [
      "Trey Brosnan"
    ],
    "url": "http://arxiv.org/abs/2601.02357v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on AI for music generation (drum accompaniment), not scientific discovery in natural sciences. It describes rhythm control in generative models, not predicting system responses to perturbations."
  },
  {
    "id": "http://arxiv.org/abs/2601.02353v1",
    "title": "Meta-Learning Guided Pruning for Few-Shot Plant Pathology on Edge Devices",
    "summary": "Farmers in remote areas need quick and reliable methods for identifying plant diseases, yet they often lack access to laboratories or high-performance computing resources. Deep learning models can detect diseases from leaf images with high accuracy, but these models are typically too large and computationally expensive to run on low-cost edge devices such as Raspberry Pi. Furthermore, collecting thousands of labeled disease images for training is both expensive and time-consuming. This paper addresses both challenges by combining neural network pruning -- removing unnecessary parts of the model -- with few-shot learning, which enables the model to learn from limited examples. This paper proposes Disease-Aware Channel Importance Scoring (DACIS), a method that identifies which parts of the neural network are most important for distinguishing between different plant diseases, integrated into a three-stage Prune-then-Meta-Learn-then-Prune (PMP) pipeline. Experiments on PlantVillage and PlantDoc datasets demonstrate that the proposed approach reduces model size by 78\\% while maintaining 92.3\\% of the original accuracy, with the compressed model running at 7 frames per second on a Raspberry Pi 4, making real-time field diagnosis practical for smallholder farmers.",
    "authors": [
      "Shahnawaz Alam",
      "Mohammed Mudassir Uddin",
      "Mohammed Kaif Pasha"
    ],
    "url": "http://arxiv.org/abs/2601.02353v1",
    "published": "2026-01-05",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "The paper applies AI (deep learning with meta-learning and pruning) to solve a biological problem (plant disease diagnosis), which aligns with AI4Science. It does not involve predicting system responses to perturbations; instead, it focuses on model optimization for edge deployment."
  },
  {
    "id": "http://arxiv.org/abs/2601.02349v1",
    "title": "PRIMAD-LID: A Developed Framework for Computational Reproducibility",
    "summary": "Over the past decade alongside increased focus on computational reproducibility significant efforts have been made to define reproducibility. However, these definitions provide a textual description rather than a framework. The community has sought conceptual frameworks that identify all factors that must be controlled and described for credible computational reproducibility. The PRIMAD model was initially introduced to address inconsistencies in terminology surrounding computational reproducibility by outlining six key factors: P (Platforms), R (Research objective), I (Implementations), M (Methods), A (Actors), and D (Data). Subsequently various studies across different fields adopted the model and proposed extensions. However, these contributions remain fragmented and require systematic integration and cross-disciplinary validation. To bridge this gap and recognising that PRIMAD provides a broadly applicable framework for reproducibility in computational science, this work undertakes a focused investigation of the PRIMAD model. It combines the models previous extensions into a unified framework suitable for diverse research contexts. The result is PRIMAD-LID, a discipline-diagnostic reproducibility framework that retains the original six PRIMAD dimensions and enhances each with three overarching modifiers: Lifespan (temporal qualifier), Interpretation (contextual reasoning) and Depth (necessary granularity), thereby establishing a more cohesive and robust foundation for computational reproducibility practices.",
    "authors": [
      "Meznah Aloqalaa",
      "Stian Soiland-Reyes",
      "Carole Goble"
    ],
    "url": "http://arxiv.org/abs/2601.02349v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper presents PRIMAD-LID, a conceptual framework for computational reproducibility focusing on terminology, factors, and modifiers (Platforms, Research objective, Implementations, Methods, Actors, Data, Lifespan, Interpretation, Depth). It does not discuss using AI for scientific discovery in specific domains like biology, chemistry, or physics, nor does it address predicting system responses to perturbations."
  },
  {
    "id": "http://arxiv.org/abs/2601.02347v1",
    "title": "Solving Matrix Games with Even Fewer Matrix-Vector Products",
    "summary": "We study the problem of computing an $ε$-approximate Nash equilibrium of a two-player, bilinear, zero-sum game with a bounded payoff matrix $A \\in \\mathbb{R}^{m \\times n}$, when the players' strategies are constrained to lie in simple sets. We provide algorithms which solve this problem in $\\tilde{O}(ε^{-2/3})$ matrix-vector multiplies (matvecs) in two well-studied cases: $\\ell_1$-$\\ell_1$ games, where the players' strategies are both in the probability simplex, and $\\ell_2$-$\\ell_1$ games, where the players' strategies are in the unit Euclidean ball and probability simplex respectively. These results improve upon the previous state-of-the-art complexities of $\\tilde{O}(ε^{-8/9})$ for $\\ell_1$-$\\ell_1$ and of $\\tilde{O}(ε^{-7/9})$ for $\\ell_2$-$\\ell_1$ due to [KOS '25]. In particular, our result for $\\ell_2$-$\\ell_1$, which corresponds to hard-margin support vector machines (SVMs), matches the lower bound of [KS '25] up to polylogarithmic factors.",
    "authors": [
      "Ishani Karmarkar",
      "Liam O'Carroll",
      "Aaron Sidford"
    ],
    "url": "http://arxiv.org/abs/2601.02347v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on algorithmic improvements for computing approximate Nash equilibria in constrained matrix games, specifically in computational complexity theory and optimization. It does not involve applying AI to scientific discovery domains like biology, chemistry, or physics, nor does it address predicting system responses to perturbations."
  },
  {
    "id": "http://arxiv.org/abs/2601.02346v1",
    "title": "Falcon-H1R: Pushing the Reasoning Frontiers with a Hybrid Model for Efficient Test-Time Scaling",
    "summary": "This work introduces Falcon-H1R, a 7B-parameter reasoning-optimized model that establishes the feasibility of achieving competitive reasoning performance with small language models (SLMs). Falcon-H1R stands out for its parameter efficiency, consistently matching or outperforming SOTA reasoning models that are $2\\times$ to $7\\times$ larger across a variety of reasoning-intensive benchmarks. These results underscore the importance of careful data curation and targeted training strategies (via both efficient SFT and RL scaling) in delivering significant performance gains without increasing model size. Furthermore, Falcon-H1R advances the 3D limits of reasoning efficiency by combining faster inference (through its hybrid-parallel architecture design), token efficiency, and higher accuracy. This unique blend makes Falcon-H1R-7B a practical backbone for scaling advanced reasoning systems, particularly in scenarios requiring extensive chain-of-thoughts generation and parallel test-time scaling. Leveraging the recently introduced DeepConf approach, Falcon-H1R achieves state-of-the-art test-time scaling efficiency, offering substantial improvements in both accuracy and computational cost. As a result, Falcon-H1R demonstrates that compact models, through targeted model training and architectural choices, can deliver robust and scalable reasoning performance.",
    "authors": [
      "Falcon LLM Team",
      "Iheb Chaabane",
      "Puneesh Khanna",
      "Suhail Mohmad",
      "Slim Frikha",
      "Shi Hu",
      "Abdalgader Abubaker",
      "Reda Alami",
      "Mikhail Lubinets",
      "Mohamed El Amine Seddik",
      "Hakim Hacid"
    ],
    "url": "http://arxiv.org/abs/2601.02346v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on developing an efficient reasoning-optimized language model (Falcon-H1R) for general reasoning tasks, emphasizing parameter efficiency, architectural design, and test-time scaling. It does not mention applications in scientific discovery domains like biology, chemistry, or physics, nor does it address predicting system responses to perturbations."
  },
  {
    "id": "http://arxiv.org/abs/2601.02324v1",
    "title": "Hunting for \"Oddballs\" with Machine Learning: Detecting Anomalous Exoplanets Using a Deep-Learned Low-Dimensional Representation of Transit Spectra with Autoencoders",
    "summary": "This study explores the application of autoencoder-based machine learning techniques for anomaly detection to identify exoplanet atmospheres with unconventional chemical signatures using a low-dimensional data representation. We use the Atmospheric Big Challenge (ABC) database, a publicly available dataset with over 100,000 simulated exoplanet spectra, to construct an anomaly detection scenario by defining CO2-rich atmospheres as anomalies and CO2-poor atmospheres as the normal class. We benchmarked four different anomaly detection strategies: Autoencoder Reconstruction Loss, One-Class Support Vector Machine (1 class-SVM), K-means Clustering, and Local Outlier Factor (LOF). Each method was evaluated in both the original spectral space and the autoencoder's latent space using Receiver Operating Characteristic (ROC) curves and Area Under the Curve (AUC) metrics. To test the performance of the different methods under realistic conditions, we introduced Gaussian noise levels ranging from 10 to 50 ppm. Our results indicate that anomaly detection is consistently more effective when performed within the latent space across all noise levels. Specifically, K-means clustering in the latent space emerged as a stable and high-performing method. We demonstrate that this anomaly detection approach is robust to noise levels up to 30 ppm (consistent with realistic space-based observations) and remains viable even at 50 ppm when leveraging latent space representations. On the other hand, the performance of the anomaly detection methods applied directly in the raw spectral space degrades significantly with increasing the level of noise. This suggests that autoencoder-driven dimensionality reduction offers a robust methodology for flagging chemically anomalous targets in large-scale surveys where exhaustive retrievals are computationally prohibitive.",
    "authors": [
      "Alexander Roman",
      "Emilie Panek",
      "Roy T. Forestano",
      "Eyup B. Unlu",
      "Katia Matcheva",
      "Konstantin T. Matchev"
    ],
    "url": "http://arxiv.org/abs/2601.02324v1",
    "published": "2026-01-05",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "The paper applies autoencoder-based machine learning for anomaly detection in exoplanet atmospheric spectra, which is a clear example of using AI for scientific discovery in astronomy/physics. It does not involve predicting system responses to perturbations; rather, it focuses on identifying statistical outliers in observational data."
  },
  {
    "id": "http://arxiv.org/abs/2601.02322v1",
    "title": "Environment-Adaptive Covariate Selection: Learning When to Use Spurious Correlations for Out-of-Distribution Prediction",
    "summary": "Out-of-distribution (OOD) prediction is often approached by restricting models to causal or invariant covariates, avoiding non-causal spurious associations that may be unstable across environments. Despite its theoretical appeal, this strategy frequently underperforms empirical risk minimization (ERM) in practice. We investigate the source of this gap and show that such failures naturally arise when only a subset of the true causes of the outcome is observed. In these settings, non-causal spurious covariates can serve as informative proxies for unobserved causes and substantially improve prediction, except under distribution shifts that break these proxy relationships. Consequently, the optimal set of predictive covariates is neither universal nor necessarily exhibits invariant relationships with the outcome across all environments, but instead depends on the specific type of shift encountered. Crucially, we observe that different covariate shifts induce distinct, observable signatures in the covariate distribution itself. Moreover, these signatures can be extracted from unlabeled data in the target OOD environment and used to assess when proxy covariates remain reliable and when they fail. Building on this observation, we propose an environment-adaptive covariate selection (EACS) algorithm that maps environment-level covariate summaries to environment-specific covariate sets, while allowing the incorporation of prior causal knowledge as constraints. Across simulations and applied datasets, EACS consistently outperforms static causal, invariant, and ERM-based predictors under diverse distribution shifts.",
    "authors": [
      "Shuozhi Zuo",
      "Yixin Wang"
    ],
    "url": "http://arxiv.org/abs/2601.02322v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on developing a machine learning methodology (EACS algorithm) for improving out-of-distribution prediction by adaptively selecting covariates based on environmental signatures. It does not specifically apply AI to scientific discovery in domains like biology, chemistry, or physics (AI4Science), nor does it address predicting system responses to perturbations (Perturbation Prediction)."
  },
  {
    "id": "http://arxiv.org/abs/2601.02316v1",
    "title": "DatBench: Discriminative, Faithful, and Efficient VLM Evaluations",
    "summary": "Empirical evaluation serves as the primary compass guiding research progress in foundation models. Despite a large body of work focused on training frontier vision-language models (VLMs), approaches to their evaluation remain nascent. To guide their maturation, we propose three desiderata that evaluations should satisfy: (1) faithfulness to the modality and application, (2) discriminability between models of varying quality, and (3) efficiency in compute. Through this lens, we identify critical failure modes that violate faithfulness and discriminability, misrepresenting model capabilities: (i) multiple-choice formats reward guessing, poorly reflect downstream use cases, and saturate early as models improve; (ii) blindly solvable questions, which can be answered without images, constitute up to 70% of some evaluations; and (iii) mislabeled or ambiguous samples compromise up to 42% of examples in certain datasets. Regarding efficiency, the computational burden of evaluating frontier models has become prohibitive: by some accounts, nearly 20% of development compute is devoted to evaluation alone. Rather than discarding existing benchmarks, we curate them via transformation and filtering to maximize fidelity and discriminability. We find that converting multiple-choice questions to generative tasks reveals sharp capability drops of up to 35%. In addition, filtering blindly solvable and mislabeled samples improves discriminative power while simultaneously reducing computational cost. We release DatBench-Full, a cleaned evaluation suite of 33 datasets spanning nine VLM capabilities, and DatBench, a discriminative subset that achieves 13x average speedup (up to 50x) while closely matching the discriminative power of the original datasets. Our work outlines a path toward evaluation practices that are both rigorous and sustainable as VLMs continue to scale.",
    "authors": [
      "Siddharth Joshi",
      "Haoli Yin",
      "Rishabh Adiga",
      "Ricardo Monti",
      "Aldo Carranza",
      "Alex Fang",
      "Alvin Deng",
      "Amro Abbas",
      "Brett Larsen",
      "Cody Blakeney",
      "Darren Teh",
      "David Schwab",
      "Fan Pan",
      "Haakon Mongstad",
      "Jack Urbanek",
      "Jason Lee",
      "Jason Telanoff",
      "Josh Wills",
      "Kaleigh Mentzer",
      "Luke Merrick",
      "Parth Doshi",
      "Paul Burstein",
      "Pratyush Maini",
      "Scott Loftin",
      "Spandan Das",
      "Tony Jiang",
      "Vineeth Dorna",
      "Zhengping Wang",
      "Bogdan Gaza",
      "Ari Morcos",
      "Matthew Leavitt"
    ],
    "url": "http://arxiv.org/abs/2601.02316v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "This paper focuses on developing better evaluation methods for vision-language models (VLMs), specifically addressing issues with existing benchmarks and proposing more faithful, discriminative, and efficient evaluation practices. It does not involve using AI for scientific discovery in domains like biology, chemistry, or physics, nor does it address predicting system responses to perturbations."
  },
  {
    "id": "http://arxiv.org/abs/2601.02314v1",
    "title": "Project Ariadne: A Structural Causal Framework for Auditing Faithfulness in LLM Agents",
    "summary": "As Large Language Model (LLM) agents are increasingly tasked with high-stakes autonomous decision-making, the transparency of their reasoning processes has become a critical safety concern. While \\textit{Chain-of-Thought} (CoT) prompting allows agents to generate human-readable reasoning traces, it remains unclear whether these traces are \\textbf{faithful} generative drivers of the model's output or merely \\textbf{post-hoc rationalizations}. We introduce \\textbf{Project Ariadne}, a novel XAI framework that utilizes Structural Causal Models (SCMs) and counterfactual logic to audit the causal integrity of agentic reasoning. Unlike existing interpretability methods that rely on surface-level textual similarity, Project Ariadne performs \\textbf{hard interventions} ($do$-calculus) on intermediate reasoning nodes -- systematically inverting logic, negating premises, and reversing factual claims -- to measure the \\textbf{Causal Sensitivity} ($φ$) of the terminal answer. Our empirical evaluation of state-of-the-art models reveals a persistent \\textit{Faithfulness Gap}. We define and detect a widespread failure mode termed \\textbf{Causal Decoupling}, where agents exhibit a violation density ($ρ$) of up to $0.77$ in factual and scientific domains. In these instances, agents arrive at identical conclusions despite contradictory internal logic, proving that their reasoning traces function as \"Reasoning Theater\" while decision-making is governed by latent parametric priors. Our findings suggest that current agentic architectures are inherently prone to unfaithful explanation, and we propose the Ariadne Score as a new benchmark for aligning stated logic with model action.",
    "authors": [
      "Sourena Khanzadeh"
    ],
    "url": "http://arxiv.org/abs/2601.02314v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": true,
    "reasoning": "The paper focuses on auditing faithfulness in LLM agents using structural causal models and counterfactual interventions, which involves systematically perturbing reasoning nodes (hard interventions) to measure causal sensitivity. This aligns with perturbation prediction as it studies how model outputs respond to controlled perturbations of internal reasoning. It does not involve using AI for scientific discovery in domains like biology, chemistry, or physics."
  },
  {
    "id": "http://arxiv.org/abs/2601.02313v1",
    "title": "Game of Coding: Coding Theory in the Presence of Rational Adversaries, Motivated by Decentralized Machine Learning",
    "summary": "Coding theory plays a crucial role in enabling reliable communication, storage, and computation. Classical approaches assume a worst-case adversarial model and ensure error correction and data recovery only when the number of honest nodes exceeds the number of adversarial ones by some margin. However, in some emerging decentralized applications, particularly in decentralized machine learning (DeML), participating nodes are rewarded for accepted contributions. This incentive structure naturally gives rise to rational adversaries who act strategically rather than behaving in purely malicious ways.   In this paper, we first motivate the need for coding in the presence of rational adversaries, particularly in the context of outsourced computation in decentralized systems. We contrast this need with existing approaches and highlight their limitations. We then introduce the game of coding, a novel game-theoretic framework that extends coding theory to trust-minimized settings where honest nodes are not in the majority. Focusing on repetition coding, we highlight two key features of this framework: (1) the ability to achieve a non-zero probability of data recovery even when adversarial nodes are in the majority, and (2) Sybil resistance, i.e., the equilibrium remains unchanged even as the number of adversarial nodes increases. Finally, we explore scenarios in which the adversary's strategy is unknown and outline several open problems for future research.",
    "authors": [
      "Hanzaleh Akbari Nodehi",
      "Viveck R. Cadambe",
      "Mohammad Ali Maddah-Ali"
    ],
    "url": "http://arxiv.org/abs/2601.02313v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on coding theory and game theory applied to decentralized machine learning systems with rational adversaries. It does not involve using AI for scientific discovery in fields like biology, chemistry, or physics (AI4Science), nor does it address predicting system responses to perturbations (Perturbation Prediction)."
  },
  {
    "id": "http://arxiv.org/abs/2601.02311v1",
    "title": "Placement Semantics for Distributed Deep Learning: A Systematic Framework for Analyzing Parallelism Strategies",
    "summary": "Training large language models requires distributing computation across many accelerators, yet practitioners select parallelism strategies (data, tensor, pipeline, ZeRO) through trial and error because no unified systematic framework predicts their behavior. We introduce placement semantics: each strategy is specified by how it places four training states (parameters, optimizer, gradients, activations) across devices using five modes (replicated, sharded, sharded-with-gather, materialized, offloaded). From placement alone, without implementation details, we derive memory consumption and communication volume. Our predictions match published results exactly: ZeRO-3 uses 8x less memory than data parallelism at 1.5x communication cost, as reported in the original paper. We prove two conditions (gradient integrity, state consistency) are necessary and sufficient for distributed training to match single-device results, and provide composition rules for combining strategies safely. The framework unifies ZeRO Stages 1-3, Fully Sharded Data Parallel (FSDP), tensor parallelism, and pipeline parallelism as instances with different placement choices.",
    "authors": [
      "Deep Pankajbhai Mehta"
    ],
    "url": "http://arxiv.org/abs/2601.02311v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on developing a systematic framework for analyzing parallelism strategies in distributed deep learning training, specifically for large language models. It addresses computational efficiency, memory usage, and communication optimization rather than applying AI to scientific discovery domains (biology, chemistry, physics) or predicting system responses to perturbations."
  },
  {
    "id": "http://arxiv.org/abs/2601.02310v1",
    "title": "Temporal Kolmogorov-Arnold Networks (T-KAN) for High-Frequency Limit Order Book Forecasting: Efficiency, Interpretability, and Alpha Decay",
    "summary": "High-Frequency trading (HFT) environments are characterised by large volumes of limit order book (LOB) data, which is notoriously noisy and non-linear. Alpha decay represents a significant challenge, with traditional models such as DeepLOB losing predictive power as the time horizon (k) increases. In this paper, using data from the FI-2010 dataset, we introduce Temporal Kolmogorov-Arnold Networks (T-KAN) to replace the fixed, linear weights of standard LSTMs with learnable B-spline activation functions. This allows the model to learn the 'shape' of market signals as opposed to just their magnitude. This resulted in a 19.1% relative improvement in the F1-score at the k = 100 horizon. The efficacy of T-KAN networks cannot be understated, producing a 132.48% return compared to the -82.76% DeepLOB drawdown under 1.0 bps transaction costs. In addition to this, the T-KAN model proves quite interpretable, with the 'dead-zones' being clearly visible in the splines. The T-KAN architecture is also uniquely optimized for low-latency FPGA implementation via High level Synthesis (HLS). The code for the experiments in this project can be found at https://github.com/AhmadMak/Temporal-Kolmogorov-Arnold-Networks-T-KAN-for-High-Frequency-Limit-Order-Book-Forecasting.",
    "authors": [
      "Ahmad Makinde"
    ],
    "url": "http://arxiv.org/abs/2601.02310v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on financial market prediction (high-frequency trading and limit order book forecasting) using a novel neural network architecture (T-KAN). It does not involve scientific discovery in fields like biology, chemistry, or physics (AI4Science), nor does it address predicting system responses to perturbations in a general scientific context."
  },
  {
    "id": "http://arxiv.org/abs/2601.02307v1",
    "title": "Differential Privacy for Transformer Embeddings of Text with Nonparametric Variational Information Bottleneck",
    "summary": "We propose a privacy-preserving method for sharing text data by sharing noisy versions of their transformer embeddings. It has been shown that hidden representations learned by deep models can encode sensitive information from the input, making it possible for adversaries to recover the input data with considerable accuracy. This problem is exacerbated in transformer embeddings because they consist of multiple vectors, one per token. To mitigate this risk, we propose Nonparametric Variational Differential Privacy (NVDP), which ensures both useful data sharing and strong privacy protection. We take a differential privacy approach, integrating a Nonparametric Variational Information Bottleneck (NVIB) layer into the transformer architecture to inject noise into its multi-vector embeddings and thereby hide information, and measuring privacy protection with Rényi divergence and its corresponding Bayesian Differential Privacy (BDP) guarantee. Training the NVIB layer calibrates the noise level according to utility. We test NVDP on the GLUE benchmark and show that varying the noise level gives us a useful tradeoff between privacy and accuracy. With lower noise levels, our model maintains high accuracy while offering strong privacy guarantees, effectively balancing privacy and utility.",
    "authors": [
      "Dina El Zein",
      "James Henderson"
    ],
    "url": "http://arxiv.org/abs/2601.02307v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on privacy-preserving methods for text embeddings using differential privacy and information bottleneck techniques, not on applying AI to scientific discovery domains like biology, chemistry, or physics. While it involves adding noise (perturbation) to embeddings, its goal is privacy protection rather than predicting system responses to perturbations."
  },
  {
    "id": "http://arxiv.org/abs/2601.02285v1",
    "title": "pdfQA: Diverse, Challenging, and Realistic Question Answering over PDFs",
    "summary": "PDFs are the second-most used document type on the internet (after HTML). Yet, existing QA datasets commonly start from text sources or only address specific domains. In this paper, we present pdfQA, a multi-domain 2K human-annotated (real-pdfQA) and 2K synthetic dataset (syn-pdfQA) differentiating QA pairs in ten complexity dimensions (e.g., file type, source modality, source position, answer type). We apply and evaluate quality and difficulty filters on both datasets, obtaining valid and challenging QA pairs. We answer the questions with open-source LLMs, revealing existing challenges that correlate with our complexity dimensions. pdfQA presents a basis for end-to-end QA pipeline evaluation, testing diverse skill sets and local optimizations (e.g., in information retrieval or parsing).",
    "authors": [
      "Tobias Schimanski",
      "Imene Kolli",
      "Jingwei Ni",
      "Yu Fan",
      "Ario Saeid Vaghefi",
      "Elliott Ash",
      "Markus Leippold"
    ],
    "url": "http://arxiv.org/abs/2601.02285v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on creating a dataset for evaluating question answering systems on PDF documents, with complexity dimensions related to document structure and content. It does not specifically address scientific discovery in domains like biology, chemistry, or physics, nor does it involve predicting system responses to perturbations."
  },
  {
    "id": "http://arxiv.org/abs/2601.02273v1",
    "title": "TopoLoRA-SAM: Topology-Aware Parameter-Efficient Adaptation of Foundation Segmenters for Thin-Structure and Cross-Domain Binary Semantic Segmentation",
    "summary": "Foundation segmentation models such as the Segment Anything Model (SAM) exhibit strong zero-shot generalization through large-scale pretraining, but adapting them to domain-specific semantic segmentation remains challenging, particularly for thin structures (e.g., retinal vessels) and noisy modalities (e.g., SAR imagery). Full fine-tuning is computationally expensive and risks catastrophic forgetting. We propose \\textbf{TopoLoRA-SAM}, a topology-aware and parameter-efficient adaptation framework for binary semantic segmentation. TopoLoRA-SAM injects Low-Rank Adaptation (LoRA) into the frozen ViT encoder, augmented with a lightweight spatial convolutional adapter and optional topology-aware supervision via differentiable clDice. We evaluate our approach on five benchmarks spanning retinal vessel segmentation (DRIVE, STARE, CHASE\\_DB1), polyp segmentation (Kvasir-SEG), and SAR sea/land segmentation (SL-SSDD), comparing against U-Net, DeepLabV3+, SegFormer, and Mask2Former. TopoLoRA-SAM achieves the best retina-average Dice and the best overall average Dice across datasets, while training only \\textbf{5.2\\%} of model parameters ($\\sim$4.9M). On the challenging CHASE\\_DB1 dataset, our method substantially improves segmentation accuracy and robustness, demonstrating that topology-aware parameter-efficient adaptation can match or exceed fully fine-tuned specialist models. Code is available at : https://github.com/salimkhazem/Seglab.git",
    "authors": [
      "Salim Khazem"
    ],
    "url": "http://arxiv.org/abs/2601.02273v1",
    "published": "2026-01-05",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "The paper applies AI (specifically segmentation models) to medical imaging tasks (retinal vessel segmentation, polyp segmentation) which falls under AI4Science in biology/medicine. There is no mention of predicting system responses to perturbations; it focuses on adapting foundation models for segmentation tasks."
  },
  {
    "id": "http://arxiv.org/abs/2601.02265v1",
    "title": "Predicting Early and Complete Drug Release from Long-Acting Injectables Using Explainable Machine Learning",
    "summary": "Polymer-based long-acting injectables (LAIs) have transformed the treatment of chronic diseases by enabling controlled drug delivery, thus reducing dosing frequency and extending therapeutic duration. Achieving controlled drug release from LAIs requires extensive optimization of the complex underlying physicochemical properties. Machine learning (ML) can accelerate LAI development by modeling the complex relationships between LAI properties and drug release. However, recent ML studies have provided limited information on key properties that modulate drug release, due to the lack of custom modeling and analysis tailored to LAI data. This paper presents a novel data transformation and explainable ML approach to synthesize actionable information from 321 LAI formulations by predicting early drug release at 24, 48, and 72 hours, classification of release profile types, and prediction of complete release profiles. These three experiments investigate the contribution and control of LAI material characteristics in early and complete drug release profiles. A strong correlation (>0.65) is observed between the true and predicted drug release in 72 hours, while a 0.87 F1-score is obtained in classifying release profile types. A time-independent ML framework predicts delayed biphasic and triphasic curves with better performance than current time-dependent approaches. Shapley additive explanations reveal the relative influence of material characteristics during early and for complete release which fill several gaps in previous in-vitro and ML-based studies. The novel approach and findings can provide a quantitative strategy and recommendations for scientists to optimize the drug-release dynamics of LAI. The source code for the model implementation is publicly available.",
    "authors": [
      "Karla N. Robles",
      "Manar D. Samad"
    ],
    "url": "http://arxiv.org/abs/2601.02265v1",
    "published": "2026-01-05",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "The paper uses explainable machine learning to model drug release from polymer-based long-acting injectables, applying AI to accelerate pharmaceutical development and optimize material properties, which falls under AI4Science in chemistry/pharmacology. It does not focus on predicting system responses to perturbations but rather on modeling release profiles based on material characteristics."
  },
  {
    "id": "http://arxiv.org/abs/2601.02264v1",
    "title": "POSEIDON: Physics-Optimized Seismic Energy Inference and Detection Operating Network",
    "summary": "Earthquake prediction and seismic hazard assessment remain fundamental challenges in geophysics, with existing machine learning approaches often operating as black boxes that ignore established physical laws. We introduce POSEIDON (Physics-Optimized Seismic Energy Inference and Detection Operating Network), a physics-informed energy-based model for unified multi-task seismic event prediction, alongside the Poseidon dataset -- the largest open-source global earthquake catalog comprising 2.8 million events spanning 30 years. POSEIDON embeds fundamental seismological principles, including the Gutenberg-Richter magnitude-frequency relationship and Omori-Utsu aftershock decay law, as learnable constraints within an energy-based modeling framework. The architecture simultaneously addresses three interconnected prediction tasks: aftershock sequence identification, tsunami generation potential, and foreshock detection. Extensive experiments demonstrate that POSEIDON achieves state-of-the-art performance across all tasks, outperforming gradient boosting, random forest, and CNN baselines with the highest average F1 score among all compared methods. Crucially, the learned physics parameters converge to scientifically interpretable values -- Gutenberg-Richter b-value of 0.752 and Omori-Utsu parameters p=0.835, c=0.1948 days -- falling within established seismological ranges while enhancing rather than compromising predictive accuracy. The Poseidon dataset is publicly available at https://huggingface.co/datasets/BorisKriuk/Poseidon, providing pre-computed energy features, spatial grid indices, and standardized quality metrics to advance physics-informed seismic research.",
    "authors": [
      "Boris Kriuk",
      "Fedor Kriuk"
    ],
    "url": "http://arxiv.org/abs/2601.02264v1",
    "published": "2026-01-05",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "The paper directly applies AI (physics-informed energy-based modeling) to geophysics/earthquake science, embedding seismological principles like Gutenberg-Richter and Omori-Utsu laws for multi-task seismic prediction. It does not focus on predicting system responses to perturbations, but rather on event detection and hazard assessment."
  },
  {
    "id": "http://arxiv.org/abs/2601.02257v1",
    "title": "Improved Accuracy for Private Continual Cardinality Estimation in Fully Dynamic Streams via Matrix Factorization",
    "summary": "We study differentially-private statistics in the fully dynamic continual observation model, where many updates can arrive at each time step and updates to a stream can involve both insertions and deletions of an item. Earlier work (e.g., Jain et al., NeurIPS 2023 for counting distinct elements; Raskhodnikova & Steiner, PODS 2025 for triangle counting with edge updates) reduced the respective cardinality estimation problem to continual counting on the difference stream associated with the true function values on the input stream. In such reductions, a change in the original stream can cause many changes in the difference stream, this poses a challenge for applying private continual counting algorithms to obtain optimal error bounds. We improve the accuracy of several such reductions by studying the associated $\\ell_p$-sensitivity vectors of the resulting difference streams and isolating their properties.   We demonstrate that our framework gives improved bounds for counting distinct elements, estimating degree histograms, and estimating triangle counts (under a slightly relaxed privacy model), thus offering a general approach to private continual cardinality estimation in streaming settings. Our improved accuracy stems from tight analysis of known factorization mechanisms for the counting matrix in this setting; the key technical challenge is arguing that one can use state-of-the-art factorizations for sensitivity vector sets with the properties we isolate. Empirically and analytically, we demonstrate that our improved error bounds offer a substantial improvement in accuracy for cardinality estimation problems over a large range of parameters.",
    "authors": [
      "Joel Daniel Andersson",
      "Palak Jain",
      "Satchit Sivakumar"
    ],
    "url": "http://arxiv.org/abs/2601.02257v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on differential privacy mechanisms for cardinality estimation in streaming data, specifically improving accuracy through matrix factorization techniques. It does not involve applying AI to scientific discovery in fields like biology, chemistry, or physics (AI4Science), nor does it address predicting system responses to perturbations (Perturbation Prediction)."
  },
  {
    "id": "http://arxiv.org/abs/2601.02256v1",
    "title": "VAR RL Done Right: Tackling Asynchronous Policy Conflicts in Visual Autoregressive Generation",
    "summary": "Visual generation is dominated by three paradigms: AutoRegressive (AR), diffusion, and Visual AutoRegressive (VAR) models. Unlike AR and diffusion, VARs operate on heterogeneous input structures across their generation steps, which creates severe asynchronous policy conflicts. This issue becomes particularly acute in reinforcement learning (RL) scenarios, leading to unstable training and suboptimal alignment. To resolve this, we propose a novel framework to enhance Group Relative Policy Optimization (GRPO) by explicitly managing these conflicts. Our method integrates three synergistic components: 1) a stabilizing intermediate reward to guide early-stage generation; 2) a dynamic time-step reweighting scheme for precise credit assignment; and 3) a novel mask propagation algorithm, derived from principles of Reward Feedback Learning (ReFL), designed to isolate optimization effects both spatially and temporally. Our approach demonstrates significant improvements in sample quality and objective alignment over the vanilla GRPO baseline, enabling robust and effective optimization for VAR models.",
    "authors": [
      "Shikun Sun",
      "Liao Qu",
      "Huichao Zhang",
      "Yiheng Liu",
      "Yangyang Song",
      "Xian Li",
      "Xu Wang",
      "Yi Jiang",
      "Daniel K. Du",
      "Xinglong Wu",
      "Jia Jia"
    ],
    "url": "http://arxiv.org/abs/2601.02256v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on improving reinforcement learning for visual autoregressive generation models, addressing training stability and alignment in image synthesis. It does not involve applying AI to scientific discovery in domains like biology, chemistry, or physics, nor does it involve predicting system responses to perturbations."
  },
  {
    "id": "http://arxiv.org/abs/2601.02253v1",
    "title": "Neuro-Channel Networks: A Multiplication-Free Architecture by Biological Signal Transmission",
    "summary": "The rapid proliferation of Deep Learning is increasingly constrained by its heavy reliance on high-performance hardware, particularly Graphics Processing Units (GPUs). These specialized accelerators are not only prohibitively expensive and energy-intensive but also suffer from significant supply scarcity, limiting the ubiquity of Artificial Intelligence (AI) deployment on edge devices. The core of this inefficiency stems from the standard artificial perceptron's dependence on intensive matrix multiplications. However, biological nervous systems achieve unparalleled efficiency without such arithmetic intensity; synaptic signal transmission is regulated by physical ion channel limits and chemical neurotransmitter levels rather than a process that can be analogous to arithmetic multiplication. Inspired by this biological mechanism, we propose Neuro-Channel Networks (NCN), a novel multiplication-free architecture designed to decouple AI from expensive hardware dependencies. In our model, weights are replaced with Channel Widths that physically limit the signal magnitude, while a secondary parameter acts as a Neurotransmitter to regulate Signal Transmission based on sign logic. The forward pass relies exclusively on addition, subtraction, and bitwise operations (minimum, sign), eliminating floating-point multiplication entirely. In this proof-of-concept study, we demonstrate that NCNs can solve non-linearly separable problems like XOR and the Majority function with 100% accuracy using standard backpropagation, proving their capability to form complex decision boundaries without multiplicative weights. This architecture offers a highly efficient alternative for next-generation neuromorphic hardware, paving the way for running complex models on commodity CPUs or ultra-low-power chips without relying on costly GPU clusters.",
    "authors": [
      "Emrah Mete",
      "Emin Erkan Korkmaz"
    ],
    "url": "http://arxiv.org/abs/2601.02253v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper proposes a novel neural network architecture inspired by biological signal transmission mechanisms, but it does not use AI for scientific discovery in biology, chemistry, or physics (AI4Science). It also does not focus on predicting how systems respond to perturbations; instead, it introduces a multiplication-free model for efficient AI deployment on edge devices."
  },
  {
    "id": "http://arxiv.org/abs/2601.02246v1",
    "title": "A Comparative Study of Custom CNNs, Pre-trained Models, and Transfer Learning Across Multiple Visual Datasets",
    "summary": "Convolutional Neural Networks (CNNs) are a standard approach for visual recognition due to their capacity to learn hierarchical representations from raw pixels. In practice, practitioners often choose among (i) training a compact custom CNN from scratch, (ii) using a large pre-trained CNN as a fixed feature extractor, and (iii) performing transfer learning via partial or full fine-tuning of a pre-trained backbone. This report presents a controlled comparison of these three paradigms across five real-world image classification datasets spanning road-surface defect recognition, agricultural variety identification, fruit/leaf disease recognition, pedestrian walkway encroachment recognition, and unauthorized vehicle recognition. Models are evaluated using accuracy and macro F1-score, complemented by efficiency metrics including training time per epoch and parameter counts. The results show that transfer learning consistently yields the strongest predictive performance, while the custom CNN provides an attractive efficiency--accuracy trade-off, especially when compute and memory budgets are constrained.",
    "authors": [
      "Annoor Sharara Akhand"
    ],
    "url": "http://arxiv.org/abs/2601.02246v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on comparing CNN training paradigms for general visual recognition tasks (road defects, agriculture, pedestrian/vehicle monitoring) rather than scientific discovery in domains like biology, chemistry, or physics. It also does not involve predicting system responses to perturbations; it is about image classification performance and efficiency metrics."
  },
  {
    "id": "http://arxiv.org/abs/2601.02242v1",
    "title": "VIBE: Visual Instruction Based Editor",
    "summary": "Instruction-based image editing is among the fastest developing areas in generative AI. Over the past year, the field has reached a new level, with dozens of open-source models released alongside highly capable commercial systems. However, only a limited number of open-source approaches currently achieve real-world quality. In addition, diffusion backbones, the dominant choice for these pipelines, are often large and computationally expensive for many deployments and research settings, with widely used variants typically containing 6B to 20B parameters. This paper presents a compact, high-throughput instruction-based image editing pipeline that uses a modern 2B-parameter Qwen3-VL model to guide the editing process and the 1.6B-parameter diffusion model Sana1.5 for image generation. Our design decisions across architecture, data processing, training configuration, and evaluation target low-cost inference and strict source consistency while maintaining high quality across the major edit categories feasible at this scale. Evaluated on the ImgEdit and GEdit benchmarks, the proposed method matches or exceeds the performance of substantially heavier baselines, including models with several times as many parameters and higher inference cost, and is particularly strong on edits that require preserving the input image, such as an attribute adjustment, object removal, background edits, and targeted replacement. The model fits within 24 GB of GPU memory and generates edited images at up to 2K resolution in approximately 4 seconds on an NVIDIA H100 in BF16, without additional inference optimizations or distillation.",
    "authors": [
      "Grigorii Alekseenko",
      "Aleksandr Gordeev",
      "Irina Tolstykh",
      "Bulat Suleimanov",
      "Vladimir Dokholyan",
      "Georgii Fedorov",
      "Sergey Yakubson",
      "Aleksandra Tsybina",
      "Mikhail Chernyshov",
      "Maksim Kuprashevich"
    ],
    "url": "http://arxiv.org/abs/2601.02242v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on instruction-based image editing using generative AI models, specifically for visual content manipulation tasks like attribute adjustment, object removal, and background edits. It does not address scientific discovery in fields like biology, chemistry, or physics (AI4Science), nor does it involve predicting system responses to perturbations in scientific contexts."
  },
  {
    "id": "http://arxiv.org/abs/2601.02241v1",
    "title": "From Mice to Trains: Amortized Bayesian Inference on Graph Data",
    "summary": "Graphs arise across diverse domains, from biology and chemistry to social and information networks, as well as in transportation and logistics. Inference on graph-structured data requires methods that are permutation-invariant, scalable across varying sizes and sparsities, and capable of capturing complex long-range dependencies, making posterior estimation on graph parameters particularly challenging. Amortized Bayesian Inference (ABI) is a simulation-based framework that employs generative neural networks to enable fast, likelihood-free posterior inference. We adapt ABI to graph data to address these challenges to perform inference on node-, edge-, and graph-level parameters. Our approach couples permutation-invariant graph encoders with flexible neural posterior estimators in a two-module pipeline: a summary network maps attributed graphs to fixed-length representations, and an inference network approximates the posterior over parameters. In this setting, several neural architectures can serve as the summary network. In this work we evaluate multiple architectures and assess their performance on controlled synthetic settings and two real-world domains - biology and logistics - in terms of recovery and calibration.",
    "authors": [
      "Svenja Jedhoff",
      "Elizaveta Semenova",
      "Aura Raulo",
      "Anne Meyer",
      "Paul-Christian Bürkner"
    ],
    "url": "http://arxiv.org/abs/2601.02241v1",
    "published": "2026-01-05",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "The paper explicitly applies AI methods (amortized Bayesian inference with neural networks) to graph data in scientific domains including biology and chemistry, which qualifies as AI4Science. While it involves inference on graph parameters, there is no mention of predicting system responses to perturbations or intervention effects."
  },
  {
    "id": "http://arxiv.org/abs/2601.02233v1",
    "title": "PauliEngine: High-Performant Symbolic Arithmetic for Quantum Operations",
    "summary": "Quantum computation is inherently hybrid, and fast classical manipulation of qubit operators is necessary to ensure scalability in quantum software. We introduce PauliEngine, a high-performance C++ framework that provides efficient primitives for Pauli string multiplication, commutators, symbolic phase tracking, and structural transformations. Built on a binary symplectic representation and optimized bit-wise operations, PauliEngine supports both numerical and symbolic coefficients and is accessible through a Python interface. Runtime benchmarks demonstrate substantial speedups over state-of-the-art implementations. PauliEngine provides a scalable backend for operator-based quantum software tools and simulations.",
    "authors": [
      "Leon Müller",
      "Adelina Bärligea",
      "Alexander Knapp",
      "Jakob S. Kottmann"
    ],
    "url": "http://arxiv.org/abs/2601.02233v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper describes a computational framework (PauliEngine) for efficient manipulation of quantum operators using symbolic arithmetic and optimized bit-wise operations. It focuses on classical software tools for quantum computation, not on applying AI/machine learning to scientific discovery (AI4Science) nor on predicting system responses to perturbations (perturbation prediction)."
  },
  {
    "id": "http://arxiv.org/abs/2601.02232v1",
    "title": "ELLA: Efficient Lifelong Learning for Adapters in Large Language Models",
    "summary": "Large Language Models (LLMs) suffer severe catastrophic forgetting when adapted sequentially to new tasks in a continual learning (CL) setting. Existing approaches are fundamentally limited: replay-based methods are impractical and privacy-violating, while strict orthogonality-based methods collapse under scale: each new task is projected onto an orthogonal complement, progressively reducing the residual degrees of freedom and eliminating forward transfer by forbidding overlap in shared representations. In this work, we introduce ELLA, a training framework built on the principle of selective subspace de-correlation. Rather than forbidding all overlap, ELLA explicitly characterizes the structure of past updates and penalizes alignments along their high-energy, task-specific directions, while preserving freedom in the low-energy residual subspaces to enable transfer. Formally, this is realized via a lightweight regularizer on a single aggregated update matrix. We prove this mechanism corresponds to an anisotropic shrinkage operator that bounds interference, yielding a penalty that is both memory- and compute-constant regardless of task sequence length. ELLA requires no data replay, no architectural expansion, and negligible storage. Empirically, it achieves state-of-the-art CL performance on three popular benchmarks, with relative accuracy gains of up to $9.6\\%$ and a $35\\times$ smaller memory footprint. Further, ELLA scales robustly across architectures and actively enhances the model's zero-shot generalization performance on unseen tasks, establishing a principled and scalable solution for constructive lifelong LLM adaptation.",
    "authors": [
      "Shristi Das Biswas",
      "Yue Zhang",
      "Anwesan Pal",
      "Radhika Bhargava",
      "Kaushik Roy"
    ],
    "url": "http://arxiv.org/abs/2601.02232v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on continual learning methods for large language models to prevent catastrophic forgetting, specifically introducing the ELLA framework with selective subspace de-correlation. It does not involve applying AI to scientific discovery in fields like biology, chemistry, or physics, nor does it address predicting system responses to perturbations."
  },
  {
    "id": "http://arxiv.org/abs/2601.02229v1",
    "title": "Extended real number arithmetics via Dedekind cuts",
    "summary": "It is shown how Dedekind cuts can be used to introduce the extended real numbers along with sound arithmetic laws via one simple rule for the addition of sets. The crucial idea is that the use of the lower and the upper part of the cuts, respectively, leads to two different additions which are known in the literature as inf-addition and sup-addition. Moreover, the two resulting structures are conlinear spaces which at the same time are complete lattices with respect to the natural order. This admits the definition of pseudo-differences on the extended reals which also provide formulas for expressions like $(+\\infty) - (+\\infty)$, $(-\\infty) - (-\\infty)$. There are two major motivations: one is that proper and improper extended real-valued functions can be treated in a unified manner, the other that set-valued functions can often be represented by families of scalar functions which may include improper ones.",
    "authors": [
      "Andreas H Hamel"
    ],
    "url": "http://arxiv.org/abs/2601.02229v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on mathematical foundations of extended real numbers using Dedekind cuts, conlinear spaces, and complete lattices, with applications to function theory and set-valued functions. It does not mention AI methods, scientific discovery applications, or perturbation analysis of systems."
  },
  {
    "id": "http://arxiv.org/abs/2601.02215v1",
    "title": "LLM-Empowered Functional Safety and Security by Design in Automotive Systems",
    "summary": "This paper presents LLM-empowered workflow to support Software Defined Vehicle (SDV) software development, covering the aspects of security-aware system topology design, as well as event-driven decision-making code analysis. For code analysis we adopt event chains model which provides formal foundations to systematic validation of functional safety, taking into account the semantic validity of messages exchanged between key components, including both CAN and Vehicle Signal Specification (VSS). Analysis of security aspects for topology relies on synergy with Model-Driven Engineering (MDE) approach and Object Constraint Language (OCL) rules. Both locally deployable and proprietary solution are taken into account for evaluation within Advanced Driver-Assistance Systems (ADAS)-related scenarios.",
    "authors": [
      "Nenad Petrovic",
      "Vahid Zolfaghari",
      "Fengjunjie Pan",
      "Alois Knoll"
    ],
    "url": "http://arxiv.org/abs/2601.02215v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on applying Large Language Models (LLMs) to automotive software development for functional safety and security in Software Defined Vehicles (SDVs), specifically for system topology design and code analysis using event chains and Model-Driven Engineering. It does not address AI for scientific discovery in fields like biology, chemistry, or physics (AI4Science), nor does it involve predicting system responses to perturbations (Perturbation Prediction)."
  },
  {
    "id": "http://arxiv.org/abs/2601.02213v1",
    "title": "Quantized SO(3)-Equivariant Graph Neural Networks for Efficient Molecular Property Prediction",
    "summary": "Deploying 3D graph neural networks (GNNs) that are equivariant to 3D rotations (the group SO(3)) on edge devices is challenging due to their high computational cost. This paper addresses the problem by compressing and accelerating an SO(3)-equivariant GNN using low-bit quantization techniques. Specifically, we introduce three innovations for quantized equivariant transformers: (1) a magnitude-direction decoupled quantization scheme that separately quantizes the norm and orientation of equivariant (vector) features, (2) a branch-separated quantization-aware training strategy that treats invariant and equivariant feature channels differently in an attention-based $SO(3)$-GNN, and (3) a robustness-enhancing attention normalization mechanism that stabilizes low-precision attention computations. Experiments on the QM9 and rMD17 molecular benchmarks demonstrate that our 8-bit models achieve accuracy on energy and force predictions comparable to full-precision baselines with markedly improved efficiency. We also conduct ablation studies to quantify the contribution of each component to maintain accuracy and equivariance under quantization, using the Local error of equivariance (LEE) metric. The proposed techniques enable the deployment of symmetry-aware GNNs in practical chemistry applications with 2.37--2.73x faster inference and 4x smaller model size, without sacrificing accuracy or physical symmetry.",
    "authors": [
      "Haoyu Zhou",
      "Ping Xue",
      "Tianfan Fu",
      "Hao Zhang"
    ],
    "url": "http://arxiv.org/abs/2601.02213v1",
    "published": "2026-01-05",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "The paper applies AI (quantized graph neural networks) to molecular property prediction in chemistry, specifically energy and force predictions on QM9 and rMD17 benchmarks, which is a core AI4Science application. While it mentions force predictions (which relate to responses to atomic displacements), the focus is on model compression/quantization techniques rather than systematically predicting system responses to perturbations."
  },
  {
    "id": "http://arxiv.org/abs/2601.02207v1",
    "title": "Risk-Averse Markov Decision Processes: Applications to Electricity Grid and Reservoir Management",
    "summary": "This paper develops risk-averse models to support system operators in planning and operating the electricity grid under uncertainty from renewable power generation. We incorporate financial risk hedging using conditional value at risk (CVaR) within a Markov Decision Process (MDP) framework and propose efficient, exact solution methods for these models. In addition, we introduce a power reliability-oriented risk measure and present new, computationally efficient models for risk-averse grid planning and operations.",
    "authors": [
      "Arash Khojaste",
      "Jonathan Pearce",
      "Daniela Pucci de Farias",
      "Geoffrey Pritchard",
      "Golbon Zakeri"
    ],
    "url": "http://arxiv.org/abs/2601.02207v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on risk-averse optimization models for electricity grid and reservoir management using Markov Decision Processes and financial risk measures (CVaR). It does not involve AI techniques for scientific discovery in domains like biology, chemistry, or physics, nor does it specifically address predicting system responses to perturbations."
  },
  {
    "id": "http://arxiv.org/abs/2601.02206v1",
    "title": "Seeing the Unseen: Zooming in the Dark with Event Cameras",
    "summary": "This paper addresses low-light video super-resolution (LVSR), aiming to restore high-resolution videos from low-light, low-resolution (LR) inputs. Existing LVSR methods often struggle to recover fine details due to limited contrast and insufficient high-frequency information. To overcome these challenges, we present RetinexEVSR, the first event-driven LVSR framework that leverages high-contrast event signals and Retinex-inspired priors to enhance video quality under low-light scenarios. Unlike previous approaches that directly fuse degraded signals, RetinexEVSR introduces a novel bidirectional cross-modal fusion strategy to extract and integrate meaningful cues from noisy event data and degraded RGB frames. Specifically, an illumination-guided event enhancement module is designed to progressively refine event features using illumination maps derived from the Retinex model, thereby suppressing low-light artifacts while preserving high-contrast details. Furthermore, we propose an event-guided reflectance enhancement module that utilizes the enhanced event features to dynamically recover reflectance details via a multi-scale fusion mechanism. Experimental results show that our RetinexEVSR achieves state-of-the-art performance on three datasets. Notably, on the SDSD benchmark, our method can get up to 2.95 dB gain while reducing runtime by 65% compared to prior event-based methods. Code: https://github.com/DachunKai/RetinexEVSR.",
    "authors": [
      "Dachun Kai",
      "Zeyu Xiao",
      "Huyue Zhu",
      "Jiaxiao Wang",
      "Yueyi Zhang",
      "Xiaoyan Sun"
    ],
    "url": "http://arxiv.org/abs/2601.02206v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on computer vision techniques for low-light video super-resolution using event cameras and Retinex models, which is an engineering/technology application rather than scientific discovery in fields like biology, chemistry, or physics. It does not involve predicting system responses to perturbations; instead, it addresses image enhancement through signal fusion and refinement."
  },
  {
    "id": "http://arxiv.org/abs/2601.02204v1",
    "title": "NextFlow: Unified Sequential Modeling Activates Multimodal Understanding and Generation",
    "summary": "We present NextFlow, a unified decoder-only autoregressive transformer trained on 6 trillion interleaved text-image discrete tokens. By leveraging a unified vision representation within a unified autoregressive architecture, NextFlow natively activates multimodal understanding and generation capabilities, unlocking abilities of image editing, interleaved content and video generation. Motivated by the distinct nature of modalities - where text is strictly sequential and images are inherently hierarchical - we retain next-token prediction for text but adopt next-scale prediction for visual generation. This departs from traditional raster-scan methods, enabling the generation of 1024x1024 images in just 5 seconds - orders of magnitude faster than comparable AR models. We address the instabilities of multi-scale generation through a robust training recipe. Furthermore, we introduce a prefix-tuning strategy for reinforcement learning. Experiments demonstrate that NextFlow achieves state-of-the-art performance among unified models and rivals specialized diffusion baselines in visual quality.",
    "authors": [
      "Huichao Zhang",
      "Liao Qu",
      "Yiheng Liu",
      "Hang Chen",
      "Yangyang Song",
      "Yongsheng Dong",
      "Shikun Sun",
      "Xian Li",
      "Xu Wang",
      "Yi Jiang",
      "Hu Ye",
      "Bo Chen",
      "Yiming Gao",
      "Peng Liu",
      "Akide Liu",
      "Zhipeng Yang",
      "Qili Deng",
      "Linjie Xing",
      "Jiyang Liu",
      "Zhao Wang",
      "Yang Zhou",
      "Mingcong Liu",
      "Yi Zhang",
      "Qian He",
      "Xiwei Hu",
      "Zhongqi Qi",
      "Jie Shao",
      "Zhiye Fu",
      "Shuai Wang",
      "Fangmin Chen",
      "Xuezhi Chai",
      "Zhihua Wu",
      "Yitong Wang",
      "Zehuan Yuan",
      "Daniel K. Du",
      "Xinglong Wu"
    ],
    "url": "http://arxiv.org/abs/2601.02204v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper presents NextFlow, a multimodal AI model for text and image generation/understanding, focusing on architectural innovations for faster image generation. It does not mention applications in scientific discovery domains like biology, chemistry, or physics, nor does it address predicting system responses to perturbations."
  },
  {
    "id": "http://arxiv.org/abs/2601.02202v1",
    "title": "Density-based topology optimization for turbulent fluid flow using the standard k-epsilon RANS model with wall-functions imposed through an implicit wall penalty formulation",
    "summary": "Turbulent flows have high requirements for very fine meshes near the boundary to ensure accuracy. In the context of topology optimization (TO), such fine meshes become unrealistic and common approaches are hampered by low accuracy and overestimation of boundary layer thickness. Wall-functions are a natural way to ease the computational requirements, but they are not naturally imposed in density-based TO due to the diffuse design parametrization. We propose an implicit wall-function formulation for the Reynolds-Averaged Navier-Stokes (RANS), standard k-epsilon model that extracts wall-normal information directly from the gradient of the design variable and enables a penalty-based formulation for imposing wall-functions to the RANS equations, without the need for body-fitted meshes. The method provides a reliable route to high Reynolds number turbulent topology optimization, delivering boundary layer accuracy comparable to explicit-wall body-fitted analyses, while retaining the flexibility of density-based TO. Furthermore, because wall effects are modeled using wall-functions, accurate solutions are obtained on substantially coarser meshes, leading to significant reductions in computational cost. The approach is validated on three canonical benchmarks over Reynolds numbers up to Re = 2e5: a pipe-bend; a U-bend; and a Tesla-valve. Across all cases, the proposed method accurately recovers near-wall velocity profiles, closely matching verification simulations on body-fitted meshes with explicit wall-functions. In contrast, a conventional turbulent TO formulation, without the proposed wall-function treatment, mispredicts boundary-layer development and yields sub-optimal results.",
    "authors": [
      "Amirhossein Bayat",
      "Hao Li",
      "Joe Alexandersen"
    ],
    "url": "http://arxiv.org/abs/2601.02202v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on developing a computational fluid dynamics method for topology optimization of turbulent flows using the RANS k-epsilon model with wall-functions. It does not involve artificial intelligence techniques or machine learning for scientific discovery. Additionally, it does not address predicting system responses to perturbations; instead, it presents a numerical formulation for steady-state turbulent flow optimization."
  },
  {
    "id": "http://arxiv.org/abs/2601.02201v1",
    "title": "CORE: Code-based Inverse Self-Training Framework with Graph Expansion for Virtual Agents",
    "summary": "The development of Multimodal Virtual Agents has made significant progress through the integration of Multimodal Large Language Models. However, mainstream training paradigms face key challenges: Behavior Cloning is simple and effective through imitation but suffers from low behavioral diversity, while Reinforcement Learning is capable of discovering novel strategies through exploration but heavily relies on manually designed reward functions. To address the conflict between these two methods, we present CORE, a Code-based Inverse Self-Training Framework with Graph Expansion that bridges imitation and exploration, offering a novel training framework that promotes behavioral diversity while eliminating the reliance on manually reward design. Specifically, we introduce Semantic Code Abstraction to automatically infers reward functions from expert demonstrations without manual design. The inferred reward function, referred to as the Label Function, is executable code that verifies one key step within a task. Building on this, we propose Strategy Graph Expansion to enhance in-domain behavioral diversity, which constructs a multi-path graph called Strategy Graph that captures diverse valid solutions beyond expert demonstrations. Furthermore, we introduce Trajectory-Guided Extrapolation, which enriches out-of-domain behavioral diversity by utilizing both successful and failed trajectories to expand the task space. Experiments on Web and Android platforms demonstrate that CORE significantly improves both overall performance and generalization, highlighting its potential as a robust and generalizable training paradigm for building powerful virtual agents.",
    "authors": [
      "Keyu Wang",
      "Bingchen Miao",
      "Wendong Bu",
      "Yu Wu",
      "Juncheng Li",
      "Shengyu Zhang",
      "Wenqiao Zhang",
      "Siliang Tang",
      "Jun Xiao",
      "Yueting Zhuang"
    ],
    "url": "http://arxiv.org/abs/2601.02201v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on training multimodal virtual agents for web and Android platforms, addressing imitation vs. exploration trade-offs in agent behavior. It does not involve scientific discovery in biology, chemistry, or physics (AI4Science), nor does it study system responses to perturbations (Perturbation Prediction)."
  },
  {
    "id": "http://arxiv.org/abs/2601.02200v1",
    "title": "Code for Machines, Not Just Humans: Quantifying AI-Friendliness with Code Health Metrics",
    "summary": "We are entering a hybrid era in which human developers and AI coding agents work in the same codebases. While industry practice has long optimized code for human comprehension, it is increasingly important to ensure that LLMs with different capabilities can edit code reliably. In this study, we investigate the concept of ``AI-friendly code'' via LLM-based refactoring on a dataset of 5,000 Python files from competitive programming. We find a meaningful association between CodeHealth, a quality metric calibrated for human comprehension, and semantic preservation after AI refactoring. Our findings confirm that human-friendly code is also more compatible with AI tooling. These results suggest that organizations can use CodeHealth to guide where AI interventions are lower risk and where additional human oversight is warranted. Investing in maintainability not only helps humans; it also prepares for large-scale AI adoption.",
    "authors": [
      "Markus Borg",
      "Nadim Hagatulah",
      "Adam Tornhill",
      "Emma Söderberg"
    ],
    "url": "http://arxiv.org/abs/2601.02200v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on AI-assisted software engineering and code quality metrics for AI coding agents, not scientific discovery in natural sciences. It examines code refactoring and maintainability, not predicting system responses to perturbations."
  },
  {
    "id": "http://arxiv.org/abs/2601.02198v1",
    "title": "Mind the Gap: Continuous Magnification Sampling for Pathology Foundation Models",
    "summary": "In histopathology, pathologists examine both tissue architecture at low magnification and fine-grained morphology at high magnification. Yet, the performance of pathology foundation models across magnifications and the effect of magnification sampling during training remain poorly understood. We model magnification sampling as a multi-source domain adaptation problem and develop a simple theoretical framework that reveals systematic trade-offs between sampling strategies. We show that the widely used discrete uniform sampling of magnifications (0.25, 0.5, 1.0, 2.0 mpp) leads to degradation at intermediate magnifications. We introduce continuous magnification sampling, which removes gaps in magnification coverage while preserving performance at standard scales. Further, we derive sampling distributions that optimize representation quality across magnification scales. To evaluate these strategies, we introduce two new benchmarks (TCGA-MS, BRACS-MS) with appropriate metrics. Our experiments show that continuous sampling substantially improves over discrete sampling at intermediate magnifications, with gains of up to 4 percentage points in balanced classification accuracy, and that optimized distributions can further improve performance. Finally, we evaluate current histopathology foundation models, finding that magnification is a primary driver of performance variation across models. Our work paves the way towards future pathology foundation models that perform reliably across magnifications.",
    "authors": [
      "Alexander Möllers",
      "Julius Hense",
      "Florian Schulz",
      "Timo Milbich",
      "Maximilian Alber",
      "Lukas Ruff"
    ],
    "url": "http://arxiv.org/abs/2601.02198v1",
    "published": "2026-01-05",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "The paper develops AI methods (foundation models and sampling strategies) specifically for histopathology, a biological/medical science domain, making it AI4Science. While it studies performance variation across magnifications, this is not about predicting system responses to perturbations but about optimizing training strategies for consistent performance."
  },
  {
    "id": "http://arxiv.org/abs/2601.02196v1",
    "title": "ACDZero: Graph-Embedding-Based Tree Search for Mastering Automated Cyber Defense",
    "summary": "Automated cyber defense (ACD) seeks to protect computer networks with minimal or no human intervention, reacting to intrusions by taking corrective actions such as isolating hosts, resetting services, deploying decoys, or updating access controls. However, existing approaches for ACD, such as deep reinforcement learning (RL), often face difficult exploration in complex networks with large decision/state spaces and thus require an expensive amount of samples. Inspired by the need to learn sample-efficient defense policies, we frame ACD in CAGE Challenge 4 (CAGE-4 / CC4) as a context-based partially observable Markov decision problem and propose a planning-centric defense policy based on Monte Carlo Tree Search (MCTS). It explicitly models the exploration-exploitation tradeoff in ACD and uses statistical sampling to guide exploration and decision making. We make novel use of graph neural networks (GNNs) to embed observations from the network as attributed graphs, to enable permutation-invariant reasoning over hosts and their relationships. To make our solution practical in complex search spaces, we guide MCTS with learned graph embeddings and priors over graph-edit actions, combining model-free generalization and policy distillation with look-ahead planning. We evaluate the resulting agent on CC4 scenarios involving diverse network structures and adversary behaviors, and show that our search-guided, graph-embedding-based planning improves defense reward and robustness relative to state-of-the-art RL baselines.",
    "authors": [
      "Yu Li",
      "Sizhe Tang",
      "Rongqian Chen",
      "Fei Xu Yu",
      "Guangyu Jiang",
      "Mahdi Imani",
      "Nathaniel D. Bastian",
      "Tian Lan"
    ],
    "url": "http://arxiv.org/abs/2601.02196v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": true,
    "reasoning": "The paper focuses on automated cyber defense using AI techniques (MCTS, GNNs) for network security, not scientific discovery in fields like biology, chemistry, or physics. It relates to perturbation prediction as it involves modeling how computer networks respond to adversarial intrusions (perturbations) and planning defensive actions accordingly."
  },
  {
    "id": "http://arxiv.org/abs/2601.02193v1",
    "title": "Learning with Monotone Adversarial Corruptions",
    "summary": "We study the extent to which standard machine learning algorithms rely on exchangeability and independence of data by introducing a monotone adversarial corruption model. In this model, an adversary, upon looking at a \"clean\" i.i.d. dataset, inserts additional \"corrupted\" points of their choice into the dataset. These added points are constrained to be monotone corruptions, in that they get labeled according to the ground-truth target function. Perhaps surprisingly, we demonstrate that in this setting, all known optimal learning algorithms for binary classification can be made to achieve suboptimal expected error on a new independent test point drawn from the same distribution as the clean dataset. On the other hand, we show that uniform convergence-based algorithms do not degrade in their guarantees. Our results showcase how optimal learning algorithms break down in the face of seemingly helpful monotone corruptions, exposing their overreliance on exchangeability.",
    "authors": [
      "Kasper Green Larsen",
      "Chirag Pabbaraju",
      "Abhishek Shetty"
    ],
    "url": "http://arxiv.org/abs/2601.02193v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": true,
    "reasoning": "The paper focuses on analyzing how machine learning algorithms respond to adversarial data corruptions (perturbations), specifically studying their robustness and error behavior when data exchangeability is violated. This aligns with perturbation prediction in AI systems. It does not involve applying AI to scientific discovery in domains like biology, chemistry, or physics."
  },
  {
    "id": "http://arxiv.org/abs/2601.02189v1",
    "title": "QuIC: A Quantum-Inspired Interaction Classifier for Revitalizing Shallow CNNs in Fine-Grained Recognition",
    "summary": "Deploying deep learning models for Fine-Grained Visual Classification (FGVC) on resource-constrained edge devices remains a significant challenge. While deep architectures achieve high accuracy on benchmarks like CUB-200-2011, their computational cost is often prohibitive. Conversely, shallow networks (e.g., AlexNet, VGG) offer efficiency but fail to distinguish visually similar sub-categories. This is because standard Global Average Pooling (GAP) heads capture only first-order statistics, missing the subtle high-order feature interactions required for FGVC. While Bilinear CNNs address this, they suffer from high feature dimensionality and instability during training. To bridge this gap, we propose the Quantum-inspired Interaction Classifier (QuIC). Drawing inspiration from quantum mechanics, QuIC models feature channels as interacting quantum states and captures second-order feature covariance via a learnable observable operator. Designed as a lightweight, plug-and-play module, QuIC supports stable, single-stage end-to-end training without exploding feature dimensions. Experimental results demonstrate that QuIC significantly revitalizes shallow backbones: it boosts the Top-1 accuracy of VGG16 by nearly 20% and outperforms state-of-the-art attention mechanisms (SE-Block) on ResNet18. Qualitative analysis, including t-SNE visualization, further confirms that QuIC resolves ambiguous cases by explicitly attending to fine-grained discriminative features and enforcing compact intra-class clustering.",
    "authors": [
      "Cheng Ying Wu",
      "Yen Jui Chang"
    ],
    "url": "http://arxiv.org/abs/2601.02189v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper proposes a quantum-inspired computer vision method for fine-grained image classification, focusing on improving shallow CNN architectures. It does not apply AI to scientific discovery in fields like biology, chemistry, or physics (AI4Science), nor does it involve predicting system responses to perturbations. The quantum inspiration is metaphorical for feature interaction modeling, not actual quantum computing or physics applications."
  },
  {
    "id": "http://arxiv.org/abs/2601.02172v1",
    "title": "A stable and accurate X-FFT solver for linear elastic homogenization problems in 3D",
    "summary": "Although FFT-based methods are renowned for their numerical efficiency and stability, traditional discretizations fail to capture material interfaces that are not aligned with the grid, resulting in suboptimal accuracy. To address this issue, the work at hand introduces a novel FFT-based solver that achieves interface-conforming accuracy for three-dimensional mechanical problems. More precisely, we integrate the extended finite element (X-FEM) discretization into the FFT-based framework, leveraging its ability to resolve discontinuities via additional shape functions. We employ the modified abs(olute) enrichment and develop a preconditioner based on the concept of strongly stable GFEM, which mitigates the conditioning issues observed in traditional X-FEM implementations. Our computational studies demonstrate that the developed X-FFT solver achieves interface-conforming accuracy, numerical efficiency, and stability when solving three-dimensional linear elastic homogenization problems with smooth material interfaces.",
    "authors": [
      "Flavia Gehrig",
      "Matti Schneider"
    ],
    "url": "http://arxiv.org/abs/2601.02172v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper introduces a novel FFT-based solver combining X-FEM discretization for 3D linear elastic homogenization problems, focusing on numerical methods for material interface accuracy and stability. It does not involve AI/ML techniques for scientific discovery (AI4Science) nor specifically address predicting system responses to perturbations (Perturbation Prediction)."
  },
  {
    "id": "http://arxiv.org/abs/2601.02170v1",
    "title": "Streaming Hallucination Detection in Long Chain-of-Thought Reasoning",
    "summary": "Long chain-of-thought (CoT) reasoning improves the performance of large language models, yet hallucinations in such settings often emerge subtly and propagate across reasoning steps. We suggest that hallucination in long CoT reasoning is better understood as an evolving latent state rather than a one-off erroneous event. Accordingly, we treat step-level hallucination judgments as local observations and introduce a cumulative prefix-level hallucination signal that tracks the global evolution of the reasoning state over the entire trajectory. Overall, our approach enables streaming hallucination detection in long CoT reasoning, providing real-time, interpretable evidence.",
    "authors": [
      "Haolang Lu",
      "Minghui Pan",
      "Ripeng Li",
      "Guoshun Nan",
      "Jialin Zhuang",
      "Zijie Zhao",
      "Zhongxiang Sun",
      "Kun Wang",
      "Yang Liu"
    ],
    "url": "http://arxiv.org/abs/2601.02170v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on detecting hallucinations in long chain-of-thought reasoning for large language models, which is a methodological AI/ML advancement. It does not apply AI to scientific discovery in domains like biology, chemistry, or physics (AI4Science), nor does it involve predicting system responses to perturbations (Perturbation Prediction)."
  },
  {
    "id": "http://arxiv.org/abs/2601.02163v1",
    "title": "EverMemOS: A Self-Organizing Memory Operating System for Structured Long-Horizon Reasoning",
    "summary": "Large Language Models (LLMs) are increasingly deployed as long-term interactive agents, yet their limited context windows make it difficult to sustain coherent behavior over extended interactions. Existing memory systems often store isolated records and retrieve fragments, limiting their ability to consolidate evolving user states and resolve conflicts. We introduce EverMemOS, a self-organizing memory operating system that implements an engram-inspired lifecycle for computational memory. Episodic Trace Formation converts dialogue streams into MemCells that capture episodic traces, atomic facts, and time-bounded Foresight signals. Semantic Consolidation organizes MemCells into thematic MemScenes, distilling stable semantic structures and updating user profiles. Reconstructive Recollection performs MemScene-guided agentic retrieval to compose the necessary and sufficient context for downstream reasoning. Experiments on LoCoMo and LongMemEval show that EverMemOS achieves state-of-the-art performance on memory-augmented reasoning tasks. We further report a profile study on PersonaMem v2 and qualitative case studies illustrating chat-oriented capabilities such as user profiling and Foresight. Code is available at https://github.com/EverMind-AI/EverMemOS.",
    "authors": [
      "Chuanrui Hu",
      "Xingze Gao",
      "Zuyi Zhou",
      "Dannong Xu",
      "Yi Bai",
      "Xintong Li",
      "Hui Zhang",
      "Tong Li",
      "Chong Zhang",
      "Lidong Bing",
      "Yafeng Deng"
    ],
    "url": "http://arxiv.org/abs/2601.02163v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on developing a memory system (EverMemOS) for Large Language Models to improve long-term interactive reasoning, with applications in dialogue systems, user profiling, and memory-augmented tasks. It does not address scientific discovery in fields like biology, chemistry, or physics (AI4Science), nor does it involve predicting system responses to perturbations (Perturbation Prediction)."
  },
  {
    "id": "http://arxiv.org/abs/2601.02158v1",
    "title": "FormationEval, an open multiple-choice benchmark for petroleum geoscience",
    "summary": "This paper presents FormationEval, an open multiple-choice question benchmark for evaluating language models on petroleum geoscience and subsurface disciplines. The dataset contains 505 questions across seven domains including petrophysics, petroleum geology and reservoir engineering, derived from three authoritative sources using a reasoning model with detailed instructions and a concept-based approach that avoids verbatim copying of copyrighted text. Each question includes source metadata to support traceability and audit. The evaluation covers 72 models from major providers including OpenAI, Anthropic, Google, Meta and open-weight alternatives. The top performers achieve over 97\\% accuracy, with Gemini 3 Pro Preview reaching 99.8\\%, while tier and domain gaps persist. Among open-weight models, GLM-4.7 leads at 98.6\\%, with several DeepSeek, Llama, Qwen and Mistral models also exceeding 93\\%. The performance gap between open-weight and closed models is narrower than expected, with several lower-cost open-weight models exceeding 90\\% accuracy. Petrophysics emerges as the most challenging domain across all models, while smaller models show wider performance variance. Residual length bias in the dataset (correct answers tend to be longer) is documented along with bias mitigation strategies applied during construction. The benchmark, evaluation code and results are publicly available.",
    "authors": [
      "Almaz Ermilov"
    ],
    "url": "http://arxiv.org/abs/2601.02158v1",
    "published": "2026-01-05",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "The paper presents FormationEval, a benchmark for evaluating language models on petroleum geoscience and subsurface disciplines, which involves using AI (language models) for scientific applications in geoscience, falling under AI4Science. It does not involve predicting system responses to perturbations, so it is not related to perturbation prediction."
  },
  {
    "id": "http://arxiv.org/abs/2601.02157v1",
    "title": "Multi-fidelity graph-based neural networks architectures to learn Navier-Stokes solutions on non-parametrized 2D domains",
    "summary": "We propose a graph-based, multi-fidelity learning framework for the prediction of stationary Navier--Stokes solutions in non-parametrized two-dimensional geometries. The method is designed to guide the learning process through successive approximations, starting from reduced-order and full Stokes models, and progressively approaching the Navier--Stokes solution. To effectively capture both local and long-range dependencies in the velocity and pressure fields, we combine graph neural networks with Transformer and Mamba architectures. While Transformers achieve the highest accuracy, we show that Mamba can be successfully adapted to graph-structured data through an unsupervised node-ordering strategy. The Mamba approach significantly reduces computational cost while maintaining performance. Physical knowledge is embedded directly into the architecture through an encoding -- processing -- physics informed decoding pipeline. Derivatives are computed through algebraic operators constructed via the Weighted Least Squares method. The flexibility of these operators allows us not only to make the output obey the governing equations, but also to constrain selected hidden features to satisfy mass conservation. We introduce additional physical biases through an enriched graph convolution with the same differential operators describing the PDEs. Overall, we successfully guide the learning process by physical knowledge and fluid dynamics insights, leading to more regular and accurate predictions",
    "authors": [
      "Francesco Songia",
      "Raoul Sallé de Chou",
      "Hugues Talbot",
      "Irene Vignon-Clementel"
    ],
    "url": "http://arxiv.org/abs/2601.02157v1",
    "published": "2026-01-05",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "The paper applies AI (graph neural networks with Transformer/Mamba architectures) to solve physics problems (Navier-Stokes equations in fluid dynamics), fitting AI4Science. It focuses on learning stationary solutions rather than predicting responses to perturbations, so not perturbation prediction."
  },
  {
    "id": "http://arxiv.org/abs/2601.02151v1",
    "title": "Entropy-Adaptive Fine-Tuning: Resolving Confident Conflicts to Mitigate Forgetting",
    "summary": "Supervised Fine-Tuning (SFT) is the standard paradigm for domain adaptation, yet it frequently incurs the cost of catastrophic forgetting. In sharp contrast, on-policy Reinforcement Learning (RL) effectively preserves general capabilities. We investigate this discrepancy and identify a fundamental distributional gap: while RL aligns with the model's internal belief, SFT forces the model to fit external supervision. This mismatch often manifests as \"Confident Conflicts\" tokens characterized by low probability but low entropy. In these instances, the model is highly confident in its own prediction but is forced to learn a divergent ground truth, triggering destructive gradient updates. To address this, we propose Entropy-Adaptive Fine-Tuning (EAFT). Unlike methods relying solely on prediction probability, EAFT utilizes token-level entropy as a gating mechanism to distinguish between epistemic uncertainty and knowledge conflict. This allows the model to learn from uncertain samples while suppressing gradients on conflicting data. Extensive experiments on Qwen and GLM series (ranging from 4B to 32B parameters) across mathematical, medical, and agentic domains confirm our hypothesis. EAFT consistently matches the downstream performance of standard SFT while significantly mitigating the degradation of general capabilities.",
    "authors": [
      "Muxi Diao",
      "Lele Yang",
      "Wuxuan Gong",
      "Yutong Zhang",
      "Zhonghao Yan",
      "Yufei Han",
      "Kongming Liang",
      "Weiran Xu",
      "Zhanyu Ma"
    ],
    "url": "http://arxiv.org/abs/2601.02151v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on improving fine-tuning methods for large language models to mitigate catastrophic forgetting, with experiments in mathematical, medical, and agentic domains. It does not involve using AI for scientific discovery in traditional sciences (biology, chemistry, physics) nor does it address predicting system responses to perturbations."
  },
  {
    "id": "http://arxiv.org/abs/2601.02149v1",
    "title": "AI-enhanced tuning of quantum dot Hamiltonians toward Majorana modes",
    "summary": "We propose a neural network-based model capable of learning the broad landscape of working regimes in quantum dot simulators, and using this knowledge to autotune these devices - based on transport measurements - toward obtaining Majorana modes in the structure. The model is trained in an unsupervised manner on synthetic data in the form of conductance maps, using a physics-informed loss that incorporates key properties of Majorana zero modes. We show that, with appropriate training, a deep vision-transformer network can efficiently memorize relation between Hamiltonian parameters and structures on conductance maps and use it to propose parameters update for a quantum dot chain that drive the system toward topological phase. Starting from a broad range of initial detunings in parameter space, a single update step is sufficient to generate nontrivial zero modes. Moreover, by enabling an iterative tuning procedure - where the system acquires updated conductance maps at each step - we demonstrate that the method can address a much larger region of the parameter space.",
    "authors": [
      "Mateusz Krawczyk",
      "Jarosław Pawłowski"
    ],
    "url": "http://arxiv.org/abs/2601.02149v1",
    "published": "2026-01-05",
    "is_ai4science": true,
    "is_perturbation": true,
    "reasoning": "The paper uses AI (neural network) for scientific discovery in physics by autotuning quantum dot devices toward Majorana modes, and involves predicting parameter updates that perturb the system toward desired states."
  },
  {
    "id": "http://arxiv.org/abs/2601.02147v1",
    "title": "BiPrompt: Bilateral Prompt Optimization for Visual and Textual Debiasing in Vision-Language Models",
    "summary": "Vision language foundation models such as CLIP exhibit impressive zero-shot generalization yet remain vulnerable to spurious correlations across visual and textual modalities. Existing debiasing approaches often address a single modality either visual or textual leading to partial robustness and unstable adaptation under distribution shifts. We propose a bilateral prompt optimization framework (BiPrompt) that simultaneously mitigates non-causal feature reliance in both modalities during test-time adaptation. On the visual side, it employs structured attention-guided erasure to suppress background activations and enforce orthogonal prediction consistency between causal and spurious regions. On the textual side, it introduces balanced prompt normalization, a learnable re-centering mechanism that aligns class embeddings toward an isotropic semantic space. Together, these modules jointly minimize conditional mutual information between spurious cues and predictions, steering the model toward causal, domain invariant reasoning without retraining or domain supervision. Extensive evaluations on real-world and synthetic bias benchmarks demonstrate consistent improvements in both average and worst-group accuracies over prior test-time debiasing methods, establishing a lightweight yet effective path toward trustworthy and causally grounded vision-language adaptation.",
    "authors": [
      "Sunny Gupta",
      "Shounak Das",
      "Amit Sethi"
    ],
    "url": "http://arxiv.org/abs/2601.02147v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on debiasing vision-language models (CLIP) through prompt optimization and attention mechanisms, which is a methodological improvement in AI robustness rather than applying AI to scientific discovery. It does not involve predicting system responses to perturbations; instead, it addresses spurious correlations during test-time adaptation."
  },
  {
    "id": "http://arxiv.org/abs/2601.02145v1",
    "title": "Feature-based Inversion of 2.5D Controlled Source Electromagnetic Data using Generative Priors",
    "summary": "In this study, we investigate feature-based 2.5D controlled source marine electromagnetic (mCSEM) data inversion using generative priors. Two-and-half dimensional modeling using finite difference method (FDM) is adopted to compute the response of horizontal electric dipole (HED) excitation. Rather than using a neural network to approximate the entire inverse mapping in a black-box manner, we adopt a plug-andplay strategy in which a variational autoencoder (VAE) is used solely to learn prior information on conductivity distributions. During the inversion process, the conductivity model is iteratively updated using the Gauss Newton method, while the model space is constrained by projections onto the learned VAE decoder. This framework preserves explicit control over data misfit and enables flexible adaptation to different survey configurations. Numerical and field experiments demonstrate that the proposed approach effectively incorporates prior information, improves reconstruction accuracy, and exhibits good generalization performance.",
    "authors": [
      "Hongyu Zhou",
      "Haoran Sun",
      "Rui Guo",
      "Maokun Li",
      "Fan Yang",
      "Shenheng Xu"
    ],
    "url": "http://arxiv.org/abs/2601.02145v1",
    "published": "2026-01-05",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "The paper uses a variational autoencoder (VAE) as a generative prior in geophysical inversion of electromagnetic data, applying AI to enhance scientific discovery in physics/geophysics. It does not focus on predicting system responses to perturbations; instead, it involves iterative model updating using the Gauss Newton method for inversion."
  },
  {
    "id": "http://arxiv.org/abs/2601.02144v1",
    "title": "Routing by Analogy: kNN-Augmented Expert Assignment for Mixture-of-Experts",
    "summary": "Mixture-of-Experts (MoE) architectures scale large language models efficiently by employing a parametric \"router\" to dispatch tokens to a sparse subset of experts. Typically, this router is trained once and then frozen, rendering routing decisions brittle under distribution shifts. We address this limitation by introducing kNN-MoE, a retrieval-augmented routing framework that reuses optimal expert assignments from a memory of similar past cases. This memory is constructed offline by directly optimizing token-wise routing logits to maximize the likelihood on a reference set. Crucially, we use the aggregate similarity of retrieved neighbors as a confidence-driven mixing coefficient, thus allowing the method to fall back to the frozen router when no relevant cases are found. Experiments show kNN-MoE outperforms zero-shot baselines and rivals computationally expensive supervised fine-tuning.",
    "authors": [
      "Boxuan Lyu",
      "Soichiro Murakami",
      "Hidetaka Kamigaito",
      "Peinan Zhang"
    ],
    "url": "http://arxiv.org/abs/2601.02144v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on improving routing mechanisms in Mixture-of-Experts architectures for large language models, specifically addressing brittleness under distribution shifts through retrieval-augmented methods. It does not involve applying AI to scientific discovery domains like biology, chemistry, or physics (AI4Science), nor does it address predicting system responses to perturbations (Perturbation Prediction)."
  },
  {
    "id": "http://arxiv.org/abs/2601.02138v1",
    "title": "Edge-aware GAT-based protein binding site prediction",
    "summary": "Accurate identification of protein binding sites is crucial for understanding biomolecular interaction mechanisms and for the rational design of drug targets. Traditional predictive methods often struggle to balance prediction accuracy with computational efficiency when capturing complex spatial conformations. To address this challenge, we propose an Edge-aware Graph Attention Network (Edge-aware GAT) model for the fine-grained prediction of binding sites across various biomolecules, including proteins, DNA/RNA, ions, ligands, and lipids. Our method constructs atom-level graphs and integrates multidimensional structural features, including geometric descriptors, DSSP-derived secondary structure, and relative solvent accessibility (RSA), to generate spatially aware embedding vectors. By incorporating interatomic distances and directional vectors as edge features within the attention mechanism, the model significantly enhances its representation capacity. On benchmark datasets, our model achieves an ROC-AUC of 0.93 for protein-protein binding site prediction, outperforming several state-of-the-art methods. The use of directional tensor propagation and residue-level attention pooling further improves both binding site localization and the capture of local structural details. Visualizations using PyMOL confirm the model's practical utility and interpretability. To facilitate community access and application, we have deployed a publicly accessible web server at http://119.45.201.89:5000/. In summary, our approach offers a novel and efficient solution that balances prediction accuracy, generalization, and interpretability for identifying functional sites in proteins.",
    "authors": [
      "Weisen Yang",
      "Hanqing Zhang",
      "Wangren Qiu",
      "Xuan Xiao",
      "Weizhong Lin"
    ],
    "url": "http://arxiv.org/abs/2601.02138v1",
    "published": "2026-01-05",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "The paper uses an Edge-aware Graph Attention Network (a deep learning/AI method) to predict protein binding sites, which is a biological discovery task in structural biology. It does not involve predicting system responses to perturbations; it focuses on static structural prediction of binding sites."
  },
  {
    "id": "http://arxiv.org/abs/2601.02134v1",
    "title": "Complexity of quadratic penalty methods with adaptive accuracy under a PL condition for the constraints",
    "summary": "We study the quadratic penalty method (QPM) for smooth nonconvex optimization problems with equality constraints. Assuming the constraint violation satisfies the PL condition near the feasible set, we derive sharper worst-case complexity bounds for obtaining approximate first-order KKT points. When the objective and constraints are twice continuously differentiable, we show that QPM equipped with a suitable first-order inner solver requires at most $O(\\varepsilon_{0}^{-1}\\varepsilon_{1}^{-2})$ first-order oracle calls to find an $(\\varepsilon_{0},\\varepsilon_{1})$-approximate KKT point -- that is, a point that is $\\varepsilon_{0}$-approximately feasible and $\\varepsilon_{1}$-approximately stationary. Furthermore, when the objective and constraints are three times continuously differentiable, we show that QPM with a suitable second-order inner solver requires at most $O\\left(\\varepsilon_{0}^{-1/2}\\varepsilon_{1}^{-3/2}\\right)$ second-order oracle calls to find an $(\\varepsilon_{0},\\varepsilon_{1})$-approximate KKT point. We also introduce an adaptive, feasibility-aware stopping criterion for the subproblems, which relaxes the stationarity tolerance when far from feasibility. This rule preserves all theoretical guarantees while substantially reducing computational effort in practice.",
    "authors": [
      "Florentin Goyens",
      "Geovani N. Grapiglia"
    ],
    "url": "http://arxiv.org/abs/2601.02134v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on theoretical optimization methods (quadratic penalty method) for nonconvex constrained problems, deriving complexity bounds and proposing adaptive stopping criteria. It does not mention AI techniques, scientific discovery applications, or perturbation prediction in dynamical systems."
  },
  {
    "id": "http://arxiv.org/abs/2601.02126v1",
    "title": "Remote Sensing Change Detection via Weak Temporal Supervision",
    "summary": "Semantic change detection in remote sensing aims to identify land cover changes between bi-temporal image pairs. Progress in this area has been limited by the scarcity of annotated datasets, as pixel-level annotation is costly and time-consuming. To address this, recent methods leverage synthetic data or generate artificial change pairs, but out-of-domain generalization remains limited. In this work, we introduce a weak temporal supervision strategy that leverages additional temporal observations of existing single-temporal datasets, without requiring any new annotations. Specifically, we extend single-date remote sensing datasets with new observations acquired at different times and train a change detection model by assuming that real bi-temporal pairs mostly contain no change, while pairing images from different locations to generate change examples. To handle the inherent noise in these weak labels, we employ an object-aware change map generation and an iterative refinement process. We validate our approach on extended versions of the FLAIR and IAILD aerial datasets, achieving strong zero-shot and low-data regime performance across different benchmarks. Lastly, we showcase results over large areas in France, highlighting the scalability potential of our method.",
    "authors": [
      "Xavier Bou",
      "Elliot Vincent",
      "Gabriele Facciolo",
      "Rafael Grompone von Gioi",
      "Jean-Michel Morel",
      "Thibaud Ehret"
    ],
    "url": "http://arxiv.org/abs/2601.02126v1",
    "published": "2026-01-05",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "The paper applies AI (specifically deep learning for change detection) to remote sensing data for monitoring land cover changes, which falls under Earth/environmental science applications of AI for scientific discovery. It does not involve predicting system responses to perturbations; instead, it focuses on detecting changes between temporal observations without perturbation modeling."
  },
  {
    "id": "http://arxiv.org/abs/2601.02125v1",
    "title": "SingingBot: An Avatar-Driven System for Robotic Face Singing Performance",
    "summary": "Equipping robotic faces with singing capabilities is crucial for empathetic Human-Robot Interaction. However, existing robotic face driving research primarily focuses on conversations or mimicking static expressions, struggling to meet the high demands for continuous emotional expression and coherence in singing. To address this, we propose a novel avatar-driven framework for appealing robotic singing. We first leverage portrait video generation models embedded with extensive human priors to synthesize vivid singing avatars, providing reliable expression and emotion guidance. Subsequently, these facial features are transferred to the robot via semantic-oriented mapping functions that span a wide expression space. Furthermore, to quantitatively evaluate the emotional richness of robotic singing, we propose the Emotion Dynamic Range metric to measure the emotional breadth within the Valence-Arousal space, revealing that a broad emotional spectrum is crucial for appealing performances. Comprehensive experiments prove that our method achieves rich emotional expressions while maintaining lip-audio synchronization, significantly outperforming existing approaches.",
    "authors": [
      "Zhuoxiong Xu",
      "Xuanchen Li",
      "Yuhao Cheng",
      "Fei Xu",
      "Yichao Yan",
      "Xiaokang Yang"
    ],
    "url": "http://arxiv.org/abs/2601.02125v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on robotic face animation for singing performance using avatar generation and emotion mapping, which falls under human-robot interaction and computer vision, not scientific discovery in natural sciences. It does not involve predicting system responses to perturbations, but rather expression transfer and emotional evaluation."
  },
  {
    "id": "http://arxiv.org/abs/2601.02123v1",
    "title": "DeCode: Decoupling Content and Delivery for Medical QA",
    "summary": "Large language models (LLMs) exhibit strong medical knowledge and can generate factually accurate responses. However, existing models often fail to account for individual patient contexts, producing answers that are clinically correct yet poorly aligned with patients' needs. In this work, we introduce DeCode, a training-free, model-agnostic framework that adapts existing LLMs to produce contextualized answers in clinical settings. We evaluate DeCode on OpenAI HealthBench, a comprehensive and challenging benchmark designed to assess clinical relevance and validity of LLM responses. DeCode improves the previous state of the art from $28.4\\%$ to $49.8\\%$, corresponding to a $75\\%$ relative improvement. Experimental results suggest the effectiveness of DeCode in improving clinical question answering of LLMs.",
    "authors": [
      "Po-Jen Ko",
      "Chen-Han Tsai",
      "Yu-Shao Peng"
    ],
    "url": "http://arxiv.org/abs/2601.02123v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on improving clinical question answering by adapting LLMs to patient contexts, which falls under healthcare AI applications rather than AI for scientific discovery in fields like biology or physics. It does not involve predicting system responses to perturbations, as it addresses contextual adaptation in medical QA rather than perturbation analysis."
  },
  {
    "id": "http://arxiv.org/abs/2601.02121v1",
    "title": "Inferring Network Evolutionary History via Structure-State Coupled Learning",
    "summary": "Inferring a network's evolutionary history from a single final snapshot with limited temporal annotations is fundamental yet challenging. Existing approaches predominantly rely on topology alone, which often provides insufficient and noisy cues. This paper leverages network steady-state dynamics -- converged node states under a given dynamical process -- as an additional and widely accessible observation for network evolution history inference. We propose CS$^2$, which explicitly models structure-state coupling to capture how topology modulates steady states and how the two signals jointly improve edge discrimination for formation-order recovery. Experiments on six real temporal networks, evaluated under multiple dynamical processes, show that CS$^2$ consistently outperforms strong baselines, improving pairwise edge precedence accuracy by 4.0% on average and global ordering consistency (Spearman-$ρ$) by 7.7% on average. CS$^2$ also more faithfully recovers macroscopic evolution trajectories such as clustering formation, degree heterogeneity, and hub growth. Moreover, a steady-state-only variant remains competitive when reliable topology is limited, highlighting steady states as an independent signal for evolution inference.",
    "authors": [
      "En Xu",
      "Shihe Zhou",
      "Huandong Wang",
      "Jingtao Ding",
      "Yong Li"
    ],
    "url": "http://arxiv.org/abs/2601.02121v1",
    "published": "2026-01-05",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "The paper develops a machine learning method (CS²) that couples network structure with steady-state dynamics to infer evolutionary history, which is applicable to scientific domains like biology (e.g., protein interaction networks) and social systems. It does not focus on predicting responses to external perturbations but on reconstructing historical evolution from static observations."
  },
  {
    "id": "http://arxiv.org/abs/2601.02112v1",
    "title": "Car Drag Coefficient Prediction from 3D Point Clouds Using a Slice-Based Surrogate Model",
    "summary": "The automotive industry's pursuit of enhanced fuel economy and performance necessitates efficient aerodynamic design. However, traditional evaluation methods such as computational fluid dynamics (CFD) and wind tunnel testing are resource intensive, hindering rapid iteration in the early design stages. Machine learning-based surrogate models offer a promising alternative, yet many existing approaches suffer from high computational complexity, limited interpretability, or insufficient accuracy for detailed geometric inputs. This paper introduces a novel lightweight surrogate model for the prediction of the aerodynamic drag coefficient (Cd) based on a sequential slice-wise processing of the geometry of the 3D vehicle. Inspired by medical imaging, 3D point clouds of vehicles are decomposed into an ordered sequence of 2D cross-sectional slices along the stream-wise axis. Each slice is encoded by a lightweight PointNet2D module, and the sequence of slice embeddings is processed by a bidirectional LSTM to capture longitudinal geometric evolution. The model, trained and evaluated on the DrivAerNet++ dataset, achieves a high coefficient of determination (R^2 > 0.9528) and a low mean absolute error (MAE approx 6.046 x 10^{-3}) in Cd prediction. With an inference time of approximately 0.025 seconds per sample on a consumer-grade GPU, our approach provides fast, accurate, and interpretable aerodynamic feedback, facilitating more agile and informed automotive design exploration.",
    "authors": [
      "Utkarsh Singh",
      "Absaar Ali",
      "Adarsh Roy"
    ],
    "url": "http://arxiv.org/abs/2601.02112v1",
    "published": "2026-01-05",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "The paper applies machine learning (specifically a novel surrogate model using PointNet2D and bidirectional LSTM) to predict aerodynamic drag coefficients from 3D vehicle geometries, which falls under AI4Science as it uses AI for scientific/engineering discovery in physics (fluid dynamics). It does not involve perturbation prediction, as it focuses on static geometric analysis rather than predicting system responses to perturbations."
  },
  {
    "id": "http://arxiv.org/abs/2601.02106v1",
    "title": "Prototype-Based Learning for Healthcare: A Demonstration of Interpretable AI",
    "summary": "Despite recent advances in machine learning and explainable AI, a gap remains in personalized preventive healthcare: predictions, interventions, and recommendations should be both understandable and verifiable for all stakeholders in the healthcare sector. We present a demonstration of how prototype-based learning can address these needs. Our proposed framework, ProtoPal, features both front- and back-end modes; it achieves superior quantitative performance while also providing an intuitive presentation of interventions and their simulated outcomes.",
    "authors": [
      "Ashish Rana",
      "Ammar Shaker",
      "Sascha Saralajew",
      "Takashi Suzuki",
      "Kosuke Yasuda",
      "Shintaro Kato",
      "Toshikazu Wada",
      "Toshiyuki Fujikawa",
      "Toru Kikutsuji"
    ],
    "url": "http://arxiv.org/abs/2601.02106v1",
    "published": "2026-01-05",
    "is_ai4science": true,
    "is_perturbation": true,
    "reasoning": "The paper applies AI (prototype-based learning) to healthcare, which involves biological/medical science, fitting AI4Science. It focuses on predicting interventions and simulated outcomes, which inherently involves predicting system responses to perturbations (interventions) in healthcare contexts."
  },
  {
    "id": "http://arxiv.org/abs/2601.02105v1",
    "title": "LION-DG: Layer-Informed Initialization with Deep Gradient Protocols for Accelerated Neural Network Training",
    "summary": "Weight initialization remains decisive for neural network optimization, yet existing methods are largely layer-agnostic. We study initialization for deeply-supervised architectures with auxiliary classifiers, where untrained auxiliary heads can destabilize early training through gradient interference.   We propose LION-DG, a layer-informed initialization that zero-initializes auxiliary classifier heads while applying standard He-initialization to the backbone. We prove that this implements Gradient Awakening: auxiliary gradients are exactly zero at initialization, then phase in naturally as weights grow -- providing an implicit warmup without hyperparameters.   Experiments on CIFAR-10 and CIFAR-100 with DenseNet-DS and ResNet-DS architectures demonstrate: (1) DenseNet-DS: +8.3% faster convergence on CIFAR-10 with comparable accuracy, (2) Hybrid approach: Combining LSUV with LION-DG achieves best accuracy (81.92% on CIFAR-10), (3) ResNet-DS: Positive speedup on CIFAR-100 (+11.3%) with side-tap auxiliary design.   We identify architecture-specific trade-offs and provide clear guidelines for practitioners. LION-DG is simple, requires zero hyperparameters, and adds no computational overhead.",
    "authors": [
      "Hyunjun Kim"
    ],
    "url": "http://arxiv.org/abs/2601.02105v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on neural network training optimization through weight initialization techniques (LION-DG method), specifically for deeply-supervised architectures with auxiliary classifiers. It addresses gradient interference and convergence acceleration, with experiments on standard computer vision datasets (CIFAR-10/100). There is no mention of applying AI to scientific discovery domains like biology, chemistry, or physics, nor does it involve predicting system responses to perturbations."
  },
  {
    "id": "http://arxiv.org/abs/2601.02094v1",
    "title": "Horizon Activation Mapping for Neural Networks in Time Series Forecasting",
    "summary": "Neural networks for time series forecasting have relied on error metrics and architecture-specific interpretability approaches for model selection that don't apply across models of different families. To interpret forecasting models agnostic to the types of layers across state-of-the-art model families, we introduce Horizon Activation Mapping (HAM), a visual interpretability technique inspired by grad-CAM that uses gradient norm averages to study the horizon's subseries where grad-CAM studies attention maps over image data. We introduce causal and anti-causal modes to calculate gradient update norm averages across subseries at every timestep and lines of proportionality signifying uniform distributions of the norm averages. Optimization landscape studies with respect to changes in batch sizes, early stopping, train-val-test splits, univariate forecasting and dropouts are studied with respect to performances and subseries in HAM. Interestingly, batch size based differences in activities seem to indicate potential for existence of an exponential approximation across them per epoch relative to each other. Multivariate forecasting models including MLP-based CycleNet, N-Linear, N-HITS, self attention-based FEDformer, Pyraformer, SSM-based SpaceTime and diffusion-based Multi-Resolution DDPM over different horizon sizes trained over the ETTm2 dataset are used for HAM plots in this study. NHITS' neural approximation theorem and SpaceTime's exponential autoregressive activities have been attributed to trends in HAM plots over their training, validation and test sets. In general, HAM can be used for granular model selection, validation set choices and comparisons across different neural network model families.",
    "authors": [
      "Hans Krupakar",
      "V A Kandappan"
    ],
    "url": "http://arxiv.org/abs/2601.02094v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on developing a visual interpretability technique (HAM) for neural networks in time series forecasting, specifically for model selection and comparison across architectures. It does not apply AI to scientific discovery in fields like biology, chemistry, or physics (AI4Science), nor does it involve predicting system responses to perturbations (Perturbation Prediction). The work is methodological in machine learning, using time series data (ETTm2 dataset) for forecasting evaluation."
  },
  {
    "id": "http://arxiv.org/abs/2601.02093v1",
    "title": "Optimal Spectral Inequality for the Higher-Dimensional Landau Operator",
    "summary": "We prove optimal spectral inequalities for Landau operators in full space and in arbitrary dimension. Spectral inequalities are lower bounds on the L 2 -mass of functions in spectral subspaces of finite energy when integrated over a sampling set S $\\subset$ R d . Landau operators are Schr{ö}dinger operators associated with a constant magnetic field of the form (-$\\nabla$ + A(x)) 2 where A is a -in case of non-vanishing magnetic field -unbounded vector potential. Our strategy relies on so-called magnetic Bernstein estimates and analyticity, adapting an approach used by Kovrijkine in the context of the Logvinenko-Sereda theorem. We generalize results previously only known in dimension d = 2. The main difficulty in dimension d $\\ge$ 3 are the magnetic Bernstein inequalities which, in comparison to the twodimensional case, lead to additional complications and require more delicate estimates. Our results have immediate consequences for control theory, spectral theory and mathematical physics which we comment on.",
    "authors": [
      "Sedef Özcan",
      "Matthias Täufer"
    ],
    "url": "http://arxiv.org/abs/2601.02093v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper presents mathematical proofs for spectral inequalities of Landau operators using analytic methods and Bernstein estimates, with applications in control theory and mathematical physics. It does not involve artificial intelligence techniques or focus on predicting system responses to perturbations."
  },
  {
    "id": "http://arxiv.org/abs/2601.02085v1",
    "title": "Vision-Based Early Fault Diagnosis and Self-Recovery for Strawberry Harvesting Robots",
    "summary": "Strawberry harvesting robots faced persistent challenges such as low integration of visual perception, fruit-gripper misalignment, empty grasping, and strawberry slippage from the gripper due to insufficient gripping force, all of which compromised harvesting stability and efficiency in orchard environments. To overcome these issues, this paper proposed a visual fault diagnosis and self-recovery framework that integrated multi-task perception with corrective control strategies. At the core of this framework was SRR-Net, an end-to-end multi-task perception model that simultaneously performed strawberry detection, segmentation, and ripeness estimation, thereby unifying visual perception with fault diagnosis. Based on this integrated perception, a relative error compensation method based on the simultaneous target-gripper detection was designed to address positional misalignment, correcting deviations when error exceeded the tolerance threshold. To mitigate empty grasping and fruit-slippage faults, an early abort strategy was implemented. A micro-optical camera embedded in the end-effector provided real-time visual feedback, enabling grasp detection during the deflating stage and strawberry slip prediction during snap-off through MobileNet V3-Small classifier and a time-series LSTM classifier. Experiments demonstrated that SRR-Net maintained high perception accuracy. For detection, it achieved a precision of 0.895 and recall of 0.813 on strawberries, and 0.972/0.958 on hands. In segmentation, it yielded a precision of 0.887 and recall of 0.747 for strawberries, and 0.974/0.947 for hands. For ripeness estimation, SRR-Net attained a mean absolute error of 0.035, while simultaneously supporting multi-task perception and sustaining a competitive inference speed of 163.35 FPS.",
    "authors": [
      "Meili Sun",
      "Chunjiang Zhao",
      "Lichao Yang",
      "Hao Liu",
      "Shimin Hu",
      "Ya Xiong"
    ],
    "url": "http://arxiv.org/abs/2601.02085v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on robotics and computer vision applications for agricultural automation, specifically strawberry harvesting. It develops AI models (SRR-Net, MobileNet V3-Small, LSTM) for perception and control tasks in a robotic system, but does not apply AI to fundamental scientific discovery in fields like biology, chemistry, or physics. The work addresses fault diagnosis and recovery in robotic operations, not prediction of system responses to perturbations in scientific contexts."
  },
  {
    "id": "http://arxiv.org/abs/2601.02084v1",
    "title": "A Perturbed DCA for Computing d-Stationary Points of Nonsmooth DC Programs",
    "summary": "This paper introduces an efficient perturbed difference-of-convex algorithm (pDCA) for computing d-stationary points of an important class of structured nonsmooth difference-of-convex problems. Compared to the principal algorithms introduced in [J.-S. Pang, M. Razaviyayn, and A. Alvarado, Math. Oper. Res. 42(1):95--118 (2017)], which may require solving several subproblems for a one-step update, pDCA only requires solving a single subproblem. Therefore, the computational cost of pDCA for one-step update is comparable to the widely used difference-of-convex algorithm (DCA) introduced in [D. T. Pham and H. A. Le Thi, Acta Math. Vietnam. 22(1):289--355 (1997)] for computing a critical point. Importantly, under practical assumptions, we prove that every accumulation point of the sequence generated by pDCA is a d-stationary point almost surely. Numerical experiment results on several important examples of nonsmooth DC programs demonstrate the efficiency of pDCA for computing d-stationary points.",
    "authors": [
      "Zhangcheng Feng",
      "Yancheng Yuan"
    ],
    "url": "http://arxiv.org/abs/2601.02084v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper presents a computational optimization algorithm (pDCA) for solving nonsmooth difference-of-convex problems, focusing on mathematical optimization theory and numerical methods. It does not involve applying AI to scientific discovery in fields like biology, chemistry, or physics, nor does it address predicting system responses to perturbations; the term 'perturbed' here refers to a mathematical technique within the algorithm, not to perturbation prediction in dynamical systems."
  },
  {
    "id": "http://arxiv.org/abs/2601.02081v1",
    "title": "A Differentiable Adversarial Framework for Task-Aware Data Subsampling",
    "summary": "The proliferation of large-scale datasets poses a major computational challenge to model training. The traditional data subsampling method works as a static, task independent preprocessing step which usually discards information that is critical to downstream prediction. In this paper, we introduces the antagonistic soft selection subsampling (ASSS) framework as is a novel paradigm that reconstructs data reduction into a differentiable end-to-end learning problem. ASSS uses the adversarial game between selector network and task network, and selector network learning assigns continuous importance weights to samples. This direct optimization implemented by Gumbel-Softmax relaxation allows the selector to identify and retain samples with the maximum amount of information for a specific task target under the guidance of the loss function that balances the fidelity and sparsity of the prediction. Theoretical analysis links this framework with the information bottleneck principle. Comprehensive experiments on four large-scale real world datasets show that ASSS has always been better than heuristic subsampling baselines such as clustering and nearest neighbor thinning in maintaining model performance. It is worth noting that ASSS can not only match, but also sometimes exceed the training performance of the entire dataset, showcasing the effect of intelligent denoising. This work establishes task aware data subsampling as a learnable component, providing a principled solution for effective large-scale data learning.",
    "authors": [
      "Jiacheng Lyu",
      "Bihua Bao"
    ],
    "url": "http://arxiv.org/abs/2601.02081v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on a general machine learning framework for task-aware data subsampling to improve computational efficiency in model training, without specific application to scientific domains like biology, chemistry, or physics. It also does not address predicting system responses to perturbations, but rather optimizes sample selection through adversarial learning for data reduction."
  },
  {
    "id": "http://arxiv.org/abs/2601.02080v1",
    "title": "The Homogeneity Trap: Spectral Collapse in Doubly-Stochastic Deep Networks",
    "summary": "Doubly-stochastic matrices (DSM) are increasingly utilized in structure-preserving deep architectures -- such as Optimal Transport layers and Sinkhorn-based attention -- to enforce numerical stability and probabilistic interpretability. In this work, we identify a critical spectral degradation phenomenon inherent to these constraints, termed the Homogeneity Trap. We demonstrate that the maximum-entropy bias, typical of Sinkhorn-based projections, drives the mixing operator towards the uniform barycenter, thereby suppressing the subdominant singular value σ_2 and filtering out high-frequency feature components. We derive a spectral bound linking σ_2 to the network's effective depth, showing that high-entropy constraints restrict feature transformation to a shallow effective receptive field. Furthermore, we formally demonstrate that Layer Normalization fails to mitigate this collapse in noise-dominated regimes; specifically, when spectral filtering degrades the Signal-to-Noise Ratio (SNR) below a critical threshold, geometric structure is irreversibly lost to noise-induced orthogonal collapse. Our findings highlight a fundamental trade-off between entropic stability and spectral expressivity in DSM-constrained networks.",
    "authors": [
      "Yizhi Liu"
    ],
    "url": "http://arxiv.org/abs/2601.02080v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on theoretical analysis of spectral collapse in deep neural networks using doubly-stochastic matrices, examining architectural constraints, entropy-stability trade-offs, and normalization effects. It does not apply AI to scientific discovery domains like biology, chemistry, or physics, nor does it address predicting system responses to perturbations."
  },
  {
    "id": "http://arxiv.org/abs/2601.02076v1",
    "title": "Deferred Commitment Decoding for Diffusion Language Models with Confidence-Aware Sliding Windows",
    "summary": "Diffusion language models (DLMs) have recently emerged as a strong alternative to autoregressive models by enabling parallel text generation. To improve inference efficiency and KV-cache compatibility, prior work commonly adopts block-based diffusion, decoding tokens block by block. However, this paradigm suffers from a structural limitation that we term Boundary-Induced Context Truncation (BICT): undecoded tokens near block boundaries are forced to commit without access to nearby future context, even when such context could substantially reduce uncertainty. This limitation degrades decoding confidence and generation quality, especially for tasks requiring precise reasoning, such as mathematical problem solving and code generation. We propose Deferred Commitment Decoding (DCD), a novel, training-free decoding strategy that mitigates this issue. DCD maintains a confidence-aware sliding window over masked tokens, resolving low-uncertainty tokens early while deferring high-uncertainty tokens until sufficient contextual evidence becomes available. This design enables effective bidirectional information flow within the decoding window without sacrificing efficiency. Extensive experiments across multiple diffusion language models, benchmarks, and caching configurations show that DCD improves generation accuracy by 1.39% with comparable time on average compared to fixed block-based diffusion methods, with the most significant improvement reaching 9.0%. These results demonstrate that deferring token commitment based on uncertainty is a simple yet effective principle for improving both the quality and efficiency of diffusion language model decoding.",
    "authors": [
      "Yingte Shu",
      "Yuchuan Tian",
      "Chao Xu",
      "Yunhe Wang",
      "Hanting Chen"
    ],
    "url": "http://arxiv.org/abs/2601.02076v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on improving decoding efficiency and quality for diffusion language models through a novel decoding strategy (Deferred Commitment Decoding). It addresses technical challenges in text generation (mathematical problem solving, code generation) rather than applying AI to scientific discovery domains like biology, chemistry, or physics. There is no mention of predicting system responses to perturbations or studying perturbation effects."
  },
  {
    "id": "http://arxiv.org/abs/2601.02075v1",
    "title": "MDAgent2: Large Language Model for Code Generation and Knowledge Q&A in Molecular Dynamics",
    "summary": "Molecular dynamics (MD) simulations are essential for understanding atomic-scale behaviors in materials science, yet writing LAMMPS scripts remains highly specialized and time-consuming tasks. Although LLMs show promise in code generation and domain-specific question answering, their performance in MD scenarios is limited by scarce domain data, the high deployment cost of state-of-the-art LLMs, and low code executability. Building upon our prior MDAgent, we present MDAgent2, the first end-to-end framework capable of performing both knowledge Q&A and code generation within the MD domain. We construct a domain-specific data-construction pipeline that yields three high-quality datasets spanning MD knowledge, question answering, and code generation. Based on these datasets, we adopt a three stage post-training strategy--continued pre-training (CPT), supervised fine-tuning (SFT), and reinforcement learning (RL)--to train two domain-adapted models, MD-Instruct and MD-Code. Furthermore, we introduce MD-GRPO, a closed-loop RL method that leverages simulation outcomes as reward signals and recycles low-reward trajectories for continual refinement. We further build MDAgent2-RUNTIME, a deployable multi-agent system that integrates code generation, execution, evaluation, and self-correction. Together with MD-EvalBench proposed in this work, the first benchmark for LAMMPS code generation and question answering, our models and system achieve performance surpassing several strong baselines.This work systematically demonstrates the adaptability and generalization capability of large language models in industrial simulation tasks, laying a methodological foundation for automatic code generation in AI for Science and industrial-scale simulations. URL: https://github.com/FredericVAN/PKU_MDAgent2",
    "authors": [
      "Zhuofan Shi",
      "Hubao A",
      "Yufei Shao",
      "Mengyan Dai",
      "Yadong Yu",
      "Pan Xiang",
      "Dongliang Huang",
      "Hongxu An",
      "Chunxiao Xin",
      "Haiyang Shen",
      "Zhenyu Wang",
      "Yunshan Na",
      "Gang Huang",
      "Xiang Jing"
    ],
    "url": "http://arxiv.org/abs/2601.02075v1",
    "published": "2026-01-05",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "The paper explicitly focuses on using large language models for molecular dynamics simulations in materials science, which falls under AI for scientific discovery (AI4Science). While molecular dynamics involves studying system responses, the paper's core contribution is code generation and knowledge Q&A for LAMMPS scripts, not specifically predicting responses to perturbations."
  },
  {
    "id": "http://arxiv.org/abs/2601.02071v1",
    "title": "FormuLLA: A Large Language Model Approach to Generating Novel 3D Printable Formulations",
    "summary": "Pharmaceutical three-dimensional (3D) printing is an advanced fabrication technology with the potential to enable truly personalised dosage forms. Recent studies have integrated artificial intelligence (AI) to accelerate formulation and process development, drastically transforming current approaches to pharmaceutical 3D printing. To date, most AI-driven efforts remain narrowly focused, while failing to account for the broader formulation challenges inherent to the technology. Recent advances in AI have introduced artificial general intelligence concepts, wherein systems extend beyond conventional predictive modelling toward more generalised, human-like reasoning. In this work, we investigate the application of large language models (LLMs), fine-tuned on a fused deposition modelling (FDM) dataset comprising over 1400 formulations, to recommend suitable excipients based on active pharmaceutical ingredient (API) dose, and predict filament mechanical properties. Four LLM architectures were fine-tuned, with systematic evaluation of both fine-tuning and generative parameter configurations. Our results demonstrate that Llama2 was best suited for recommending excipients for FDM formulations. Additionally, model selection and parameterisation significantly influence performance, with smaller LLMs exhibiting instances of catastrophic forgetting. Furthermore, we demonstrate: (i) even with relatively small dataset of over 1400 formulations, it can lead to model catastrophic forgetting; (ii) standard LLM metrics only evaluate linguistic performance but not formulation processability; and (iii) LLMs trained on biomedically-related data do not always produce the best results. Addressing these challenges is essential to advancing LLMs beyond linguistic proficiency and toward reliable systems for pharmaceutical formulation development.",
    "authors": [
      "Adeshola Okubena",
      "Yusuf Ali Mohammed",
      "Moe Elbadawi"
    ],
    "url": "http://arxiv.org/abs/2601.02071v1",
    "published": "2026-01-05",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "The paper applies large language models (AI) to pharmaceutical formulation development, specifically for 3D printing of personalized dosage forms, which falls under AI for scientific discovery in chemistry/pharmaceutical science. It does not involve predicting system responses to perturbations; rather, it focuses on formulation recommendation and property prediction."
  },
  {
    "id": "http://arxiv.org/abs/2601.02065v1",
    "title": "Cost-Efficient Cross-Lingual Retrieval-Augmented Generation for Low-Resource Languages: A Case Study in Bengali Agricultural Advisory",
    "summary": "Access to reliable agricultural advisory remains limited in many developing regions due to a persistent language barrier: authoritative agricultural manuals are predominantly written in English, while farmers primarily communicate in low-resource local languages such as Bengali. Although recent advances in Large Language Models (LLMs) enable natural language interaction, direct generation in low-resource languages often exhibits poor fluency and factual inconsistency, while cloud-based solutions remain cost-prohibitive. This paper presents a cost-efficient, cross-lingual Retrieval-Augmented Generation (RAG) framework for Bengali agricultural advisory that emphasizes factual grounding and practical deployability. The proposed system adopts a translation-centric architecture in which Bengali user queries are translated into English, enriched through domain-specific keyword injection to align colloquial farmer terminology with scientific nomenclature, and answered via dense vector retrieval over a curated corpus of English agricultural manuals (FAO, IRRI). The generated English response is subsequently translated back into Bengali to ensure accessibility. The system is implemented entirely using open-source models and operates on consumer-grade hardware without reliance on paid APIs. Experimental evaluation demonstrates reliable source-grounded responses, robust rejection of out-of-domain queries, and an average end-to-end latency below 20 seconds. The results indicate that cross-lingual retrieval combined with controlled translation offers a practical and scalable solution for agricultural knowledge access in low-resource language settings",
    "authors": [
      "Md. Asif Hossain",
      "Nabil Subhan",
      "Mantasha Rahman Mahi",
      "Jannatul Ferdous Nabila"
    ],
    "url": "http://arxiv.org/abs/2601.02065v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on developing a cost-efficient cross-lingual RAG system for agricultural advisory in Bengali, addressing language barriers and accessibility issues. It does not involve using AI for scientific discovery in fields like biology, chemistry, or physics (AI4Science), nor does it involve predicting system responses to perturbations (Perturbation Prediction)."
  },
  {
    "id": "http://arxiv.org/abs/2601.02061v1",
    "title": "Higher-Order Action Regularization in Deep Reinforcement Learning: From Continuous Control to Building Energy Management",
    "summary": "Deep reinforcement learning agents often exhibit erratic, high-frequency control behaviors that hinder real-world deployment due to excessive energy consumption and mechanical wear. We systematically investigate action smoothness regularization through higher-order derivative penalties, progressing from theoretical understanding in continuous control benchmarks to practical validation in building energy management. Our comprehensive evaluation across four continuous control environments demonstrates that third-order derivative penalties (jerk minimization) consistently achieve superior smoothness while maintaining competitive performance. We extend these findings to HVAC control systems where smooth policies reduce equipment switching by 60%, translating to significant operational benefits. Our work establishes higher-order action regularization as an effective bridge between RL optimization and operational constraints in energy-critical applications.",
    "authors": [
      "Faizan Ahmed",
      "Aniket Dixit",
      "James Brusey"
    ],
    "url": "http://arxiv.org/abs/2601.02061v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on improving deep reinforcement learning for control applications (continuous control benchmarks and building energy management), not on using AI for scientific discovery in fields like biology, chemistry, or physics. It also does not involve predicting system responses to perturbations; instead, it addresses action smoothness regularization to reduce erratic control behaviors."
  },
  {
    "id": "http://arxiv.org/abs/2601.02060v1",
    "title": "Perish or Flourish? A Holistic Evaluation of Large Language Models for Code Generation in Functional Programming",
    "summary": "Functional programming provides strong foundations for developing reliable and secure software systems, yet its adoption remains not widespread due to the steep learning curve. Recent advances in Large Language Models (LLMs) for code generation present new opportunities to lower these barriers. However, extensive evaluations of LLMs largely focus on imperative programming languages, and their capabilities in functional programming languages (FP) remain underexplored. To address this gap, we introduce FPEval, a holistic evaluation framework built on FPBench, a new benchmark of 721 programming tasks across three difficulty levels on three mainstream FP languages: Haskell, Ocaml and Scala. FPEval provides compehensive evaluation infrastructures with both test validations with comprehensive test suites and static analysis tools to assess both functional correctness and code style and maintainability. Using this framework, we evaluate state-of-the-art LLMs, including GPT-3.5, GPT-4o, and GPT-5, for code generation in functional programming languages and Java as an imperative baseline. Our results demonstrate that LLM performance in functional programming improves substantially with model advancement; however, error rates remain significantly higher in purely functional languages (Haskell and OCaml) than in hybrid (Scala) or imperative (Java) languages. Moreover, LLMs frequently generate non-idiomatic functional code that follows imperative patterns, raising concerns about code style and long-term maintainability. Finally, we show that LLMs can partially self-repair both correctness and quality issues when provided with static analysis feedback and hand-crafted instructions for common types of issues.",
    "authors": [
      "Nguyet-Anh H. Lang",
      "Eric Lang",
      "Thanh Le-Cong",
      "Bach Le",
      "Quyet-Thang Huynh"
    ],
    "url": "http://arxiv.org/abs/2601.02060v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper evaluates LLMs for code generation in functional programming languages, focusing on programming tasks, correctness, and code quality. It does not involve using AI for scientific discovery in fields like biology, chemistry, or physics (AI4Science), nor does it address predicting system responses to perturbations (Perturbation Prediction)."
  },
  {
    "id": "http://arxiv.org/abs/2601.02050v1",
    "title": "Explore the Ideology of Deep Learning in ENSO Forecasts",
    "summary": "The El Ni{~n}o-Southern Oscillation (ENSO) exerts profound influence on global climate variability, yet its prediction remains a grand challenge. Recent advances in deep learning have significantly improved forecasting skill, but the opacity of these models hampers scientific trust and operational deployment. Here, we introduce a mathematically grounded interpretability framework based on bounded variation function. By rescuing the \"dead\" neurons from the saturation zone of the activation function, we enhance the model's expressive capacity. Our analysis reveals that ENSO predictability emerges dominantly from the tropical Pacific, with contributions from the Indian and Atlantic Oceans, consistent with physical understanding. Controlled experiments affirm the robustness of our method and its alignment with established predictors. Notably, we probe the persistent Spring Predictability Barrier (SPB), finding that despite expanded sensitivity during spring, predictive performance declines-likely due to suboptimal variable selection. These results suggest that incorporating additional ocean-atmosphere variables may help transcend SPB limitations and advance long-range ENSO prediction.",
    "authors": [
      "Yanhai Gan",
      "Yipeng Chen",
      "Ning Li",
      "Xingguo Liu",
      "Junyu Dong",
      "Xianyao Chen"
    ],
    "url": "http://arxiv.org/abs/2601.02050v1",
    "published": "2026-01-05",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "The paper applies deep learning (an AI technique) to improve forecasting of ENSO, a climate phenomenon, which falls under scientific discovery in climate science/physics. It does not focus on predicting system responses to perturbations; instead, it addresses model interpretability and predictability barriers in climate forecasting."
  },
  {
    "id": "http://arxiv.org/abs/2601.02046v1",
    "title": "Agentic Retoucher for Text-To-Image Generation",
    "summary": "Text-to-image (T2I) diffusion models such as SDXL and FLUX have achieved impressive photorealism, yet small-scale distortions remain pervasive in limbs, face, text and so on. Existing refinement approaches either perform costly iterative re-generation or rely on vision-language models (VLMs) with weak spatial grounding, leading to semantic drift and unreliable local edits. To close this gap, we propose Agentic Retoucher, a hierarchical decision-driven framework that reformulates post-generation correction as a human-like perception-reasoning-action loop. Specifically, we design (1) a perception agent that learns contextual saliency for fine-grained distortion localization under text-image consistency cues, (2) a reasoning agent that performs human-aligned inferential diagnosis via progressive preference alignment, and (3) an action agent that adaptively plans localized inpainting guided by user preference. This design integrates perceptual evidence, linguistic reasoning, and controllable correction into a unified, self-corrective decision process. To enable fine-grained supervision and quantitative evaluation, we further construct GenBlemish-27K, a dataset of 6K T2I images with 27K annotated artifact regions across 12 categories. Extensive experiments demonstrate that Agentic Retoucher consistently outperforms state-of-the-art methods in perceptual quality, distortion localization and human preference alignment, establishing a new paradigm for self-corrective and perceptually reliable T2I generation.",
    "authors": [
      "Shaocheng Shen",
      "Jianfeng Liang. Chunlei Cai",
      "Cong Geng",
      "Huiyu Duan",
      "Xiaoyun Zhang",
      "Qiang Hu",
      "Guangtao Zhai"
    ],
    "url": "http://arxiv.org/abs/2601.02046v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on improving text-to-image generation quality through a hierarchical agent framework for post-generation correction, addressing distortions in generated images. It does not involve scientific discovery in fields like biology, chemistry, or physics (AI4Science), nor does it study system responses to perturbations; instead, it deals with image refinement and human preference alignment in generative AI."
  },
  {
    "id": "http://arxiv.org/abs/2601.02045v1",
    "title": "The New Compiler Stack: A Survey on the Synergy of LLMs and Compilers",
    "summary": "This survey has provided a systematic overview of the emerging field of LLM-enabled compilation by addressing several key research questions. We first answered how LLMs are being integrated by proposing a comprehensive, multi-dimensional taxonomy that categorizes works based on their Design Philosophy (Selector, Translator, Generator), LLM Methodology, their operational Level of Code Abstraction, and the specific Task Type they address. In answering what advancements these approaches offer, we identified three primary benefits: the democratization of compiler development, the discovery of novel optimization strategies, and the broadening of the compiler's traditional scope. Finally, in addressing the field's challenges and opportunities, we highlighted the critical hurdles of ensuring correctness and achieving scalability, while identifying the development of hybrid systems as the most promising path forward. By providing these answers, this survey serves as a foundational roadmap for researchers and practitioners, charting the course for a new generation of LLM-powered, intelligent, adaptive and synergistic compilation tools.",
    "authors": [
      "Shuoming Zhang",
      "Jiacheng Zhao",
      "Qiuchu Yu",
      "Chunwei Xia",
      "Zheng Wang",
      "Xiaobing Feng",
      "Huimin Cui"
    ],
    "url": "http://arxiv.org/abs/2601.02045v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on LLMs in compiler design and code optimization, not scientific discovery in biology, chemistry, or physics. It also does not address predicting system responses to perturbations."
  },
  {
    "id": "http://arxiv.org/abs/2601.02043v1",
    "title": "Simulated Reasoning is Reasoning",
    "summary": "Reasoning has long been understood as a pathway between stages of understanding. Proper reasoning leads to understanding of a given subject. This reasoning was conceptualized as a process of understanding in a particular way, i.e., \"symbolic reasoning\". Foundational Models (FM) demonstrate that this is not a necessary condition for many reasoning tasks: they can \"reason\" by way of imitating the process of \"thinking out loud\", testing the produced pathways, and iterating on these pathways on their own. This leads to some form of reasoning that can solve problems on its own or with few-shot learning, but appears fundamentally different from human reasoning due to its lack of grounding and common sense, leading to brittleness of the reasoning process. These insights promise to substantially alter our assessment of reasoning and its necessary conditions, but also inform the approaches to safety and robust defences against this brittleness of FMs. This paper offers and discusses several philosophical interpretations of this phenomenon, argues that the previously apt metaphor of the \"stochastic parrot\" has lost its relevance and thus should be abandoned, and reflects on different normative elements in the safety- and appropriateness-considerations emerging from these reasoning models and their growing capacity.",
    "authors": [
      "Hendrik Kempt",
      "Alon Lavie"
    ],
    "url": "http://arxiv.org/abs/2601.02043v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on philosophical interpretations of reasoning in foundational models, discussing concepts like symbolic reasoning, imitation of thinking processes, and safety considerations. It does not mention applications in scientific discovery domains (biology, chemistry, physics) nor address predicting system responses to perturbations."
  },
  {
    "id": "http://arxiv.org/abs/2601.02037v1",
    "title": "Multivariate Time-series Anomaly Detection via Dynamic Model Pool & Ensembling",
    "summary": "Multivariate time-series (MTS) anomaly detection is critical in domains such as service monitor, IoT, and network security. While multi-model methods based on selection or ensembling outperform single-model ones, they still face limitations: (i) selection methods rely on a single chosen model and are sensitive to the strategy; (ii) ensembling methods often combine all models or are restricted to univariate data; and (iii) most methods depend on fixed data dimensionality, limiting scalability. To address these, we propose DMPEAD, a Dynamic Model Pool and Ensembling framework for MTS Anomaly Detection. The framework first (i) constructs a diverse model pool via parameter transfer and diversity metric, then (ii) updates it with a meta-model and similarity-based strategy for adaptive pool expansion, subset selection, and pool merging, finally (iii) ensembles top-ranked models through proxy metric ranking and top-k aggregation in the selected subset, outputting the final anomaly detection result. Extensive experiments on 8 real-world datasets show that our model outperforms all baselines, demonstrating superior adaptability and scalability.",
    "authors": [
      "Wei Hu",
      "Zewei Yu",
      "Jianqiu Xu"
    ],
    "url": "http://arxiv.org/abs/2601.02037v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on developing a general anomaly detection framework for multivariate time-series data in applied domains like service monitoring, IoT, and network security. It does not specifically address scientific discovery in fields like biology, chemistry, or physics (AI4Science). While anomaly detection could theoretically involve identifying perturbations, the paper's methodology centers on model ensembling and dynamic pool management rather than predicting system responses to specific perturbations."
  },
  {
    "id": "http://arxiv.org/abs/2601.02036v1",
    "title": "GDRO: Group-level Reward Post-training Suitable for Diffusion Models",
    "summary": "Recent advancements adopt online reinforcement learning (RL) from LLMs to text-to-image rectified flow diffusion models for reward alignment. The use of group-level rewards successfully aligns the model with the targeted reward. However, it faces challenges including low efficiency, dependency on stochastic samplers, and reward hacking. The problem is that rectified flow models are fundamentally different from LLMs: 1) For efficiency, online image sampling takes much more time and dominates the time of training. 2) For stochasticity, rectified flow is deterministic once the initial noise is fixed. Aiming at these problems and inspired by the effects of group-level rewards from LLMs, we design Group-level Direct Reward Optimization (GDRO). GDRO is a new post-training paradigm for group-level reward alignment that combines the characteristics of rectified flow models. Through rigorous theoretical analysis, we point out that GDRO supports full offline training that saves the large time cost for image rollout sampling. Also, it is diffusion-sampler-independent, which eliminates the need for the ODE-to-SDE approximation to obtain stochasticity. We also empirically study the reward hacking trap that may mislead the evaluation, and involve this factor in the evaluation using a corrected score that not only considers the original evaluation reward but also the trend of reward hacking. Extensive experiments demonstrate that GDRO effectively and efficiently improves the reward score of the diffusion model through group-wise offline optimization across the OCR and GenEval tasks, while demonstrating strong stability and robustness in mitigating reward hacking.",
    "authors": [
      "Yiyang Wang",
      "Xi Chen",
      "Xiaogang Xu",
      "Yu Liu",
      "Hengshuang Zhao"
    ],
    "url": "http://arxiv.org/abs/2601.02036v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on improving reward alignment in text-to-image diffusion models through a new post-training method (GDRO). It addresses efficiency, stochasticity, and reward hacking issues specific to diffusion models, with applications in OCR and GenEval tasks. There is no mention of using AI for scientific discovery in fields like biology, chemistry, or physics, nor does it involve predicting system responses to perturbations."
  },
  {
    "id": "http://arxiv.org/abs/2601.02031v1",
    "title": "Output Embedding Centering for Stable LLM Pretraining",
    "summary": "Pretraining of large language models is not only expensive but also prone to certain training instabilities. A specific instability that often occurs for large learning rates at the end of training is output logit divergence. The most widely used mitigation strategy, z-loss, merely addresses the symptoms rather than the underlying cause of the problem. In this paper, we analyze the instability from the perspective of the output embeddings' geometry and identify its cause. Based on this, we propose output embedding centering (OEC) as a new mitigation strategy, and prove that it suppresses output logit divergence. OEC can be implemented in two different ways, as a deterministic operation called μ-centering, or a regularization method called μ-loss. Our experiments show that both variants outperform z-loss in terms of training stability and learning rate sensitivity. In particular, they ensure that training converges even for large learning rates when z-loss fails. Furthermore, we find that μ-loss is significantly less sensitive to regularization hyperparameter tuning than z-loss.",
    "authors": [
      "Felix Stollenwerk",
      "Anna Lokrantz",
      "Niclas Hertzberg"
    ],
    "url": "http://arxiv.org/abs/2601.02031v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on improving the training stability of large language models through output embedding centering techniques. It addresses technical challenges in AI model development rather than applying AI to scientific discovery domains like biology, chemistry, or physics. The work involves analyzing and mitigating training instabilities, not predicting system responses to perturbations."
  },
  {
    "id": "http://arxiv.org/abs/2601.02023v1",
    "title": "Not All Needles Are Found: How Fact Distribution and Don't Make It Up Prompts Shape Literal Extraction, Logical Inference, and Hallucination Risks in Long-Context LLMs",
    "summary": "Large language models (LLMs) increasingly support very long input contexts. Yet it remains unclear how reliably they extract and infer information at scale. Performance varies with context length and strongly interacts with how information is distributed in real-world corpora. Motivated by these observations, we study how fact placement, corpus-level fact distributions, and Don't Make It Up prompts influence model behavior. We introduce an extended needle-in-a-haystack benchmark across four production-scale models: Gemini-2.5-flash, ChatGPT-5-mini, Claude-4.5-haiku, and Deepseek-v3.2-chat. Unlike prior work, we separately evaluate literal extraction, logical inference, and hallucination risk. Our study considers both positional effects and realistic distributions of evidence across long contexts, as well as prompts that explicitly discourage fabrication. We find that longer contexts alone do not guarantee better performance and can be detrimental when relevant evidence is diluted or widely dispersed. Performance varies substantially across models: some show severe degradation under realistic conditions, while others remain more robust at longer context lengths. Anti-hallucination (AH) instructions can make some models overly conservative, sharply reducing accuracy in literal extraction and logical inference. While we do not directly compare retrieval-augmented generation (RAG) and cache-augmented generation (CAG), our results suggest many failures stem from ineffective context utilization. Models often struggle to identify and prioritize relevant information even when it is present. These findings have direct practical implications, as enterprise workflows increasingly involve pasting large volumes of unfiltered documents into LLM prompts. Effective context length and model-specific robustness to long contexts are therefore critical for reliable LLM deployment in research and business.",
    "authors": [
      "Amirali Ebrahimzadeh",
      "Seyyed M. Salili"
    ],
    "url": "http://arxiv.org/abs/2601.02023v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on evaluating LLM performance in long-context information extraction, inference, and hallucination risks, using benchmark testing across models. It does not involve applying AI to scientific discovery in natural sciences (AI4Science) nor predicting system responses to perturbations (Perturbation Prediction)."
  },
  {
    "id": "http://arxiv.org/abs/2601.02022v1",
    "title": "Prior Diffusiveness and Regret in the Linear-Gaussian Bandit",
    "summary": "We prove that Thompson sampling exhibits $\\tilde{O}(σd \\sqrt{T} + d r \\sqrt{\\mathrm{Tr}(Σ_0)})$ Bayesian regret in the linear-Gaussian bandit with a $\\mathcal{N}(μ_0, Σ_0)$ prior distribution on the coefficients, where $d$ is the dimension, $T$ is the time horizon, $r$ is the maximum $\\ell_2$ norm of the actions, and $σ^2$ is the noise variance. In contrast to existing regret bounds, this shows that to within logarithmic factors, the prior-dependent ``burn-in'' term $d r \\sqrt{\\mathrm{Tr}(Σ_0)}$ decouples additively from the minimax (long run) regret $σd \\sqrt{T}$. Previous regret bounds exhibit a multiplicative dependence on these terms. We establish these results via a new ``elliptical potential'' lemma, and also provide a lower bound indicating that the burn-in term is unavoidable.",
    "authors": [
      "Yifan Zhu",
      "John C. Duchi",
      "Benjamin Van Roy"
    ],
    "url": "http://arxiv.org/abs/2601.02022v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on theoretical analysis of Thompson sampling algorithm in linear-Gaussian bandit problems, deriving Bayesian regret bounds and introducing a new mathematical lemma. It does not address applications in scientific discovery domains (biology, chemistry, physics) nor does it study system responses to perturbations. The work is purely theoretical in machine learning/statistics."
  },
  {
    "id": "http://arxiv.org/abs/2601.02016v1",
    "title": "Enhancing Object Detection with Privileged Information: A Model-Agnostic Teacher-Student Approach",
    "summary": "This paper investigates the integration of the Learning Using Privileged Information (LUPI) paradigm in object detection to exploit fine-grained, descriptive information available during training but not at inference. We introduce a general, model-agnostic methodology for injecting privileged information-such as bounding box masks, saliency maps, and depth cues-into deep learning-based object detectors through a teacher-student architecture. Experiments are conducted across five state-of-the-art object detection models and multiple public benchmarks, including UAV-based litter detection datasets and Pascal VOC 2012, to assess the impact on accuracy, generalization, and computational efficiency. Our results demonstrate that LUPI-trained students consistently outperform their baseline counterparts, achieving significant boosts in detection accuracy with no increase in inference complexity or model size. Performance improvements are especially marked for medium and large objects, while ablation studies reveal that intermediate weighting of teacher guidance optimally balances learning from privileged and standard inputs. The findings affirm that the LUPI framework provides an effective and practical strategy for advancing object detection systems in both resource-constrained and real-world settings.",
    "authors": [
      "Matthias Bartolo",
      "Dylan Seychell",
      "Gabriel Hili",
      "Matthew Montebello",
      "Carl James Debono",
      "Saviour Formosa",
      "Konstantinos Makantasis"
    ],
    "url": "http://arxiv.org/abs/2601.02016v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on improving object detection models using a teacher-student architecture with privileged information (like bounding box masks and depth cues), which is a computer vision methodology enhancement. It does not involve scientific discovery in fields like biology, chemistry, or physics (AI4Science), nor does it address predicting system responses to perturbations (Perturbation Prediction)."
  },
  {
    "id": "http://arxiv.org/abs/2601.02015v1",
    "title": "Surprisal and Metaphor Novelty: Moderate Correlations and Divergent Scaling Effects",
    "summary": "Novel metaphor comprehension involves complex semantic processes and linguistic creativity, making it an interesting task for studying language models (LMs). This study investigates whether surprisal, a probabilistic measure of predictability in LMs, correlates with different metaphor novelty datasets. We analyse surprisal from 16 LM variants on corpus-based and synthetic metaphor novelty datasets. We explore a cloze-style surprisal method that conditions on full-sentence context. Results show that LMs yield significant moderate correlations with scores/labels of metaphor novelty. We further identify divergent scaling patterns: on corpus-based data, correlation strength decreases with model size (inverse scaling effect), whereas on synthetic data it increases (Quality-Power Hypothesis). We conclude that while surprisal can partially account for annotations of metaphor novelty, it remains a limited metric of linguistic creativity.",
    "authors": [
      "Omar Momen",
      "Emilie Sitter",
      "Berenike Herrmann",
      "Sina Zarrieß"
    ],
    "url": "http://arxiv.org/abs/2601.02015v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper studies language models' surprisal in relation to metaphor novelty in linguistics, not applying AI to scientific discovery in natural sciences like biology, chemistry, or physics. It also does not involve predicting system responses to perturbations, focusing instead on correlation analysis and scaling effects in language processing."
  },
  {
    "id": "http://arxiv.org/abs/2601.02010v1",
    "title": "A neural network for modeling human concept formation, understanding and communication",
    "summary": "A remarkable capability of the human brain is to form more abstract conceptual representations from sensorimotor experiences and flexibly apply them independent of direct sensory inputs. However, the computational mechanism underlying this ability remains poorly understood. Here, we present a dual-module neural network framework, the CATS Net, to bridge this gap. Our model consists of a concept-abstraction module that extracts low-dimensional conceptual representations, and a task-solving module that performs visual judgement tasks under the hierarchical gating control of the formed concepts. The system develops transferable semantic structure based on concept representations that enable cross-network knowledge transfer through conceptual communication. Model-brain fitting analyses reveal that these emergent concept spaces align with both neurocognitive semantic model and brain response structures in the human ventral occipitotemporal cortex, while the gating mechanisms mirror that in the semantic control brain network. This work establishes a unified computational framework that can offer mechanistic insights for understanding human conceptual cognition and engineering artificial systems with human-like conceptual intelligence.",
    "authors": [
      "Liangxuan Guo",
      "Haoyang Chen",
      "Yang Chen",
      "Yanchao Bi",
      "Shan Yu"
    ],
    "url": "http://arxiv.org/abs/2601.02010v1",
    "published": "2026-01-05",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "The paper develops a neural network model to study human concept formation and brain function, specifically aligning with neurocognitive semantic models and brain response structures in the ventral occipitotemporal cortex, which constitutes using AI for scientific discovery in neuroscience/biology. It does not focus on predicting system responses to perturbations."
  },
  {
    "id": "http://arxiv.org/abs/2601.02008v1",
    "title": "XAI-MeD: Explainable Knowledge Guided Neuro-Symbolic Framework for Domain Generalization and Rare Class Detection in Medical Imaging",
    "summary": "Explainability domain generalization and rare class reliability are critical challenges in medical AI where deep models often fail under real world distribution shifts and exhibit bias against infrequent clinical conditions This paper introduces XAIMeD an explainable medical AI framework that integrates clinically accurate expert knowledge into deep learning through a unified neuro symbolic architecture XAIMeD is designed to improve robustness under distribution shift enhance rare class sensitivity and deliver transparent clinically aligned interpretations The framework encodes clinical expertise as logical connectives over atomic medical propositions transforming them into machine checkable class specific rules Their diagnostic utility is quantified through weighted feature satisfaction scores enabling a symbolic reasoning branch that complements neural predictions A confidence weighted fusion integrates symbolic and deep outputs while a Hunt inspired adaptive routing mechanism guided by Entropy Imbalance Gain EIG and Rare Class Gini mitigates class imbalance high intra class variability and uncertainty We evaluate XAIMeD across diverse modalities on four challenging tasks i Seizure Onset Zone SOZ localization from rs fMRI ii Diabetic Retinopathy grading across 6 multicenter datasets demonstrate substantial performance improvements including 6 percent gains in cross domain generalization and a 10 percent improved rare class F1 score far outperforming state of the art deep learning baselines Ablation studies confirm that the clinically grounded symbolic components act as effective regularizers ensuring robustness to distribution shifts XAIMeD thus provides a principled clinically faithful and interpretable approach to multimodal medical AI.",
    "authors": [
      "Midhat Urooj",
      "Ayan Banerjee",
      "Sandeep Gupta"
    ],
    "url": "http://arxiv.org/abs/2601.02008v1",
    "published": "2026-01-05",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "The paper focuses on medical imaging AI (seizure localization, diabetic retinopathy grading), which falls under AI4Science as it applies AI methods to biomedical research and clinical diagnostics. It does not involve predicting system responses to perturbations; instead, it addresses domain generalization and rare class detection through neuro-symbolic integration."
  },
  {
    "id": "http://arxiv.org/abs/2601.02002v1",
    "title": "Exploring Approaches for Detecting Memorization of Recommender System Data in Large Language Models",
    "summary": "Large Language Models (LLMs) are increasingly applied in recommendation scenarios due to their strong natural language understanding and generation capabilities. However, they are trained on vast corpora whose contents are not publicly disclosed, raising concerns about data leakage. Recent work has shown that the MovieLens-1M dataset is memorized by both the LLaMA and OpenAI model families, but the extraction of such memorized data has so far relied exclusively on manual prompt engineering. In this paper, we pose three main questions: Is it possible to enhance manual prompting? Can LLM memorization be detected through methods beyond manual prompting? And can the detection of data leakage be automated? To address these questions, we evaluate three approaches: (i) jailbreak prompt engineering; (ii) unsupervised latent knowledge discovery, probing internal activations via Contrast-Consistent Search (CCS) and Cluster-Norm; and (iii) Automatic Prompt Engineering (APE), which frames prompt discovery as a meta-learning process that iteratively refines candidate instructions. Experiments on MovieLens-1M using LLaMA models show that jailbreak prompting does not improve the retrieval of memorized items and remains inconsistent; CCS reliably distinguishes genuine from fabricated movie titles but fails on numerical user and rating data; and APE retrieves item-level information with moderate success yet struggles to recover numerical interactions. These findings suggest that automatically optimizing prompts is the most promising strategy for extracting memorized samples.",
    "authors": [
      "Antonio Colacicco",
      "Vito Guida",
      "Dario Di Palma",
      "Fedelucio Narducci",
      "Tommaso Di Noia"
    ],
    "url": "http://arxiv.org/abs/2601.02002v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on detecting data memorization in LLMs for recommendation systems, which is a computer science/ML security/privacy topic, not using AI for scientific discovery in natural sciences. It also does not involve predicting system responses to perturbations; it evaluates detection methods for memorized data."
  },
  {
    "id": "http://arxiv.org/abs/2601.01997v1",
    "title": "Exploring Diversity, Novelty, and Popularity Bias in ChatGPT's Recommendations",
    "summary": "ChatGPT has emerged as a versatile tool, demonstrating capabilities across diverse domains. Given these successes, the Recommender Systems (RSs) community has begun investigating its applications within recommendation scenarios primarily focusing on accuracy. While the integration of ChatGPT into RSs has garnered significant attention, a comprehensive analysis of its performance across various dimensions remains largely unexplored. Specifically, the capabilities of providing diverse and novel recommendations or exploring potential biases such as popularity bias have not been thoroughly examined. As the use of these models continues to expand, understanding these aspects is crucial for enhancing user satisfaction and achieving long-term personalization.   This study investigates the recommendations provided by ChatGPT-3.5 and ChatGPT-4 by assessing ChatGPT's capabilities in terms of diversity, novelty, and popularity bias. We evaluate these models on three distinct datasets and assess their performance in Top-N recommendation and cold-start scenarios. The findings reveal that ChatGPT-4 matches or surpasses traditional recommenders, demonstrating the ability to balance novelty and diversity in recommendations. Furthermore, in the cold-start scenario, ChatGPT models exhibit superior performance in both accuracy and novelty, suggesting they can be particularly beneficial for new users. This research highlights the strengths and limitations of ChatGPT's recommendations, offering new perspectives on the capacity of these models to provide recommendations beyond accuracy-focused metrics.",
    "authors": [
      "Dario Di Palma",
      "Giovanni Maria Biancofiore",
      "Vito Walter Anelli",
      "Fedelucio Narducci",
      "Tommaso Di Noia"
    ],
    "url": "http://arxiv.org/abs/2601.01997v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on evaluating ChatGPT's performance in recommender systems across dimensions like diversity, novelty, and popularity bias, using datasets for recommendation tasks. It does not involve using AI for scientific discovery in fields like biology, chemistry, or physics (AI4Science), nor does it address predicting system responses to perturbations (Perturbation Prediction)."
  },
  {
    "id": "http://arxiv.org/abs/2601.01993v1",
    "title": "MindChat: A Privacy-preserving Large Language Model for Mental Health Support",
    "summary": "Large language models (LLMs) have shown promise for mental health support, yet training such models is constrained by the scarcity and sensitivity of real counseling dialogues. In this article, we present MindChat, a privacy-preserving LLM for mental health support, together with MindCorpus, a synthetic multi-turn counseling dataset constructed via a multi-agent role-playing framework. To synthesize high-quality counseling data, the developed dialogue-construction framework employs a dual closed-loop feedback design to integrate psychological expertise and counseling techniques through role-playing: (i) turn-level critique-and-revision to improve coherence and counseling appropriateness within a session, and (ii) session-level strategy refinement to progressively enrich counselor behaviors across sessions. To mitigate privacy risks under decentralized data ownership, we fine-tune the base model using federated learning with parameter-efficient LoRA adapters and incorporate differentially private optimization to reduce membership and memorization risks. Experiments on synthetic-data quality assessment and counseling capability evaluation show that MindCorpus improves training effectiveness and that MindChat is competitive with existing general and counseling-oriented LLM baselines under both automatic LLM-judge and human evaluation protocols, while exhibiting reduced privacy leakage under membership inference attacks.",
    "authors": [
      "Dong Xue",
      "Jicheng Tu",
      "Ming Wang",
      "Xin Yan",
      "Fangzhou Liu",
      "Jie Hu"
    ],
    "url": "http://arxiv.org/abs/2601.01993v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on developing a privacy-preserving large language model for mental health counseling support, involving synthetic data generation, federated learning, and privacy protection techniques. This is an application of AI in healthcare/mental health rather than scientific discovery in traditional sciences like biology, chemistry, or physics. There is no mention of predicting system responses to perturbations, which typically involves analyzing how biological, chemical, or physical systems react to changes or disturbances."
  },
  {
    "id": "http://arxiv.org/abs/2601.01989v1",
    "title": "VIT-Ped: Visionary Intention Transformer for Pedestrian Behavior Analysis",
    "summary": "Pedestrian Intention prediction is one of the key technologies in the transition from level 3 to level 4 autonomous driving. To understand pedestrian crossing behaviour, several elements and features should be taken into consideration to make the roads of tomorrow safer for everybody. We introduce a transformer / video vision transformer based algorithm of different sizes which uses different data modalities .We evaluated our algorithms on popular pedestrian behaviour dataset, JAAD, and have reached SOTA performance and passed the SOTA in metrics like Accuracy, AUC and F1-score. The advantages brought by different model design choices are investigated via extensive ablation studies.",
    "authors": [
      "Aly R. Elkammar",
      "Karim M. Gamaleldin",
      "Catherine M. Elias"
    ],
    "url": "http://arxiv.org/abs/2601.01989v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on pedestrian behavior analysis for autonomous driving using transformer models, which is an application of AI in transportation/robotics, not scientific discovery in fields like biology, chemistry, or physics. It also does not involve predicting system responses to perturbations; instead, it predicts pedestrian crossing intentions from video data."
  },
  {
    "id": "http://arxiv.org/abs/2601.01982v1",
    "title": "ChaosBench-Logic: A Benchmark for Logical and Symbolic Reasoning on Chaotic Dynamical Systems",
    "summary": "Large language models (LLMs) excel at natural language tasks but remain brittle in domains requiring precise logical and symbolic reasoning. Chaotic dynamical systems provide an especially demanding test because chaos is deterministic yet often misinterpreted as randomness or complexity. We introduce ChaosBench-Logic, a benchmark that evaluates LLM reasoning across 30 diverse dynamical systems using a unified first-order logic (FOL) ontology. Each system is annotated with truth assignments for 11 semantic predicates, and 621 questions are generated across seven reasoning categories, including multi-hop implications, cross-system analogies, counterfactual reasoning, bias probes, and multi-turn dialogues. We define metrics for logical accuracy, implication consistency, dialogue coherence, and contradiction, and we release an open-source evaluation pipeline. Initial experiments show that frontier LLMs such as GPT-4, Claude 3.5 Sonnet, Gemini 2.5 Flash, and the open-source LLaMA-3 70B achieve 91-94% per-item accuracy, yet still score 0% on compositional items and exhibit fragile global coherence. Dialogue-level accuracy ranges from 53.1% (GPT-4 CoT) to 75.5% (LLaMA-3 zero-shot). ChaosBench-Logic provides a rigorous testbed for diagnosing such failures and a foundation for developing neuro-symbolic approaches that improve scientific reasoning in LLMs.",
    "authors": [
      "Noel Thomas"
    ],
    "url": "http://arxiv.org/abs/2601.01982v1",
    "published": "2026-01-05",
    "is_ai4science": true,
    "is_perturbation": true,
    "reasoning": "The paper is AI4Science because it uses LLMs to reason about chaotic dynamical systems (physics/engineering domains) and aims to improve scientific reasoning. It's related to perturbation prediction because chaotic dynamical systems inherently involve sensitivity to perturbations, and the benchmark includes counterfactual reasoning which tests how systems respond to changes."
  },
  {
    "id": "http://arxiv.org/abs/2601.01979v1",
    "title": "SerpentFlow: Generative Unpaired Domain Alignment via Shared-Structure Decomposition",
    "summary": "Domain alignment refers broadly to learning correspondences between data distributions from distinct domains. In this work, we focus on a setting where domains share underlying structural patterns despite differences in their specific realizations. The task is particularly challenging in the absence of paired observations, which removes direct supervision across domains. We introduce a generative framework, called SerpentFlow (SharEd-structuRe decomPosition for gEnerative domaiN adapTation), for unpaired domain alignment. SerpentFlow decomposes data within a latent space into a shared component common to both domains and a domain-specific one. By isolating the shared structure and replacing the domain-specific component with stochastic noise, we construct synthetic training pairs between shared representations and target-domain samples, thereby enabling the use of conditional generative models that are traditionally restricted to paired settings. We apply this approach to super-resolution tasks, where the shared component naturally corresponds to low-frequency content while high-frequency details capture domain-specific variability. The cutoff frequency separating low- and high-frequency components is determined automatically using a classifier-based criterion, ensuring a data-driven and domain-adaptive decomposition. By generating pseudo-pairs that preserve low-frequency structures while injecting stochastic high-frequency realizations, we learn the conditional distribution of the target domain given the shared representation. We implement SerpentFlow using Flow Matching as the generative pipeline, although the framework is compatible with other conditional generative approaches. Experiments on synthetic images, physical process simulations, and a climate downscaling task demonstrate that the method effectively reconstructs high-frequency structures consistent with underlying low-frequency patterns, supporting shared-structure decomposition as an effective strategy for unpaired domain alignment.",
    "authors": [
      "Julie Keisler",
      "Anastase Alexandre Charantonis",
      "Yannig Goude",
      "Boutheina Oueslati",
      "Claire Monteleoni"
    ],
    "url": "http://arxiv.org/abs/2601.01979v1",
    "published": "2026-01-05",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "The paper applies AI methods (generative domain alignment) to scientific tasks including physical process simulations and climate downscaling, which qualifies as AI4Science. However, it focuses on domain alignment and super-resolution rather than predicting system responses to perturbations."
  },
  {
    "id": "http://arxiv.org/abs/2601.01976v1",
    "title": "CNC-TP: Classifier Nominal Concept Based on Top-Pertinent Attributes",
    "summary": "Knowledge Discovery in Databases (KDD) aims to exploit the vast amounts of data generated daily across various domains of computer applications. Its objective is to extract hidden and meaningful knowledge from datasets through a structured process comprising several key steps: data selection, preprocessing, transformation, data mining, and visualization. Among the core data mining techniques are classification and clustering. Classification involves predicting the class of new instances using a classifier trained on labeled data. Several approaches have been proposed in the literature, including Decision Tree Induction, Bayesian classifiers, Nearest Neighbor search, Neural Networks, Support Vector Machines, and Formal Concept Analysis (FCA). The last one is recognized as an effective approach for interpretable and explainable learning. It is grounded in the mathematical structure of the concept lattice, which enables the generation of formal concepts and the discovery of hidden relationships among them. In this paper, we present a state-of-theart review of FCA-based classifiers. We explore various methods for computing closure operators from nominal data and introduce a novel approach for constructing a partial concept lattice that focuses on the most relevant concepts. Experimental results are provided to demonstrate the efficiency of the proposed method.",
    "authors": [
      "Yasmine Souissi",
      "Fabrice Boissier",
      "Nida Meddouri"
    ],
    "url": "http://arxiv.org/abs/2601.01976v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on data mining techniques, specifically Formal Concept Analysis (FCA) for classification tasks in general databases, with no mention of scientific domains like biology, chemistry, or physics. It also does not address predicting system responses to perturbations, instead discussing attribute relevance in concept lattice construction."
  },
  {
    "id": "http://arxiv.org/abs/2601.01970v1",
    "title": "A Multilayered Approach to Classifying Customer Responsiveness and Credit Risk",
    "summary": "This study evaluates the performance of various classifiers in three distinct models: response, risk, and response-risk, concerning credit card mail campaigns and default prediction. In the response model, the Extra Trees classifier demonstrates the highest recall level (79.1%), emphasizing its effectiveness in identifying potential responders to targeted credit card offers. Conversely, in the risk model, the Random Forest classifier exhibits remarkable specificity of 84.1%, crucial for identifying customers least likely to default. Furthermore, in the multi-class response-risk model, the Random Forest classifier achieves the highest accuracy (83.2%), indicating its efficacy in discerning both potential responders to credit card mail campaign and low-risk credit card users. In this study, we optimized various performance metrics to solve a specific credit risk and mail responsiveness business problem.",
    "authors": [
      "Ayomide Afolabi",
      "Ebere Ogburu",
      "Symon Kimitei"
    ],
    "url": "http://arxiv.org/abs/2601.01970v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on business applications (credit risk assessment and marketing campaign responsiveness) using machine learning classifiers, not scientific discovery in fields like biology, chemistry, or physics. It does not involve predicting system responses to perturbations but rather classifies customer behavior patterns."
  },
  {
    "id": "http://arxiv.org/abs/2601.01966v1",
    "title": "Refinement Provenance Inference: Detecting LLM-Refined Training Prompts from Model Behavior",
    "summary": "Instruction tuning increasingly relies on LLM-based prompt refinement, where prompts in the training corpus are selectively rewritten by an external refiner to improve clarity and instruction alignment. This motivates an instance-level audit problem: for a fine-tuned model and a training prompt-response pair, can we infer whether the model was trained on the original prompt or its LLM-refined version within a mixed corpus? This matters for dataset governance and dispute resolution when training data are contested. However, it is non-trivial in practice: refined and raw instances are interleaved in the training corpus with unknown, source-dependent mixture ratios, making it harder to develop provenance methods that generalize across models and training setups. In this paper, we formalize this audit task as Refinement Provenance Inference (RPI) and show that prompt refinement yields stable, detectable shifts in teacher-forced token distributions, even when semantic differences are not obvious. Building on this phenomenon, we propose RePro, a logit-based provenance framework that fuses teacher-forced likelihood features with logit-ranking signals. During training, RePro learns a transferable representation via shadow fine-tuning, and uses a lightweight linear head to infer provenance on unseen victims without training-data access. Empirically, RePro consistently attains strong performance and transfers well across refiners, suggesting that it exploits refiner-agnostic distribution shifts rather than rewrite-style artifacts.",
    "authors": [
      "Bo Yin",
      "Qi Li",
      "Runpeng Yu",
      "Xinchao Wang"
    ],
    "url": "http://arxiv.org/abs/2601.01966v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on auditing LLM training data provenance by detecting whether prompts were refined by another LLM, using teacher-forced token distributions. This is an AI methodology paper about model auditing and dataset governance, not applying AI to scientific discovery in natural sciences. While it involves analyzing changes (refinements), it does not predict system responses to perturbations in the general sense used in perturbation prediction literature."
  },
  {
    "id": "http://arxiv.org/abs/2601.01963v1",
    "title": "Forget Less by Learning Together through Concept Consolidation",
    "summary": "Custom Diffusion Models (CDMs) have gained significant attention due to their remarkable ability to personalize generative processes. However, existing CDMs suffer from catastrophic forgetting when continuously learning new concepts. Most prior works attempt to mitigate this issue under the sequential learning setting with a fixed order of concept inflow and neglect inter-concept interactions. In this paper, we propose a novel framework - Forget Less by Learning Together (FL2T) - that enables concurrent and order-agnostic concept learning while addressing catastrophic forgetting. Specifically, we introduce a set-invariant inter-concept learning module where proxies guide feature selection across concepts, facilitating improved knowledge retention and transfer. By leveraging inter-concept guidance, our approach preserves old concepts while efficiently incorporating new ones. Extensive experiments, across three datasets, demonstrates that our method significantly improves concept retention and mitigates catastrophic forgetting, highlighting the effectiveness of inter-concept catalytic behavior in incremental concept learning of ten tasks with at least 2% gain on average CLIP Image Alignment scores.",
    "authors": [
      "Arjun Ramesh Kaushik",
      "Naresh Kumar Devulapally",
      "Vishnu Suresh Lokhande",
      "Nalini Ratha",
      "Venu Govindaraju"
    ],
    "url": "http://arxiv.org/abs/2601.01963v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on improving custom diffusion models for generative AI by addressing catastrophic forgetting through inter-concept learning, without mentioning applications in scientific discovery fields like biology, chemistry, or physics. It also does not involve predicting system responses to perturbations, instead concentrating on machine learning methodology for concept retention in generative models."
  },
  {
    "id": "http://arxiv.org/abs/2601.01944v1",
    "title": "The Invisible Hand of AI Libraries Shaping Open Source Projects and Communities",
    "summary": "In the early 1980s, Open Source Software emerged as a revolutionary concept amidst the dominance of proprietary software. What began as a revolutionary idea has now become the cornerstone of computer science. Amidst OSS projects, AI is increasing its presence and relevance. However, despite the growing popularity of AI, its adoption and impacts on OSS projects remain underexplored.   We aim to assess the adoption of AI libraries in Python and Java OSS projects and examine how they shape development, including the technical ecosystem and community engagement. To this end, we will perform a large-scale analysis on 157.7k potential OSS repositories, employing repository metrics and software metrics to compare projects adopting AI libraries against those that do not. We expect to identify measurable differences in development activity, community engagement, and code complexity between OSS projects that adopt AI libraries and those that do not, offering evidence-based insights into how AI integration reshapes software development practices.",
    "authors": [
      "Matteo Esposito",
      "Andrea Janes",
      "Valentina Lenarduzzi",
      "Davide Taibi"
    ],
    "url": "http://arxiv.org/abs/2601.01944v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on analyzing the adoption and impacts of AI libraries on open source software development practices, communities, and technical ecosystems. It does not involve using AI for scientific discovery in fields like biology, chemistry, or physics (AI4Science), nor does it address predicting system responses to perturbations (perturbation prediction)."
  },
  {
    "id": "http://arxiv.org/abs/2601.01943v1",
    "title": "SynRXN: An Open Benchmark and Curated Dataset for Computational Reaction Modeling",
    "summary": "We present SynRXN, a unified benchmarking framework and open-data resource for computer-aided synthesis planning (CASP). SynRXN decomposes end-to-end synthesis planning into five task families, covering reaction rebalancing, atom-to-atom mapping, reaction classification, reaction property prediction, and synthesis route design. Curated, provenance-tracked reaction corpora are assembled from heterogeneous public sources into a harmonized representation and packaged as versioned datasets for each task family, with explicit source metadata, licence tags, and machine-readable manifests that record checksums, and row counts. For every task, SynRXN provides transparent splitting functions that generate leakage-aware train, validation, and test partitions, together with standardized evaluation workflows and metric suites tailored to classification, regression, and structured prediction settings. For sensitive benchmarking, we combine public training and validation data with held-out gold-standard test sets, and contamination-prone tasks such as reaction rebalancing and atom-to-atom mapping are distributed only as evaluation sets and are explicitly not intended for model training. Scripted build recipes enable bitwise-reproducible regeneration of all corpora across machines and over time, and the entire resource is released under permissive open licences to support reuse and extension. By removing dataset heterogeneity and packaging transparent, reusable evaluation scaffolding, SynRXN enables fair longitudinal comparison of CASP methods, supports rigorous ablations and stress tests along the full reaction-informatics pipeline, and lowers the barrier for practitioners who seek robust and comparable performance estimates for real-world synthesis planning workloads.",
    "authors": [
      "Tieu-Long Phan",
      "Nhu-Ngoc Nguyen Song",
      "Peter F. Stadler"
    ],
    "url": "http://arxiv.org/abs/2601.01943v1",
    "published": "2026-01-05",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "The paper presents SynRXN, a benchmarking framework and dataset for computer-aided synthesis planning (CASP) in chemistry, which involves using AI/machine learning for reaction modeling tasks like reaction classification and property prediction, aligning with AI4Science. It does not focus on predicting system responses to perturbations, as its tasks are centered on reaction informatics and synthesis planning rather than perturbation analysis."
  },
  {
    "id": "http://arxiv.org/abs/2601.01940v1",
    "title": "Policy Optimization with Differentiable MPC: Convergence Analysis under Uncertainty",
    "summary": "Model-based policy optimization is a well-established framework for designing reliable and high-performance controllers across a wide range of control applications. Recently, this approach has been extended to model predictive control policies, where explicit dynamical models are embedded within the control law. However, the performance of the resulting controllers, and the convergence of the associated optimization algorithms, critically depends on the accuracy of the models. In this paper, we demonstrate that combining gradient-based policy optimization with recursive system identification ensures convergence to an optimal controller design and showcase our finding in several control examples.",
    "authors": [
      "Riccardo Zuliani",
      "Efe C. Balta",
      "John Lygeros"
    ],
    "url": "http://arxiv.org/abs/2601.01940v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on control theory and optimization for designing controllers using model predictive control and system identification, not on applying AI to scientific discovery in fields like biology, chemistry, or physics. It does not specifically address predicting system responses to perturbations, as its emphasis is on convergence analysis and optimization under uncertainty in control applications."
  },
  {
    "id": "http://arxiv.org/abs/2601.01939v1",
    "title": "OpenSocInt: A Multi-modal Training Environment for Human-Aware Social Navigation",
    "summary": "In this paper, we introduce OpenSocInt, an open-source software package providing a simulator for multi-modal social interactions and a modular architecture to train social agents. We described the software package and showcased its interest via an experimental protocol based on the task of social navigation. Our framework allows for exploring the use of different perceptual features, their encoding and fusion, as well as the use of different agents. The software is already publicly available under GPL at https://gitlab.inria.fr/robotlearn/OpenSocInt/.",
    "authors": [
      "Victor Sanchez",
      "Chris Reinke",
      "Ahamed Mohamed",
      "Xavier Alameda-Pineda"
    ],
    "url": "http://arxiv.org/abs/2601.01939v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper describes a simulator for training social navigation agents, focusing on robotics and human-robot interaction rather than scientific discovery in natural sciences. It does not involve predicting system responses to perturbations, but rather developing agents for navigation in social environments."
  },
  {
    "id": "http://arxiv.org/abs/2601.01932v1",
    "title": "Visualizing the Structure of Lenia Parameter Space",
    "summary": "Continuous cellular automata are rocketing in popularity, yet developing a theoretical understanding of their behaviour remains a challenge. In the case of Lenia, a few fundamental open problems include determining what exactly constitutes a soliton, what is the overall structure of the parameter space, and where do the solitons occur in it. In this abstract, we present a new method to automatically classify Lenia systems into four qualitatively different dynamical classes. This allows us to detect moving solitons, and to provide an interactive visualization of Lenia's parameter space structure on our website https://lenia-explorer.vercel.app/. The results shed new light on the above-mentioned questions and lead to several observations: the existence of new soliton families for parameters where they were not believed to exist, or the universality of the phase space structure across various kernels.",
    "authors": [
      "Barbora Hudcová",
      "František Dušek",
      "Marco Tuccio",
      "Clément Hongler"
    ],
    "url": "http://arxiv.org/abs/2601.01932v1",
    "published": "2026-01-05",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "The paper develops an AI/ML method (automatic classification of dynamical systems) to study continuous cellular automata (Lenia), which are mathematical models used in complex systems research, falling under AI4Science. It does not focus on predicting system responses to perturbations, but rather on classifying parameter space structure and detecting solitons."
  },
  {
    "id": "http://arxiv.org/abs/2601.01931v1",
    "title": "DéjàQ: Open-Ended Evolution of Diverse, Learnable and Verifiable Problems",
    "summary": "Recent advances in reasoning models have yielded impressive results in mathematics and coding. However, most approaches rely on static datasets, which have been suggested to encourage memorisation and limit generalisation. We introduce DéjàQ, a framework that departs from this paradigm by jointly evolving a diverse set of synthetic mathematical problems alongside model training. This evolutionary process adapts to the model's ability throughout training, optimising problems for learnability. We propose two LLM-driven mutation strategies in which the model itself mutates the training data, either by altering contextual details or by directly modifying problem structure. We find that the model can generate novel and meaningful problems, and that these LLM-driven mutations improve RL training. We analyse key aspects of DéjàQ, including the validity of generated problems and computational overhead. Our results underscore the potential of dynamically evolving training data to enhance mathematical reasoning and indicate broader applicability, which we will support by open-sourcing our code.",
    "authors": [
      "Willem Röpke",
      "Samuel Coward",
      "Andrei Lupu",
      "Thomas Foster",
      "Tim Rocktäschel",
      "Jakob Foerster"
    ],
    "url": "http://arxiv.org/abs/2601.01931v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on evolving synthetic mathematical problems for AI training, not applying AI to scientific discovery in fields like biology, chemistry, or physics. It also does not involve predicting system responses to perturbations; instead, it uses mutation strategies for data generation in machine learning."
  },
  {
    "id": "http://arxiv.org/abs/2601.01930v1",
    "title": "MCGI: Manifold-Consistent Graph Indexing for Billion-Scale Disk-Resident Vector Search",
    "summary": "Graph-based Approximate Nearest Neighbor (ANN) search often suffers from performance degradation in high-dimensional spaces due to the ``Euclidean-Geodesic mismatch,'' where greedy routing diverges from the underlying data manifold. To address this, we propose Manifold-Consistent Graph Indexing (MCGI), a geometry-aware and disk-resident indexing method that leverages Local Intrinsic Dimensionality (LID) to dynamically adapt search strategies to the data's intrinsic geometry. Unlike standard algorithms that treat dimensions uniformly, MCGI modulates its beam search budget based on in situ geometric analysis, eliminating dependency on static hyperparameters. Theoretical analysis confirms that MCGI enables improved approximation guarantees by preserving manifold-consistent topological connectivity. Empirically, MCGI achieves 5.8$\\times$ higher throughput at 95\\% recall on high-dimensional GIST1M compared to state-of-the-art DiskANN. On the billion-scale SIFT1B dataset, MCGI further validates its scalability by reducing high-recall query latency by 3$\\times$, while maintaining performance parity on standard lower-dimensional datasets.",
    "authors": [
      "Dongfang Zhao"
    ],
    "url": "http://arxiv.org/abs/2601.01930v1",
    "published": "2026-01-05",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "The paper focuses on improving graph-based approximate nearest neighbor search algorithms for high-dimensional vector data through manifold-aware indexing techniques. It addresses computational efficiency and scalability challenges in vector search systems, with applications likely in information retrieval or database systems, rather than scientific discovery domains like biology, chemistry, or physics. There is no mention of perturbation analysis, system response prediction, or scientific modeling that would relate to perturbation prediction."
  }
]