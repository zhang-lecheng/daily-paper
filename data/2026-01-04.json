[
  {
    "id": "http://arxiv.org/abs/2601.01692v1",
    "title": "Enhanced Multi-model Online Conformal Prediction",
    "summary": "Conformal prediction is a framework for uncertainty quantification that constructs prediction sets for previously unseen data, guaranteeing coverage of the true label with a specified probability. However, the efficiency of these prediction sets, measured by their size, depends on the choice of the underlying learning model. Relying on a single fixed model may lead to suboptimal performance in online environments, as a single model may not consistently perform well across all time steps. To mitigate this, prior work has explored selecting a model from a set of candidates. However, this approach becomes computationally expensive as the number of candidate models increases. Moreover, poorly performing models in the set may also hinder the effectiveness. To tackle this challenge, this work develops a novel multi-model online conformal prediction algorithm that reduces computational complexity and improves prediction efficiency. At each time step, a bipartite graph is generated to identify a subset of effective models, from which a model is selected to construct the prediction set. Experiments demonstrate that our method outperforms existing multi-model conformal prediction techniques in terms of both prediction set size and computational efficiency.",
    "authors": [
      "Erfan Hajihashemi",
      "Yanning Shen"
    ],
    "url": "http://arxiv.org/abs/2601.01692v1",
    "published": "2026-01-04",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种改进的多模型在线共形预测算法，通过构建二分图选择有效模型来提升预测效率，属于机器学习方法论的通用改进，而非针对特定科学领域或扰动预测的应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01690v1",
    "title": "All-Optical Deep Learning with Quantum Nonlinearity",
    "summary": "The rapid scaling of deep neural networks comes at the cost of unsustainable power consumption. While optical neural networks offer an alternative, their capabilities remain constrained by the lack of efficient optical nonlinearities. To address this, we propose an all-optical deep learning architecture by embedding quantum emitters in inverse-designed nanophotonic structures. Due to their saturability, quantum emitters exhibit exceptionally strong nonlinearity compared with conventional materials. Using physics-aware training, we demonstrate that the proposed architecture can solve complex tasks, including nonlinear classification and reinforcement learning, which have not been realized in all-optical neural networks. To enable fair comparison across different platforms, we introduce a framework that quantitatively links nonlinearity to a network's expressive power. Analysis shows that our quantum activation, operating below nW/μm^2 intensity, reduces the power budget by seven orders of magnitude. System-level estimates show that the optical power required for large language models scales sublinearly with model size, enabling watt-level operation. Our results indicate that quantum nanophotonics provides a route toward sustainable AI inference.",
    "authors": [
      "Qingyi Zhou",
      "Jungmin Kim",
      "Yutian Tao",
      "Guoming Huang",
      "Ming Zhou",
      "Zewei Shao",
      "Zongfu Yu"
    ],
    "url": "http://arxiv.org/abs/2601.01690v1",
    "published": "2026-01-04",
    "primary_category": "physics.optics",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种利用量子非线性实现全光学深度学习的架构，旨在解决神经网络能耗问题，而非将AI应用于其他科学领域或预测扰动响应。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01688v1",
    "title": "DiMEx: Breaking the Cold Start Barrier in Data-Free Model Extraction via Latent Diffusion Priors",
    "summary": "Model stealing attacks pose an existential threat to Machine Learning as a Service (MLaaS), allowing adversaries to replicate proprietary models for a fraction of their training cost. While Data-Free Model Extraction (DFME) has emerged as a stealthy vector, it remains fundamentally constrained by the \"Cold Start\" problem: GAN-based adversaries waste thousands of queries converging from random noise to meaningful data. We propose DiMEx, a framework that weaponizes the rich semantic priors of pre-trained Latent Diffusion Models to bypass this initialization barrier entirely. By employing Random Embedding Bayesian Optimization (REMBO) within the generator's latent space, DiMEx synthesizes high-fidelity queries immediately, achieving 52.1 percent agreement on SVHN with just 2,000 queries - outperforming state-of-the-art GAN baselines by over 16 percent. To counter this highly semantic threat, we introduce the Hybrid Stateful Ensemble (HSE) defense, which identifies the unique \"optimization trajectory\" of latent-space attacks. Our results demonstrate that while DiMEx evades static distribution detectors, HSE exploits this temporal signature to suppress attack success rates to 21.6 percent with negligible latency.",
    "authors": [
      "Yash Thesia",
      "Meera Suthar"
    ],
    "url": "http://arxiv.org/abs/2601.01688v1",
    "published": "2026-01-04",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种利用预训练潜在扩散模型进行数据无关模型窃取的攻击方法及其防御机制，属于机器学习安全领域而非科学发现或生物医学扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01687v1",
    "title": "FALCON: Few-Shot Adversarial Learning for Cross-Domain Medical Image Segmentation",
    "summary": "Precise delineation of anatomical and pathological structures within 3D medical volumes is crucial for accurate diagnosis, effective surgical planning, and longitudinal disease monitoring. Despite advancements in AI, clinically viable segmentation is often hindered by the scarcity of 3D annotations, patient-specific variability, data privacy concerns, and substantial computational overhead. In this work, we propose FALCON, a cross-domain few-shot segmentation framework that achieves high-precision 3D volume segmentation by processing data as 2D slices. The framework is first meta-trained on natural images to learn-to-learn generalizable segmentation priors, then transferred to the medical domain via adversarial fine-tuning and boundary-aware learning. Task-aware inference, conditioned on support cues, allows FALCON to adapt dynamically to patient-specific anatomical variations across slices. Experiments on four benchmarks demonstrate that FALCON consistently achieves the lowest Hausdorff Distance scores, indicating superior boundary accuracy while maintaining a Dice Similarity Coefficient comparable to the state-of-the-art models. Notably, these results are achieved with significantly less labeled data, no data augmentation, and substantially lower computational overhead.",
    "authors": [
      "Abdur R. Fayjie",
      "Pankhi Kashyap",
      "Jutika Borah",
      "Patrick Vandewalle"
    ],
    "url": "http://arxiv.org/abs/2601.01687v1",
    "published": "2026-01-04",
    "primary_category": "cs.CV",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于医学图像分割的少样本对抗学习框架，通过跨域迁移和边界感知学习来提高诊断精度，属于AI在生物医学科学中的应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01685v1",
    "title": "Lying with Truths: Open-Channel Multi-Agent Collusion for Belief Manipulation via Generative Montage",
    "summary": "As large language models (LLMs) transition to autonomous agents synthesizing real-time information, their reasoning capabilities introduce an unexpected attack surface. This paper introduces a novel threat where colluding agents steer victim beliefs using only truthful evidence fragments distributed through public channels, without relying on covert communications, backdoors, or falsified documents. By exploiting LLMs' overthinking tendency, we formalize the first cognitive collusion attack and propose Generative Montage: a Writer-Editor-Director framework that constructs deceptive narratives through adversarial debate and coordinated posting of evidence fragments, causing victims to internalize and propagate fabricated conclusions. To study this risk, we develop CoPHEME, a dataset derived from real-world rumor events, and simulate attacks across diverse LLM families. Our results show pervasive vulnerability across 14 LLM families: attack success rates reach 74.4% for proprietary models and 70.6% for open-weights models. Counterintuitively, stronger reasoning capabilities increase susceptibility, with reasoning-specialized models showing higher attack success than base models or prompts. Furthermore, these false beliefs then cascade to downstream judges, achieving over 60% deception rates, highlighting a socio-technical vulnerability in how LLM-based agents interact with dynamic information environments. Our implementation and data are available at: https://github.com/CharlesJW222/Lying_with_Truth/tree/main.",
    "authors": [
      "Jinwei Hu",
      "Xinmiao Huang",
      "Youcheng Sun",
      "Yi Dong",
      "Xiaowei Huang"
    ],
    "url": "http://arxiv.org/abs/2601.01685v1",
    "published": "2026-01-04",
    "primary_category": "cs.CL",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文研究多智能体共谋通过真实证据碎片操纵信念的认知攻击，属于AI安全领域而非科学发现或生物扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01683v1",
    "title": "Adaptive Thrust Regulation in Solid-fuel Ramjet with Variable Geometry Inlet",
    "summary": "This paper presents the application of a novel data-driven adaptive control technique, dynamic mode adaptive control (DMAC), to regulate thrust in a solid-fuel ramjet (SFRJ). A quasi-static one-dimensional model of SFRJ with a variable geometry inlet is developed to compute thrust. An adaptive tracking controller is then designed using the DMAC framework, which leverages dynamic mode decomposition to approximate the local system behavior, followed by a tracking controller designed around the identified model. Simulation results demonstrate that DMAC achieves accurate thrust regulation across a range of commanded profiles and operating conditions, without requiring an analytical model of the SFRJ. These findings indicate that DMAC provides a reliable and effective approach for model-free thrust regulation in an SFRJ with variable-geometry inlets as the control input.",
    "authors": [
      "Parham Oveissi",
      "Ryan DeBoskey",
      "Venkateswaran Narayanaswamy",
      "Ankit Goel"
    ],
    "url": "http://arxiv.org/abs/2601.01683v1",
    "published": "2026-01-04",
    "primary_category": "math.OC",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于动态模态分解的数据驱动自适应控制方法，用于固体燃料冲压发动机的推力调节，属于航空航天工程的控制系统研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01679v1",
    "title": "Simplex Deep Linear Discriminant Analysis",
    "summary": "We revisit Deep Linear Discriminant Analysis (Deep LDA) from a likelihood-based perspective. While classical LDA is a simple Gaussian model with linear decision boundaries, attaching an LDA head to a neural encoder raises the question of how to train the resulting deep classifier by maximum likelihood estimation (MLE). We first show that end-to-end MLE training of an unconstrained Deep LDA model ignores discrimination: when both the LDA parameters and the encoder parameters are learned jointly, the likelihood admits a degenerate solution in which some of the class clusters may heavily overlap or even collapse, and classification performance deteriorates. Batchwise moment re-estimation of the LDA parameters does not remove this failure mode. We then propose a constrained Deep LDA formulation that fixes the class means to the vertices of a regular simplex in the latent space and restricts the shared covariance to be spherical, leaving only the priors and a single variance parameter to be learned along with the encoder. Under these geometric constraints, MLE becomes stable and yields well-separated class clusters in the latent space. On images (Fashion-MNIST, CIFAR-10, CIFAR-100), the resulting Deep LDA models achieve accuracy competitive with softmax baselines while offering a simple, interpretable latent geometry that is clearly visible in two-dimensional projections.",
    "authors": [
      "Maxat Tezekbayev",
      "Arman Bolatov",
      "Zhenisbek Assylbekov"
    ],
    "url": "http://arxiv.org/abs/2601.01679v1",
    "published": "2026-01-04",
    "primary_category": "stat.ML",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种改进的深度线性判别分析方法，通过几何约束解决训练中的退化问题，属于机器学习分类方法的研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01678v1",
    "title": "HeurekaBench: A Benchmarking Framework for AI Co-scientist",
    "summary": "LLM-based reasoning models have enabled the development of agentic systems that act as co-scientists, assisting in multi-step scientific analysis. However, evaluating these systems is challenging, as it requires realistic, end-to-end research scenarios that integrate data analysis, interpretation, and the generation of new insights from the experimental data. To address this limitation, we introduce HeurekaBench, a framework to create benchmarks with exploratory, open-ended research questions for experimental datasets. Each such question is grounded in a scientific study and its corresponding code repository, and is created using a semi-automated pipeline that leverages multiple LLMs to extract insights and generate candidate workflows, which are then verified against reported findings. We instantiate the framework in single-cell biology to obtain sc-HeurekaBench benchmark and use it to compare state-of-the-art single-cell agents. We further showcase the benefits of our benchmark for quantitatively analyzing current design choices in agentic systems. We find that the addition of a critic module can improve ill-formed responses for open-source LLM-based agents by up to 22% and close the gap with their closed-source counterparts. Overall, HeurekaBench sets a path toward rigorous, end-to-end evaluation of scientific agents, grounding benchmark construction in real scientific workflows.",
    "authors": [
      "Siba Smarak Panigrahi",
      "Jovana Videnović",
      "Maria Brbić"
    ],
    "url": "http://arxiv.org/abs/2601.01678v1",
    "published": "2026-01-04",
    "primary_category": "cs.LG",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一个用于评估AI辅助科学发现系统的基准框架，并应用于单细胞生物学领域，属于AI4Science范畴。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01673v1",
    "title": "Exposing Hidden Interfaces: LLM-Guided Type Inference for Reverse Engineering macOS Private Frameworks",
    "summary": "Private macOS frameworks underpin critical services and daemons but remain undocumented and distributed only as stripped binaries, complicating security analysis. We present MOTIF, an agentic framework that integrates tool-augmented analysis with a finetuned large language model specialized for Objective-C type inference. The agent manages runtime metadata extraction, binary inspection, and constraint checking, while the model generates candidate method signatures that are validated and refined into compilable headers. On MOTIF-Bench, a benchmark built from public frameworks with groundtruth headers, MOTIF improves signature recovery from 15% to 86% compared to baseline static analysis tooling, with consistent gains in tool-use correctness and inference stability. Case studies on private frameworks show that reconstructed headers compile, link, and facilitate downstream security research and vulnerability studies. By transforming opaque binaries into analyzable interfaces, MOTIF establishes a scalable foundation for systematic auditing of macOS internals.",
    "authors": [
      "Arina Kharlamova",
      "Youcheng Sun",
      "Ting Yu"
    ],
    "url": "http://arxiv.org/abs/2601.01673v1",
    "published": "2026-01-04",
    "primary_category": "cs.CR",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种利用微调大语言模型进行macOS私有框架逆向工程的智能代理系统，属于计算机安全与软件工程领域，而非传统自然科学发现或生物医学扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01668v1",
    "title": "EHRSummarizer: A Privacy-Aware, FHIR-Native Architecture for Structured Clinical Summarization of Electronic Health Records",
    "summary": "Clinicians routinely navigate fragmented electronic health record (EHR) interfaces to assemble a coherent picture of a patient's problems, medications, recent encounters, and longitudinal trends. This work describes EHRSummarizer, a privacy-aware, FHIR-native reference architecture that retrieves a targeted set of high-yield FHIR R4 resources, normalizes them into a consistent clinical context package, and produces structured summaries intended to support structured chart review. The system can be configured for data minimization, stateless processing, and flexible deployment, including local inference within an organization's trust boundary. To mitigate the risk of unsupported or unsafe behavior, the summarization stage is constrained to evidence present in the retrieved context package, is intended to indicate missing or unavailable domains where feasible, and avoids diagnostic or treatment recommendations. Prototype demonstrations on synthetic and test FHIR environments illustrate end-to-end behavior and output formats; however, this manuscript does not report clinical outcomes or controlled workflow studies. We outline an evaluation plan centered on faithfulness, omission risk, temporal correctness, usability, and operational monitoring to guide future institutional assessments.",
    "authors": [
      "Houman Kazemzadeh",
      "Nima Minaifar",
      "Kamyar Naderi",
      "Sho Tabibzadeh"
    ],
    "url": "http://arxiv.org/abs/2601.01668v1",
    "published": "2026-01-04",
    "primary_category": "cs.CL",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出一个基于FHIR标准的电子健康记录结构化摘要系统架构，专注于临床工作流程支持而非基础科学发现或分子扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01665v1",
    "title": "Adversarial Instance Generation and Robust Training for Neural Combinatorial Optimization with Multiple Objectives",
    "summary": "Deep reinforcement learning (DRL) has shown great promise in addressing multi-objective combinatorial optimization problems (MOCOPs). Nevertheless, the robustness of these learning-based solvers has remained insufficiently explored, especially across diverse and complex problem distributions. In this paper, we propose a unified robustness-oriented framework for preference-conditioned DRL solvers for MOCOPs. Within this framework, we develop a preference-based adversarial attack to generate hard instances that expose solver weaknesses, and quantify the attack impact by the resulting degradation on Pareto-front quality. We further introduce a defense strategy that integrates hardness-aware preference selection into adversarial training to reduce overfitting to restricted preference regions and improve out-of-distribution performance. The experimental results on multi-objective traveling salesman problem (MOTSP), multi-objective capacitated vehicle routing problem (MOCVRP), and multi-objective knapsack problem (MOKP) verify that our attack method successfully learns hard instances for different solvers. Furthermore, our defense method significantly strengthens the robustness and generalizability of neural solvers, delivering superior performance on hard or out-of-distribution instances.",
    "authors": [
      "Wei Liu",
      "Yaoxin Wu",
      "Yingqian Zhang",
      "Thomas Bäck",
      "Yingjie Fan"
    ],
    "url": "http://arxiv.org/abs/2601.01665v1",
    "published": "2026-01-04",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种针对多目标组合优化问题的对抗攻击与防御框架，属于机器学习鲁棒性研究范畴，而非特定科学领域的发现或细胞/分子层面的扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01664v1",
    "title": "Who is the Winning Algorithm? Rank Aggregation for Comparative Studies",
    "summary": "Consider a collection of m competing machine learning algorithms. Given their performance on a benchmark of datasets, we would like to identify the best performing algorithm. Specifically, which algorithm is most likely to ``win'' (rank highest) on a future, unseen dataset. The standard maximum likelihood approach suggests counting the number of wins per each algorithm. In this work, we argue that there is much more information in the complete rankings. That is, the number of times that each algorithm finished second, third and so forth. Yet, it is not entirely clear how to effectively utilize this information for our purpose. In this work we introduce a novel conceptual framework for estimating the win probability for each of the m algorithms, given their complete rankings over a benchmark of datasets. Our proposed framework significantly improves upon currently known methods in synthetic and real-world examples.",
    "authors": [
      "Amichai Painsky"
    ],
    "url": "http://arxiv.org/abs/2601.01664v1",
    "published": "2026-01-04",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于完整排名数据的机器学习算法性能评估框架，旨在更准确地预测算法在未来数据集上的获胜概率。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01663v1",
    "title": "Length-Aware Adversarial Training for Variable-Length Trajectories: Digital Twins for Mall Shopper Paths",
    "summary": "We study generative modeling of \\emph{variable-length trajectories} -- sequences of visited locations/items with associated timestamps -- for downstream simulation and counterfactual analysis. A recurring practical issue is that standard mini-batch training can be unstable when trajectory lengths are highly heterogeneous, which in turn degrades \\emph{distribution matching} for trajectory-derived statistics. We propose \\textbf{length-aware sampling (LAS)}, a simple batching strategy that groups trajectories by length and samples batches from a single length bucket, reducing within-batch length heterogeneity (and making updates more consistent) without changing the model class. We integrate LAS into a conditional trajectory GAN with auxiliary time-alignment losses and provide (i) a distribution-level guarantee for derived variables under mild boundedness assumptions, and (ii) an IPM/Wasserstein mechanism explaining why LAS improves distribution matching by removing length-only shortcut critics and targeting within-bucket discrepancies. Empirically, LAS consistently improves matching of derived-variable distributions on a multi-mall dataset of shopper trajectories and on diverse public sequence datasets (GPS, education, e-commerce, and movies), outperforming random sampling across dataset-specific metrics.",
    "authors": [
      "He Sun",
      "Jiwoong Shin",
      "Ravi Dhar"
    ],
    "url": "http://arxiv.org/abs/2601.01663v1",
    "published": "2026-01-04",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种针对可变长度轨迹的生成建模方法，通过长度感知采样策略改进分布匹配，应用于商场购物路径等序列数据模拟，而非传统科学发现或细胞扰动预测领域。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01658v1",
    "title": "STEMNIST: Spiking Tactile Extended MNIST Neuromorphic Dataset",
    "summary": "Tactile sensing is essential for robotic manipulation, prosthetics and assistive technologies, yet neuromorphic tactile datasets remain limited compared to their visual counterparts. We introduce STEMNIST, a large-scale neuromorphic tactile dataset extending ST-MNIST from 10 digits to 35 alphanumeric classes (uppercase letters A--Z and digits 1--9), providing a challenging benchmark for event-based haptic recognition. The dataset comprises 7,700 samples collected from 34 participants using a custom \\(16\\times 16\\) tactile sensor array operating at 120 Hz, encoded as 1,005,592 spike events through adaptive temporal differentiation. Following EMNIST's visual character recognition protocol, STEMNIST addresses the critical gap between simplified digit classification and real-world tactile interaction scenarios requiring alphanumeric discrimination. Baseline experiments using conventional CNNs (90.91% test accuracy) and spiking neural networks (89.16%) establish performance benchmarks. The dataset's event-based format, unrestricted spatial variability and rich temporal structure makes it suitable for testing neuromorphic hardware and bio-inspired learning algorithms. STEMNIST enables reproducible evaluation of tactile recognition systems and provides a foundation for advancing energy-efficient neuromorphic perception in robotics, biomedical engineering and human-machine interfaces. The dataset, documentation and codes are publicly available to accelerate research in neuromorphic tactile computing.",
    "authors": [
      "Anubhab Tripathi",
      "Li Gaishan",
      "Zhengnan Fu",
      "Chiara Bartolozzi",
      "Bert E. Shi",
      "Arindam Basu"
    ],
    "url": "http://arxiv.org/abs/2601.01658v1",
    "published": "2026-01-04",
    "primary_category": "cs.NE",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于为机器人触觉感知开发神经形态数据集和基准测试，而非利用AI进行生物学、化学或物理学等领域的科学发现。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01657v1",
    "title": "FLOAT: Fatigue-Aware Design Optimization of Floating Offshore Wind Turbine Towers",
    "summary": "Upscaling is central to offshore wind's cost-reduction strategy, with increasingly large rotors and nacelles requiring taller and stronger towers. In Floating Offshore Wind Turbines (FOWTs), this trend amplifies fatigue loads due to coupled wind-wave dynamics and platform motion. Conventional fatigue evaluation requires millions of high-fidelity simulations, creating prohibitive computational costs and slowing design innovation. This paper presents FLOAT (Fatigue-aware Lightweight Optimization and Analysis for Towers), a framework that accelerates fatigue-aware tower design. It integrates three key contributions: a lightweight fatigue estimation method that enables efficient optimization, a Monte Carlo-based probabilistic wind-wave sampling approach that reduces required simulations, and enhanced high-fidelity modeling through pitch/heave-platform calibration and High-Performance Computing execution. The framework is applied to the IEA 22 MW FOWT tower, delivering, to the authors' knowledge, the first fatigue-oriented redesign of this benchmark model: FLOAT 22 MW FOWT tower. Validation against 6,468 simulations shows that the optimized tower extends the estimated fatigue life from 9 months to 25 years while avoiding resonance, and that the lightweight fatigue estimator provides conservative predictions with a mean relative error of -8.6%. Achieving this lifetime requires increased tower mass, yielding the lowest-mass fatigue-compliant design. All results and the reported lifetime extension are obtained within the considered fatigue scope (DLC 1.2, aligned wind-wave conditions). By reducing simulation requirements by orders of magnitude, FLOAT enables reliable and scalable tower design for next-generation FOWTs, bridging industrial needs and academic research while generating high-fidelity datasets that can support data-driven and AI-assisted design methodologies.",
    "authors": [
      "João Alves Ribeiro",
      "Francisco Pimenta",
      "Bruno Alves Ribeiro",
      "Sérgio M. O. Tavares",
      "Faez Ahmed"
    ],
    "url": "http://arxiv.org/abs/2601.01657v1",
    "published": "2026-01-04",
    "primary_category": "cs.CE",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于浮式海上风力发电机塔架疲劳优化设计的计算框架，通过轻量化疲劳估计和高效采样方法加速工程优化，而非利用人工智能进行科学发现或预测分子层面的扰动响应。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01655v1",
    "title": "UniCrop: A Universal, Multi-Source Data Engineering Pipeline for Scalable Crop Yield Prediction",
    "summary": "Accurate crop yield prediction relies on diverse data streams, including satellite, meteorological, soil, and topographic information. However, despite rapid advances in machine learning, existing approaches remain crop- or region-specific and require data engineering efforts. This limits scalability, reproducibility, and operational deployment. This study introduces UniCrop, a universal and reusable data pipeline designed to automate the acquisition, cleaning, harmonisation, and engineering of multi-source environmental data for crop yield prediction. For any given location, crop type, and temporal window, UniCrop automatically retrieves, harmonises, and engineers over 200 environmental variables (Sentinel-1/2, MODIS, ERA5-Land, NASA POWER, SoilGrids, and SRTM), reducing them to a compact, analysis-ready feature set utilising a structured feature reduction workflow with minimum redundancy maximum relevance (mRMR). To validate, UniCrop was applied to a rice yield dataset comprising 557 field observations. Using only the selected 15 features, four baseline machine learning models (LightGBM, Random Forest, Support Vector Regression, and Elastic Net) were trained. LightGBM achieved the best single-model performance (RMSE = 465.1 kg/ha, $R^2 = 0.6576$), while a constrained ensemble of all baselines further improved accuracy (RMSE = 463.2 kg/ha, $R^2 = 0.6604$). UniCrop contributes a scalable and transparent data-engineering framework that addresses the primary bottleneck in operational crop yield modelling: the preparation of consistent and harmonised multi-source data. By decoupling data specification from implementation and supporting any crop, region, and time frame through simple configuration updates, UniCrop provides a practical foundation for scalable agricultural analytics. The code and implementation documentation are shared in https://github.com/CoDIS-Lab/UniCrop.",
    "authors": [
      "Emiliya Khidirova",
      "Oktay Karakuş"
    ],
    "url": "http://arxiv.org/abs/2601.01655v1",
    "published": "2026-01-04",
    "primary_category": "eess.IV",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文通过开发通用数据工程管道UniCrop，利用机器学习模型预测作物产量，属于AI在农业科学领域的应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01653v1",
    "title": "Learning Resilient Elections with Adversarial GNNs",
    "summary": "In the face of adverse motives, it is indispensable to achieve a consensus. Elections have been the canonical way by which modern democracy has operated since the 17th century. Nowadays, they regulate markets, provide an engine for modern recommender systems or peer-to-peer networks, and remain the main approach to represent democracy. However, a desirable universal voting rule that satisfies all hypothetical scenarios is still a challenging topic, and the design of these systems is at the forefront of mechanism design research. Automated mechanism design is a promising approach, and recent works have demonstrated that set-invariant architectures are uniquely suited to modelling electoral systems. However, various concerns prevent the direct application to real-world settings, such as robustness to strategic voting. In this paper, we generalise the expressive capability of learned voting rules, and combine improvements in neural network architecture with adversarial training to improve the resilience of voting rules while maximizing social welfare. We evaluate the effectiveness of our methods on both synthetic and real-world datasets. Our method resolves critical limitations of prior work regarding learning voting rules by representing elections using bipartite graphs, and learning such voting rules using graph neural networks. We believe this opens new frontiers for applying machine learning to real-world elections.",
    "authors": [
      "Hao Xiang Li",
      "Yash Shah",
      "Lorenzo Giusti"
    ],
    "url": "http://arxiv.org/abs/2601.01653v1",
    "published": "2026-01-04",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出使用对抗性图神经网络学习弹性选举机制，属于计算社会科学而非传统自然科学领域。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01649v1",
    "title": "Communication-Efficient Federated AUC Maximization with Cyclic Client Participation",
    "summary": "Federated AUC maximization is a powerful approach for learning from imbalanced data in federated learning (FL). However, existing methods typically assume full client availability, which is rarely practical. In real-world FL systems, clients often participate in a cyclic manner: joining training according to a fixed, repeating schedule. This setting poses unique optimization challenges for the non-decomposable AUC objective. This paper addresses these challenges by developing and analyzing communication-efficient algorithms for federated AUC maximization under cyclic client participation. We investigate two key settings: First, we study AUC maximization with a squared surrogate loss, which reformulates the problem as a nonconvex-strongly-concave minimax optimization. By leveraging the Polyak-Łojasiewicz (PL) condition, we establish a state-of-the-art communication complexity of $\\widetilde{O}(1/ε^{1/2})$ and iteration complexity of $\\widetilde{O}(1/ε)$. Second, we consider general pairwise AUC losses. We establish a communication complexity of $O(1/ε^3)$ and an iteration complexity of $O(1/ε^4)$. Further, under the PL condition, these bounds improve to communication complexity of $\\widetilde{O}(1/ε^{1/2})$ and iteration complexity of $\\widetilde{O}(1/ε)$. Extensive experiments on benchmark tasks in image classification, medical imaging, and fraud detection demonstrate the superior efficiency and effectiveness of our proposed methods.",
    "authors": [
      "Umesh Vangapally",
      "Wenhan Wu",
      "Chen Chen",
      "Zhishuai Guo"
    ],
    "url": "http://arxiv.org/abs/2601.01649v1",
    "published": "2026-01-04",
    "primary_category": "cs.LG",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种针对非平衡数据的联邦AUC最大化方法，通过优化算法在周期性客户端参与下的通信效率，适用于医疗影像等科学发现任务。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01641v1",
    "title": "Ab initio quantum embedding at finite temperature with density matrix embedding theory",
    "summary": "We present a finite-temperature extension of density matrix embedding theory (FT-DMET) for realistic crystalline systems. We describe a practical framework for constructing extended bath orbitals, solving the embedding problem, and performing DMET self-consistency at finite temperature. To reduce computational cost, we introduce strategies based on mutual-information-guided bath truncation, controlled treatment of the thermal electron number without explicit optimization, and the use of low-temperature impurity solvers and one-shot FT-DMET in the low-temperature regime. We apply this approach to periodic hydrogen chains and square lattices to characterize their finite-temperature phases. We observe the Pomeranchuk-like effect in one dimension and enhanced stability of long-range order in two dimensions.",
    "authors": [
      "Laurence Giordano",
      "Y. Stanley Tan",
      "Zhi-Hao Cui",
      "Chong Sun"
    ],
    "url": "http://arxiv.org/abs/2601.01641v1",
    "published": "2026-01-04",
    "primary_category": "physics.comp-ph",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种有限温度下的密度矩阵嵌入理论扩展方法，用于研究晶体系统的相变特性，属于计算物理领域而非AI驱动的科学研究或扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01634v1",
    "title": "Boundary control systems on a one-dimension spatial domain",
    "summary": "The aim of this paper is to investigate the well-posedness of a class of boundary control and observation systems on a one dimensional spatial domain. We derive a necessary and sufficient condition characterizing the well-posedness of these systems. Furthermore, we show that the well-posedness and full control and observation implies exact controllability and exact observability. The theoretical results are illustrated using Euler-Bernoulli beam models.",
    "authors": [
      "Bouchra Elghazi",
      "Birgit Jacob",
      "Hans Zwart"
    ],
    "url": "http://arxiv.org/abs/2601.01634v1",
    "published": "2026-01-04",
    "primary_category": "math.OC",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文研究一维空间域上边界控制系统的适定性条件及其在梁模型中的应用，属于控制理论与偏微分方程领域，未涉及人工智能方法或细胞/分子扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01632v1",
    "title": "Learning Stiff Dynamical Operators: Scaling, Fast-Slow Excitation, and Eigen-Consistent Neural Models",
    "summary": "Stiff dynamical systems represent a central challenge in multi scale modeling across combustion, chemical kinetics, and nonlinear dynamical systems. Neural operator learning has recently emerged as a promising approach to approximate dynamical generators from data, yet stiffness imposes severe obstacles: training errors concentrate on slow manifold states, collapse of fast dynamics occurs, and the learned operator may fail to reproduce the true eigenstructure.   We demonstrate three key advances enabling accurate learning of stiff operators and preserving spectral fidelity: (i) stiffness aware scaling of time derivatives, (ii) fast direction excitation via local trajectory cloud bursts, and (iii) autograd-based Jacobian diagnostics ensuring eigenstructure fidelity. Applied to the Davis-Skodje system, the approach recovers both slow and fast modes across stiffness regimes, reducing fast eigenvalue error by an order of magnitude while improving rollout fidelity. These results argue that spectral fidelity - not trajectory accuracy alone - should be a first-class target in data driven learning of stiff operators.",
    "authors": [
      "Mauro Valorani"
    ],
    "url": "http://arxiv.org/abs/2601.01632v1",
    "published": "2026-01-04",
    "primary_category": "physics.comp-ph",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于神经算子学习的方法，用于准确模拟多尺度科学领域（如燃烧、化学动力学）中的刚性动力系统，并确保谱保真度。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01631v1",
    "title": "Stochastic Maximum Principles and Linear-Quadratic Optimal Control Problems for Fractional Backward Stochastic Evolution Equations in Hilbert Spaces",
    "summary": "This paper develops a comprehensive framework for optimal control of systems governed by fractional backward stochastic evolution equations (FBSEEs) in Hilbert spaces. We first establish a stochastic maximum principle (SMP) as a necessary condition for optimality. This is achieved by introducing spike variations, deriving precise estimates for the associated variational equations, and constructing an adjoint process tailored to the fractional dynamics. Subsequently, we apply this general principle to solve the linear-quadratic (LQ) optimal control problem explicitly. The resulting optimal control is characterized in closed form via the adjoint process and is shown to be governed by a system of coupled fractional forward-backward stochastic equations. Our work bridges fractional calculus with stochastic control theory, providing a rigorous foundation for controlling infinite-dimensional systems with memory and long-range dependencies.",
    "authors": [
      "Javad A. Asadzade",
      "Nazim I. Mahmudov"
    ],
    "url": "http://arxiv.org/abs/2601.01631v1",
    "published": "2026-01-04",
    "primary_category": "math.OC",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文聚焦于分数阶随机演化方程的最优控制理论框架，属于数学控制论领域，未涉及人工智能在科学发现或细胞/基因扰动预测的应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01627v1",
    "title": "JMedEthicBench: A Multi-Turn Conversational Benchmark for Evaluating Medical Safety in Japanese Large Language Models",
    "summary": "As Large Language Models (LLMs) are increasingly deployed in healthcare field, it becomes essential to carefully evaluate their medical safety before clinical use. However, existing safety benchmarks remain predominantly English-centric, and test with only single-turn prompts despite multi-turn clinical consultations. To address these gaps, we introduce JMedEthicBench, the first multi-turn conversational benchmark for evaluating medical safety of LLMs for Japanese healthcare. Our benchmark is based on 67 guidelines from the Japan Medical Association and contains over 50,000 adversarial conversations generated using seven automatically discovered jailbreak strategies. Using a dual-LLM scoring protocol, we evaluate 27 models and find that commercial models maintain robust safety while medical-specialized models exhibit increased vulnerability. Furthermore, safety scores decline significantly across conversation turns (median: 9.5 to 5.0, $p < 0.001$). Cross-lingual evaluation on both Japanese and English versions of our benchmark reveals that medical model vulnerabilities persist across languages, indicating inherent alignment limitations rather than language-specific factors. These findings suggest that domain-specific fine-tuning may accidentally weaken safety mechanisms and that multi-turn interactions represent a distinct threat surface requiring dedicated alignment strategies.",
    "authors": [
      "Junyu Liu",
      "Zirui Li",
      "Qian Niu",
      "Zequn Zhang",
      "Yue Xun",
      "Wenlong Hou",
      "Shujun Wang",
      "Yusuke Iwasawa",
      "Yutaka Matsuo",
      "Kan Hatakeyama-Sato"
    ],
    "url": "http://arxiv.org/abs/2601.01627v1",
    "published": "2026-01-04",
    "primary_category": "cs.CL",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于评估日语大语言模型在医疗安全方面的表现，而非利用AI进行科学发现或预测细胞/基因层面的扰动响应。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01621v1",
    "title": "A Three-Tier Time-Scale Architecture for Controlling Complex Nonlinear Systems",
    "summary": "This letter proposes a three-tier computational architecture for the real-time control of nonlinear complex systems, such as time-dependent PDEs. There is an important class of such problems for which existing single- and two-time-scale approaches are fundamentally insufficient due to lack of a priori system knowledge, computational complexity, model fidelity requirements, and uncertainty. The proposed architecture consists of an offline, meso-scale, and real-time layer of computation, with distinct roles for each layer and specific information flow between them. The result is a practical systems-level paradigm that enables real-time operation of complex nonlinear control problems.",
    "authors": [
      "Vyacheslav Kungurtsev"
    ],
    "url": "http://arxiv.org/abs/2601.01621v1",
    "published": "2026-01-04",
    "primary_category": "math.OC",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于控制非线性复杂系统的三层次计算架构，属于控制理论与计算工程领域，而非AI驱动的科学发现或分子层面的扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01619v1",
    "title": "Deep Linear Discriminant Analysis Revisited",
    "summary": "We show that for unconstrained Deep Linear Discriminant Analysis (LDA) classifiers, maximum-likelihood training admits pathological solutions in which class means drift together, covariances collapse, and the learned representation becomes almost non-discriminative. Conversely, cross-entropy training yields excellent accuracy but decouples the head from the underlying generative model, leading to highly inconsistent parameter estimates. To reconcile generative structure with discriminative performance, we introduce the \\emph{Discriminative Negative Log-Likelihood} (DNLL) loss, which augments the LDA log-likelihood with a simple penalty on the mixture density. DNLL can be interpreted as standard LDA NLL plus a term that explicitly discourages regions where several classes are simultaneously likely. Deep LDA trained with DNLL produces clean, well-separated latent spaces, matches the test accuracy of softmax classifiers on synthetic data and standard image benchmarks, and yields substantially better calibrated predictive probabilities, restoring a coherent probabilistic interpretation to deep discriminant models.",
    "authors": [
      "Maxat Tezekbayev",
      "Rustem Takhanov",
      "Arman Bolatov",
      "Zhenisbek Assylbekov"
    ],
    "url": "http://arxiv.org/abs/2601.01619v1",
    "published": "2026-01-04",
    "primary_category": "stat.ML",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种改进深度线性判别分析的方法，通过引入判别性负对数似然损失来协调生成结构与判别性能，属于机器学习模型优化研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01616v1",
    "title": "Real Time NILM Based Power Monitoring of Identical Induction Motors Representing Cutting Machines in Textile Industry",
    "summary": "The textile industry in Bangladesh is one of the most energy-intensive sectors, yet its monitoring practices remain largely outdated, resulting in inefficient power usage and high operational costs. To address this, we propose a real-time Non-Intrusive Load Monitoring (NILM)-based framework tailored for industrial applications, with a focus on identical motor-driven loads representing textile cutting machines. A hardware setup comprising voltage and current sensors, Arduino Mega and ESP8266 was developed to capture aggregate and individual load data, which was stored and processed on cloud platforms. A new dataset was created from three identical induction motors and auxiliary loads, totaling over 180,000 samples, to evaluate the state-of-the-art MATNILM model under challenging industrial conditions. Results indicate that while aggregate energy estimation was reasonably accurate, per-appliance disaggregation faced difficulties, particularly when multiple identical machines operated simultaneously. Despite these challenges, the integrated system demonstrated practical real-time monitoring with remote accessibility through the Blynk application. This work highlights both the potential and limitations of NILM in industrial contexts, offering insights into future improvements such as higher-frequency data collection, larger-scale datasets and advanced deep learning approaches for handling identical loads.",
    "authors": [
      "Md Istiauk Hossain Rifat",
      "Moin Khan",
      "Mohammad Zunaed"
    ],
    "url": "http://arxiv.org/abs/2601.01616v1",
    "published": "2026-01-04",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于非侵入式负载监测的实时电力监控框架，专注于工业应用中的相同感应电机，而非AI在传统科学发现或细胞扰动预测领域的应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01609v1",
    "title": "Structured Decomposition for LLM Reasoning: Cross-Domain Validation and Semantic Web Integration",
    "summary": "Rule-based reasoning over natural language input arises in domains where decisions must be auditable and justifiable: clinical protocols specify eligibility criteria in prose, evidence rules define admissibility through textual conditions, and scientific standards dictate methodological requirements. Applying rules to such inputs demands both interpretive flexibility and formal guarantees. Large language models (LLMs) provide flexibility but cannot ensure consistent rule application; symbolic systems provide guarantees but require structured input. This paper presents an integration pattern that combines these strengths: LLMs serve as ontology population engines, translating unstructured text into ABox assertions according to expert-authored TBox specifications, while SWRL-based reasoners apply rules with deterministic guarantees. The framework decomposes reasoning into entity identification, assertion extraction, and symbolic verification, with task definitions grounded in OWL 2 ontologies. Experiments across three domains (legal hearsay determination, scientific method-task application, clinical trial eligibility) and eleven language models validate the approach. Structured decomposition achieves statistically significant improvements over few-shot prompting in aggregate, with gains observed across all three domains. An ablation study confirms that symbolic verification provides substantial benefit beyond structured prompting alone. The populated ABox integrates with standard semantic web tooling for inspection and querying, positioning the framework for richer inference patterns that simpler formalisms cannot express.",
    "authors": [
      "Albert Sadowski",
      "Jarosław A. Chudziak"
    ],
    "url": "http://arxiv.org/abs/2601.01609v1",
    "published": "2026-01-04",
    "primary_category": "cs.AI",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种结合大语言模型与语义网推理的框架，通过结构化分解实现跨领域规则推理的验证与集成。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01605v1",
    "title": "REE-TTT: Highly Adaptive Radar Echo Extrapolation Based on Test-Time Training",
    "summary": "Precipitation nowcasting is critically important for meteorological forecasting. Deep learning-based Radar Echo Extrapolation (REE) has become a predominant nowcasting approach, yet it suffers from poor generalization due to its reliance on high-quality local training data and static model parameters, limiting its applicability across diverse regions and extreme events. To overcome this, we propose REE-TTT, a novel model that incorporates an adaptive Test-Time Training (TTT) mechanism. The core of our model lies in the newly designed Spatio-temporal Test-Time Training (ST-TTT) block, which replaces the standard linear projections in TTT layers with task-specific attention mechanisms, enabling robust adaptation to non-stationary meteorological distributions and thereby significantly enhancing the feature representation of precipitation. Experiments under cross-regional extreme precipitation scenarios demonstrate that REE-TTT substantially outperforms state-of-the-art baseline models in prediction accuracy and generalization, exhibiting remarkable adaptability to data distribution shifts.",
    "authors": [
      "Xin Di",
      "Xinglin Piao",
      "Fei Wang",
      "Guodong Jing",
      "Yong Zhang"
    ],
    "url": "http://arxiv.org/abs/2601.01605v1",
    "published": "2026-01-04",
    "primary_category": "cs.LG",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于测试时训练的雷达回波外推模型，用于改进降水临近预报，属于人工智能在气象科学领域的应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01604v1",
    "title": "grangersearch: An R Package for Exhaustive Granger Causality Testing with Tidyverse Integration",
    "summary": "This paper introduces grangersearch, an R package for performing exhaustive Granger causality searches on multiple time series. The package provides: (1) exhaustive pairwise search across multiple variables, (2) automatic lag order optimization with visualization, (3) tidyverse-compatible syntax with pipe operators and non-standard evaluation, and (4) integration with the broom ecosystem through tidy() and glance() methods. The package wraps the vars infrastructure while providing a simple interface for exploratory causal analysis. We describe the statistical methodology, demonstrate the package through worked examples, and discuss practical considerations for applied researchers.",
    "authors": [
      "Nikolaos Korfiatis"
    ],
    "url": "http://arxiv.org/abs/2601.01604v1",
    "published": "2026-01-04",
    "primary_category": "stat.CO",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文介绍了一个用于时间序列因果分析的R包，专注于统计方法而非AI驱动的科学发现或分子扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01599v1",
    "title": "From Theory of Mind to Theory of Environment: Counterfactual Simulation of Latent Environmental Dynamics",
    "summary": "The vertebrate motor system employs dimensionality-reducing strategies to limit the complexity of movement coordination, for efficient motor control. But when environments are dense with hidden action-outcome contingencies, movement complexity can promote behavioral innovation. Humans, perhaps uniquely, may infer the presence of hidden environmental dynamics from social cues, by drawing upon computational mechanisms shared with Theory of Mind. This proposed \"Theory of Environment\" supports behavioral innovation by expanding the dimensionality of motor exploration.",
    "authors": [
      "Ryutaro Uchiyama"
    ],
    "url": "http://arxiv.org/abs/2601.01599v1",
    "published": "2026-01-04",
    "primary_category": "q-bio.NC",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文探讨人类通过类似心理理论的机制推断环境隐藏动态以促进行为创新的认知过程，属于认知神经科学领域，而非AI4Science或分子层面的扰动预测研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01594v1",
    "title": "Variance-Reduced Diffusion Sampling via Conditional Score Expectation Identity",
    "summary": "We introduce and prove a \\textbf{Conditional Score Expectation (CSE)} identity: an exact relation for the marginal score of affine diffusion processes that links scores across time via a conditional expectation under the forward dynamics. Motivated by this identity, we propose a CSE-based statistical estimator for the score using a Self-Normalized Importance Sampling (SNIS) procedure with prior samples and forward noise. We analyze its relationship to the standard Tweedie estimator, proving anti-correlation for Gaussian targets and establishing the same behavior for general targets in the small time-step regime. Exploiting this structure, we derive a variance-minimizing blended score estimator given by a state--time dependent convex combination of the CSE and Tweedie estimators. Numerical experiments show that this optimal-blending estimator reduces variance and improves sample quality for a fixed computational budget compared to either baseline. We further extend the framework to Bayesian inverse problems via likelihood-informed SNIS weights, and demonstrate improved reconstruction quality and sample diversity on high-dimensional image reconstruction tasks and PDE-governed inverse problems.",
    "authors": [
      "Alois Duston",
      "Tan Bui-Thanh"
    ],
    "url": "http://arxiv.org/abs/2601.01594v1",
    "published": "2026-01-04",
    "primary_category": "stat.ML",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于条件得分期望的方差缩减扩散采样方法，通过优化得分估计器提高了高维逆问题（包括图像重建和PDE控制问题）的计算效率和样本质量，属于AI在科学计算和逆问题求解中的应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01591v1",
    "title": "Optimization problems for elliptic PDEs",
    "summary": "In this paper we consider some optimal control problems governed by elliptic partial differential equations. The solution is the state variable, while the control variable is, depending on the case, the coefficient of the PDE, the potential, the right-hand side. The cost functional is of integral type and involves both the state and control variables.",
    "authors": [
      "Giuseppe Buttazzo",
      "Juan Casado-Díaz",
      "Faustino Maestre"
    ],
    "url": "http://arxiv.org/abs/2601.01591v1",
    "published": "2026-01-04",
    "primary_category": "math.OC",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于椭圆偏微分方程的最优控制理论分析，属于传统数学物理领域，未涉及人工智能方法或生物/化学扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01590v1",
    "title": "Identifying recurrent flows in high-dimensional dissipative chaos from low-dimensional embeddings",
    "summary": "Unstable periodic orbits (UPOs) are the non-chaotic, dynamical building blocks of spatio-temporal chaos, motivating a first-principles based theory for turbulence ever since the discovery of deterministic chaos. Despite their key role in the ergodic theory approach to fluid turbulence, identifying UPOs is challenging for two reasons: chaotic dynamics and the high-dimensionality of the spatial discretization. We address both issues at once by proposing a loop convergence algorithm for UPOs directly within a low-dimensional embedding of the chaotic attractor. The convergence algorithm circumvents time-integration, hence avoiding instabilities from exponential error amplification, and operates on a latent dynamics obtained by pulling back the physical equations using automatic differentiation through the learned embedding function. The interpretable latent dynamics is accurate in a statistical sense, and, crucially, the embedding preserves the internal structure of the attractor, which we demonstrate through an equivalence between the latent and physical UPOs of both a model PDE and the 2D Navier-Stokes equations. This allows us to exploit the collapse of high-dimensional dissipative systems onto a lower dimensional manifold, and identify UPOs in the low-dimensional embedding.",
    "authors": [
      "Pierre Beck",
      "Tobias M. Schneider"
    ],
    "url": "http://arxiv.org/abs/2601.01590v1",
    "published": "2026-01-04",
    "primary_category": "nlin.CD",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文通过自动微分学习低维嵌入函数，在混沌系统中识别不稳定周期轨道，属于AI在流体物理领域的科学发现应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01589v1",
    "title": "Learning Relationship between Quantum Walks and Underdamped Langevin Dynamics",
    "summary": "Fast computational algorithms are in constant demand, and their development has been driven by advances such as quantum speedup and classical acceleration. This paper intends to study search algorithms based on quantum walks in quantum computation and sampling algorithms based on Langevin dynamics in classical computation. On the quantum side, quantum walk-based search algorithms can achieve quadratic speedups over their classical counterparts. In classical computation, a substantial body of work has focused on gradient acceleration, with gradient-adjusted algorithms derived from underdamped Langevin dynamics providing quadratic acceleration over conventional Langevin algorithms.   Since both search and sampling algorithms are designed to address learning tasks, we study learning relationship between coined quantum walks and underdamped Langevin dynamics. Specifically, we show that, in terms of the Le Cam deficiency distance, a quantum walk with randomization is asymptotically equivalent to underdamped Langevin dynamics, whereas the quantum walk without randomization is not asymptotically equivalent due to its high-frequency oscillatory behavior. We further discuss the implications of these equivalence and nonequivalence results for the computational and inferential properties of the associated algorithms in machine learning tasks. Our findings offer new insight into the relationship between quantum walks and underdamped Langevin dynamics, as well as the intrinsic mechanisms underlying quantum speedup and classical gradient acceleration.",
    "authors": [
      "Yazhen Wang"
    ],
    "url": "http://arxiv.org/abs/2601.01589v1",
    "published": "2026-01-04",
    "primary_category": "quant-ph",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文研究量子行走与朗之万动力学的数学等价关系，属于计算数学与量子计算的基础理论研究，而非应用AI解决具体科学问题或预测生物扰动响应。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01581v1",
    "title": "CONSENT: A Negotiation Framework for Leveraging User Flexibility in Vehicle-to-Building Charging under Uncertainty",
    "summary": "The growth of Electric Vehicles (EVs) creates a conflict in vehicle-to-building (V2B) settings between building operators, who face high energy costs from uncoordinated charging, and drivers, who prioritize convenience and a full charge. To resolve this, we propose a negotiation-based framework that, by design, guarantees voluntary participation, strategy-proofness, and budget feasibility. It transforms EV charging into a strategic resource by offering drivers a range of incentive-backed options for modest flexibility in their departure time or requested state of charge (SoC). Our framework is calibrated with user survey data and validated using real operational data from a commercial building and an EV manufacturer. Simulations show that our negotiation protocol creates a mutually beneficial outcome: lowering the building operator's costs by over 3.5\\% compared to an optimized, non-negotiating smart charging policy, while simultaneously reducing user charging expenses by 22\\% below the utility's retail energy rate. By aligning operator and EV user objectives, our framework provides a strategic bridge between energy and mobility systems, transforming EV charging from a source of operational friction into a platform for collaboration and shared savings.",
    "authors": [
      "Rishav Sen",
      "Fangqi Liu",
      "Jose Paolo Talusan",
      "Ava Pettet",
      "Yoshinori Suzue",
      "Mark Bailey",
      "Ayan Mukhopadhyay",
      "Abhishek Dubey"
    ],
    "url": "http://arxiv.org/abs/2601.01581v1",
    "published": "2026-01-04",
    "primary_category": "cs.MA",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一个基于协商的电动汽车充电管理框架，通过激励机制协调建筑运营商与用户需求，属于能源系统优化领域，而非AI驱动的科学发现或细胞/基因扰动预测研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01580v1",
    "title": "The Two-Stage Decision-Sampling Hypothesis: Understanding the Emergence of Self-Reflection in RL-Trained LLMs",
    "summary": "Self-reflection capabilities emerge in Large Language Models after RL post-training, with multi-turn RL achieving substantial gains over SFT counterparts. Yet the mechanism of how a unified optimization objective gives rise to functionally distinct capabilities of generating solutions and evaluating when to revise them remains opaque. To address this question, we introduce the Gradient Attribution Property to characterize how reward gradients distribute across policy components, formalized through the Two-Stage Decision-Sampling (DS) Hypothesis, which decomposes the policy into sampling ($π_{sample}$) for generation and decision ($π_{d}$) for verification. We prove that surrogate rewards exhibit Balanced Gradient Attribution, while SFT and KL penalties exhibit Unbalanced Gradient Attribution, with length-weighting creating asymmetric regularization that constrains $π_{sample}$ while leaving $π_{d}$ under-optimized, providing an theoretical explanation of why RL succeeds where SFT fails. We also empirically validate our theoretical predictions on arithmetic reasoning demonstrates that RL's superior generalization stems primarily from improved decision-making ($π_{d}$) rather than sampling capabilities, providing a first-principles mechanistic explanation for self-correction in thinking models.",
    "authors": [
      "Zibo Zhao",
      "Yuanting Zha",
      "Haipeng Zhang",
      "Xingcheng Xu"
    ],
    "url": "http://arxiv.org/abs/2601.01580v1",
    "published": "2026-01-04",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文研究强化学习训练中语言模型自我反思能力的涌现机制，属于机器学习基础理论研究，而非应用AI解决具体科学问题或预测生物扰动响应。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01577v1",
    "title": "HanoiWorld : A Joint Embedding Predictive Architecture BasedWorld Model for Autonomous Vehicle Controller",
    "summary": "Current attempts of Reinforcement Learning for Autonomous Controller are data-demanding while the results are under-performed, unstable, and unable to grasp and anchor on the concept of safety, and over-concentrating on noise features due to the nature of pixel reconstruction. While current Self-Supervised Learningapproachs that learning on high-dimensional representations by leveraging the JointEmbedding Predictive Architecture (JEPA) are interesting and an effective alternative, as the idea mimics the natural ability of the human brain in acquiring new skill usingimagination and minimal samples of observations. This study introduces Hanoi-World, a JEPA-based world model that using recurrent neural network (RNN) formaking longterm horizontal planning with effective inference time. Experimentsconducted on the Highway-Env package with difference enviroment showcase the effective capability of making a driving plan while safety-awareness, with considerablecollision rate in comparison with SOTA baselines",
    "authors": [
      "Tran Tien Dat",
      "Nguyen Hai An",
      "Nguyen Khanh Viet Dung",
      "Nguyen Duy Duc"
    ],
    "url": "http://arxiv.org/abs/2601.01577v1",
    "published": "2026-01-04",
    "primary_category": "cs.RO",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于联合嵌入预测架构的世界模型，用于自动驾驶控制器的长期规划与安全感知，属于人工智能在工程应用领域的研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01576v1",
    "title": "OpenNovelty: An LLM-powered Agentic System for Verifiable Scholarly Novelty Assessment",
    "summary": "Evaluating novelty is critical yet challenging in peer review, as reviewers must assess submissions against a vast, rapidly evolving literature. This report presents OpenNovelty, an LLM-powered agentic system for transparent, evidence-based novelty analysis. The system operates through four phases: (1) extracting the core task and contribution claims to generate retrieval queries; (2) retrieving relevant prior work based on extracted queries via semantic search engine; (3) constructing a hierarchical taxonomy of core-task-related work and performing contribution-level full-text comparisons against each contribution; and (4) synthesizing all analyses into a structured novelty report with explicit citations and evidence snippets. Unlike naive LLM-based approaches, \\textsc{OpenNovelty} grounds all assessments in retrieved real papers, ensuring verifiable judgments. We deploy our system on 500+ ICLR 2026 submissions with all reports publicly available on our website, and preliminary analysis suggests it can identify relevant prior work, including closely related papers that authors may overlook. OpenNovelty aims to empower the research community with a scalable tool that promotes fair, consistent, and evidence-backed peer review.",
    "authors": [
      "Ming Zhang",
      "Kexin Tan",
      "Yueyuan Huang",
      "Yujiong Shen",
      "Chunchun Ma",
      "Li Ju",
      "Xinran Zhang",
      "Yuhui Wang",
      "Wenqing Jing",
      "Jingyi Deng",
      "Huayu Sha",
      "Binze Hu",
      "Jingqi Tong",
      "Changhao Jiang",
      "Yage Geng",
      "Yuankai Ying",
      "Yue Zhang",
      "Zhangyue Yin",
      "Zhiheng Xi",
      "Shihan Dou",
      "Tao Gui",
      "Qi Zhang",
      "Xuanjing Huang"
    ],
    "url": "http://arxiv.org/abs/2601.01576v1",
    "published": "2026-01-04",
    "primary_category": "cs.IR",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出一个基于大语言模型的学术新颖性评估系统，用于辅助同行评审过程，而非直接应用于自然科学领域的科学发现。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01575v1",
    "title": "A MINRES-based Linesearch Algorithm for Nonconvex Optimization with Non-positive Curvature Detection",
    "summary": "We propose a MINRES-based Newton-type algorithm for solving unconstrained nonconvex optimization problems. Our approach uses the minimal residual method (MINRES), a well-known solver for indefinite symmetric linear systems, to compute descent directions that leverage second-order and non-positive curvature (NPC) information. Comprehensive asymptotic convergence properties are derived under standard assumptions. In particular, under the Kurdyka-Łojasiewicz inequality and a mild NPC-detectability condition, we prove that our algorithm can avoid strict saddle points and converge to second-order critical points. This is primarily achieved by integrating proper regularization techniques and forward linesearch mechanisms along NPC directions. Furthermore, fast local superlinear convergence to potentially non-isolated minima is established, when the local Polyak-Łojasiewicz condition is satisfied. Numerical experiments on the CUTEst test collection and on a deep auto-encoder problem illustrate the efficiency of the proposed method.",
    "authors": [
      "Hanfeng Zeng",
      "Yang Liu",
      "Wenqing Ouyang",
      "Andre Milzarek"
    ],
    "url": "http://arxiv.org/abs/2601.01575v1",
    "published": "2026-01-04",
    "primary_category": "math.OC",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于MINRES的非凸优化算法，专注于数值优化方法的理论分析和算法设计，而非特定科学领域的AI应用或扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01569v1",
    "title": "CaveAgent: Transforming LLMs into Stateful Runtime Operators",
    "summary": "LLM-based agents are increasingly capable of complex task execution, yet current agentic systems remain constrained by text-centric paradigms. Traditional approaches rely on procedural JSON-based function calling, which often struggles with long-horizon tasks due to fragile multi-turn dependencies and context drift. In this paper, we present CaveAgent, a framework that transforms the paradigm from \"LLM-as-Text-Generator\" to \"LLM-as-Runtime-Operator.\" We introduce a Dual-stream Context Architecture that decouples state management into a lightweight semantic stream for reasoning and a persistent, deterministic Python Runtime stream for execution. In addition to leveraging code generation to efficiently resolve interdependent sub-tasks (e.g., loops, conditionals) in a single step, we introduce \\textit{Stateful Runtime Management} in CaveAgent. Distinct from existing code-based approaches that remain text-bound and lack the support for external object injection and retrieval, CaveAgent injects, manipulates, and retrieves complex Python objects (e.g., DataFrames, database connections) that persist across turns. This persistence mechanism acts as a high-fidelity external memory to eliminate context drift, avoid catastrophic forgetting, while ensuring that processed data flows losslessly to downstream applications. Comprehensive evaluations on Tau$^2$-bench, BFCL and various case studies across representative SOTA LLMs demonstrate CaveAgent's superiority. Specifically, our framework achieves a 10.5\\% success rate improvement on retail tasks and reduces total token consumption by 28.4\\% in multi-turn scenarios. On data-intensive tasks, direct variable storage and retrieval reduces token consumption by 59\\%, allowing CaveAgent to handle large-scale data that causes context overflow failures in both JSON-based and Code-based agents.",
    "authors": [
      "Maohao Ran",
      "Zhenglin Wan",
      "Cooper Lin",
      "Yanting Zhang",
      "Hongyu Xin",
      "Hongwei Fan",
      "Yibo Xu",
      "Beier Luo",
      "Yaxin Zhou",
      "Wangbo Zhao",
      "Lijie Yang",
      "Lang Feng",
      "Fuchao Yang",
      "Jingxuan Wu",
      "Yiqiao Huang",
      "Chendong Ma",
      "Dailing Jiang",
      "Jianbo Deng",
      "Sihui Han",
      "Bo An",
      "Yike Guo",
      "Jun Song"
    ],
    "url": "http://arxiv.org/abs/2601.01569v1",
    "published": "2026-01-04",
    "primary_category": "cs.AI",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种将大语言模型转化为状态化运行时操作符的通用框架，通过双流上下文架构和持久化Python对象管理来提升多轮任务执行效率，而非针对特定科学领域或扰动预测问题。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01568v1",
    "title": "MM-Sonate: Multimodal Controllable Audio-Video Generation with Zero-Shot Voice Cloning",
    "summary": "Joint audio-video generation aims to synthesize synchronized multisensory content, yet current unified models struggle with fine-grained acoustic control, particularly for identity-preserving speech. Existing approaches either suffer from temporal misalignment due to cascaded generation or lack the capability to perform zero-shot voice cloning within a joint synthesis framework. In this work, we present MM-Sonate, a multimodal flow-matching framework that unifies controllable audio-video joint generation with zero-shot voice cloning capabilities. Unlike prior works that rely on coarse semantic descriptions, MM-Sonate utilizes a unified instruction-phoneme input to enforce strict linguistic and temporal alignment. To enable zero-shot voice cloning, we introduce a timbre injection mechanism that effectively decouples speaker identity from linguistic content. Furthermore, addressing the limitations of standard classifier-free guidance in multimodal settings, we propose a noise-based negative conditioning strategy that utilizes natural noise priors to significantly enhance acoustic fidelity. Empirical evaluations demonstrate that MM-Sonate establishes new state-of-the-art performance in joint generation benchmarks, significantly outperforming baselines in lip synchronization and speech intelligibility, while achieving voice cloning fidelity comparable to specialized Text-to-Speech systems.",
    "authors": [
      "Chunyu Qiang",
      "Jun Wang",
      "Xiaopeng Wang",
      "Kang Yin",
      "Yuxin Guo",
      "Xijuan Zeng",
      "Nan Li",
      "Zihan Li",
      "Yuzhe Liang",
      "Ziyu Zhang",
      "Teng Ma",
      "Yushen Chen",
      "Zhongliang Liu",
      "Feng Deng",
      "Chen Zhang",
      "Pengfei Wan"
    ],
    "url": "http://arxiv.org/abs/2601.01568v1",
    "published": "2026-01-04",
    "primary_category": "cs.SD",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种多模态可控音视频生成框架，专注于语音克隆和音视频同步技术，属于计算机视觉与语音合成的交叉领域，而非科学发现或细胞扰动预测研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01562v1",
    "title": "Logics-STEM: Empowering LLM Reasoning via Failure-Driven Post-Training and Document Knowledge Enhancement",
    "summary": "We present Logics-STEM, a state-of-the-art reasoning model fine-tuned on Logics-STEM-SFT-Dataset, a high-quality and diverse dataset at 10M scale that represents one of the largest-scale open-source long chain-of-thought corpora. Logics-STEM targets reasoning tasks in the domains of Science, Technology, Engineering, and Mathematics (STEM), and exhibits exceptional performance on STEM-related benchmarks with an average improvement of 4.68% over the next-best model at 8B scale. We attribute the gains to our data-algorithm co-design engine, where they are jointly optimized to fit a gold-standard distribution behind reasoning. Data-wise, the Logics-STEM-SFT-Dataset is constructed from a meticulously designed data curation engine with 5 stages to ensure the quality, diversity, and scalability, including annotation, deduplication, decontamination, distillation, and stratified sampling. Algorithm-wise, our failure-driven post-training framework leverages targeted knowledge retrieval and data synthesis around model failure regions in the Supervised Fine-tuning (SFT) stage to effectively guide the second-stage SFT or the reinforcement learning (RL) for better fitting the target distribution. The superior empirical performance of Logics-STEM reveals the vast potential of combining large-scale open-source data with carefully designed synthetic data, underscoring the critical role of data-algorithm co-design in enhancing reasoning capabilities through post-training. We make both the Logics-STEM models (8B and 32B) and the Logics-STEM-SFT-Dataset (10M and downsampled 2.2M versions) publicly available to support future research in the open-source community.",
    "authors": [
      "Mingyu Xu",
      "Cheng Fang",
      "Keyue Jiang",
      "Yuqian Zheng",
      "Yanghua Xiao",
      "Baojian Zhou",
      "Qifang Zhao",
      "Suhang Zheng",
      "Xiuwen Zhu",
      "Jiyang Tang",
      "Yongchi Zhao",
      "Yijia Luo",
      "Zhiqi Bai",
      "Yuchi Xu",
      "Wenbo Su",
      "Wei Wang",
      "Bing Zhao",
      "Lin Qu",
      "Xiaoxiao Xu"
    ],
    "url": "http://arxiv.org/abs/2601.01562v1",
    "published": "2026-01-04",
    "primary_category": "cs.AI",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文通过开发Logics-STEM模型和数据集，专注于提升大型语言模型在STEM领域的推理能力，属于利用AI技术增强科学领域研究的方法学创新。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01558v1",
    "title": "Utilizing Earth Foundation Models to Enhance the Simulation Performance of Hydrological Models with AlphaEarth Embeddings",
    "summary": "Predicting river flow in places without streamflow records is challenging because basins respond differently to climate, terrain, vegetation, and soils. Traditional basin attributes describe some of these differences, but they cannot fully represent the complexity of natural environments. This study examines whether AlphaEarth Foundation embeddings, which are learned from large collections of satellite images rather than designed by experts, offer a more informative way to describe basin characteristics. These embeddings summarize patterns in vegetation, land surface properties, and long-term environmental dynamics. We find that models using them achieve higher accuracy when predicting flows in basins not used for training, suggesting that they capture key physical differences more effectively than traditional attributes. We further investigate how selecting appropriate donor basins influences prediction in ungauged regions. Similarity based on the embeddings helps identify basins with comparable environmental and hydrological behavior, improving performance, whereas adding many dissimilar basins can reduce accuracy. The results show that satellite-informed environmental representations can strengthen hydrological forecasting and support the development of models that adapt more easily to different landscapes.",
    "authors": [
      "Pengfei Qu",
      "Wenyu Ouyang",
      "Chi Zhang",
      "Yikai Chai",
      "Shuolong Xu",
      "Lei Ye",
      "Yongri Piao",
      "Miao Zhang",
      "Huchuan Lu"
    ],
    "url": "http://arxiv.org/abs/2601.01558v1",
    "published": "2026-01-04",
    "primary_category": "cs.LG",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该研究利用AI从卫星图像中学习环境特征嵌入，以提升水文模型在无径流记录区域的预测性能，属于AI在环境科学领域的应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01554v1",
    "title": "MOSS Transcribe Diarize: Accurate Transcription with Speaker Diarization",
    "summary": "Speaker-Attributed, Time-Stamped Transcription (SATS) aims to transcribe what is said and to precisely determine the timing of each speaker, which is particularly valuable for meeting transcription. Existing SATS systems rarely adopt an end-to-end formulation and are further constrained by limited context windows, weak long-range speaker memory, and the inability to output timestamps. To address these limitations, we present MOSS Transcribe Diarize, a unified multimodal large language model that jointly performs Speaker-Attributed, Time-Stamped Transcription in an end-to-end paradigm. Trained on extensive real wild data and equipped with a 128k context window for up to 90-minute inputs, MOSS Transcribe Diarize scales well and generalizes robustly. Across comprehensive evaluations, it outperforms state-of-the-art commercial systems on multiple public and in-house benchmarks.",
    "authors": [
      "Donghua Yu",
      "Zhengyuan Lin",
      "Chen Yang",
      "Yiyang Zhang",
      "Zhaoye Fei",
      "Hanfu Chen",
      "Jingqi Chen",
      "Ke Chen",
      "Qinyuan Cheng",
      "Liwei Fan",
      "Yi Jiang",
      "Jie Zhu",
      "Muchen Li",
      "Shimin Li",
      "Wenxuan Wang",
      "Yang Wang",
      "Zhe Xu",
      "Yitian Gong",
      "Yuqian Zhang"
    ],
    "url": "http://arxiv.org/abs/2601.01554v1",
    "published": "2026-01-04",
    "primary_category": "cs.SD",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于会议转录的端到端多模态大语言模型，专注于语音识别和说话人分离任务，而非科学发现或扰动预测领域。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01547v1",
    "title": "EscherVerse: An Open World Benchmark and Dataset for Teleo-Spatial Intelligence with Physical-Dynamic and Intent-Driven Understanding",
    "summary": "The ability to reason about spatial dynamics is a cornerstone of intelligence, yet current research overlooks the human intent behind spatial changes. To address these limitations, we introduce Teleo-Spatial Intelligence (TSI), a new paradigm that unifies two critical pillars: Physical-Dynamic Reasoning--understanding the physical principles of object interactions--and Intent-Driven Reasoning--inferring the human goals behind these actions. To catalyze research in TSI, we present EscherVerse, consisting of a large-scale, open-world benchmark (Escher-Bench), a dataset (Escher-35k), and models (Escher series). Derived from real-world videos, EscherVerse moves beyond constrained settings to explicitly evaluate an agent's ability to reason about object permanence, state transitions, and trajectory prediction in dynamic, human-centric scenarios. Crucially, it is the first benchmark to systematically assess Intent-Driven Reasoning, challenging models to connect physical events to their underlying human purposes. Our work, including a novel data curation pipeline, provides a foundational resource to advance spatial intelligence from passive scene description toward a holistic, purpose-driven understanding of the world.",
    "authors": [
      "Tianjun Gu",
      "Chenghua Gong",
      "Jingyu Gong",
      "Zhizhong Zhang",
      "Yuan Xie",
      "Lizhuang Ma",
      "Xin Tan"
    ],
    "url": "http://arxiv.org/abs/2601.01547v1",
    "published": "2026-01-04",
    "primary_category": "cs.CV",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一个结合物理动态推理与意图驱动推理的新范式Teleo-Spatial Intelligence，并构建了开放世界基准EscherVerse来推动空间智能从被动场景描述向目的驱动理解发展。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01546v1",
    "title": "Improving Behavioral Alignment in LLM Social Simulations via Context Formation and Navigation",
    "summary": "Large language models (LLMs) are increasingly used to simulate human behavior in experimental settings, but they systematically diverge from human decisions in complex decision-making environments, where participants must anticipate others' actions and form beliefs based on observed behavior. We propose a two-stage framework for improving behavioral alignment. The first stage, context formation, explicitly specifies the experimental design to establish an accurate representation of the decision task and its context. The second stage, context navigation, guides the reasoning process within that representation to make decisions. We validate this framework through a focal replication of a sequential purchasing game with quality signaling (Kremer and Debo, 2016), extending to a crowdfunding game with costly signaling (Cason et al., 2025) and a demand-estimation task (Gui and Toubia, 2025) to test generalizability across decision environments. Across four state-of-the-art (SOTA) models (GPT-4o, GPT-5, Claude-4.0-Sonnet-Thinking, DeepSeek-R1), we find that complex decision-making environments require both stages to achieve behavioral alignment with human benchmarks, whereas the simpler demand-estimation task requires only context formation. Our findings clarify when each stage is necessary and provide a systematic approach for designing and diagnosing LLM social simulations as complements to human subjects in behavioral research.",
    "authors": [
      "Letian Kong",
      "Qianran",
      "Jin",
      "Renyu Zhang"
    ],
    "url": "http://arxiv.org/abs/2601.01546v1",
    "published": "2026-01-04",
    "primary_category": "cs.AI",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出一个两阶段框架（情境形成与导航）来改进大语言模型在复杂决策环境中的行为对齐，属于社会科学模拟方法学研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01543v1",
    "title": "Bridging the Data Gap: Creating a Hindi Text Summarization Dataset from the English XSUM",
    "summary": "Current advancements in Natural Language Processing (NLP) have largely favored resource-rich languages, leaving a significant gap in high-quality datasets for low-resource languages like Hindi. This scarcity is particularly evident in text summarization, where the development of robust models is hindered by a lack of diverse, specialized corpora.   To address this disparity, this study introduces a cost-effective, automated framework for creating a comprehensive Hindi text summarization dataset. By leveraging the English Extreme Summarization (XSUM) dataset as a source, we employ advanced translation and linguistic adaptation techniques. To ensure high fidelity and contextual relevance, we utilize the Crosslingual Optimized Metric for Evaluation of Translation (COMET) for validation, supplemented by the selective use of Large Language Models (LLMs) for curation.   The resulting dataset provides a diverse, multi-thematic resource that mirrors the complexity of the original XSUM corpus. This initiative not only provides a direct tool for Hindi NLP research but also offers a scalable methodology for democratizing NLP in other underserved languages. By reducing the costs associated with dataset creation, this work fosters the development of more nuanced, culturally relevant models in computational linguistics.",
    "authors": [
      "Praveenkumar Katwe",
      "RakeshChandra Balabantaray",
      "Kaliprasad Vittala"
    ],
    "url": "http://arxiv.org/abs/2601.01543v1",
    "published": "2026-01-04",
    "primary_category": "cs.CL",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种利用翻译和语言适应技术从英语XSUM数据集创建印地语文本摘要数据集的自动化框架，旨在解决低资源语言在自然语言处理中的数据集稀缺问题。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01538v1",
    "title": "Lyapunov Functions can Exactly Quantify Rate Performance of Nonlinear Differential Equations",
    "summary": "Pointwise-in-time stability notions for Ordinary Differential Equations (ODEs) provide quantitative metrics for system performance by establishing bounds on the rate of decay of the system state in terms of initial condition -- allowing stability to be quantified by e.g. the maximum provable decay rate. Such bounds may be obtained by finding suitable Lyapunov functions using, e.g. Sum-of-Squares (SOS) optimization. While Lyapunov tests have been proposed for numerous pointwise-in-time stability notions, including exponential, rational, and finite-time stability, it is unclear whether these characterizations are able to provide accurate bounds on system performance.   In this paper, we start by proposing a generalized notion of rate performance -- with exponential, rational, and finite-time decay rates being special cases. Then, for any such notion and rate, we associate a Lyapunov condition which is shown to be necessary and sufficient for a system to achieve that rate. Finally, we show how the proposed conditions can be enforced using SOS programming in the case of exponential, rational, and finite-time stability. Numerical examples in each case demonstrate that the corresponding SOS test can achieve tight bounds on the rate performance with accurate inner bounds on the associated regions of performance.",
    "authors": [
      "Declan S. Jagt",
      "Matthew M. Peet"
    ],
    "url": "http://arxiv.org/abs/2601.01538v1",
    "published": "2026-01-04",
    "primary_category": "math.OC",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于Lyapunov函数的通用框架，用于精确量化非线性微分方程系统的速率性能，并通过SOS优化实现数值验证。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01532v1",
    "title": "Aletheia: Quantifying Cognitive Conviction in Reasoning Models via Regularized Inverse Confusion Matrix",
    "summary": "In the progressive journey toward Artificial General Intelligence (AGI), current evaluation paradigms face an epistemological crisis. Static benchmarks measure knowledge breadth but fail to quantify the depth of belief. While Simhi et al. (2025) defined the CHOKE phenomenon in standard QA, we extend this framework to quantify \"Cognitive Conviction\" in System 2 reasoning models. We propose Project Aletheia, a cognitive physics framework that employs Tikhonov Regularization to invert the judge's confusion matrix. To validate this methodology without relying on opaque private data, we implement a Synthetic Proxy Protocol. Our preliminary pilot study on 2025 baselines (e.g., DeepSeek-R1, OpenAI o1) suggests that while reasoning models act as a \"cognitive buffer,\" they may exhibit \"Defensive OverThinking\" under adversarial pressure. Furthermore, we introduce the Aligned Conviction Score (S_aligned) to verify that conviction does not compromise safety. This work serves as a blueprint for measuring AI scientific integrity.",
    "authors": [
      "Fanzhe Fu"
    ],
    "url": "http://arxiv.org/abs/2601.01532v1",
    "published": "2026-01-04",
    "primary_category": "cs.AI",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一个通过正则化逆混淆矩阵量化推理模型认知确信度的认知物理框架，属于人工智能评估方法论研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01528v1",
    "title": "DrivingGen: A Comprehensive Benchmark for Generative Video World Models in Autonomous Driving",
    "summary": "Video generation models, as one form of world models, have emerged as one of the most exciting frontiers in AI, promising agents the ability to imagine the future by modeling the temporal evolution of complex scenes. In autonomous driving, this vision gives rise to driving world models: generative simulators that imagine ego and agent futures, enabling scalable simulation, safe testing of corner cases, and rich synthetic data generation. Yet, despite fast-growing research activity, the field lacks a rigorous benchmark to measure progress and guide priorities. Existing evaluations remain limited: generic video metrics overlook safety-critical imaging factors; trajectory plausibility is rarely quantified; temporal and agent-level consistency is neglected; and controllability with respect to ego conditioning is ignored. Moreover, current datasets fail to cover the diversity of conditions required for real-world deployment. To address these gaps, we present DrivingGen, the first comprehensive benchmark for generative driving world models. DrivingGen combines a diverse evaluation dataset curated from both driving datasets and internet-scale video sources, spanning varied weather, time of day, geographic regions, and complex maneuvers, with a suite of new metrics that jointly assess visual realism, trajectory plausibility, temporal coherence, and controllability. Benchmarking 14 state-of-the-art models reveals clear trade-offs: general models look better but break physics, while driving-specific ones capture motion realistically but lag in visual quality. DrivingGen offers a unified evaluation framework to foster reliable, controllable, and deployable driving world models, enabling scalable simulation, planning, and data-driven decision-making.",
    "authors": [
      "Yang Zhou",
      "Hao Shao",
      "Letian Wang",
      "Zhuofan Zong",
      "Hongsheng Li",
      "Steven L. Waslander"
    ],
    "url": "http://arxiv.org/abs/2601.01528v1",
    "published": "2026-01-04",
    "primary_category": "cs.CV",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出自动驾驶领域的视频生成模型基准测试，属于计算机视觉与自动驾驶应用，而非基础科学发现或生物医学扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01522v1",
    "title": "Bayesian Orchestration of Multi-LLM Agents for Cost-Aware Sequential Decision-Making",
    "summary": "Large language models (LLMs) are increasingly deployed as autonomous decision agents in settings with asymmetric error costs: hiring (missed talent vs wasted interviews), medical triage (missed emergencies vs unnecessary escalation), and fraud detection (approved fraud vs declined legitimate payments). The dominant design queries a single LLM for a posterior over states, thresholds \"confidence,\" and acts; we prove this is inadequate for sequential decisions with costs. We propose a Bayesian, cost-aware multi-LLM orchestration framework that treats LLMs as approximate likelihood models rather than classifiers. For each candidate state, we elicit likelihoods via contrastive prompting, aggregate across diverse models with robust statistics, and update beliefs with Bayes rule under explicit priors as new evidence arrives. This enables coherent belief updating, expected-cost action selection, principled information gathering via value of information, and fairness gains via ensemble bias mitigation. In resume screening with costs of 40000 USD per missed hire, 2500 USD per interview, and 150 USD per phone screen, experiments on 1000 resumes using five LLMs (GPT-4o, Claude 4.5 Sonnet, Gemini Pro, Grok, DeepSeek) reduce total cost by 294000 USD (34 percent) versus the best single-LLM baseline and improve demographic parity by 45 percent (max group gap 22 to 5 percentage points). Ablations attribute 51 percent of savings to multi-LLM aggregation, 43 percent to sequential updating, and 20 percent to disagreement-triggered information gathering, consistent with the theoretical benefits of correct probabilistic foundations.",
    "authors": [
      "Danial Amin"
    ],
    "url": "http://arxiv.org/abs/2601.01522v1",
    "published": "2026-01-04",
    "primary_category": "cs.AI",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于成本感知顺序决策的贝叶斯多LLM协调框架，属于人工智能方法论研究而非具体科学领域的发现应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01513v1",
    "title": "FastV-RAG: Towards Fast and Fine-Grained Video QA with Retrieval-Augmented Generation",
    "summary": "Vision-Language Models (VLMs) excel at visual reasoning but still struggle with integrating external knowledge. Retrieval-Augmented Generation (RAG) is a promising solution, but current methods remain inefficient and often fail to maintain high answer quality. To address these challenges, we propose VideoSpeculateRAG, an efficient VLM-based RAG framework built on two key ideas. First, we introduce a speculative decoding pipeline: a lightweight draft model quickly generates multiple answer candidates, which are then verified and refined by a more accurate heavyweight model, substantially reducing inference latency without sacrificing correctness. Second, we identify a major source of error - incorrect entity recognition in retrieved knowledge - and mitigate it with a simple yet effective similarity-based filtering strategy that improves entity alignment and boosts overall answer accuracy. Experiments demonstrate that VideoSpeculateRAG achieves comparable or higher accuracy than standard RAG approaches while accelerating inference by approximately 2x. Our framework highlights the potential of combining speculative decoding with retrieval-augmented reasoning to enhance efficiency and reliability in complex, knowledge-intensive multimodal tasks.",
    "authors": [
      "Gen Li",
      "Peiyu Liu"
    ],
    "url": "http://arxiv.org/abs/2601.01513v1",
    "published": "2026-01-04",
    "primary_category": "cs.CV",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种结合推测解码与检索增强的视频问答框架，旨在提升多模态任务中的推理效率和准确性。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01512v1",
    "title": "A Novel Deep Learning Method for Segmenting the Left Ventricle in Cardiac Cine MRI",
    "summary": "This research aims to develop a novel deep learning network, GBU-Net, utilizing a group-batch-normalized U-Net framework, specifically designed for the precise semantic segmentation of the left ventricle in short-axis cine MRI scans. The methodology includes a down-sampling pathway for feature extraction and an up-sampling pathway for detail restoration, enhanced for medical imaging. Key modifications include techniques for better contextual understanding crucial in cardiac MRI segmentation. The dataset consists of 805 left ventricular MRI scans from 45 patients, with comparative analysis using established metrics such as the dice coefficient and mean perpendicular distance. GBU-Net significantly improves the accuracy of left ventricle segmentation in cine MRI scans. Its innovative design outperforms existing methods in tests, surpassing standard metrics like the dice coefficient and mean perpendicular distance. The approach is unique in its ability to capture contextual information, often missed in traditional CNN-based segmentation. An ensemble of the GBU-Net attains a 97% dice score on the SunnyBrook testing dataset. GBU-Net offers enhanced precision and contextual understanding in left ventricle segmentation for surgical robotics and medical analysis.",
    "authors": [
      "Wenhui Chu",
      "Aobo Jin",
      "Hardik A. Gohel"
    ],
    "url": "http://arxiv.org/abs/2601.01512v1",
    "published": "2026-01-04",
    "primary_category": "cs.CV",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文开发了一种用于心脏MRI左心室分割的深度学习网络GBU-Net，属于AI在医学影像分析领域的应用，符合AI4Science范畴。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01511v1",
    "title": "Reading Between the Lines: Deconfounding Causal Estimates using Text Embeddings and Deep Learning",
    "summary": "Estimating causal treatment effects in observational settings is frequently compromised by selection bias arising from unobserved confounders. While traditional econometric methods struggle when these confounders are orthogonal to structured covariates, high-dimensional unstructured text often contains rich proxies for these latent variables. This study proposes a Neural Network-Enhanced Double Machine Learning (DML) framework designed to leverage text embeddings for causal identification. Using a rigorous synthetic benchmark, we demonstrate that unstructured text embeddings capture critical confounding information that is absent from structured tabular data. However, we show that standard tree-based DML estimators retain substantial bias (+24%) due to their inability to model the continuous topology of embedding manifolds. In contrast, our deep learning approach reduces bias to -0.86% with optimized architectures, effectively recovering the ground-truth causal parameter. These findings suggest that deep learning architectures are essential for satisfying the unconfoundedness assumption when conditioning on high-dimensional natural language data",
    "authors": [
      "Ahmed Dawoud",
      "Osama El-Shamy"
    ],
    "url": "http://arxiv.org/abs/2601.01511v1",
    "published": "2026-01-04",
    "primary_category": "cs.AI",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种利用文本嵌入和深度学习消除因果估计中混淆变量的方法，属于计量经济学和机器学习交叉领域，而非特定科学发现或扰动预测研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01502v1",
    "title": "Multiscale replay: A robust algorithm for stochastic variational inequalities with a Markovian buffer",
    "summary": "We introduce the Multiscale Experience Replay (MER) algorithm for solving a class of stochastic variational inequalities (VIs) in settings where samples are generated from a Markov chain and we have access to a memory buffer to store them. Rather than uniformly sampling from the buffer, MER utilizes a multi-scale sampling scheme to emulate the behavior of VI algorithms designed for independent and identically distributed samples, overcoming bias in the de facto serial scheme and thereby accelerating convergence. Notably, unlike standard sample-skipping variants of serial algorithms, MER is robust in that it achieves this acceleration in iteration complexity whenever possible, and without requiring knowledge of the mixing time of the Markov chain. We also discuss applications of MER, particularly in policy evaluation with temporal difference learning and in training generalized linear models with dependent data.",
    "authors": [
      "Milind Nakul",
      "Tianjiao Li",
      "Ashwin Pananjady"
    ],
    "url": "http://arxiv.org/abs/2601.01502v1",
    "published": "2026-01-04",
    "primary_category": "math.OC",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于解决马尔可夫链样本下随机变分不等式的多尺度重放算法，属于机器学习优化方法的研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01501v1",
    "title": "Advanced Global Wildfire Activity Modeling with Hierarchical Graph ODE",
    "summary": "Wildfires, as an integral component of the Earth system, are governed by a complex interplay of atmospheric, oceanic, and terrestrial processes spanning a vast range of spatiotemporal scales. Modeling their global activity on large timescales is therefore a critical yet challenging task. While deep learning has recently achieved significant breakthroughs in global weather forecasting, its potential for global wildfire behavior prediction remains underexplored. In this work, we reframe this problem and introduce the Hierarchical Graph ODE (HiGO), a novel framework designed to learn the multi-scale, continuous-time dynamics of wildfires. Specifically, we represent the Earth system as a multi-level graph hierarchy and propose an adaptive filtering message passing mechanism for both intra- and inter-level information flow, enabling more effective feature extraction and fusion. Furthermore, we incorporate GNN-parameterized Neural ODE modules at multiple levels to explicitly learn the continuous dynamics inherent to each scale. Through extensive experiments on the SeasFire Cube dataset, we demonstrate that HiGO significantly outperforms state-of-the-art baselines on long-range wildfire forecasting. Moreover, its continuous-time predictions exhibit strong observational consistency, highlighting its potential for real-world applications.",
    "authors": [
      "Fan Xu",
      "Wei Gong",
      "Hao Wu",
      "Lilan Peng",
      "Nan Wang",
      "Qingsong Wen",
      "Xian Wu",
      "Kun Wang",
      "Xibin Zhao"
    ],
    "url": "http://arxiv.org/abs/2601.01501v1",
    "published": "2026-01-04",
    "primary_category": "cs.LG",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于分层图ODE的AI模型，用于预测全球野火活动的多尺度连续时间动态，属于AI在地球系统科学领域的应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01497v1",
    "title": "On the Practical Estimation and Interpretation of Rényi Transfer Entropy",
    "summary": "Rényi transfer entropy (RTE) is a generalization of classical transfer entropy that replaces Shannon's entropy with Rényi's information measure. This, in turn, introduces a new tunable parameter $α$, which accounts for sensitivity to low- or high-probability events. Although RTE shows strong potential for analyzing causal relations in complex, non-Gaussian systems, its practical use is limited, primarily due to challenges related to its accurate estimation and interpretation. These difficulties are especially pronounced when working with finite, high-dimensional, or heterogeneous datasets. In this paper, we systematically study the performance of a k-nearest neighbor estimator for both Rényi entropy (RE) and RTE using various synthetic data sets with clear cause-and-effect relationships inherent to their construction. We test the estimator across a broad range of parameters, including sample size, dimensionality, memory length, and Rényi order $α$. In particular, we apply the estimator to a set of simulated processes with increasing structural complexity, ranging from linear dynamics to nonlinear systems with multi-source couplings. To address interpretational challenges arising from potentially negative RE and RTE values, we introduce three reliability conditions and formulate practical guidelines for tuning the estimator parameters. We show that when the reliability conditions are met and the parameters are calibrated accordingly, the resulting effective RTE estimates accurately capture directional information flow across a broad range of scenarios. Results obtained show that the explanatory power of RTE depends sensitively on the choice of the Rényi parameter $α$. This highlights the usefulness of the RTE framework for identifying the drivers of extreme behavior in complex systems.",
    "authors": [
      "Zlata Tabachová",
      "Petr Jizba",
      "Hynek Lavička",
      "Milan Paluš"
    ],
    "url": "http://arxiv.org/abs/2601.01497v1",
    "published": "2026-01-04",
    "primary_category": "nlin.PS",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文通过开发Rényi转移熵的估计方法，为分析复杂系统中的因果信息流提供了新工具，可应用于AI辅助的科学发现。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01496v1",
    "title": "The Optimal Sample Complexity of Linear Contracts",
    "summary": "In this paper, we settle the problem of learning optimal linear contracts from data in the offline setting, where agent types are drawn from an unknown distribution and the principal's goal is to design a contract that maximizes her expected utility. Specifically, our analysis shows that the simple Empirical Utility Maximization (EUM) algorithm yields an $\\varepsilon$-approximation of the optimal linear contract with probability at least $1-δ$, using just $O(\\ln(1/δ) / \\varepsilon^2)$ samples. This result improves upon previously known bounds and matches a lower bound from Duetting et al. [2025] up to constant factors, thereby proving its optimality. Our analysis uses a chaining argument, where the key insight is to leverage a simple structural property of linear contracts: their expected reward is non-decreasing. This property, which holds even though the utility function itself is non-monotone and discontinuous, enables the construction of fine-grained nets required for the chaining argument, which in turn yields the optimal sample complexity. Furthermore, our proof establishes the stronger guarantee of uniform convergence: the empirical utility of every linear contract is a $\\varepsilon$-approximation of its true expectation with probability at least $1-δ$, using the same optimal $O(\\ln(1/δ) / \\varepsilon^2)$ sample complexity.",
    "authors": [
      "Mikael Møller Høgsgaard"
    ],
    "url": "http://arxiv.org/abs/2601.01496v1",
    "published": "2026-01-04",
    "primary_category": "cs.GT",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文通过链式论证证明了线性合约的样本复杂度最优性，属于经济学机制设计领域，而非AI4Science或扰动预测研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01493v1",
    "title": "Accelerating Decentralized Optimization via Overlapping Local Steps",
    "summary": "Decentralized optimization has emerged as a critical paradigm for distributed learning, enabling scalable training while preserving data privacy through peer-to-peer collaboration. However, existing methods often suffer from communication bottlenecks due to frequent synchronization between nodes. We present Overlapping Local Decentralized SGD (OLDSGD), a novel approach to accelerate decentralized training by computation-communication overlapping, significantly reducing network idle time. With a deliberately designed update, OLDSGD preserves the same average update as Local SGD while avoiding communication-induced stalls. Theoretically, we establish non-asymptotic convergence rates for smooth non-convex objectives, showing that OLDSGD retains the same iteration complexity as standard Local Decentralized SGD while improving per-iteration runtime. Empirical results demonstrate OLDSGD's consistent improvements in wall-clock time convergence under different levels of communication delays. With minimal modifications to existing frameworks, OLDSGD offers a practical solution for faster decentralized learning without sacrificing theoretical guarantees.",
    "authors": [
      "Yijie Zhou",
      "Shi Pu"
    ],
    "url": "http://arxiv.org/abs/2601.01493v1",
    "published": "2026-01-04",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种通过重叠本地步骤加速去中心化优化的新方法，专注于分布式学习中的计算-通信重叠技术改进，而非AI4Science或扰动预测领域。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01490v1",
    "title": "Distortion Instead of Hallucination: The Effect of Reasoning Under Strict Constraints",
    "summary": "With the widespread adoption of large language models (LLMs), hallucinations, which are non-factual fabrications in model outputs, have become serious concerns. Reasoning capabilities have received attention as a self-verification process to improve output reliability. However, the effect of reasoning within a closed system where LLMs cannot rely on external tools or knowledge has yet to be clarified. We therefore conduct experiments under strict constraints (recommending peer-reviewed journal articles in computer science) to examine the effect of reasoning across multiple models (GPT-5.2 and Gemini 3 Flash). Our results reveal a problematic trade-off between constraint compliance and factual accuracy. Non-reasoning models exhibit high constraint violation rates (66-75%) but maintain factual accuracy, while reasoning models reduce violations (13-26%) but systematically distort known facts to satisfy constraints and increase complete fabrication. This trade-off pattern is consistent across both models despite different architectures, indicating a fundamental limitation of reasoning. Furthermore, reasoning does not uniformly improve output authenticity: effects diverge by model, reflecting different allocations of the compliance-truthfulness trade-off. These findings challenge the assumption that reasoning universally improves reliability: reasoning models trade honest constraint violations for detection-resistant distortions.",
    "authors": [
      "Junichiro Niimi"
    ],
    "url": "http://arxiv.org/abs/2601.01490v1",
    "published": "2026-01-04",
    "primary_category": "cs.CL",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该研究揭示了大型语言模型在严格约束下进行推理时，会以牺牲事实准确性为代价来满足约束条件，挑战了推理能普遍提高输出可靠性的假设。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01489v1",
    "title": "Importance sampling of unbounded random stopping times: computing committor functions and exit rates without reweighting",
    "summary": "Rare events in molecular dynamics are often related to noise-induced transitions between different macroscopic states (e.g., in protein folding). A common feature of these rare transitions is that they happen on timescales that are on average exponentially long compared to the characteristic timescale of the system, with waiting time distributions that have (sub)exponential tails and infinite support. As a result, sampling such rare events can lead to trajectories that can be become arbitrarily long, with not too low probability, which makes the reweighting of such trajectories a real challenge. Here, we discuss rare event simulation by importance sampling from a variational perspective, with a focus on applications in molecular dynamics, in particular the computation of committor functions. The idea is to design importance sampling schemes that (a) reduce the variance of a rare event estimator while controlling the average length of the trajectories and (b) that do not require the reweighting of possibly very long trajectories. In doing so, we study different stochastic control formulations for committor and mean first exit times, which we compare both from a theoretical and a computational point of view, including numerical studies of some benchmark examples.",
    "authors": [
      "Carsten Hartmann",
      "Annika Jöster",
      "Christof Schütte",
      "Alexander Sikorski",
      "Marcus Weber"
    ],
    "url": "http://arxiv.org/abs/2601.01489v1",
    "published": "2026-01-04",
    "primary_category": "math.PR",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种无需重加权的重要性采样方法，用于计算分子动力学中的转换概率和逃逸率，属于计算数学和统计物理领域。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01488v1",
    "title": "Four Quadrants of Difficulty: A Simple Categorisation and its Limits",
    "summary": "Curriculum Learning (CL) aims to improve the outcome of model training by estimating the difficulty of samples and scheduling them accordingly. In NLP, difficulty is commonly approximated using task-agnostic linguistic heuristics or human intuition, implicitly assuming that these signals correlate with what neural models find difficult to learn. We propose a four-quadrant categorisation of difficulty signals -- human vs. model and task-agnostic vs. task-dependent -- and systematically analyse their interactions on a natural language understanding dataset. We find that task-agnostic features behave largely independently and that only task-dependent features align. These findings challenge common CL intuitions and highlight the need for lightweight, task-dependent difficulty estimators that better reflect model learning behaviour.",
    "authors": [
      "Vanessa Toborek",
      "Sebastian Müller",
      "Christian Bauckhage"
    ],
    "url": "http://arxiv.org/abs/2601.01488v1",
    "published": "2026-01-04",
    "primary_category": "cs.CL",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于自然语言处理中课程学习的难度评估方法分类与验证，不涉及生物学、化学或物理学等自然科学领域的AI应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01487v1",
    "title": "DeepInv: A Novel Self-supervised Learning Approach for Fast and Accurate Diffusion Inversion",
    "summary": "Diffusion inversion is a task of recovering the noise of an image in a diffusion model, which is vital for controllable diffusion image editing. At present, diffusion inversion still remains a challenging task due to the lack of viable supervision signals. Thus, most existing methods resort to approximation-based solutions, which however are often at the cost of performance or efficiency. To remedy these shortcomings, we propose a novel self-supervised diffusion inversion approach in this paper, termed Deep Inversion (DeepInv). Instead of requiring ground-truth noise annotations, we introduce a self-supervised objective as well as a data augmentation strategy to generate high-quality pseudo noises from real images without manual intervention. Based on these two innovative designs, DeepInv is also equipped with an iterative and multi-scale training regime to train a parameterized inversion solver, thereby achieving the fast and accurate image-to-noise mapping. To the best of our knowledge, this is the first attempt of presenting a trainable solver to predict inversion noise step by step. The extensive experiments show that our DeepInv can achieve much better performance and inference speed than the compared methods, e.g., +40.435% SSIM than EasyInv and +9887.5% speed than ReNoise on COCO dataset. Moreover, our careful designs of trainable solvers can also provide insights to the community. Codes and model parameters will be released in https://github.com/potato-kitty/DeepInv.",
    "authors": [
      "Ziyue Zhang",
      "Luxi Lin",
      "Xiaolin Hu",
      "Chao Chang",
      "HuaiXi Wang",
      "Yiyi Zhou",
      "Rongrong Ji"
    ],
    "url": "http://arxiv.org/abs/2601.01487v1",
    "published": "2026-01-04",
    "primary_category": "cs.CV",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于扩散模型图像编辑的自监督噪声预测方法，属于计算机视觉领域的算法改进，不涉及生物学、化学或物理学等自然科学发现。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01484v1",
    "title": "SGD-Based Knowledge Distillation with Bayesian Teachers: Theory and Guidelines",
    "summary": "Knowledge Distillation (KD) is a central paradigm for transferring knowledge from a large teacher network to a typically smaller student model, often by leveraging soft probabilistic outputs. While KD has shown strong empirical success in numerous applications, its theoretical underpinnings remain only partially understood. In this work, we adopt a Bayesian perspective on KD to rigorously analyze the convergence behavior of students trained with Stochastic Gradient Descent (SGD). We study two regimes: $(i)$ when the teacher provides the exact Bayes Class Probabilities (BCPs); and $(ii)$ supervision with noisy approximations of the BCPs. Our analysis shows that learning from BCPs yields variance reduction and removes neighborhood terms in the convergence bounds compared to one-hot supervision. We further characterize how the level of noise affects generalization and accuracy. Motivated by these insights, we advocate the use of Bayesian deep learning models, which typically provide improved estimates of the BCPs, as teachers in KD. Consistent with our analysis, we experimentally demonstrate that students distilled from Bayesian teachers not only achieve higher accuracies (up to +4.27%), but also exhibit more stable convergence (up to 30% less noise), compared to students distilled from deterministic teachers.",
    "authors": [
      "Itai Morad",
      "Nir Shlezinger",
      "Yonina C. Eldar"
    ],
    "url": "http://arxiv.org/abs/2601.01484v1",
    "published": "2026-01-04",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于知识蒸馏的理论分析和算法改进，属于机器学习方法论的范畴，不涉及特定科学领域的发现或扰动预测应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01480v1",
    "title": "Modeling Information Blackouts in Missing Not-At-Random Time Series Data",
    "summary": "Large-scale traffic forecasting relies on fixed sensor networks that often exhibit blackouts: contiguous intervals of missing measurements caused by detector or communication failures. These outages are typically handled under a Missing At Random (MAR) assumption, even though blackout events may correlate with unobserved traffic conditions (e.g., congestion or anomalous flow), motivating a Missing Not At Random (MNAR) treatment. We propose a latent state-space framework that jointly models (i) traffic dynamics via a linear dynamical system and (ii) sensor dropout via a Bernoulli observation channel whose probability depends on the latent traffic state. Inference uses an Extended Kalman Filter with Rauch-Tung-Striebel smoothing, and parameters are learned via an approximate EM procedure with a dedicated update for detector-specific missingness parameters. On the Seattle inductive loop detector data, introducing latent dynamics yields large gains over naive baselines, reducing blackout imputation RMSE from 7.02 (LOCF) and 5.02 (linear interpolation + seasonal naive) to 4.23 (MAR LDS), corresponding to about a 64% reduction in MSE relative to LOCF. Explicit MNAR modeling provides a consistent but smaller additional improvement on real data (imputation RMSE 4.20; 0.8% RMSE reduction relative to MAR), with similar modest gains for short-horizon post-blackout forecasts (evaluated at 1, 3, and 6 steps). In controlled synthetic experiments, the MNAR advantage increases as the true missingness dependence on latent state strengthens. Overall, temporal dynamics dominate performance, while MNAR modeling offers a principled refinement that becomes most valuable when missingness is genuinely informative.",
    "authors": [
      "Aman Sunesh",
      "Allan Ma",
      "Siddarth Nilol"
    ],
    "url": "http://arxiv.org/abs/2601.01480v1",
    "published": "2026-01-04",
    "primary_category": "stat.ML",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于交通传感器数据缺失值插补的隐状态空间模型，通过联合建模交通动态和传感器丢失机制来改进预测精度。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01475v1",
    "title": "Multi-Subspace Multi-Modal Modeling for Diffusion Models: Estimation, Convergence and Mixture of Experts",
    "summary": "Recently, diffusion models have achieved a great performance with a small dataset of size $n$ and a fast optimization process. However, the estimation error of diffusion models suffers from the curse of dimensionality $n^{-1/D}$ with the data dimension $D$. Since images are usually a union of low-dimensional manifolds, current works model the data as a union of linear subspaces with Gaussian latent and achieve a $1/\\sqrt{n}$ bound. Though this modeling reflects the multi-manifold property, the Gaussian latent can not capture the multi-modal property of the latent manifold. To bridge this gap, we propose the mixture subspace of low-rank mixture of Gaussian (MoLR-MoG) modeling, which models the target data as a union of $K$ linear subspaces, and each subspace admits a mixture of Gaussian latent ($n_k$ modals with dimension $d_k$). With this modeling, the corresponding score function naturally has a mixture of expert (MoE) structure, captures the multi-modal information, and contains nonlinear property. We first conduct real-world experiments to show that the generation results of MoE-latent MoG NN are much better than MoE-latent Gaussian score. Furthermore, MoE-latent MoG NN achieves a comparable performance with MoE-latent Unet with $10 \\times$ parameters. These results indicate that the MoLR-MoG modeling is reasonable and suitable for real-world data. After that, based on such MoE-latent MoG score, we provide a $R^4\\sqrt{Σ_{k=1}^Kn_k}\\sqrt{Σ_{k=1}^Kn_kd_k}/\\sqrt{n}$ estimation error, which escapes the curse of dimensionality by using data structure. Finally, we study the optimization process and prove the convergence guarantee under the MoLR-MoG modeling. Combined with these results, under a setting close to real-world data, this work explains why diffusion models only require a small training sample and enjoy a fast optimization process to achieve a great performance.",
    "authors": [
      "Ruofeng Yang",
      "Yongcan Li",
      "Bo Jiang",
      "Cheng Chen",
      "Shuai Li"
    ],
    "url": "http://arxiv.org/abs/2601.01475v1",
    "published": "2026-01-04",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于扩散模型的多子空间多模态建模方法，通过混合低秩高斯模型改进生成质量并规避维度灾难，属于机器学习模型改进的基础研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01473v1",
    "title": "Accelerating Storage-Based Training for Graph Neural Networks",
    "summary": "Graph neural networks (GNNs) have achieved breakthroughs in various real-world downstream tasks due to their powerful expressiveness. As the scale of real-world graphs has been continuously growing, \\textit{a storage-based approach to GNN training} has been studied, which leverages external storage (e.g., NVMe SSDs) to handle such web-scale graphs on a single machine. Although such storage-based GNN training methods have shown promising potential in large-scale GNN training, we observed that they suffer from a severe bottleneck in data preparation since they overlook a critical challenge: \\textit{how to handle a large number of small storage I/Os}. To address the challenge, in this paper, we propose a novel storage-based GNN training framework, named \\textsf{AGNES}, that employs a method of \\textit{block-wise storage I/O processing} to fully utilize the I/O bandwidth of high-performance storage devices. Moreover, to further enhance the efficiency of each storage I/O, \\textsf{AGNES} employs a simple yet effective strategy, \\textit{hyperbatch-based processing} based on the characteristics of real-world graphs. Comprehensive experiments on five real-world graphs reveal that \\textsf{AGNES} consistently outperforms four state-of-the-art methods, by up to 4.1$\\times$ faster than the best competitor. Our code is available at https://github.com/Bigdasgit/agnes-kdd26.",
    "authors": [
      "Myung-Hwan Jang",
      "Jeong-Min Park",
      "Yunyong Ko",
      "Sang-Wook Kim"
    ],
    "url": "http://arxiv.org/abs/2601.01473v1",
    "published": "2026-01-04",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于存储的图神经网络训练框架AGNES，通过块状存储I/O处理和超批次处理优化大规模图数据训练效率，属于机器学习系统优化研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01471v1",
    "title": "Double Machine Learning of Continuous Treatment Effects with General Instrumental Variables",
    "summary": "Estimating causal effects of continuous treatments is a common problem in practice, for example, in studying dose-response functions. Classical analyses typically assume that all confounders are fully observed, whereas in real-world applications, unmeasured confounding often persists. In this article, we propose a novel framework for local identification of dose-response functions using instrumental variables, thereby mitigating bias induced by unobserved confounders. We introduce the concept of a uniform regular weighting function and consider covering the treatment space with a finite collection of open sets. On each of these sets, such a weighting function exists, allowing us to identify the dose-response function locally within the corresponding region. For estimation, we develop an augmented inverse probability weighting score for continuous treatments under a debiased machine learning framework with instrumental variables. We further establish the asymptotic properties when the dose-response function is estimated via kernel regression or empirical risk minimization. Finally, we conduct both simulation and empirical studies to assess the finite-sample performance of the proposed methods.",
    "authors": [
      "Shuyuan Chen",
      "Peng Zhang",
      "Yifan Cui"
    ],
    "url": "http://arxiv.org/abs/2601.01471v1",
    "published": "2026-01-04",
    "primary_category": "math.ST",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种结合机器学习和工具变量的因果推断方法，用于估计连续处理（如剂量反应）的因果效应，适用于存在未观测混杂的科学发现场景。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01467v1",
    "title": "A construction of an optimal base for conditional attribute and attributional condition implications in triadic contexts",
    "summary": "This article studies implications in triadic contexts. Specifically, we focus on those introduced by Ganter and Obiedkov, namely conditional attribute and attributional condition implications. Our aim is to construct an optimal base for these implications.",
    "authors": [
      "Romuald Kwessy Mouona",
      "Blaise Blériot Koguep Njionou",
      "Etienne Romuald Temgoua Alomo",
      "Rokia Missaoui",
      "Leonard Kwuida"
    ],
    "url": "http://arxiv.org/abs/2601.01467v1",
    "published": "2026-01-04",
    "primary_category": "cs.AI",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文研究三元背景下的形式概念分析中的蕴含关系，属于纯数学和理论计算机科学领域，不涉及AI4Science或扰动预测的具体应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01465v1",
    "title": "Leveraging Flatness to Improve Information-Theoretic Generalization Bounds for SGD",
    "summary": "Information-theoretic (IT) generalization bounds have been used to study the generalization of learning algorithms. These bounds are intrinsically data- and algorithm-dependent so that one can exploit the properties of data and algorithm to derive tighter bounds. However, we observe that although the flatness bias is crucial for SGD's generalization, these bounds fail to capture the improved generalization under better flatness and are also numerically loose. This is caused by the inadequate leverage of SGD's flatness bias in existing IT bounds. This paper derives a more flatness-leveraging IT bound for the flatness-favoring SGD. The bound indicates the learned models generalize better if the large-variance directions of the final weight covariance have small local curvatures in the loss landscape. Experiments on deep neural networks show our bound not only correctly reflects the better generalization when flatness is improved, but is also numerically much tighter. This is achieved by a flexible technique called \"omniscient trajectory\". When applied to Gradient Descent's minimax excess risk on convex-Lipschitz-Bounded problems, it improves representative IT bounds' $Ω(1)$ rates to $O(1/\\sqrt{n})$. It also implies a by-pass of memorization-generalization trade-offs.",
    "authors": [
      "Ze Peng",
      "Jian Zhang",
      "Yisen Wang",
      "Lei Qi",
      "Yinghuan Shi",
      "Yang Gao"
    ],
    "url": "http://arxiv.org/abs/2601.01465v1",
    "published": "2026-01-04",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于改进随机梯度下降算法的信息论泛化界，属于机器学习理论领域，不涉及将AI应用于其他科学领域或细胞/分子扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01456v1",
    "title": "Rethinking Multimodal Few-Shot 3D Point Cloud Segmentation: From Fused Refinement to Decoupled Arbitration",
    "summary": "In this paper, we revisit multimodal few-shot 3D point cloud semantic segmentation (FS-PCS), identifying a conflict in \"Fuse-then-Refine\" paradigms: the \"Plasticity-Stability Dilemma.\" In addition, CLIP's inter-class confusion can result in semantic blindness. To address these issues, we present the Decoupled-experts Arbitration Few-Shot SegNet (DA-FSS), a model that effectively distinguishes between semantic and geometric paths and mutually regularizes their gradients to achieve better generalization. DA-FSS employs the same backbone and pre-trained text encoder as MM-FSS to generate text embeddings, which can increase free modalities' utilization rate and better leverage each modality's information space. To achieve this, we propose a Parallel Expert Refinement module to generate each modal correlation. We also propose a Stacked Arbitration Module (SAM) to perform convolutional fusion and arbitrate correlations for each modality pathway. The Parallel Experts decouple two paths: a Geometric Expert maintains plasticity, and a Semantic Expert ensures stability. They are coordinated via a Decoupled Alignment Module (DAM) that transfers knowledge without propagating confusion. Experiments on popular datasets (S3DIS, ScanNet) demonstrate the superiority of DA-FSS over MM-FSS. Meanwhile, geometric boundaries, completeness, and texture differentiation are all superior to the baseline. The code is available at: https://github.com/MoWenQAQ/DA-FSS.",
    "authors": [
      "Wentao Bian",
      "Fenglei Xu"
    ],
    "url": "http://arxiv.org/abs/2601.01456v1",
    "published": "2026-01-04",
    "primary_category": "cs.CV",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于三维点云分割的多模态少样本学习方法，通过解耦几何与语义路径优化模型性能，属于计算机视觉领域而非特定科学发现或扰动预测研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01452v1",
    "title": "Bayesian Subspace Gradient Estimation for Zeroth-Order Optimization of Large Language Models",
    "summary": "Fine-tuning large language models (LLMs) with zeroth-order (ZO) optimization reduces memory by approximating gradients through function evaluations, but existing methods rely on one-step gradient estimates from random perturbations. We introduce Bayesian Subspace Zeroth-Order optimization (BSZO), a ZO optimizer that applies Kalman filtering to combine finite-difference information across multiple perturbation directions. By treating each finite-difference measurement as a noisy observation, BSZO builds a posterior distribution over the projected gradient and updates it through Bayesian inference, with a residual-based adaptive mechanism to adjust perturbation scales. Theoretical analysis shows that BSZO improves the convergence rate by a factor of $k/γ$ compared to standard ZO methods. Experiments on RoBERTa, Mistral, and OPT models show that BSZO outperforms MeZO, MeZO-Adam, and HiZOO across various tasks, achieving up to 6.67\\% absolute average improvement on OPT-13B while keeping memory usage close to inference-only baselines (1.00$\\times$--1.08$\\times$ of MeZO).",
    "authors": [
      "Jian Feng",
      "Zhihong Huang"
    ],
    "url": "http://arxiv.org/abs/2601.01452v1",
    "published": "2026-01-04",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于贝叶斯子空间梯度估计的零阶优化方法，用于提升大语言模型微调时的内存效率与收敛速度，而非应用于生物、化学等科学发现领域或细胞/基因扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01449v1",
    "title": "Segmentation and Processing of German Court Decisions from Open Legal Data",
    "summary": "The availability of structured legal data is important for advancing Natural Language Processing (NLP) techniques for the German legal system. One of the most widely used datasets, Open Legal Data, provides a large-scale collection of German court decisions. While the metadata in this raw dataset is consistently structured, the decision texts themselves are inconsistently formatted and often lack clearly marked sections. Reliable separation of these sections is important not only for rhetorical role classification but also for downstream tasks such as retrieval and citation analysis. In this work, we introduce a cleaned and sectioned dataset of 251,038 German court decisions derived from the official Open Legal Data dataset. We systematically separated three important sections in German court decisions, namely Tenor (operative part of the decision), Tatbestand (facts of the case), and Entscheidungsgründe (judicial reasoning), which are often inconsistently represented in the original dataset. To ensure the reliability of our extraction process, we used Cochran's formula with a 95% confidence level and a 5% margin of error to draw a statistically representative random sample of 384 cases, and manually verified that all three sections were correctly identified. We also extracted the Rechtsmittelbelehrung (appeal notice) as a separate field, since it is a procedural instruction and not part of the decision itself. The resulting corpus is publicly available in the JSONL format, making it an accessible resource for further research on the German legal system.",
    "authors": [
      "Harshil Darji",
      "Martin Heckelmann",
      "Christina Kratsch",
      "Gerard de Melo"
    ],
    "url": "http://arxiv.org/abs/2601.01449v1",
    "published": "2026-01-04",
    "primary_category": "cs.CL",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于法律文本处理，通过构建结构化的德国法院判决数据集来支持法律领域的自然语言处理研究，而非生物学、化学或物理学等自然科学领域的科学发现。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01446v1",
    "title": "iFlip: Iterative Feedback-driven Counterfactual Example Refinement",
    "summary": "Counterfactual examples are minimal edits to an input that alter a model's prediction. They are widely employed in explainable AI to probe model behavior and in natural language processing (NLP) to augment training data. However, generating valid counterfactuals with large language models (LLMs) remains challenging, as existing single-pass methods often fail to induce reliable label changes, neglecting LLMs' self-correction capabilities. To explore this untapped potential, we propose iFlip, an iterative refinement approach that leverages three types of feedback, including model confidence, feature attribution, and natural language. Our results show that iFlip achieves an average 57.8% higher validity than the five state-of-the-art baselines, as measured by the label flipping rate. The user study further corroborates that iFlip outperforms baselines in completeness, overall satisfaction, and feasibility. In addition, ablation studies demonstrate that three components are paramount for iFlip to generate valid counterfactuals: leveraging an appropriate number of iterations, pointing to highly attributed words, and early stopping. Finally, counterfactuals generated by iFlip enable effective counterfactual data augmentation, substantially improving model performance and robustness.",
    "authors": [
      "Yilong Wang",
      "Qianli Wang",
      "Nils Feldhus"
    ],
    "url": "http://arxiv.org/abs/2601.01446v1",
    "published": "2026-01-04",
    "primary_category": "cs.CL",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种利用大语言模型迭代反馈机制生成反事实示例的方法，属于自然语言处理领域的模型解释与数据增强研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01442v1",
    "title": "Fast Gibbs Sampling on Bayesian Hidden Markov Model with Missing Observations",
    "summary": "The Hidden Markov Model (HMM) is a widely-used statistical model for handling sequential data. However, the presence of missing observations in real-world datasets often complicates the application of the model. The EM algorithm and Gibbs samplers can be used to estimate the model, yet suffering from various problems including non-convexity, high computational complexity and slow mixing. In this paper, we propose a collapsed Gibbs sampler that efficiently samples from HMMs' posterior by integrating out both the missing observations and the corresponding latent states. The proposed sampler is fast due to its three advantages. First, it achieves an estimation accuracy that is comparable to existing methods. Second, it can produce a larger Effective Sample Size (ESS) per iteration, which can be justified theoretically and numerically. Third, when the number of missing entries is large, the sampler has a significant smaller computational complexity per iteration compared to other methods, thus is faster computationally. In summary, the proposed sampling algorithm is fast both computationally and theoretically and is particularly advantageous when there are a lot of missing entries. Finally, empirical evaluations based on numerical simulations and real data analysis demonstrate that the proposed algorithm consistently outperforms existing algorithms in terms of time complexity and sampling efficiency (measured in ESS).",
    "authors": [
      "Dongrong Li",
      "Tianwei Yu",
      "Xiaodan Fan"
    ],
    "url": "http://arxiv.org/abs/2601.01442v1",
    "published": "2026-01-04",
    "primary_category": "stat.ML",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于处理缺失观测的隐马尔可夫模型高效采样算法，属于统计计算方法改进，未涉及特定科学领域的AI应用或扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01438v1",
    "title": "Online Estimation and Manipulation of Articulated Objects",
    "summary": "From refrigerators to kitchen drawers, humans interact with articulated objects effortlessly every day while completing household chores. For automating these tasks, service robots must be capable of manipulating arbitrary articulated objects. Recent deep learning methods have been shown to predict valuable priors on the affordance of articulated objects from vision. In contrast, many other works estimate object articulations by observing the articulation motion, but this requires the robot to already be capable of manipulating the object. In this article, we propose a novel approach combining these methods by using a factor graph for online estimation of articulation which fuses learned visual priors and proprioceptive sensing during interaction into an analytical model of articulation based on Screw Theory. With our method, a robotic system makes an initial prediction of articulation from vision before touching the object, and then quickly updates the estimate from kinematic and force sensing during manipulation. We evaluate our method extensively in both simulations and real-world robotic manipulation experiments. We demonstrate several closed-loop estimation and manipulation experiments in which the robot was capable of opening previously unseen drawers. In real hardware experiments, the robot achieved a 75% success rate for autonomous opening of unknown articulated objects.",
    "authors": [
      "Russell Buchanan",
      "Adrian Röfer",
      "João Moura",
      "Abhinav Valada",
      "Sethu Vijayakumar"
    ],
    "url": "http://arxiv.org/abs/2601.01438v1",
    "published": "2026-01-04",
    "primary_category": "cs.RO",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种结合视觉先验与本体感知的在线估计方法，用于机器人对铰接物体的操作，属于机器人学而非科学发现或分子扰动预测领域。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01432v1",
    "title": "Personalizing black-box models for nonparametric regression with minimax optimality",
    "summary": "Recent advances in large-scale models, including deep neural networks and large language models, have substantially improved performance across a wide range of learning tasks. The widespread availability of such pre-trained models creates new opportunities for data-efficient statistical learning, provided they can be effectively integrated into downstream tasks. Motivated by this setting, we study few-shot personalization, where a pre-trained black-box model is adapted to a target domain using a limited number of samples. We develop a theoretical framework for few-shot personalization in nonparametric regression and propose algorithms that can incorporate a black-box pre-trained model into the regression procedure. We establish the minimax optimal rate for the personalization problem and show that the proposed method attains this rate. Our results clarify the statistical benefits of leveraging pre-trained models under sample scarcity and provide robustness guarantees when the pre-trained model is not informative. We illustrate the finite-sample performance of the methods through simulations and an application to the California housing dataset with several pre-trained models.",
    "authors": [
      "Sai Li",
      "Linjun Zhang"
    ],
    "url": "http://arxiv.org/abs/2601.01432v1",
    "published": "2026-01-04",
    "primary_category": "stat.ME",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种在非参数回归中利用预训练黑盒模型进行小样本个性化适配的理论框架和算法，并证明了其极小极大最优性。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01424v1",
    "title": "Unveiling the Heart-Brain Connection: An Analysis of ECG in Cognitive Performance",
    "summary": "Understanding the interaction of neural and cardiac systems during cognitive activity is critical to advancing physiological computing. Although EEG has been the gold standard for assessing mental workload, its limited portability restricts its real-world use. Widely available ECG through wearable devices proposes a pragmatic alternative. This research investigates whether ECG signals can reliably reflect cognitive load and serve as proxies for EEG-based indicators. In this work, we present multimodal data acquired from two different paradigms involving working-memory and passive-listening tasks. For each modality, we extracted ECG time-domain HRV metrics and Catch22 descriptors against EEG spectral and Catch22 features, respectively. We propose a cross-modal XGBoost framework to project the ECG features onto EEG-representative cognitive spaces, thereby allowing workload inferences using only ECG. Our results show that ECG-derived projections expressively capture variation in cognitive states and provide good support for accurate classification. Our findings underpin ECG as an interpretable, real-time, wearable solution for everyday cognitive monitoring.",
    "authors": [
      "Akshay Sasi",
      "Malavika Pradeep",
      "Nusaibah Farrukh",
      "Rahul Venugopal",
      "Elizabeth Sherly"
    ],
    "url": "http://arxiv.org/abs/2601.01424v1",
    "published": "2026-01-04",
    "primary_category": "cs.LG",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该研究利用XGBoost机器学习框架分析心电信号与认知负荷的关系，属于人工智能在生理学领域的科学发现应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01417v1",
    "title": "A Depth Hierarchy for Computing the Maximum in ReLU Networks via Extremal Graph Theory",
    "summary": "We consider the problem of exact computation of the maximum function over $d$ real inputs using ReLU neural networks. We prove a depth hierarchy, wherein width $Ω\\big(d^{1+\\frac{1}{2^{k-2}-1}}\\big)$ is necessary to represent the maximum for any depth $3\\le k\\le \\log_2(\\log_2(d))$. This is the first unconditional super-linear lower bound for this fundamental operator at depths $k\\ge3$, and it holds even if the depth scales with $d$. Our proof technique is based on a combinatorial argument and associates the non-differentiable ridges of the maximum with cliques in a graph induced by the first hidden layer of the computing network, utilizing Turán's theorem from extremal graph theory to show that a sufficiently narrow network cannot capture the non-linearities of the maximum. This suggests that despite its simple nature, the maximum function possesses an inherent complexity that stems from the geometric structure of its non-differentiable hyperplanes, and provides a novel approach for proving lower bounds for deep neural networks.",
    "authors": [
      "Itay Safran"
    ],
    "url": "http://arxiv.org/abs/2601.01417v1",
    "published": "2026-01-04",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文通过极值图论证明了ReLU神经网络计算最大值函数时的深度层次结构，属于神经网络理论复杂性研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01413v1",
    "title": "GlycoPy: An Equation-Oriented and Object-Oriented Software for Hierarchical Modeling, Optimization, and Control in Python",
    "summary": "Most existing model predictive control (MPC) applications in process industries employ lin-ear models, although real-world (bio)chemical processes are typically nonlinear. The use of linear models limits the performance and applicability of MPC for processes that span a wide range of operating conditions. A challenge in employing nonlinear models in MPC for com-plex systems is the lack of tools that facilitate hierarchical model development, as well as lack of efficient implementations of the corresponding nonlinear MPC (NMPC) algorithms. As a step towards making NMPC more practical for hierarchical systems, we introduce Gly-coPy, an equation-oriented, object-oriented software framework for process modeling, opti-mization, and NMPC in Python. GlycoPy enables users to focus on writing equations for modeling while supporting hierarchical modeling. GlycoPy includes algorithms for parame-ter estimation, dynamic optimization, and NMPC, and allows users to customize the simula-tion, optimization, and control algorithms. Three case studies, ranging from a simple differ-ential algebraic equation system to a multiscale bioprocess model, validate the modeling, optimization, and NMPC capabilities of GlycoPy. GlycoPy has the potential to bridge the gap between advanced NMPC algorithms and their practical application in real-world (bio)chemical processes.",
    "authors": [
      "Yingjie Ma",
      "Jing Guo",
      "Richard D. Braatz"
    ],
    "url": "http://arxiv.org/abs/2601.01413v1",
    "published": "2026-01-04",
    "primary_category": "cs.SE",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文介绍了一个用于非线性模型预测控制的软件框架，专注于过程建模、优化和控制算法的实现，而非利用人工智能进行科学发现或预测扰动响应。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01410v1",
    "title": "Reliable Grid Forecasting: State Space Models for Safety-Critical Energy Systems",
    "summary": "Accurate grid load forecasting is safety-critical: under-predictions risk supply shortfalls, while symmetric error metrics mask this operational asymmetry. We introduce a grid-specific evaluation framework--Asymmetric MAPE, Under-Prediction Rate, and Reserve Margin--that directly measures operational risk rather than statistical accuracy alone.   Using this framework, we conduct a systematic evaluation of Mamba-based State Space Models for California grid forecasting on a weather-aligned CAISO TAC-area dataset spanning Nov 2023--Nov 2025 (84,498 hourly records across 5 transmission areas). Our analysis reveals that standard accuracy metrics are poor proxies for operational safety: models with identical MAPE can require vastly different reserve margins.   We demonstrate that forecast errors are weakly but significantly associated with temperature (r = 0.16, p < 10^{-16}), motivating weather-aware modeling rather than loss function modification alone. The S-Mamba model achieves the lowest Reserve_{99.5}% margin (14.12%) compared to 16.66% for iTransformer, demonstrating superior forecast reliability under a 99.5th-percentile tail-risk reserve proxy.",
    "authors": [
      "Jisoo Lee",
      "Sunki Hong"
    ],
    "url": "http://arxiv.org/abs/2601.01410v1",
    "published": "2026-01-04",
    "primary_category": "eess.SY",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于能源系统安全，使用状态空间模型改进电网负荷预测的可靠性评估框架，而非AI在传统科学发现或细胞扰动预测中的应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01406v1",
    "title": "SwinIFS: Landmark Guided Swin Transformer For Identity Preserving Face Super Resolution",
    "summary": "Face super-resolution aims to recover high-quality facial images from severely degraded low-resolution inputs, but remains challenging due to the loss of fine structural details and identity-specific features. This work introduces SwinIFS, a landmark-guided super-resolution framework that integrates structural priors with hierarchical attention mechanisms to achieve identity-preserving reconstruction at both moderate and extreme upscaling factors. The method incorporates dense Gaussian heatmaps of key facial landmarks into the input representation, enabling the network to focus on semantically important facial regions from the earliest stages of processing. A compact Swin Transformer backbone is employed to capture long-range contextual information while preserving local geometry, allowing the model to restore subtle facial textures and maintain global structural consistency. Extensive experiments on the CelebA benchmark demonstrate that SwinIFS achieves superior perceptual quality, sharper reconstructions, and improved identity retention; it consistently produces more photorealistic results and exhibits strong performance even under 8x magnification, where most methods fail to recover meaningful structure. SwinIFS also provides an advantageous balance between reconstruction accuracy and computational efficiency, making it suitable for real-world applications in facial enhancement, surveillance, and digital restoration. Our code, model weights, and results are available at https://github.com/Habiba123-stack/SwinIFS.",
    "authors": [
      "Habiba Kausar",
      "Saeed Anwar",
      "Omar Jamal Hammad",
      "Abdul Bais"
    ],
    "url": "http://arxiv.org/abs/2601.01406v1",
    "published": "2026-01-04",
    "primary_category": "cs.CV",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于Swin Transformer和面部关键点引导的身份保持人脸超分辨率方法，属于计算机视觉领域而非传统自然科学发现。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01405v1",
    "title": "Efficient Cover Construction for Ball Mapper via Accelerated Range Queries",
    "summary": "Ball Mapper is an widely used tool in topological data analysis for summarizing the structure of high-dimensional data through metric-based coverings and graph representations. A central computational bottleneck in Ball Mapper is the construction of the underlying cover, which requires repeated range queries to identify data points within a fixed distance of selected landmarks. As data sets grow in size and dimensionality, naive implementations of this step become increasingly inefficient.   In this work, we study practical strategies for accelerating cover construction in Ball Mapper by improving the efficiency of range queries. We integrate two complementary approaches into the Ball Mapper pipeline: hierarchical geometric pruning using ball tree data structures, and hardware-aware distance computation using Facebook AI Similarity Search. We describe the underlying algorithms, discuss their trade-offs with respect to metric flexibility and dimensionality, and provide implementation details relevant to large-scale data analysis.   Empirical benchmarks demonstrate that both approaches yield substantial speedups over the baseline implementation, with performance gains depending on data set size, dimensionality, and choice of distance function. These results improve the practical scalability of Ball Mapper without modifying its theoretical formulation and provide guidance for the efficient implementation of metric-based exploratory tools in modern data analysis workflows.",
    "authors": [
      "Jay-Anne Bulauan",
      "John Rick Manzanares"
    ],
    "url": "http://arxiv.org/abs/2601.01405v1",
    "published": "2026-01-04",
    "primary_category": "cs.CG",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文通过改进Ball Mapper算法中的范围查询效率，为高维数据分析提供了更高效的计算工具，可应用于AI4Science领域的数据探索。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01403v1",
    "title": "A Graph-based Framework for Online Time Series Anomaly Detection Using Model Ensemble",
    "summary": "With the increasing volume of streaming data in industrial systems, online anomaly detection has become a critical task. The diverse and rapidly evolving data patterns pose significant challenges for online anomaly detection. Many existing anomaly detection methods are designed for offline settings or have difficulty in handling heterogeneous streaming data effectively. This paper proposes GDME, an unsupervised graph-based framework for online time series anomaly detection using model ensemble. GDME maintains a dynamic model pool that is continuously updated by pruning underperforming models and introducing new ones. It utilizes a dynamic graph structure to represent relationships among models and employs community detection on the graph to select an appropriate subset for ensemble. The graph structure is also used to detect concept drift by monitoring structural changes, allowing the framework to adapt to evolving streaming data. Experiments on seven heterogeneous time series demonstrate that GDME outperforms existing online anomaly detection methods, achieving improvements of up to 24%. In addition, its ensemble strategy provides superior detection performance compared with both individual models and average ensembles, with competitive computational efficiency.",
    "authors": [
      "Zewei Yu",
      "Jianqiu Xu",
      "Caimin Li"
    ],
    "url": "http://arxiv.org/abs/2601.01403v1",
    "published": "2026-01-04",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于图模型集成的时间序列异常检测框架，专注于工业系统流数据处理而非特定科学领域发现。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01401v1",
    "title": "LANCET: Neural Intervention via Structural Entropy for Mitigating Faithfulness Hallucinations in LLMs",
    "summary": "Large Language Models have revolutionized information processing, yet their reliability is severely compromised by faithfulness hallucinations. While current approaches attempt to mitigate this issue through node-level adjustments or coarse suppression, they often overlook the distributed nature of neural information, leading to imprecise interventions. Recognizing that hallucinations propagate through specific forward transmission pathways like an infection, we aim to surgically block this flow using precise structural analysis. To leverage this, we propose Lancet, a novel framework that achieves precise neural intervention by leveraging structural entropy and hallucination difference ratios. Lancet first locates hallucination-prone neurons via gradient-driven contrastive analysis, then maps their propagation pathways by minimizing structural entropy, and finally implements a hierarchical intervention strategy that preserves general model capabilities. Comprehensive evaluations across hallucination benchmark datasets demonstrate that Lancet significantly outperforms state-of-the-art methods, validating the effectiveness of our surgical approach to neural intervention.",
    "authors": [
      "Chenxu Wang",
      "Chaozhuo Li",
      "Pengbo Wang",
      "Litian Zhang",
      "Songyang Liu",
      "Ji Qi",
      "Jiahui Hu",
      "Yushan Cai",
      "Hao Zhao",
      "Rui Pu"
    ],
    "url": "http://arxiv.org/abs/2601.01401v1",
    "published": "2026-01-04",
    "primary_category": "cs.CL",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种通过结构熵分析进行神经干预的框架，用于减少大语言模型中的忠实性幻觉，属于人工智能模型优化领域。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01391v1",
    "title": "Bayesian Negative Binomial Regression of Afrobeats Chart Persistence",
    "summary": "Afrobeats songs compete for attention on streaming platforms, where chart visibility can influence both revenue and cultural impact. This paper examines whether collaborations help songs remain on the charts longer, using daily Nigeria Spotify Top 200 data from 2024. Each track is summarized by the number of days it appears in the Top 200 during the year and its total annual streams in Nigeria. A Bayesian negative binomial regression is applied, with days on chart as the outcome and collaboration status (solo versus multi-artist) and log total streams as predictors. This approach is well suited for overdispersed count data and allows the effect of collaboration to be interpreted while controlling for overall popularity. Posterior inference is conducted using Markov chain Monte Carlo, and results are assessed using rate ratios, posterior probabilities, and predictive checks. The findings indicate that, after accounting for total streams, collaboration tracks tend to spend slightly fewer days on the chart than comparable solo tracks.",
    "authors": [
      "Ian Jacob Cabansag",
      "Paul Ntegeka"
    ],
    "url": "http://arxiv.org/abs/2601.01391v1",
    "published": "2026-01-04",
    "primary_category": "eess.AS",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文使用贝叶斯统计方法分析音乐排行榜数据，属于社会科学应用，不涉及AI驱动的自然科学发现或细胞/分子扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01387v1",
    "title": "Scale-Adaptive Power Flow Analysis with Local Topology Slicing and Multi-Task Graph Learning",
    "summary": "Developing deep learning models with strong adaptability to topological variations is of great practical significance for power flow analysis. To enhance model performance under variable system scales and improve robustness in branch power prediction, this paper proposes a Scale-adaptive Multi-task Power Flow Analysis (SaMPFA) framework. SaMPFA introduces a Local Topology Slicing (LTS) sampling technique that extracts subgraphs of different scales from the complete power network to strengthen the model's cross-scale learning capability. Furthermore, a Reference-free Multi-task Graph Learning (RMGL) model is designed for robust power flow prediction. Unlike existing approaches, RMGL predicts bus voltages and branch powers instead of phase angles. This design not only avoids the risk of error amplification in branch power calculation but also guides the model to learn the physical relationships of phase angle differences. In addition, the loss function incorporates extra terms that encourage the model to capture the physical patterns of angle differences and power transmission, further improving consistency between predictions and physical laws. Simulations on the IEEE 39-bus system and a real provincial grid in China demonstrate that the proposed model achieves superior adaptability and generalization under variable system scales, with accuracy improvements of 4.47% and 36.82%, respectively.",
    "authors": [
      "Yongzhe Li",
      "Lin Guan",
      "Zihan Cai",
      "Zuxian Lin",
      "Jiyu Huang",
      "Liukai Chen"
    ],
    "url": "http://arxiv.org/abs/2601.01387v1",
    "published": "2026-01-04",
    "primary_category": "cs.LG",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于局部拓扑切片和多任务图学习的自适应电力系统潮流分析框架，属于AI在物理系统建模中的应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01386v1",
    "title": "ParkGaussian: Surround-view 3D Gaussian Splatting for Autonomous Parking",
    "summary": "Parking is a critical task for autonomous driving systems (ADS), with unique challenges in crowded parking slots and GPS-denied environments. However, existing works focus on 2D parking slot perception, mapping, and localization, 3D reconstruction remains underexplored, which is crucial for capturing complex spatial geometry in parking scenarios. Naively improving the visual quality of reconstructed parking scenes does not directly benefit autonomous parking, as the key entry point for parking is the slots perception module. To address these limitations, we curate the first benchmark named ParkRecon3D, specifically designed for parking scene reconstruction. It includes sensor data from four surround-view fisheye cameras with calibrated extrinsics and dense parking slot annotations. We then propose ParkGaussian, the first framework that integrates 3D Gaussian Splatting (3DGS) for parking scene reconstruction. To further improve the alignment between reconstruction and downstream parking slot detection, we introduce a slot-aware reconstruction strategy that leverages existing parking perception methods to enhance the synthesis quality of slot regions. Experiments on ParkRecon3D demonstrate that ParkGaussian achieves state-of-the-art reconstruction quality and better preserves perception consistency for downstream tasks. The code and dataset will be released at: https://github.com/wm-research/ParkGaussian",
    "authors": [
      "Xiaobao Wei",
      "Zhangjie Ye",
      "Yuxiang Gu",
      "Zunjie Zhu",
      "Yunfei Guo",
      "Yingying Shen",
      "Shan Zhao",
      "Ming Lu",
      "Haiyang Sun",
      "Bing Wang",
      "Guang Chen",
      "Rongfeng Lu",
      "Hangjun Ye"
    ],
    "url": "http://arxiv.org/abs/2601.01386v1",
    "published": "2026-01-04",
    "primary_category": "cs.CV",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于自动驾驶停车场景的3D重建框架，属于计算机视觉与自动驾驶领域，不涉及生物学、化学或物理学等自然科学发现。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01385v1",
    "title": "On IDA-PBC with Maximum Energy Shapeability",
    "summary": "Interconnection and Damping Assignment Passivity-Based Control (IDA-PBC) is a well-established stabilization technique for affine nonlinear systems. However, its application is generally hindered by the requirement of solving a set of partial differential equations (PDEs), i.e., the so-called matching equation. This paper introduces the notion of \\emph{maximum energy shapeability} which describes the scenario that the homogeneous part of the matching equation admits $m$ independent solutions with $m$ the dimension of the control input. We demonstrate that the maximum energy shapeability enables a systematic procedure for the IDA-PBC design by transforming the matching equation into a set of easier-to-solve PDEs. Sufficient conditions for maximum energy shapeability are also provided. It is shown that some existing constructive IDA-PBC designs actually implicitly exploit the maximum energy shapeability. The proposed procedure for the IDA-PBC design is illustrated with the magnetic levitation system.",
    "authors": [
      "Ziheng Jiao",
      "Chengshuai Wu",
      "Bo Fan",
      "Meng Zhang",
      "Romeo Ortega"
    ],
    "url": "http://arxiv.org/abs/2601.01385v1",
    "published": "2026-01-04",
    "primary_category": "math.OC",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于最大能量可塑性的非线性系统控制设计方法，属于控制理论领域，不涉及人工智能在科学发现或细胞扰动预测的应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01383v1",
    "title": "Data Complexity-aware Deep Model Performance Forecasting",
    "summary": "Deep learning models are widely used across computer vision and other domains. When working on the model induction, selecting the right architecture for a given dataset often relies on repetitive trial-and-error procedures. This procedure is time-consuming, resource-intensive, and difficult to automate. While previous work has explored performance prediction using partial training or complex simulations, these methods often require significant computational overhead or lack generalizability. In this work, we propose an alternative approach: a lightweight, two-stage framework that can estimate model performance before training given the understanding of the dataset and the focused deep model structures. The first stage predicts a baseline based on the analysis of some measurable properties of the dataset, while the second stage adjusts the estimation with additional information on the model's architectural and hyperparameter details. The setup allows the framework to generalize across datasets and model types. Moreover, we find that some of the underlying features used for prediction - such as dataset variance - can offer practical guidance for model selection, and can serve as early indicators of data quality. As a result, the framework can be used not only to forecast model performance, but also to guide architecture choices, inform necessary preprocessing procedures, and detect potentially problematic datasets before training begins.",
    "authors": [
      "Yen-Chia Chen",
      "Hsing-Kuo Pao",
      "Hanjuan Huang"
    ],
    "url": "http://arxiv.org/abs/2601.01383v1",
    "published": "2026-01-04",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种轻量级的两阶段框架，用于在训练前基于数据集属性和模型结构预测深度学习模型性能，属于计算机视觉领域的通用方法学研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01378v1",
    "title": "Empowering Small Language Models with Factual Hallucination-Aware Reasoning for Financial Classification",
    "summary": "Small language models (SLMs) are increasingly used for financial classification due to their fast inference and local deployability. However, compared with large language models, SLMs are more prone to factual hallucinations in reasoning and exhibit weaker classification performance. This raises a natural question: Can mitigating factual hallucinations improve SLMs' financial classification? To address this, we propose a three-step pipeline named AAAI (Association Identification, Automated Detection, and Adaptive Inference). Experiments on three representative SLMs reveal that: (1) factual hallucinations are positively correlated with misclassifications; (2) encoder-based verifiers effectively detect factual hallucinations; and (3) incorporating feedback on factual errors enables SLMs' adaptive inference that enhances classification performance. We hope this pipeline contributes to trustworthy and effective applications of SLMs in finance.",
    "authors": [
      "Han Yuan",
      "Yilin Wu",
      "Li Zhang",
      "Zheng Ma"
    ],
    "url": "http://arxiv.org/abs/2601.01378v1",
    "published": "2026-01-04",
    "primary_category": "cs.AI",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种名为AAAI的三步流程，通过减少事实幻觉来提升小型语言模型在金融分类任务中的性能。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01373v1",
    "title": "UltraEval-Audio: A Unified Framework for Comprehensive Evaluation of Audio Foundation Models",
    "summary": "The development of audio foundation models has accelerated rapidly since the emergence of GPT-4o. However, the lack of comprehensive evaluation has become a critical bottleneck for further progress in the field, particularly in audio generation. Current audio evaluation faces three major challenges: (1) audio evaluation lacks a unified framework, with datasets and code scattered across various sources, hindering fair and efficient cross-model comparison;(2) audio codecs, as a key component of audio foundation models, lack a widely accepted and holistic evaluation methodology; (3) existing speech benchmarks are heavily reliant on English, making it challenging to objectively assess models' performance on Chinese. To address the first issue, we introduce UltraEval-Audio, a unified evaluation framework for audio foundation models, specifically designed for both audio understanding and generation tasks. UltraEval-Audio features a modular architecture, supporting 10 languages and 14 core task categories, while seamlessly integrating 24 mainstream models and 36 authoritative benchmarks. To enhance research efficiency, the framework provides a one-command evaluation feature, accompanied by real-time public leaderboards. For the second challenge, UltraEval-Audio adopts a novel comprehensive evaluation scheme for audio codecs, evaluating performance across three key dimensions: semantic accuracy, timbre fidelity, and acoustic quality. To address the third issue, we propose two new Chinese benchmarks, SpeechCMMLU and SpeechHSK, designed to assess Chinese knowledge proficiency and language fluency. We wish that UltraEval-Audio will provide both academia and industry with a transparent, efficient, and fair platform for comparison of audio models. Our code, benchmarks, and leaderboards are available at https://github.com/OpenBMB/UltraEval-Audio.",
    "authors": [
      "Qundong Shi",
      "Jie Zhou",
      "Biyuan Lin",
      "Junbo Cui",
      "Guoyang Zeng",
      "Yixuan Zhou",
      "Ziyang Wang",
      "Xin Liu",
      "Zhen Luo",
      "Yudong Wang",
      "Zhiyuan Liu"
    ],
    "url": "http://arxiv.org/abs/2601.01373v1",
    "published": "2026-01-04",
    "primary_category": "cs.SD",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一个用于音频基础模型评估的统一框架，专注于音频理解和生成任务的标准化评测，而非科学发现或扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01371v1",
    "title": "SGD with Dependent Data: Optimal Estimation, Regret, and Inference",
    "summary": "This work investigates the performance of the final iterate produced by stochastic gradient descent (SGD) under temporally dependent data. We consider two complementary sources of dependence: $(i)$ martingale-type dependence in both the covariate and noise processes, which accommodates non-stationary and non-mixing time series data, and $(ii)$ dependence induced by sequential decision making. Our formulation runs in parallel with classical notions of (local) stationarity and strong mixing, while neither framework fully subsumes the other. Remarkably, SGD is shown to automatically accommodate both independent and dependent information under a broad class of stepsize schedules and exploration rate schemes.   Non-asymptotically, we show that SGD simultaneously achieves statistically optimal estimation error and regret, extending and improving existing results. In particular, our tail bounds remain sharp even for potentially infinite horizon $T=+\\infty$. Asymptotically, the SGD iterates converge to a Gaussian distribution with only an $O_{\\PP}(1/\\sqrt{t})$ remainder, demonstrating that the supposed estimation-regret trade-off claimed in prior work can in fact be avoided. We further propose a new ``conic'' approximation of the decision region that allows the covariates to have unbounded support. For online sparse regression, we develop a new SGD-based algorithm that uses only $d$ units of storage and requires $O(d)$ flops per iteration, achieving the long term statistical optimality. Intuitively, each incoming observation contributes to estimation accuracy, while aggregated summary statistics guide support recovery.",
    "authors": [
      "Yinan Shen",
      "Yichen Zhang",
      "Wen-Xin Zhou"
    ],
    "url": "http://arxiv.org/abs/2601.01371v1",
    "published": "2026-01-04",
    "primary_category": "math.ST",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于随机梯度下降算法在时间序列数据下的理论分析，属于机器学习优化理论范畴，而非特定科学领域的AI应用或扰动预测研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01368v1",
    "title": "Causal discovery for linear causal model with correlated noise: an Adversarial Learning Approach",
    "summary": "Causal discovery from data with unmeasured confounding factors is a challenging problem. This paper proposes an approach based on the f-GAN framework, learning the binary causal structure independent of specific weight values. We reformulate the structure learning problem as minimizing Bayesian free energy and prove that this problem is equivalent to minimizing the f-divergence between the true data distribution and the model-generated distribution. Using the f-GAN framework, we transform this objective into a min-max adversarial optimization problem. We implement the gradient search in the discrete graph space using Gumbel-Softmax relaxation.",
    "authors": [
      "Mujin Zhou",
      "Junzhe Zhang"
    ],
    "url": "http://arxiv.org/abs/2601.01368v1",
    "published": "2026-01-04",
    "primary_category": "cs.LG",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于f-GAN框架的因果发现方法，用于处理存在未测量混杂因素的数据，属于利用人工智能进行科学发现的方法论研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01366v1",
    "title": "KGCE: Knowledge-Augmented Dual-Graph Evaluator for Cross-Platform Educational Agent Benchmarking with Multimodal Language Models",
    "summary": "With the rapid adoption of multimodal large language models (MLMs) in autonomous agents, cross-platform task execution capabilities in educational settings have garnered significant attention. However, existing benchmark frameworks still exhibit notable deficiencies in supporting cross-platform tasks in educational contexts, especially when dealing with school-specific software (such as XiaoYa Intelligent Assistant, HuaShi XiaZi, etc.), where the efficiency of agents often significantly decreases due to a lack of understanding of the structural specifics of these private-domain software. Additionally, current evaluation methods heavily rely on coarse-grained metrics like goal orientation or trajectory matching, making it challenging to capture the detailed execution and efficiency of agents in complex tasks. To address these issues, we propose KGCE (Knowledge-Augmented Dual-Graph Evaluator for Cross-Platform Educational Agent Benchmarking with Multimodal Language Models), a novel benchmarking platform that integrates knowledge base enhancement and a dual-graph evaluation framework. We first constructed a dataset comprising 104 education-related tasks, covering Windows, Android, and cross-platform collaborative tasks. KGCE introduces a dual-graph evaluation framework that decomposes tasks into multiple sub-goals and verifies their completion status, providing fine-grained evaluation metrics. To overcome the execution bottlenecks of existing agents in private-domain tasks, we developed an enhanced agent system incorporating a knowledge base specific to school-specific software. The code can be found at https://github.com/Kinginlife/KGCE.",
    "authors": [
      "Zixian Liu",
      "Sihao Liu",
      "Yuqi Zhao"
    ],
    "url": "http://arxiv.org/abs/2601.01366v1",
    "published": "2026-01-04",
    "primary_category": "cs.AI",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于跨平台教育代理基准测试的知识增强双图评估框架，专注于教育软件环境中的任务执行评估，而非科学发现或生物医学扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01363v1",
    "title": "A unified multimodal understanding and generation model for cross-disciplinary scientific research",
    "summary": "Scientific discovery increasingly relies on integrating heterogeneous, high-dimensional data across disciplines nowadays. While AI models have achieved notable success across various scientific domains, they typically remain domain-specific or lack the capability of simultaneously understanding and generating multimodal scientific data, particularly for high-dimensional data. Yet, many pressing global challenges and scientific problems are inherently cross-disciplinary and require coordinated progress across multiple fields. Here, we present FuXi-Uni, a native unified multimodal model for scientific understanding and high-fidelity generation across scientific domains within a single architecture. Specifically, FuXi-Uni aligns cross-disciplinary scientific tokens within natural language tokens and employs science decoder to reconstruct scientific tokens, thereby supporting both natural language conversation and scientific numerical prediction. Empirically, we validate FuXi-Uni in Earth science and Biomedicine. In Earth system modeling, the model supports global weather forecasting, tropical cyclone (TC) forecast editing, and spatial downscaling driven by only language instructions. FuXi-Uni generates 10-day global forecasts at 0.25° resolution that outperform the SOTA physical forecasting system. It shows superior performance for both TC track and intensity prediction relative to the SOTA physical model, and generates high-resolution regional weather fields that surpass standard interpolation baselines. Regarding biomedicine, FuXi-Uni outperforms leading multimodal large language models on multiple biomedical visual question answering benchmarks. By unifying heterogeneous scientific modalities within a native shared latent space while maintaining strong domain-specific performance, FuXi-Uni provides a step forward more general-purpose, multimodal scientific models.",
    "authors": [
      "Xiaomeng Yang",
      "Zhiyu Tan",
      "Xiaohui Zhong",
      "Mengping Yang",
      "Qiusheng Huang",
      "Lei Chen",
      "Libo Wu",
      "Hao Li"
    ],
    "url": "http://arxiv.org/abs/2601.01363v1",
    "published": "2026-01-04",
    "primary_category": "cs.AI",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种统一的多模态模型FuXi-Uni，能够在地球科学和生物医学领域同时实现科学数据的理解与高保真生成，推动了跨学科科学AI模型的发展。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01362v1",
    "title": "Investigating the Multilingual Calibration Effects of Language Model Instruction-Tuning",
    "summary": "Ensuring that deep learning models are well-calibrated in terms of their predictive uncertainty is essential in maintaining their trustworthiness and reliability, yet despite increasing advances in foundation model research, the relationship between such large language models (LLMs) and their calibration remains an open area of research. In this work, we look at a critical gap in the calibration of LLMs within multilingual settings, in an attempt to better understand how the data scarcity can potentially lead to different calibration effects and how commonly used techniques can apply in these settings. Our analysis on two multilingual benchmarks, over 29 and 42 languages respectively, reveals that even in low-resource languages, model confidence can increase significantly after instruction-tuning on high-resource language SFT datasets. However, improvements in accuracy are marginal or non-existent, resulting in mis-calibration, highlighting a critical shortcoming of standard SFT for multilingual languages. Furthermore, we observe that the use of label smoothing to be a reasonable method alleviate this concern, again without any need for low-resource SFT data, maintaining better calibration across all languages. Overall, this highlights the importance of multilingual considerations for both training and tuning LLMs in order to improve their reliability and fairness in downstream use.",
    "authors": [
      "Jerry Huang",
      "Peng Lu",
      "Qiuhao Zeng",
      "Yusuke Iwasawa",
      "Yutaka Matsuo",
      "Sarath Chandar",
      "Edison Marrese-Taylor",
      "Irene Li"
    ],
    "url": "http://arxiv.org/abs/2601.01362v1",
    "published": "2026-01-04",
    "primary_category": "cs.CL",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文研究多语言大语言模型的校准效应，属于自然语言处理领域，不涉及生物学、化学或物理学等自然科学发现，也不涉及细胞或基因扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01358v1",
    "title": "A New Framework for Explainable Rare Cell Identification in Single-Cell Transcriptomics Data",
    "summary": "The detection of rare cell types in single-cell transcriptomics data is crucial for elucidating disease pathogenesis and tissue development dynamics. However, a critical gap that persists in current methods is their inability to provide an explanation based on genes for each cell they have detected as rare. We identify three primary sources of this deficiency. First, the anomaly detectors often function as \"black boxes\", designed to detect anomalies but unable to explain why a cell is anomalous. Second, the standard analytical framework hinders interpretability by relying on dimensionality reduction techniques, such as Principal Component Analysis (PCA), which transform meaningful gene expression data into abstract, uninterpretable features. Finally, existing explanation algorithms cannot be readily applied to this domain, as single-cell data is characterized by high dimensionality, noise, and substantial sparsity. To overcome these limitations, we introduce a framework for explainable anomaly detection in single-cell transcriptomics data which not only identifies individual anomalies, but also provides a visual explanation based on genes that makes an instance anomalous. This framework has two key ingredients that are not existed in current methods applied in this domain. First, it eliminates the PCA step which is deemed to be an essential component in previous studies. Second, it employs the state-of-art anomaly detector and explainer as the efficient and effective means to find each rare cell and the relevant gene subspace in order to provide explanations for each rare cell as well as the typical normal cell associated with the rare cell's closest normal cells.",
    "authors": [
      "Di Su",
      "Kai Ming Ting",
      "Jie Zhang",
      "Xiaorui Zhang",
      "Xinpeng Li"
    ],
    "url": "http://arxiv.org/abs/2601.01358v1",
    "published": "2026-01-04",
    "primary_category": "q-bio.GN",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于人工智能的可解释异常检测框架，用于识别单细胞转录组数据中的罕见细胞类型并解释其基因特征。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01357v1",
    "title": "Towards LLM-enabled autonomous combustion research: A literature-aware agent for self-corrective modeling workflows",
    "summary": "The rapid evolution of large language models (LLMs) is transforming artificial intelligence into autonomous research partners, yet a critical gap persists in complex scientific domains such as combustion modeling. Here, practical AI assistance requires the seamless integration of domain literature knowledge with robust execution capabilities for expertise-intensive tools such as computational fluid dynamics (CFD) codes. To bridge this gap, we introduce FlamePilot, an LLM agent designed to empower combustion modeling research through automated and self-corrective CFD workflows. FlamePilot differentiates itself through an architecture that leverages atomic tools to ensure the robust setup and execution of complex simulations in both OpenFOAM and extended frameworks such as DeepFlame. The system is also capable of learning from scientific articles, extracting key information to guide the simulation from initial setup to optimized results. Validation on a public benchmark shows FlamePilot achieved a perfect 1.0 executability score and a 0.438 success rate, surpassing the prior best reported agent scores of 0.625 and 0.250, respectively. Furthermore, a detailed case study on Moderate or Intense Low-oxygen Dilution (MILD) combustion simulation demonstrates its efficacy as a collaborative research copilot, where FlamePilot autonomously translated a research paper into a configured simulation, conducted the simulation, post-processed the results, proposed evidence-based refinements, and managed a multi-step parameter study to convergence under minimal human intervention. By adopting a transparent and interpretable paradigm, FlamePilot establishes a foundational framework for AI-empowered combustion modeling, fostering a collaborative partnership where the agent manages workflow orchestration, freeing the researcher for high-level analysis.",
    "authors": [
      "Ke Xiao",
      "Haoze Zhang",
      "Runze Mao",
      "Han Li",
      "Zhi X. Chen"
    ],
    "url": "http://arxiv.org/abs/2601.01357v1",
    "published": "2026-01-04",
    "primary_category": "cs.LG",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于大语言模型的自主代理系统FlamePilot，用于自动化燃烧建模研究，通过整合文献知识与计算流体动力学工具实现科学发现，属于AI4Science范畴。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01352v1",
    "title": "Slot-ID: Identity-Preserving Video Generation from Reference Videos via Slot-Based Temporal Identity Encoding",
    "summary": "Producing prompt-faithful videos that preserve a user-specified identity remains challenging: models need to extrapolate facial dynamics from sparse reference while balancing the tension between identity preservation and motion naturalness. Conditioning on a single image completely ignores the temporal signature, which leads to pose-locked motions, unnatural warping, and \"average\" faces when viewpoints and expressions change. To this end, we introduce an identity-conditioned variant of a diffusion-transformer video generator which uses a short reference video rather than a single portrait. Our key idea is to incorporate the dynamics in the reference. A short clip reveals subject-specific patterns, e.g., how smiles form, across poses and lighting. From this clip, a Sinkhorn-routed encoder learns compact identity tokens that capture characteristic dynamics while remaining pretrained backbone-compatible. Despite adding only lightweight conditioning, the approach consistently improves identity retention under large pose changes and expressive facial behavior, while maintaining prompt faithfulness and visual realism across diverse subjects and prompts.",
    "authors": [
      "Yixuan Lai",
      "He Wang",
      "Kun Zhou",
      "Tianjia Shao"
    ],
    "url": "http://arxiv.org/abs/2601.01352v1",
    "published": "2026-01-04",
    "primary_category": "cs.CV",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于槽位机制的时序身份编码方法，用于从参考视频生成保持特定人物身份的视频内容，属于计算机视觉和生成式AI领域，而非科学发现或生物医学扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01347v1",
    "title": "From Classification to Generation: An Open-Ended Paradigm for Adverse Drug Reaction Prediction Based on Graph-Motif Feature Fusion",
    "summary": "Computational biology offers immense potential for reducing the high costs and protracted cycles of new drug development through adverse drug reaction (ADR) prediction. However, current methods remain impeded by drug data scarcity-induced cold-start challenge, closed label sets, and inadequate modeling of label dependencies. Here we propose an open-ended ADR prediction paradigm based on Graph-Motif feature fusion and Multi-Label Generation (GM-MLG). Leveraging molecular structure as an intrinsic and inherent feature, GM-MLG constructs a dual-graph representation architecture spanning the atomic level, the local molecular level (utilizing fine-grained motifs dynamically extracted via the BRICS algorithm combined with additional fragmentation rules), and the global molecular level. Uniquely, GM-MLG pioneers transforming ADR prediction from multi-label classification into Transformer Decoder-based multi-label generation. By treating ADR labels as discrete token sequences, it employs positional embeddings to explicitly capture dependencies and co-occurrence relationships within large-scale label spaces, generating predictions via autoregressive decoding to dynamically expand the prediction space. Experiments demonstrate GM-MLG achieves up to 38% improvement and an average gain of 20%, expanding the prediction space from 200 to over 10,000 types. Furthermore, it elucidates non-linear structure-activity relationships between ADRs and motifs via retrosynthetic motif analysis, providing interpretable and innovative support for systematic risk reduction in drug safety.",
    "authors": [
      "Yuyan Pi",
      "Min Jin",
      "Wentao Xie",
      "Xinhua Liu"
    ],
    "url": "http://arxiv.org/abs/2601.01347v1",
    "published": "2026-01-04",
    "primary_category": "cs.LG",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出基于图-基序特征融合与多标签生成的开放范式，将药物不良反应预测从分类任务转化为生成任务，显著扩展预测空间并揭示结构-活性关系。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01337v1",
    "title": "HyperNetWalk: A Unified Framework for Personalized and Population-Level Cancer Driver Gene Identification via Multi-Network Hypergraph Diffusion",
    "summary": "Identifying cancer driver genes is crucial for understanding tumor biology and developing precision therapies. However, existing computational methods often rely on single biological networks or population-level mutation patterns, limiting their ability to identify patient-specific drivers and leverage the complementary information from multiple network types. Here, we present HyperNetWalk, a novel computational framework that integrates multiple biological networks and hypergraph diffusion to identify driver genes at both personalized and cohort levels. In the first stage, HyperNetWalk integrates protein-protein interaction networks, gene regulatory networks, and dynamic co-expression networks through sample-independent random walks on patient-specific subnetworks to capture topological importance and expression perturbation effects. In the second stage, it refines predictions through hypergraph-based random walks that leverage cross-sample information while preserving individual mutational contexts. Comprehensive evaluation on 12 TCGA cancer types demonstrates that HyperNetWalk achieves superior or competitive performance compared to state-of-the-art methods in both personalized and cohort-level predictions. Notably, HyperNetWalk successfully identifies known driver genes with high precision while revealing cancer type-specific drivers that reflect distinct biological mechanisms. Our framework provides a unified solution for personalized and population-based driver gene identification, offering valuable insights for precision oncology and therapeutic target discovery.",
    "authors": [
      "Xueqing Xu",
      "Yonghang Gao",
      "Duanchen Sun",
      "Ling-Yun Wu"
    ],
    "url": "http://arxiv.org/abs/2601.01337v1",
    "published": "2026-01-04",
    "primary_category": "q-bio.QM",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于多网络超图扩散的计算框架，用于在个体和群体层面识别癌症驱动基因，属于利用人工智能方法进行生物医学科学发现的范畴。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01332v1",
    "title": "FLOP-Efficient Training: Early Stopping Based on Test-Time Compute Awareness",
    "summary": "Scaling training compute, measured in FLOPs, has long been shown to improve the accuracy of large language models, yet training remains resource-intensive. Prior work shows that increasing test-time compute (TTC)-for example through iterative sampling-can allow smaller models to rival or surpass much larger ones at lower overall cost. We introduce TTC-aware training, where an intermediate checkpoint and a corresponding TTC configuration can together match or exceed the accuracy of a fully trained model while requiring substantially fewer training FLOPs. Building on this insight, we propose an early stopping algorithm that jointly selects a checkpoint and TTC configuration to minimize training compute without sacrificing accuracy. To make this practical, we develop an efficient TTC evaluation method that avoids exhaustive search, and we formalize a break-even bound that identifies when increased inference compute compensates for reduced training compute. Experiments demonstrate up to 92\\% reductions in training FLOPs while maintaining and sometimes remarkably improving accuracy. These results highlight a new perspective for balancing training and inference compute in model development, enabling faster deployment cycles and more frequent model refreshes. Codes will be publicly released.",
    "authors": [
      "Hossam Amer",
      "Maryam Dialameh",
      "Hossein Rajabzadeh",
      "Walid Ahmed",
      "Weiwei Zhang",
      "Yang Liu"
    ],
    "url": "http://arxiv.org/abs/2601.01332v1",
    "published": "2026-01-04",
    "primary_category": "cs.CL",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种基于测试时计算感知的早期停止算法，通过联合选择检查点和测试时配置来显著减少大语言模型的训练计算量而不损失精度，属于机器学习优化方法而非特定科学领域应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01331v1",
    "title": "AppellateGen: A Benchmark for Appellate Legal Judgment Generation",
    "summary": "Legal judgment generation is a critical task in legal intelligence. However, existing research in legal judgment generation has predominantly focused on first-instance trials, relying on static fact-to-verdict mappings while neglecting the dialectical nature of appellate (second-instance) review. To address this, we introduce AppellateGen, a benchmark for second-instance legal judgment generation comprising 7,351 case pairs. The task requires models to draft legally binding judgments by reasoning over the initial verdict and evidentiary updates, thereby modeling the causal dependency between trial stages. We further propose a judicial Standard Operating Procedure (SOP)-based Legal Multi-Agent System (SLMAS) to simulate judicial workflows, which decomposes the generation process into discrete stages of issue identification, retrieval, and drafting. Experimental results indicate that while SLMAS improves logical consistency, the complexity of appellate reasoning remains a substantial challenge for current LLMs. The dataset and code are publicly available at: https://anonymous.4open.science/r/AppellateGen-5763.",
    "authors": [
      "Hongkun Yang",
      "Lionel Z. Wang",
      "Wei Fan",
      "Yiran Hu",
      "Lixu Wang",
      "Chenyu Liu",
      "Shenghong Fu",
      "Haoyang Li",
      "Xin Xu",
      "Jiexin Zheng",
      "Wei Dong"
    ],
    "url": "http://arxiv.org/abs/2601.01331v1",
    "published": "2026-01-04",
    "primary_category": "cs.CY",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于法律智能领域，提出了一个用于上诉法律判决生成的基准和模拟司法工作流程的多智能体系统，不涉及自然科学领域的科学发现或细胞/分子层面的扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01330v1",
    "title": "Beyond Gemini-3-Pro: Revisiting LLM Routing and Aggregation at Scale",
    "summary": "Large Language Models (LLMs) have rapidly advanced, with Gemini-3-Pro setting a new performance milestone. In this work, we explore collective intelligence as an alternative to monolithic scaling, and demonstrate that open-source LLMs' collaboration can surpass Gemini-3-Pro. We first revisit LLM routing and aggregation at scale and identify three key bottlenecks: (1) current train-free routers are limited by a query-based paradigm focusing solely on textual similarity; (2) recent aggregation methods remain largely static, failing to select appropriate aggregators for different tasks;(3) the complementarity of routing and aggregation remains underutilized. To address these problems, we introduce JiSi, a novel framework designed to release the full potential of LLMs' collaboration through three innovations: (1) Query-Response Mixed Routing capturing both semantic information and problem difficulty; (2) Support-Set-based Aggregator Selection jointly evaluating the aggregation and domain capacity of aggregators; (3) Adaptive Routing-Aggregation Switch dynamically leveraging the advantages of routing and aggregation. Comprehensive experiments on nine benchmarks demonstrate that JiSi can surpass Gemini-3-Pro with only 47% costs by orchestrating ten open-source LLMs, while outperforming mainstream baselines. It suggests that collective intelligence represents a novel path towards Artificial General Intelligence (AGI).",
    "authors": [
      "Shengji Tang",
      "Weihao Lin",
      "Jingqi Ye",
      "Hao Li",
      "Bo Zhang",
      "Shuyue Hu",
      "Tao Chen",
      "Wangli Ouyang",
      "Lei Bai",
      "Peng Ye"
    ],
    "url": "http://arxiv.org/abs/2601.01330v1",
    "published": "2026-01-04",
    "primary_category": "cs.AI",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种名为JiSi的新框架，通过改进LLM路由和聚合机制来提升开源大语言模型的协作性能，属于通用人工智能方法学研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01322v1",
    "title": "LinMU: Multimodal Understanding Made Linear",
    "summary": "Modern Vision-Language Models (VLMs) achieve impressive performance but are limited by the quadratic complexity of self-attention, which prevents their deployment on edge devices and makes their understanding of high-resolution images and long-context videos prohibitively expensive. To address this challenge, we introduce LinMU (Linear-complexity Multimodal Understanding), a VLM design that achieves linear complexity without using any quadratic-complexity modules while maintaining the performance of global-attention-based VLMs. LinMU replaces every self-attention layer in the VLM with the M-MATE block: a dual-branch module that combines a bidirectional state-space model for global context (Flex-MA branch) with localized Swin-style window attention (Local-Swin branch) for adjacent correlations. To transform a pre-trained VLM into the LinMU architecture, we propose a three-stage distillation framework that (i) initializes both branches with self-attention weights and trains the Flex-MA branch alone, (ii) unfreezes the Local-Swin branch and fine-tunes it jointly with the Flex-MA branch, and (iii) unfreezes the remaining blocks and fine-tunes them using LoRA adapters, while regressing on hidden states and token-level logits of the frozen VLM teacher. On MMMU, TextVQA, LongVideoBench, Video-MME, and other benchmarks, LinMU matches the performance of teacher models, yet reduces Time-To-First-Token (TTFT) by up to 2.7$\\times$ and improves token throughput by up to 9.0$\\times$ on minute-length videos. Ablations confirm the importance of each distillation stage and the necessity of the two branches of the M-MATE block. The proposed framework demonstrates that state-of-the-art multimodal reasoning can be achieved without quadratic attention, thus opening up avenues for long-context VLMs that can deal with high-resolution images and long videos.",
    "authors": [
      "Hongjie Wang",
      "Niraj K. Jha"
    ],
    "url": "http://arxiv.org/abs/2601.01322v1",
    "published": "2026-01-04",
    "primary_category": "cs.CV",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种线性复杂度的多模态理解模型架构，通过替换自注意力层和蒸馏框架来提升视觉语言模型在边缘设备上的部署效率。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01321v1",
    "title": "Digital Twin AI: Opportunities and Challenges from Large Language Models to World Models",
    "summary": "Digital twins, as precise digital representations of physical systems, have evolved from passive simulation tools into intelligent and autonomous entities through the integration of artificial intelligence technologies. This paper presents a unified four-stage framework that systematically characterizes AI integration across the digital twin lifecycle, spanning modeling, mirroring, intervention, and autonomous management. By synthesizing existing technologies and practices, we distill a unified four-stage framework that systematically characterizes how AI methodologies are embedded across the digital twin lifecycle: (1) modeling the physical twin through physics-based and physics-informed AI approaches, (2) mirroring the physical system into a digital twin with real-time synchronization, (3) intervening in the physical twin through predictive modeling, anomaly detection, and optimization strategies, and (4) achieving autonomous management through large language models, foundation models, and intelligent agents. We analyze the synergy between physics-based modeling and data-driven learning, highlighting the shift from traditional numerical solvers to physics-informed and foundation models for physical systems. Furthermore, we examine how generative AI technologies, including large language models and generative world models, transform digital twins into proactive and self-improving cognitive systems capable of reasoning, communication, and creative scenario generation. Through a cross-domain review spanning eleven application domains, including healthcare, aerospace, smart manufacturing, robotics, and smart cities, we identify common challenges related to scalability, explainability, and trustworthiness, and outline directions for responsible AI-driven digital twin systems.",
    "authors": [
      "Rong Zhou",
      "Dongping Chen",
      "Zihan Jia",
      "Yao Su",
      "Yixin Liu",
      "Yiwen Lu",
      "Dongwei Shi",
      "Yue Huang",
      "Tianyang Xu",
      "Yi Pan",
      "Xinliang Li",
      "Yohannes Abate",
      "Qingyu Chen",
      "Zhengzhong Tu",
      "Yu Yang",
      "Yu Zhang",
      "Qingsong Wen",
      "Gengchen Mai",
      "Sunyang Fu",
      "Jiachen Li",
      "Xuyu Wang",
      "Ziran Wang",
      "Jing Huang",
      "Tianming Liu",
      "Yong Chen",
      "Lichao Sun",
      "Lifang He"
    ],
    "url": "http://arxiv.org/abs/2601.01321v1",
    "published": "2026-01-04",
    "primary_category": "cs.AI",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该论文提出了一个将人工智能技术融入数字孪生生命周期的四阶段统一框架，重点探讨了物理信息模型和生成式AI在跨领域科学应用中的协同作用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01320v1",
    "title": "Adaptive Hierarchical Evaluation of LLMs and SAST tools for CWE Prediction in Python",
    "summary": "Large Language Models have become integral to software development, yet they frequently generate vulnerable code. Existing code vulnerability detection benchmarks employ binary classification, lacking the CWE-level specificity required for actionable feedback in iterative correction systems. We present ALPHA (Adaptive Learning via Penalty in Hierarchical Assessment), the first function-level Python benchmark that evaluates both LLMs and SAST tools using hierarchically aware, CWE-specific penalties. ALPHA distinguishes between over-generalisation, over-specification, and lateral errors, reflecting practical differences in diagnostic utility. Evaluating seven LLMs and two SAST tools, we find LLMs substantially outperform SAST, though SAST demonstrates higher precision when detections occur. Critically, prediction consistency varies dramatically across models (8.26%-81.87% agreement), with significant implications for feedback-driven systems. We further outline a pathway for future work incorporating ALPHA penalties into supervised fine-tuning, which could provide principled hierarchy-aware vulnerability detection pending empirical validation.",
    "authors": [
      "Muntasir Adnan",
      "Carlos C. N. Kuhn"
    ],
    "url": "http://arxiv.org/abs/2601.01320v1",
    "published": "2026-01-04",
    "primary_category": "cs.SE",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于评估大型语言模型和静态应用安全测试工具在Python代码漏洞检测中的性能，属于软件工程与人工智能交叉领域，而非传统自然科学发现或生物医学扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01317v1",
    "title": "Benchmarking Continuous Dynamic Multi-Objective Optimization: Survey and Generalized Test Suite",
    "summary": "Dynamic multi-objective optimization (DMOO) has recently attracted increasing interest from both academic researchers and engineering practitioners, as numerous real-world applications that evolve over time can be naturally formulated as dynamic multi-objective optimization problems (DMOPs). This growing trend necessitates advanced benchmarks for the rigorous evaluation of optimization algorithms under realistic conditions. This paper introduces a comprehensive and principled framework for constructing highly realistic and challenging DMOO benchmarks. The proposed framework features several novel components: a generalized formulation that allows the Pareto-optimal Set (PS) to change on hypersurfaces, a mechanism for creating controlled variable contribution imbalances to generate heterogeneous landscapes, and dynamic rotation matrices for inducing time-varying variable interactions and non-separability. Furthermore, we incorporate a temporal perturbation mechanism to simulate irregular environmental changes and propose a generalized time-linkage mechanism that systematically embeds historical solution quality into future problems, thereby capturing critical real-world phenomena such as error accumulation and time-deception. Extensive experimental results validate the effectiveness of the proposed framework, demonstrating its superiority over conventional benchmarks in terms of realism, complexity, and its capability for discriminating state-of-the-art algorithmic performance. This work establishes a new standard for dynamic multi-objective optimization benchmarking, providing a powerful tool for the development and evaluation of next-generation algorithms capable of addressing the complexities of real-world dynamic systems.",
    "authors": [
      "Chang Shao",
      "Qi Zhao",
      "Nana Pu",
      "Shi Cheng",
      "Jing Jiang",
      "Yuhui Shi"
    ],
    "url": "http://arxiv.org/abs/2601.01317v1",
    "published": "2026-01-04",
    "primary_category": "cs.NE",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了动态多目标优化的通用基准测试框架，属于优化算法评估方法学的研究，而非特定科学领域的AI应用或细胞/分子层面的扰动预测。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01315v1",
    "title": "Quantifying Local Strain Field and Deformation in Active Contraction of Bladder Using a Pretrained Transformer Model: A Speckle-Free Approach",
    "summary": "Accurate quantification of local strain fields during bladder contraction is essential for understanding the biomechanics of bladder micturition, in both health and disease. Conventional digital image correlation (DIC) methods have been successfully applied to various biological tissues; however, this approach requires artificial speckling, which can alter both passive and active properties of the tissue. In this study, we introduce a speckle-free framework for quantifying local strain fields using a state-of-the-art, zero-shot transformer model, CoTracker3. We utilized a custom-designed, portable isotonic biaxial apparatus compatible with multiphoton microscopy (MPM) to demonstrate this approach, successfully tracking natural bladder lumen textures without artificial markers. Benchmark tests validated the method's high pixel accuracy and low strain errors. Our framework effectively captured heterogeneous deformation patterns, despite complex folding and buckling, which conventional DIC often fails to track. Application to in vitro active bladder contractions in four rat specimens (n=4) revealed statistically significant anisotropy (p<0.01), with higher contraction longitudinally compared to circumferentially. Multiphoton microscopy further illustrated and confirmed heterogeneous morphological changes, such as large fold formation during active contraction. This non-invasive approach eliminates speckle-induced artifacts, enabling more physiologically relevant measurements, and has broad applicability for material testing of other biological and engineered systems.",
    "authors": [
      "Alireza Asadbeygi",
      "Anne M. Robertson",
      "Yasutaka Tobe",
      "Masoud Zamani",
      "Sean D. Stocker",
      "Paul Watton",
      "Naoki Yoshimura",
      "Simon C Watkins"
    ],
    "url": "http://arxiv.org/abs/2601.01315v1",
    "published": "2026-01-04",
    "primary_category": "q-bio.TO",
    "is_ai4science": true,
    "is_perturbation": false,
    "reasoning": "该研究利用预训练的Transformer模型CoTracker3实现无散斑的膀胱局部应变场量化，属于AI在生物力学科学发现中的应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01313v1",
    "title": "Spectral-Window Hybrid (SWH)",
    "summary": "Scaling sequence modeling to extreme contexts requires balancing computational efficiency with representational expressivity. While Transformers provide precise retrieval via the attention mechanism, their quadratic $\\mathcal{O}(T^2)$ complexity limits their application to long-horizon tasks. In this work, we propose the \\textbf{Spectral-Window Hybrid (SWH)}, an architecture that decouples sequence modeling into two \\textit{parallel} streams: a global branch utilizing the Convolution Theorem to model long-range decay dynamics in $\\mathcal{O}(T \\log T)$ time, and a local branch employing sliding-window attention for token interactions within a bounded context. By aggregating these representations, SWH avoids the computational bottleneck of global attention while retaining local precision. We demonstrate that SWH matches the perplexity of standard Transformers on short contexts while enabling efficient linear scaling to extended sequences. The code is available at https://github.com/VladimerKhasia/SWH",
    "authors": [
      "Vladimer Khasia"
    ],
    "url": "http://arxiv.org/abs/2601.01313v1",
    "published": "2026-01-04",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种用于高效长序列建模的混合神经网络架构，属于机器学习方法改进，而非特定科学领域的AI应用。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01311v1",
    "title": "Concave Certificates: Geometric Framework for Distributionally Robust Risk and Complexity Analysis",
    "summary": "Distributionally Robust (DR) optimization aims to certify worst-case risk within a Wasserstein uncertainty set. Current certifications typically rely either on global Lipschitz bounds, which are often conservative, or on local gradient information, which provides only a first-order approximation. This paper introduces a novel geometric framework based on the least concave majorants of the growth rate function. Our proposed concave certificate establishes a tight bound of DR risk that remains applicable to non-Lipschitz and non-differentiable losses. We extend this framework to complexity analysis, introducing a deterministic bound that complements standard statistical generalization bound. Furthermore, we utilize this certificate to bound the gap between adversarial and empirical Rademacher complexity, demonstrating that dependencies on input diameter, network width, and depth can be eliminated. For practical application in deep learning, we introduce the adversarial score as a tractable relaxation of the concave certificate that enables efficient and layer-wise analysis of neural networks. We validate our theoretical results in various numerical experiments on classification and regression tasks on real-world data.",
    "authors": [
      "Hong T. M. Chu"
    ],
    "url": "http://arxiv.org/abs/2601.01311v1",
    "published": "2026-01-04",
    "primary_category": "math.OC",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一个基于凹包络的几何框架，用于分布鲁棒优化的风险认证和复杂性分析，属于机器学习理论方法研究。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01310v1",
    "title": "Making MoE based LLM inference resilient with Tarragon",
    "summary": "Mixture-of-Experts (MoE) models are increasingly used to serve LLMs at scale, but failures become common as deployment scale grows. Existing systems exhibit poor failure resilience: even a single worker failure triggers a coarse-grained, service-wide restart, discarding accumulated progress and halting the entire inference pipeline during recovery--an approach clearly ill-suited for latency-sensitive, LLM services.   We present Tarragon, a resilient MoE inference framework that confines the failures impact to individual workers while allowing the rest of the pipeline to continue making forward progress. Tarragon exploits the natural separation between the attention and expert computation in MoE-based transformers, treating attention workers (AWs) and expert workers (EWs) as distinct failure domains. Tarragon introduces a reconfigurable datapath to mask failures by rerouting requests to healthy workers. On top of this datapath, Tarragon implements a self-healing mechanism that relaxes the tightly synchronized execution of existing MoE frameworks. For stateful AWs, Tarragon performs asynchronous, incremental KV cache checkpointing with per-request restoration, and for stateless EWs, it leverages residual GPU memory to deploy shadow experts. These together keep recovery cost and recomputation overhead extremely low. Our evaluation shows that, compared to state-of-the-art MegaScale-Infer, Tarragon reduces failure-induced stalls by 160-213x (from ~64 s down to 0.3-0.4 s) while preserving performance when no failures occur.",
    "authors": [
      "Songyu Zhang",
      "Aaron Tam",
      "Myungjin Lee",
      "Shixiong Qi",
      "K. K. Ramakrishnan"
    ],
    "url": "http://arxiv.org/abs/2601.01310v1",
    "published": "2026-01-04",
    "primary_category": "cs.DC",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文提出了一种名为Tarragon的弹性MoE推理框架，专注于提升大规模语言模型服务在分布式系统中的容错能力和恢复效率，而非应用于科学发现或扰动预测领域。"
  },
  {
    "id": "http://arxiv.org/abs/2601.01306v1",
    "title": "Towards a Principled Muon under $μ\\mathsf{P}$: Ensuring Spectral Conditions throughout Training",
    "summary": "The $μ$-parameterization ($μ$P) provides a principled foundation for large language model (LLM) training by prescribing width-independent learning dynamics, which in turn enables predictable scaling behavior and robust hyperparameter transfer across model sizes. A central requirement of $μ$P is the satisfaction of certain spectral conditions on weight matrices, which ensure consistent feature learning and optimization behavior as model width grows. While these conditions are well understood in theory, guaranteeing their validity in practical training for matrix-based optimizers such as Muon is still under studied. Existing works that study Muon under $μ$P exhibit important limitations: they either do not ensure that the spectral conditions hold throughout the entire training horizon, or require repeated spectral normalization (or Newton-Schulz iterations) applied to both weights and updates, leading to significant computational overhead and reduced practicality. In this work, we show how to reliably guarantee the spectral conditions required by $μ$P for Muon during the entire training process. Our key insight is that for moderately large models, maintaining spectral control at the level of optimizer updates alone is sufficient to preserve $μ$P-compatible scaling, eliminating the need for explicit spectral normalization of the weights. Based on this principle, we develop a variant of Muon, namely Muon++, that satisfies spectral condition throughout the training process. Our results bridge the gap between the theoretical promises of $μ$P and the practical deployment of matrix-based optimizers in long-horizon training. We also take the first step towards an adaptive spectral condition by incorporating data-dependent effects, making it better suited for long-horizon LLM training.",
    "authors": [
      "John Zhao"
    ],
    "url": "http://arxiv.org/abs/2601.01306v1",
    "published": "2026-01-04",
    "primary_category": "cs.LG",
    "is_ai4science": false,
    "is_perturbation": false,
    "reasoning": "该论文专注于改进大型语言模型训练中的优化器算法，确保μ参数化理论在矩阵优化器中的实际应用，属于机器学习优化方法研究。"
  }
]